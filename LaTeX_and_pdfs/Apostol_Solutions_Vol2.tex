%
% Apostol_Solutions_Vol2.tex 
%
\documentclass[twoside]{amsart}
\usepackage{amssymb,latexsym}
\usepackage{times}

%\usepackage{graphics}

\oddsidemargin-0.15cm
\evensidemargin-0.15cm
\topmargin-1.8cm     %I recommend adding these three lines to increase the 
\textwidth17.5cm   %amount of usable space on the page (and save trees)
\textheight24.5cm  
\parindent0.0em

%This next line (when uncommented) allow you to use encapsulated
%postscript files for figures in your document
%\usepackage{epsfig}

%plain makes sure that we have page numbers
\pagestyle{plain}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{axiom}{Axiom}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\title{	Solutions to \emph{ Calculus \textsc{ Volume 2} Multi-Variable Calculus and Linear Algebra, with Applications to Differential Equations and Probability } by Tom Apostol }

\author{
  Ernest Yeung - Praha 10, \v Cesk\`a Republika 
       }
%\date{Winter 2006}

%This defines a new command \questionhead which takes one argument and
%prints out Question #. with some space.
\newcommand{\questionhead}[1]
  {\bigskip\bigskip
   \noindent{\small\bf Question #1.}
   \bigskip}

\newcommand{\problemhead}[1]
  {\bigskip\bigskip
   \noindent{\small\bf Problem #1.}
   \medskip}

\newcommand{\exercisehead}[1]
  {
   \noindent{\small\bf Exercise #1.}
   \smallskip}

\newcommand{\solutionhead}[1]
  {\medskip\bigskip
   \noindent{\small\bf Solution #1.}
   \medskip}


%-----------------------------------
\begin{document}
%-----------------------------------

\maketitle

\section*{ 1.5 Exercises - Introduction, The definition of a linear space, Examples of linear spaces, Elementary consequences of the axioms }

Recall the following:
\begin{definition}[Linear Space.] \quad \\
  Let $V$ be a nonempty set of objects.  \\
  Linear space if a set $V$ that satisfies the following ten axioms. 
  \begin{enumerate}
  \item (closure under addition) $\forall x,y \in V, x+y \in V$  
  \item (closure under scalar multiplication) $\forall x \in V, \alpha x \in V$  
  \item (Additive commutativity) $\forall x, y \in V, x+y = y+x$ 
  \item (Additive Associativity) $\forall x,y \in V, (x+y) + z = x + (y+z)$  
  \item (Additive Identity Existence) $\exists 0 \in V$ such that 
\[
x+ 0 = x, \forall x \in V
\]
\item (Additive Inverse Existence) $\exists (-1) x $ such that 
\[
x + (-1)x = 0 
\]
\item (Scalar Associativity) $\forall x \in V, \forall \alpha, \beta \in \mathbb{R} \text{ or } \alpha, \beta \in \mathbb{C}$
\[
(\alpha \beta)x = \alpha (\beta x)
\]
\item (distributivity for addition in $V$) $\forall x, y \in V; \forall a \in \mathbb{R}$ or $\forall a \in \mathbb{C}$, 
\[
a(x+y) = ax + ay
\]
\item (distributivity for addition of numbers) $\forall x \in V, \forall a, b \in \mathbb{R}$ or $\forall a,b \in \mathbb{C}$,
\[
(a+b)x = ax+bx
\]
\item (Multiplicative identity existence) $\forall x \in V, 1 x =x$
  \end{enumerate}
\end{definition}

\exercisehead{1}
Consider $x = \frac{p}{q}, y = \frac{r}{s} \in V$ where $p,q,r,s$ are polynomials.  $ps+rq, qs$ are polynomials as well.  
\[
\begin{gathered}
x+y = \frac{p}{q} + \frac{r}{s} = \frac{ ps + rq}{qs} \in V  \\
\alpha \in \mathcal{R}, \quad \alpha p \text{ is a polynomial } \\
\alpha x = \frac{ \alpha p }{q} \in V \\
x+ y = \frac{ ps + rq}{qs} = \frac{rq +ps}{qs} = r+ p \\
(x +y ) + z = \left( \frac{p}{q} + \frac{r}{s} \right) + \frac{t}{v} = \frac{p}{q} + \left( \frac{r}{s} + \frac{t}{v} \right) = x + (y+z)  \\
x + 0 = \frac{p}{q} + \frac{0}{q} = \frac{p}{q} = x \text{ so } \frac{0}{q} \in V \text{ if } q \neq 0 \\
x + (-1)x = \frac{p}{q} + (-1) \frac{p}{q} = \frac{0}{q} = 0 \\
(\alpha \beta)x = \frac{ (\alpha \beta )p}{q} = \frac{ \alpha (\beta p) }{q} = \alpha (\beta x ) \, \text{ (follows from associativity of real or complex numbers) } \\
\alpha( x+ y) = \alpha x + \alpha y \text{ and } (\alpha + \beta)x = \alpha x + \beta x \text{ follows from distributivity for real numbers } \\
\text{ Consider } x = \frac{p}{q} = \left( \frac{q}{q} \right) \frac{p}{q} = (1)x, \, \frac{q}{q} \in V
\end{gathered}
\]

\exercisehead{3} All $f$ with $f(0) = f(1)$ \medskip \\
$f(0) + g(0) = (f+g)(0) = f(1) + g(1) = (f+g)(1)$ \smallskip \\
$af(0) = (af)(0) = af(1) = (af)(1)$ \smallskip \\
$f(x) + g(x) = (f+g)(x) = g(x) + f(x) = (g+f)(x)$ \smallskip \\
$(f(x) +g(x))+h(x) = ((f+g)+h)(x) = f(x) + (g(x) +h(x)) = (f+ (g+h))(x)$ \smallskip \\
$0(x) = 0$  \quad $(f+0)(x) = f(x) + 0(x) = f(x)$ \smallskip \\
$(-1)f(x) = (-f)(x)$ \quad \quad \quad $(f+(-1)f)(x) = (f-f)(x) = f(x) + (-1)f(x) = 0 = 0(x)$  \smallskip \\
$(\alpha \beta)f(x) = \alpha (\beta f(x)) = \alpha (\beta f)(x)$ \smallskip \\
$a(f+g)(x) = a(f(x) + g(x)) = af(x) + ag(x) = (af+ag)(x)$ \smallskip \\
$(a+b)f(x) = af(x) + bf(x) = (af)(x) + (bf)(x) = (af+bf)(x)$ \smallskip \\
$(1f)(x) = f(x)$

\exercisehead{4} All $f$ with $2f(0) = f(1)$ \medskip \\
$2(f+g)(0) = 2f(0) + 2g(0) = f(1) + g(1) = (f+g)(1)$ \smallskip \\
$2(\alpha f)(0) = 2\alpha f(0) = \alpha f(1) =(\alpha f)(1)$ \\
$f+g = g+f, (f+g) + h = f + (g+h)$ follow from properties of the reals.  \\
$20(0) = 0 = 0(1)$; \quad $(f+0)(x) = f(x) + 0 =f(x)$ \\
$(f+(-f))(x) = f(x) + -f(x) = 0 $ \\
$(\alpha \beta) f(x) = \alpha (\beta f(x) )$ \\
$a(f+g)(x) = (af)(x) + (ag)(x), (a+b)f(x) = af(x) + bf(x)$ follow from properties of the reals.  \\
$1x = x$

\exercisehead{5} All $f$ with $f(1) = 1 + f(0)$
\[
f(1) +g(1) = (f+g)(1) = 1+f(0) + 1 + g(0) = 2 + (f+g)(0)
\]
So closure under addition is violated.  

\exercisehead{6} All step functions defined on $[0,1]$.

\exercisehead{8} Even functions, $f(-x) = f(x)$.  
\[
\begin{gathered}  
  (f+g)(-x) = f(-x) + g(-x) = f(x) + g(x) \\
  (\alpha f)(-x) = \alpha f(-x) = \alpha f(x) = (\alpha f)(x) \\
  (f+g)(x) = f(x) + g(x) = g(x) + f(x) = (g+f)(x) \, \text{ (follows from commutativity of real numbers) } \\
  \begin{aligned}
     ((f+g)+h)(-x) & = (f+g)(-x) +h(-x) = f(x) + g(x) + h(x) = f(x)+ (g+h)(x) = (f+(g+h))(x) \\
    & \quad \text{ (follows from associativity of real numbers) } 
  \end{aligned} \\
  \text{ if } 0(-x) = 0(x) = 0 \, \forall x \in D \text{ so $0$ exists and } (f+0)(x) = f(x) + 0(x) = f(x)  \\
  (-f)(-x) = -f(-x) = -f(x) \text{ so }  (f+-f)(x) = f(x) - f(x) = 0(x) \\
  \alpha (\beta f)(-x) = \alpha (\beta(f(-x))) = \alpha (\beta f(x) ) = \alpha(\beta f)(x)  \\
  ((\alpha \beta) f)(-x) = (\alpha \beta) f(-x) = (\alpha \beta)f(x) = ((\alpha \beta)f)(x) \, \text{ (from associativity of the real numbers) }  \\
  \alpha (f+g)(x) = \alpha (f(x)+g(x)) = (\alpha f)(x) + (\alpha g)(x) = (\alpha f + \alpha g)(x) \\
  (\alpha + \beta)f(x) = \alpha f(x) + \beta f(x) = (\alpha f)(x) + (\beta f)(x) = (\alpha f +\beta f)(x) \\
  1 f(x) = 1 (f(x)) = f(x)
\end{gathered}
\]

\exercisehead{22} All vectors $(x,y,z)$ in $V_3$ with $z=0$.  \smallskip \\
This space is closed under addition and scalar multiplication since 
\[
\begin{gathered}
  (x_1,y_1,0) + (x_2,y_2,0) = (x_1+x_2, y_1+y_2,0) \\
  k(x,y,0) = (kx,ky,0)
\end{gathered}
\]
both belong to this space.  \\

Additive commutativity, additive associativity, scalar associativity, distributivity in addition in $V$, and distributivity in addition of numbers are satisfied automatically, since all vectors in this subset belong to $V_3$, a linear space.  

$(0,0,0)$ belongs to this space, since $z=0$, so existence of an additive identity is fulfilled. \\

$(-x,-y,0) = -(x,y,0)$ belongs in this space and so the existence of an additive inverse for each element $(x,y,0)$ in this space is fulfilled.  \\

$1(x,y,0) = (x,y,0)$, and so multiplicative identity existence is fulfilled.  \\
This is a linear space.  Note that we could've also said that this space is exactly $V_2$, and $V_2$ is a linear space. 

\exercisehead{23} All vectors $(x,y,z)$ in $V_3$ with $x=0$ or $y=0$.  \smallskip \\
Consider $(0,y_1,z_1) + (x_2,0,z_2) = (x_2, y_1,z_1+z_2)$.  This vector does not belong to this space.  This is not a linear space.  

\exercisehead{24} All vectors $(x,y,z)$ in $V_3$ with $y=5x$.  \smallskip \\
This space is closed under addition and scalar multiplication since 
\[
\begin{gathered}
  (x_1,5x_1,0) + (x_2,5x_2,0) = (x_1+x_2,5x_1+5x_2,0) \Longrightarrow 5x_1 + 5x_2 = 5(x_1+x_2) \\
  k(x_1,5x_1,z_1) \Longrightarrow k 5x_1 = 5(kx_1)
\end{gathered}
\]

Additive commutativity, additive associativity, scalar associativity, distributivity in addition in $V$, and distributivity in addition of numbers are satisfied automatically, since all vectors in this subset belong to $V_3$, a linear space.  \\

$(0,5(0),0)$ belongs to this space, so existence of an additive identity is fulfilled. \\

$(-x,5(-x),-z) = -(x,5x,z)$ belongs in this space and so the existence of an additive inverse for each element in this space is fulfilled.  \\

$1(x,5x,z) = (x,5x,z)$, and so multiplicative identity existence is fulfilled.  \\
This is a linear space.  

\exercisehead{25} All vectors $(x,y,z)$ in $V_3$ with $3x + 4y = 1 \, z=0$.  \smallskip \\
Consider closure: 
\[
\begin{gathered}
(x_1,y_1,0) + (x_2,y_2,0) = (x_1+x_2, y_1+y_2,0) \\
  z_3 = 0; \quad 3(x_1+x_2) + 4(y_1+y_2) = 2
\end{gathered}
\]
Closure under addition is not satisfied.  Thus, this is not a linear space.  

\exercisehead{26} All vectors $(x,y,z)$ in $V_3$ which are scalar multiples of $(1,2,3)$.    \smallskip \\
Closure is fulfilled since $x+y= a(1,2,3) +b(1,2,3) = (a+b)(1,2,3)$, which is a scalar multiple of $(1,2,3)$, and $ax = ab(1,2,3)$, which is another scalar multiple of $(1,2,3)$.  \\

Additive commutativity, additive associativity, scalar associativity, distributivity in addition in $V$, and distributivity in addition of numbers are satisfied automatically, since all vectors in this subset belong to $V_3$, a linear space.  \\

$\exists \, 0$ since $0(1,2,3) = 0$ is a scalar multiple of $(1,2,3)$.  \\

$\exists \, -1x \, \forall \, x$, since $(-1)a(1,2,3)$ is a scalar multiple of $(1,2,3)$.  \\

$1(a(1,2,3)) = (a(1,2,3))$ is a scalar multiple of $(1,2,3)$ and so multiplicative identity existence is satisfied.   \\
This is a linear space.  


\exercisehead{28} All vectors in $V_n$ that are linear combinations of $2$ given vectors $A$ and $B$.   \medskip \\
$a_1 A + b_1 B + a_2 A + b_2 B = (a_1 + a_2)A + (b_1 + b_2)B$ belongs in this space.  \smallskip \\
$c(aA+ bB) = (ca)A + (cb)B$ belongs in this space. \smallskip \\
$x+y = y+x, \, (x+y) + z = x +(y+z)$ follow since the vectors belong in $V_n$, a linear space.  \smallskip \\
$0A + 0B =0$; \quad $a_1 A + b_1 B + 0A + 0B = a_1 A + b_1 B$ \smallskip \\
$-a_1 A + -b_1 B$ belongs in this space and $a_1 A + b_1 B + -a_1 A + -b_1 B = (a_1 - a_1)A + (b_1 - b_1)B = 0$ \smallskip \\
$(ab)x = a(bx), \, a(x+y) = ax + ay, \, (a+b)x = ax + bx, \, 1x = x$ follow since the vectors in this space belong in $V_n$, a linear space.  

\exercisehead{29} Let $V = \mathbb{R}^+$, let $x ``+''y = xy$ and $a ``\cdot'' x = x^a$ \medskip \\
$x ``+'' y = xy \in \mathbb{R}^+$ \smallskip \\
$a ``\cdot'' x = x^a = e^{a\ln{x}} > 0$ \quad $a ``\cdot'' x \in \mathbb{R}^+$ \smallskip \\
$x ``+'' y = xy = yx = y ``+''x$ \smallskip \\
$(x ``+'' y) ``+'' z = xyz = x(yz) = x ``+'' (y ``+'' z)$ \smallskip \\
$x ``+'' ``0'' = x1 = x$ so $''0'' = 1 \in \mathbb{R}^+$ \smallskip \\
$''(-1)x'' = \frac{1}{x} \in \mathbb{R}^+$ \quad \, $x ``+'' ``(-1)x'' = x \frac{1}{x} = 1 = ``0''$ \smallskip \\
$(ab)x = x^{ab} = (x^b)^a = a(bx)$ \smallskip \\
$a ``\cdot'' (x ``+'' y) = a ``\cdot'' (xy) = (xy)^a = x^a y^a = (a ``\cdot x) ``+'' (a ``\cdot'' y)$ \smallskip \\
$(a+b) ``\cdot'' x = x^{a+b} = x^a x^b = x^a ``+'' x^b = a ``\cdot'' x ``+'' b ``\cdot'' x$ \smallskip \\
$1 ``\cdot'' x = x^1 = x$

This is indeed a linear space.  

\exercisehead{30}
\begin{enumerate}
  \item From Axiom 5,6, the Additive Identity Existence and Additive Inverse Existence, that $\exists \, 0 \in V$ s.t. $x+0=x, \, \forall \, x \in V$ and $\exists \, (-1)x$ s.t. $x + (-1)x = 0$, then, using associativity, commutativity, and distributivity for addition of numbers, 
\[
x + 0 = x = x + (x +(-1)x) = 2x + (-1)x = (2 +(-1))x = 1x
\]
  \item If Ax.6 is replaced by Ax.6', $\forall \, x \in V, \quad \exists \, y \in V$ s.t. $x+y=0$, 
\[
x+0 = x = x + (x+y) = 2x + y = x
\]
So Ax.10 does not hold since $2x +y =x$.  
\end{enumerate}

\exercisehead{31}
\begin{enumerate}
  \item $(x_1,x_2) + (y_1,y_2) = (x_1 + y_1, x_2 + y_2) \quad \quad \quad a(x_1,x_2) = (ax_1,0)$.  \\
Not a linear space: violates Additive Inverse existence, which demands $\exists \, (-1)x$ s.t. $x+(-1)x =0$, not $\exists \, y$ s.t. $x+y=0$, so that for $(-1)x = (-x_1,0)$, $(x_1,x_2) + (-1)x = (0,x_2) \neq 0$ and Multiplicative identity existence, since $1x = (x_1,0) \neq x$.  \medskip 
  \item $(x,1,x_2) + (y_1,y_2) = (x_1+y_1,0)$ \quad \quad \quad $a(x_1,x_2) = (ax_1, ax_2)$\\
Not a linear space: violates distributivity in addition of numbers, because \\
$(a+b)x = ((a+b)x_1,(a+b)x_2)$ but $ax + bx = (ax_1 + bx_1,0)$ \medskip 
  \item $(x,1,x_2) + (y_1,y_2) = (x_1,x_2+y_2)$ \quad \quad \quad $a(x_1,x_2) = (ax_1, ax_2)$ \\
Not a linear space because it violates Additive Commutativity of elements.
$(x_1,x_2) + (y_1, y_2) = (x_1, x_2+y_2)$ but \\
$(y_1,y_2) + (x_1,x_2) = (y_1,x_2 +y_2)$  \medskip 
  \item $(x,1,x_2) + (y_1,y_2) = (|x_1+y_1|,|y_1+y_2|)$ \quad \quad \quad $a(x_1,x_2) = (|ax_1|, |ax_2|)$ \\
Not a linear linear space because it violates Distributivity for addition of numbers: 
\[
\begin{gathered}
  (a+b)(x_1,x_2) = (|(a+b)x_1|, |(a+b)x_2|) \\
  ax+bx = (|ax_1|,|ax_2|) + (|bx_1|,|bx_2|) \\
\text{ but } |(a+b)x_1 |\leq |ax_1| + |bx_1| \text{ in general }
\end{gathered}
\]
\end{enumerate}

\exercisehead{32} Theorem 1.3. 
\begin{enumerate}
\item $0x = 0$ 
\item $a0=0$ 
\item $(-a)x = -(ax) = a(-x)$
\item If $ax=0$, then either $a=0$ or $x=0$ 
\item If $ax = ay$ and $a\neq 0$, then $x=y$
\item If $ax = bx$ and $x\neq 0$, then $a=b$
\item $-(x+y) = (-x) + (-y) = -x-y$ 
\item $x+x=2x,x+x+x=3x, \sum_{j=1}^n x = nx$
\end{enumerate} \quad \smallskip

Part (d), or part 4, is proven by considering this: \\
If $ax =0$, \\
\quad then if $a=0$ and $x=0$, done.  \\
If $a\neq 0$, 
\quad $ax + a0 = a(x+0) =0$ \\
since $a$ is a real number, $\exists \frac{1}{a} \in \mathbb{R}$ s.t. $\left(\frac{1}{a} \right) a = 1$ 
\[
\Longrightarrow 1(x+0) = x+0 = x = \frac{1}{a} 0 =0
\]
If $x\neq 0$, suppose $a\neq 0$.  
\[
\frac{1}{a} ax = 1x = x = \frac{1}{a} 0 = 0 
\]
But $0$ is unique.  Contradiction.  So $a=0$ and that's okay, since by part (a) or part (1) of Thm. 1.3., $0x =0$.  \\

For part (e), or part 5, if $ax=ay, \, a\neq 0$, then subtract $ay$ from both sides to get $ax - ay =0 = a(x-y) =0$.  Use distributivity to get $ax-ay = a(x-y) = 0$.  Since $a\neq 0$, then from part (d) or part 4, $x-y=0$ must be true.  Then $-y = -x$ or, multiplying both sides by $-1$, $y=x$.   \\

For part (f), or part 6, if $ax=ay$, subtract $bx$ from both sides and use distributivity to get $ax-bx = (a-b)x = 0$.  Since $x \neq 0$, then by part (d), or part 4, $a-b=0$.  Add $b$ to both sides to get $a=b$.   \\

For part (g), or part 7, note that from the existence of an additive inverse, $x + -x =0$.  Consider $x + (-1)x =0$.  $x=1x$ by the existence of a multiplicative identity, and so using distributivity, $1x + (-1)x = (1+-1)x = 0x =0$.  Then $(-1)x$ is also an additive inverse for all $x \in V$.  But additive inverses are unique, by theorem, so $(-1)x = -x$.  Using that and distributivity, we get $(-x)+(-y) = (-1)x + (-1)y = (-1)(x+y) = -(x+y)$.  $-x-y = -(x+y)$ because \\
$x+y + -(x+y) = 0 = x - x + y -y = x +y -x -y $, where we used additive commutativity at the last step.  Then subtract $x+y$ from both sides to get $-x-y = -(x+y)$.   \\

For part (h), or part 8, use the existence of a multiplicative identity and distributivity to get $x+x = 1x +1x = (1+1)x = 2x$.  \\
Now, we'll use induction.  Assume the $n$th case, that $\sum_{j=1}^n x = nx$.  \\
Consider $\sum_{j=1}^{n+1}x$.  $\sum_{j=1}^{n+1}x = \sum_{j=1}^n x + x = nx+x = nx+1x = (n+1)x$.  Done.  

\section*{ 1.10 Exercises - Subspaces of a linear space, Dependent and independent sets in a linear space, Bases and dimension, Components }

\exercisehead{1} $x=0$
\[
\begin{gathered}
  (0,y_1,z_1) + (0,y_2,z_2) = (0,y_1 + y_2, z_1 + z_2) \in S \\
  k(0,y,z) = (0,ky,kz) \in S
\end{gathered}
\]
Yes, $S$ is a subspace.  
\[
\begin{gathered}
  (0,y,z) = y(0,1,0) + z(0,0,1) \in S \\
  0 = y(0,1,0) + z(0,0,1) \quad \Longrightarrow z = 0 \, \quad y = 0 
\end{gathered}
\]
$\boxed{ dim{S} = 2 }$

\exercisehead{2} $x+y = 0$ 
\[
\begin{gathered}
\begin{gathered}
  (x_1 + x_2,y_1 + y_2, z_1 + z_2) \in S \text{ since } \\
  x_1 + x_2 + y_1 + y_2 = 0 + 0 = 0 
\end{gathered} \quad \quad \quad \quad 
\begin{gathered}
  k(x,y,z) \in S \text{ since } \\
  kx + k y = k(x+y) = 0 
\end{gathered}
\end{gathered}
\]
Yes, $S$ is a subspace. 
\[
\begin{gathered}
  (x,y,z) = (x,-x,z) = x(1,-1,0) + z(0,0,1) \\
  0 = x(1,-1,0) + z(0,0,1) \Longrightarrow z =0, \, x =0 
\end{gathered}
\]
$\boxed{ dim{S} = 2 }$

\exercisehead{3} $x+y+z =0$ 
\[
\begin{gathered}
  \begin{gathered}
    (x_1 + x_2, y_1 + y_2,z_1 + z_2) \in S \text{ since } \\
    x_1 + x_2 + y_1 + y_2 + z_1 + z_2 = 0 + 0 =0 
    \end{gathered} \quad \quad \quad \quad 
  \begin{gathered}
    k(x,y,z) \in S \text{ since } \\
    k(x+y+z) = kx+ky+kz = 0
  \end{gathered}
\end{gathered}
\]
Yes, $S$ is a subspace.  
\[
\begin{gathered}
  (x,y,-(x+y)) = x(1,0,-1) + y(0,1,-1) \\
  0 = x(1,0,-1) + y(0,1,-1) \Longrightarrow x = 0, \, y = 0
\end{gathered}
\]
$\boxed{ dim{S} = 2 }$

\exercisehead{4} $x=y$ 
\[
\begin{gathered}
  \begin{gathered}
    (x_1 + x_2, y_1 + y_2,z_1 + z_2) \in S \text{ since } \\
    x_1 + x_2 =y+1 + y+2 
    \end{gathered} \quad \quad \quad \quad 
  \begin{gathered}
    k(x,y,z) \in S \text{ since } \\
    kx = ky 
  \end{gathered}
\end{gathered}
\]
Yes, $S$ is a subspace.  
\[
\begin{gathered}
  (x,y,z) = (x,x,z) = x(1,1,0) + z(0,0,1) \\
  0 = x(1,1,0) + z(0,0,1) \Longrightarrow x = 0, \, z = 0
\end{gathered}
\]
$\boxed{ dim{S} = 2 }$

\exercisehead{5} $x=y=z$
\[
\begin{gathered}
  \begin{gathered}
    (x_1 + x_2, y_1 + y_2,z_1 + z_2) \in S \text{ since } \\
    x_1 + x_2 =y+1 + y+2 =z_1 + z_2 
    \end{gathered} \quad \quad \quad \quad 
  \begin{gathered}
    k(x,y,z) \in S \text{ since } \\
    kx = ky = kz 
  \end{gathered}
\end{gathered}
\]
Yes, $S$ is a subspace.  
\[
\begin{gathered}
  (x,y,z) = x(1,1,1) \\
  0 = x(1,1,1)  \Longrightarrow x = 0, 
\end{gathered}
\]
$\boxed{ dim{S} = 1 }$

\exercisehead{6} $x=y$ or $x=z$ \medskip \\
If $x_1 + y_1$ \\
\quad If $x_2 = y_2$, $x_1 + x_2 = y_1 + y_2$ \\
\quad \quad else if $x_2 = z_2$, $\begin{aligned}
  & x_1 + x_2 \text{ may not equal } y_1 + y_2 \\ 
  & x_1 + x_2 \text{ may not equal } z_1 + z_2 
\end{aligned}$
No, $S$ is not a subspace.  

\exercisehead{7} $x^2 -y^2 = 0$
\[
(x_1 + x_2)^2 - (y_1^2 + y_2^2) = 2x_1 x_2 - 2y_1 y_2 \text{ maybe not equal to zero } 
\]
$S$ not a subspace.  

\exercisehead{8} $x+y=1$
\[
\begin{gathered}
  (x_1 + x_2, y_1 + y_2,z_1 + z_2 ) \notin S \text{ since } \\
  x_1 + x_2 + y_1 + y_2 = 2 
\end{gathered}
\]
No $S$ is not a subspace.  

\exercisehead{9} $y=2x$ and $z=3x$
 \[
\begin{gathered}
  \begin{gathered}
    (x_1 + x_2, y_1 + y_2 , z_1 + z_2) \in S \text{ since } \\
    y_1 + y_2 = 2x_1 + 2x_2 = 2(x_1 + x_2) \\
    z_1 + z_2 = 3x_1 + 3x_2 = 3(x_1+  x_2 ) 
  \end{gathered} \quad \quad \quad \quad 
  \begin{gathered}
  (kx,ky,kz) \in S \text{ since }  \\
  ky = k 2x = 2kx \\
  kz = k3x = 3kx 
\end{gathered}
\end{gathered}
\]
$S$ is a subspace.  
\[
\begin{gathered}
  (x,y,z) = x(1,2,3) \\
  0 = x(1,2,3) \Longrightarrow x = 0
\end{gathered}
\]
$\boxed{ dim{S} = 1 }$ 

\exercisehead{10} 
\[
\begin{aligned}
  x+y+z & = 0 \\
  x-y-z & = 0 
\end{aligned} \Longleftrightarrow 
\begin{aligned}
  x &= 0 \\
y & = -z
\end{aligned}
\]
\[
\begin{gathered}
  (x_1+x_2, y_1 + y_2,z_1 + z_2) \in S \text{ since } \\
  x_1 + x_2 = 0 \\
  y_1 + y_2 = -z_1 -z_2 = -(z_1 + z_2) \\
  k(x,y,z) \in S \text{ since } \\
  kx = 0 \quad \quad ky = -kz
\end{gathered} \quad \quad \quad \quad 
\begin{gathered}
  y(0,1,-1) = (x,y,z) \\
  0 = y(0,1,-1) \Longrightarrow y = 0 
\end{gathered}
\]
Yes $S$ is a subspace and $\boxed{ dim{S} = 1 }$ \medskip \\

For Exercises 11-20, in the $P_n$ space, we will use the $\{ u_k \}$ basis extensively, where $u_k = t^k$ \quad $k = 0,1,\dots, n$.  It could be shown that this forms a basis, specifically it forms an independent set, by differentiating a degree $n$ polynomial and set it to $0$, and then repeating the differentiation.    \\
\exercisehead{11}$f(0)=0$
\[
\begin{gathered}
  \begin{gathered}
  f+g = \sum_{j=1}^n a_j x^j  + \sum_{j=1}^n b_j x^j = \sum_{j=1}^n (a_j + b_j)x^j \in S \text{ since } \\
  (f+g)(0)= 0
\end{gathered} \quad \quad \quad 
  \begin{gathered}
    kf = \sum_{j=1}^n ka_k x^k \in S \text{ since } \\
    kf(0) = 0 
  \end{gathered}
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
  f = \sum_{j=1}^n a_j x^j \\
  0 = \sum_{j=1}^n a_j x^j  \Longrightarrow a_j = 0  
\end{gathered}
\]
$\boxed{ dim{S} = n }$

\exercisehead{12} $f'(0) = 0$ 
\[
\begin{gathered}
  (f+g)' = f' + g' \Longrightarrow (f+g)'(0) = f'(0) + g'(0) = 0 \\
  (kf)' = kf' \Longrightarrow kf'(0) = 0 
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
  \begin{aligned}  
    f & = \sum_{j=0}^n a_j x^j  \\
    f' & = \sum_{j=1}^n j a_j x^{j-1} 
  \end{aligned} 
  \quad \quad \quad f'(0) = 0 \Longrightarrow a_1 = 0 \\
  \begin{gathered}
  f= a_0 + \sum_{j=2}^n a_j x^j  \\
  0 = a_0 + \sum_{j=2}^n a_j x^j \Longrightarrow a_j = 0, \quad j = 0, 2, 3,\dots n
\end{gathered}
\end{gathered}
\]
$\boxed{ dim{S} = n }$
Note that for the last step, we could've sited the fact that a subset of an independent set, such as the $\{ t^k \}$ basis for $P_n$, is an independent set, by definition, and so if that subset spans $S$, this subset will be a basis for $S$.  

\exercisehead{13} $f''(0) = 0$ 
\[
\begin{gathered}
  (f+g)'' = f'' + g'' \Longrightarrow (f+g)''(0) = f''(0) + g''(0) = 0 \\
  (kf)'' = kf'' \Longrightarrow kf''(0) = 0 
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
  f'' = \sum_{j=2}^n j (j-1) a_j x^{j-2} \quad \, \Longrightarrow f= a_0 + a_1 x + \sum_{j=3}^n a_j x^j \\
  f''(0) = a_2 = 0 
\end{gathered}
\]
Then $f$ is a linear combination of $\{ 1,x,x^3, x^4, \dots, x^n \}$, $dim{S} = n$

\exercisehead{14} $f(0) + f'(0) = 0$
\[
\begin{gathered}
  f+g + f' +g' = (f+g) + (f+g)' \Longrightarrow (f+g)(0) + (f+g)'(0) = 0 + 0 = 0 \\
  kf + (kf)' = k(f+f') \Longrightarrow k f(0) + (kf)'(0) = k(f(0) + f'(0)) = 0 
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
  f+ f' = \sum_{j=0}^n a_j x^j + \sum_{j=1}^n j a_j x^{j-1} \\
  (f+f')(0) = a_0 + a_1 = 0 \Longrightarrow a_0 = -a_1 
\end{gathered} \quad \quad \quad 
f = a_0 (1-x) + \sum_{j=2}^n a_j x^j 
\]
If $f=0$, $a_j = 0$ for $j=2,3,\dots n$, by taking $j=2,3,\dots n$ derivatives.  $a_0 = 0$ for $f(0) = 0$.  Thus $\{ 1-x,x^2, x^3, \dots, x^n \}$ is independent and span $S$ and thus form a basis.  \\
$\boxed{ dim{S} = n }$

\exercisehead{15} $f(0) = f(1)$ 
\[
\begin{gathered}
  (f+g)(0) = f(0) + g(0) + f(1) +g(1) = (f+g)(1) \\
  kf(0)  = kf(1) 
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
  f = \sum_{j=0}^n a_j x^j \\
  f(0) = a_0 = f(1) = a_0 + \sum_{j=1}^n a_j \\
  \Longrightarrow \sum_{j=1}^n a_j =0 \text{ or } a_1 = -\sum_{j=2}^n a_j \\
  \Longrightarrow f = a_0 + \sum_{j=2}^n a_j (x^j - x) 
\end{gathered} \quad \quad \quad \begin{gathered}
  \text{ By differentiating } \\
  f' = (a_0)' + a_2 (2x-1) + a_3(3x^2 - 1) \dots \\
  f'' = a_2 (2) + a_3 x \\
  f'' = \sum_{j=2}^n a_j (jx^{j-2}) = 0 \text{ if } f = 0 
\end{gathered}
\]
Then $\{ x^{j-2} \}$ is a subset of a basis for $P_n$.  \\
$a_j = 0$ for $j=2,\dots n$.  \\
\quad \, Then $a_0 =0 $.  \\
\quad Thus, $\{ 1, x^j - x \}$ is independent and spans $S$.  Then $\{ 1, x^j -x \}$ forms a basis for $S$.  \\
$\boxed{ dim{S} = n }$

\exercisehead{16} $f(0) = f(2)$
\[
\begin{gathered}
  f(0) + g(0) = (f+g)(0) = f(2) + g(2) = (f+g)(2) \\
  kf(0) = kf(2) 
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
\begin{gathered}
  f = \sum_{j=0}^n a_j x^j \\
  f(0) = a_0 = a_0 + \sum_{j=1}^n a_j 2^j \Longrightarrow 2a_1 + \sum_{j=2}^n 2^j a_j = 0 \text{ or } a_1 = -\sum_{j=2}^n 2^{j-1}a_j \\
  \Longrightarrow f = a_0 + \sum_{j=2}^n a_j (x^j - 2^{j-1}x )
\end{gathered} \\
\begin{gathered}
  f'' = \sum_{j=2}^n a_j j(j-1)x^{j-2} \text{ and } f'' = 0 \text{ if } f = 0 
\end{gathered}
\end{gathered}
\]
$\mathcal{B}_{S_1} = \{ 1, x, \dots, x^{n-2} \}$ is a subset of the basis $\{ 1, x, \dots, x^n \} = \mathcal{B}_{P_n}$ for $P_n$.  Then $\mathcal{B}_{S_1}$ is independent, and so $a_j = 0$ for $j=2,\dots n$.  Then for $f=0$, $a_0 = 0$.  Thus $\{ 1, x^2-2x, x^3 - 2^2x,\dots, x^j - 2^{j-1}x, \dots, x^n - 2^{n-1} x \}$ is independent and spans $S$ and thus forms a basis for $S$.  \\
$\boxed{ dim{S} = n }$

\exercisehead{17} $f$ is even.  $f(-x) = f(x)$
\[
\begin{gathered}
  (f+g)(-x) = f(-x) + g(-x) = f(x) + g(x) = (f+g)(x) \\
  kf(-x) = kf(x)
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
f(-x) = \sum_{j=0}^n a_j x^j (-1)^j = f(x) = \sum_{j=0}^n a_j x^j  \Longrightarrow \sum_{j=0}^n a_j x^j ((-1)^j - 1) =0 
\end{gathered}
\]
$\frac{n}{2} + 1$ if $n$ is even, is the number of possibly nonzero coefficients for $f$.  \\
$\frac{n-1}{2} + 1 = \frac{n+1}{2}$ if $n$ is odd, is the number of possibly nonzero coefficients for $f$.  \medskip \\
Then $\frac{n}{2}$ or $\frac{n-1}{2}$, if $n$ is even, or $n$ is odd, respectively, are the number of needed elements for a subset from the basis $\mathcal{B}_{P_n}$ to span $f$ and form a basis for $S$.

\exercisehead{18} $f$ is odd.  $f(-x) = f(x)$
\[
\begin{gathered}
  (f+g)(-x) = f(-x) + g(-x) = -f(x) - g(x) = -(f+g)(x) \\
  kf(-x) = -kf(x)
\end{gathered}
\]
Yes $S$ is a subspace.  
\[
\begin{gathered}
f(-x) = \sum_{j=0}^n a_j x^j (-1)^j = -f(x) = -\sum_{j=0}^n a_j x^j  \Longrightarrow \sum_{j=0}^n a_j x^j ((-1)^j + 1) =0 
\end{gathered}
\]
$\frac{n}{2}$ if $n=2K$ is even, is the number of possibly nonzero coefficients for $f$.  \\
$\frac{n+1}{2}  = \frac{n+1}{2}$ if $n=2K-1$ is odd, is the number of possibly nonzero coefficients for $f$.  \medskip \\
Then $\frac{n}{2}$ or $\frac{n+1}{2}$, if $n$ is even, or $n$ is odd, respectively, are the number of needed elements for a subset from the basis $\mathcal{B}_{P_n}$ to span $f$ and form a basis for $S$.

\exercisehead{19}   $f$ has degree $\leq k$, where $k < n$ or $f=0$
\[
\begin{gathered}
  f = \sum_{j=0}^k a_j x^j; \quad \quad \, g = \sum_{j=0}^k b_j x^j \\
  f+g = \sum_{j=0}^k (a_j +b_j) x^j \text{ even if } a_j + b_j = 0 \text{ for any or all } j, \, f+g \text{ has degree } \leq k \text{ or } f = 0 \\
\sum_{j=0}^k c_0 a_j x^j \in S 
\end{gathered}
\]
$f$ is spanned by $\mathcal{B}_S = \{ x^j \}, \, j = 0, 1, \dots , k$ which is a subset of $\mathcal{B}_{P_n}$, which is a basis for $P^n$.  Then $\mathcal{B}_S$ is independent.  \\
\quad Then $\mathcal{B}_S$ is a basis for $S$.  \\
$dim{S} = k+1$

\exercisehead{20} Consider 
\[
\begin{gathered}
  f  +g = \left( \sum_{j=0}^{k-1} a_j x^j + a_k x^k  \right) + \left( \sum_{j=0}^{k-1} b_j x^j + -a_k x^k \right) = \sum_{j=0}^{k-1} (a_j + b_j)x^j \text{ with } a_{k-1} + b_{k-1} \neq 0 \\
  f+g \notin S
\end{gathered}
\]
Thus $S$ is not a subspace.  

\exercisehead{21} 
\begin{enumerate}
\item $\{ 1 ,t^2, t^4 \}$ \\
$f = a_0 + a_2 t^2 + a_4 t^4$, \quad $\boxed{dim{S} = 3}$
\item $\{ t, t^3, t^5 \}$ \\
  $f = a_1 t + a_3 t^3 + a^5 t^5$, \quad $\boxed{ dim{S} = 3}$
\item $\{ t,t^2 \}$ \\
  $f = a_1 t + a_2 t^2$, $\boxed{ dim{S} = 2 }$
\item $\{ 1 + t, (1+t)^2 \}$ 
\[
a_1 (1+t) + a_2 (1+t)^2 = a_1 (1+t) + a_2 (1+2t + t^2) = (a_1 + a_2) + (a_1 + 2a_2)t + a_2 t^2
\]
If $a_1(1+t) + a_2(1+t)^2 = 0$, $a_2 = 0$, $a_1 = 0$ so $(1+t), (1+t)^2$ is independent, $\boxed{ dim{S} = 2 }$
\end{enumerate}

\exercisehead{22} In this exercise, $L(S)$ denotes the subspace spanned by a subset $S$ of a linear space $V$.  
\begin{enumerate}
\item $x \in S$, \quad \, $1x \in L(S) \Longrightarrow S \subseteq L(S)$
\item If $S = \{ x_1, \dots, x_n \}$ \\
  \quad $x = \sum a_j x_j  \in L(S)$ \medskip \\
  $S \subseteq T \Longrightarrow x_j \in T$ \\ 
  $T$ is a subspace of $V$ \,  $\Longrightarrow \sum a_j x_j \in T$ ($T$ is closed under addition and scalar multiplication).  so $x \in T$ \\
  $\boxed{ L(S) \subseteq T }$
\item If $S$ is a subspace of $V$, $S$ is closed under addition and scalar multiplication.  \smallskip \\
  \quad \, Repeatedly apply addition and scalar multiplication closure for each $x_j \in S$ and $\forall \, a_j \in \mathbb{R}$, so that $\sum a_j x_j \in S$, \quad $\forall \, a_j \in \mathbb{R}$, $\forall \, x_j \in S$.  \medskip \\
  $\Longrightarrow L(S) \subseteq S$ \medskip \\

$S \subseteq L(S)$ (as proven in part(a), or part (1), of this exercise).  \medskip \\
$L(S) = S$ if $S$ is a subspace of $V$.   \\

If $L(S) = S$, \, $\forall \, \sum a_j x_j \in S$, the $S$ is closed under addition and scalar multiplication.  Then $S$ is a subspace of $V$, by theorem.  
\item Suppose $S = \{ x_1, x_2, \dots, x_m \}$ \\
  Then since $S \subseteq T$, \, $T = \{ x_1, x_2, \dots, x_m, \dots x_n \}$ 
\[
\sum_{j=1}^m a_j x_j = \sum_{j=1}^n a_j x_J \in L(T) \text{ with } a_j = 0 \text{ for } j = m+1, m+2, \dots, n \Longrightarrow L(S) \subseteq L(T)
\]
\item If $x_1, x_2 \in S \bigcap T$, then $\begin{aligned}
  & x_1 \in S \bigcap x_2 \in S \\
  & x_1 \in T \bigcap x_2 \in T
\end{aligned}$.  Since $S,T$ are subspaces, $x_1 + x_2, cx_1 \in S \bigcap x_1 + x_2, cx_1 \in T$ \\
  Then $x_1 + x_2, c x_1 \in S \bigcap T$.  So $S \bigcap T$ is a subspace. 
\item Consider $x \in L(S \bigcap T)$.  \\
  $x = \sum a_j x_j$; where $x_j \in S \bigcap T$ \\
  Since $\forall \, x_j \in S$, then $x \in L(S)$.  Since $\forall \, x_j \in T$, then $x\in L(T)$.  \\
\quad Thus $x\in L(S) \bigcap L(T)$.  \quad $\Longrightarrow L(S\bigcap T) \subseteq L(S) \bigcap L(T)$
\item Example of when $L(S\bigcap T) \neq L(S) \bigcap L(T)$. \\
Suppose $S = \{ x_1, x_2 \}$, \, $T = \{ x_3 \}$ and $x_1 + x_2 = x_3$.  \\
$S \bigcap T = \emptyset$.  $L(S \bigcap T) = \emptyset$, but $L(S) \bigcap L(T) = \{ kx_3 | k \in \mathbb{R} \} = L(T)$
\end{enumerate}

\exercisehead{23}
\begin{enumerate}
\item $\{ 1, e^{ax}, e^{bx} \}$, \, $a \neq b$ 
\[
\begin{gathered}
a_0 + a_1 e^{ax} + a_2 e^{bx} =0 \xrightarrow{ \frac{d}{dx} } a_1 a e^{ax} + a_2 be^{bx} = 0  \text{ or } a_1 a = -a_2 b e^{(b-a)x}
\end{gathered}
\]
Since $x$ arbitrary, $a_1 = a_2 = 0$.  \\
$\Longrightarrow \{ 1, e^{ax}, e^{bx} \}$ independent.  $\boxed{ dim{S} = 3 }$
\item $\{ e^{ax}, xe^{ax} \}$
\[
a_1 e^{ax} + a_2 xe^{ax} = 0 \text{ or } a_1 = -a_2 x
\]
$x$ arbitrary, so $a_1 = a_2 = 0$.  $\{ e^{ax}, xe^{ax} \}$ independent.  $\boxed{ dim{S} = 2 }$
\item $\{ 1, e^{ax}, xe^{ax} \}$
\[
\begin{gathered}
  a_0 + a_1 e^{ax} + a_2 xe^{ax} = 0 \xrightarrow{ \frac{d}{dx} } aa_1 e^{ax} + a_2 e^{ax} + a_2 a x e^{ax} = 0 \\
  aa_1 + a_2 + a_2 ax = 0 \text{ or } a_2 ax = -(aa_1 + a_2) \\
  x \text{ arbitrary, so } a_2 = 0, \, a_1 =0 
\end{gathered}
\]
Then $a_0 =0$ and so $\{ 1, e^{ax}, x e^{ax} \}$ independent.  $\boxed{ dim{S} = 3}$
\item $\{ e^{ax}, xe^{ax}, x^2 e^{ax} \}$.  
\[
a_0 e^{ax} + a_1 xe^{ax} + a_2 x^2 e^{ax} = 0 = a_0 + a_1 x + a_2 x^2
\]
$1,x,x^2$ are a subset of independent $\mathcal{B}_{P_n}$ and so $1,x,x^2$ are independent $\Longrightarrow a_0 = a_1 = a_2 =0$, and so $\{ e^{ax}, xe^{ax}, x^2 e^{ax} \}$ independent.  $\boxed{ dim{S} = 3}$.  
\item $\{ e^x, e^{-x}, \cosh{x} \}$ \\
  $\cosh{x} = \frac{e^x + e^{-x} }{ 2}$ dependent.  $\boxed{ dim{S} = 2}$
\item $\{ \cos{x}, \sin{x} \}$ 
\[
a\cos{x} + b\sin{x} =0 \text{ or } b\sin{x} = -a \cos{x}
\]
If $\cos{x} = 0$, then $\sin{x} = 1$, so $b=0$.  Otherwise, \\
$b\tan{x} = -a$.  But $x$ arbitrary $\Longrightarrow a=0, \, b =0$ 

So $\{ \cos{x}, \sin{x} \}$ independent.  $\boxed{ dim{S} = 2}$
\item $a \cos^2{x} + b\sin^2{x} = 0$, so then if $\cos^2{x} \neq 0$, we have $b\tan^2{x} = -a$.  Since $x$ is arbitrary, $a=b=0$.  Then $\{ \cos^2{x}, \sin^2{x} \}$ independent.  $\boxed{ dim{S} = 2}$
\item $\{ 1, \cos{2x}, \sin^2{x} \}$ 
\[
\cos{2x} = 1 - 2\sin^2{x}
\]
So the set is dependent.  $\boxed{ dim{S} = 2}$, since $\{ 1, \sin^2{x} \}$ independent ($\{ \cos^2{x}, \sin^2{x} \}$ were independent and $1= \cos^2{x} + \sin^2{x}$).  
\item $\{ \sin{x}, \sin{2x} \}$
\[
a\sin{x} + b \sin{2x} = \sin{x} (a+b2\cos{x}) =0 
\]
If $\sin{x}, \cos{x} \neq 0$, $a+b2\cos{x} =0$ or $2b\cos{x} = -a$.  Since $x$ is arbitrary, $a=b=0$  So then $\{ \sin{x},\sin{2x} \}$ is independent.  $\boxed{ dim{S} =2}$
\item $\{ e^x \cos{x}, e^{-x} \sin{x} \}$
\[
ae^x \cos{x} + be^{-x} \sin{x} = 0 \text{ or } b \tan{x} = -a e^{2x}
\]
Since $x$ arbitrary, $a=b=0$.  $\boxed{ dim{S} =2} $
\end{enumerate}

\exercisehead{24}
\begin{enumerate}
\item Consider $\mathcal{B}_S$, basis for $S$ and $\mathcal{B}_V$ basis for $V$.  $|\mathcal{B}_V| = n$ finite.  \\
  If $S$ is infinite-dimensional, then $\exists \, x_{n+1} \in \mathcal{B}_S$ s.t. $x_{n+1} \notin \mathcal{B}_V$ since $\mathcal{B}_V$ finite.  Then $\exists \, x_{n+1} \in S$ s.t. $x_{n+1} \notin V$.  But $S \subseteq V$ \\
  $\Longrightarrow S$ is finite-dimensional.  \\

Consider $\mathcal{B}_S = \{ x_1,\dots, x_m \}$ and $\mathcal{B}_V = \{ y_1,\dots, y_n \}$.  \\
\quad $\forall \, x_j$, $x_j \in V$, since $S \subseteq V$.  \smallskip \\
Suppose $m > n$.  Then $\mathcal{B}_S$ linearly dependent, by Thm. 12.10 of Vol.1 (a.k.a. Thm. 1.7 of Vol. 2).  This contradicts the fact that $\mathcal{B}_S$ is an independent basis.  $\Longrightarrow dim{S} \leq dim{V}$
\item If $S=V$, then by Thm. 12.10 of Vol.1, $\mathcal{B}_S$ must also contain exactly $n$ vectors, since it's a basis for $V=S$.  \\

If $dim{S} = dim{V}$, then since $\mathcal{B}_S$ is a set of $n$ linearly independent elements, it forms a basis for $V$. \\  Then $\forall\, y \in V$, $y \in L(\mathcal{B}_S)=S$.  \\
\quad $V \subseteq S$  $\Longrightarrow V = S$.  
\item Use Thm. 12.10 of Vol.1 (a.k.a. Thm. 1.7 of Vol.2): Any set of linear independent elements is a subset of some basis for $V$.  
\item Consider $\mathcal{B}_V = \{ y_1, \dots, y_n \}$ \\
  Suppose $\{ y_1 + y_2, y_1 - y_2 \} = \mathcal{B}_S$ \medskip \\
  $y_1 + y_2, y_1 - y_2 \notin \mathcal{B}_V$ because if they were, they'd make $\mathcal{B}_V$ dependent.  
\end{enumerate}

\section*{ 2.4 Exercises - Linear Transformations and Matrices, Null space and range, Nullity and rank }

\exercisehead{1} $T(x,y)= (y,x)$
\[
T(a(x_1,x_2) +b(y_1,y_2)) = T(ax_1 + by_1, ax_2 + by_2) = (ax_2 + by_2, ax_1+by_1) = a(x_2,x_1) + b(y_2,y_1) = aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is linear.  

$T(x,y) = (y,x) =0$.  $nullspace{T} = \{ 0 \}$; \quad $ker{T} = 0$ \\
$T(x,y) = (y,x) = y(1,0) + x(0,1)$.  $range{T} = V_2$.  $rank{T} =2$

\exercisehead{2} $T(x,y) = (x,-y)$
\[
T(a(x_1,x_2) +b(y_1,y_2)) = (ax_1 + by_1, -(ax_2 + by_2)) = a(x_1,-x_2) + b(y_1,-y_2) = aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is linear.  

$(x,-y) =0$.  $nullspace{T} = \{ 0 \}$; \quad $ker{T} = 0$ \\
$(x,-y) = x(1,0) + -y(0,1)$   $range{T} = V_2$; \quad $rank{T} = 2$

\exercisehead{3} $T(x,y) = (x,0)$.
\[
T(a(x_1,x_2)+b(y_1,y_2)) = (ax_1+by_1,0) = a(x_1,0) + b(y_1,0) = aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is linear.  

$T(x,y) = (x,0) = 0$ $\Longrightarrow x=0$, \quad $y \in \mathbb{R}$.  $nullspace{T} = L(\{ (0,1) \})$ \quad $ker{T}=1$ \\
$T(x,y) = (x,0) = x(1,0)$  \quad $range{T} = L(\{ (1,0) \})$.  $rank{T} =1$ 

\exercisehead{4} $T(x,y) = (x,x)$ 
\[
T(a(x_1,x_2)+b(y_1,y_2)) = (ax_1+by_1,ax_1 + by_1) = a(x_1,x_1) + b(y_1,y_1) = aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is linear.  

$T(x,y) = (x,x) = 0$ $\Longrightarrow x=0$, \quad $y \in \mathbb{R}$.  $nullspace{T} = L(\{ (0,1) \})$ \quad $ker{T}=1$ \\
$T(x,y) = (x,x) = x(1,1)$  \quad $range{T} = L(\{ (1,1) \})$.  $rank{T} =1$ 

\exercisehead{5} $T(x,y) = (x^2,y^2)$
\[
\begin{gathered}
T(a(x_1,x_2)+b(y_1,y_2)) = ((ax_1+by_1)^2,(ax_2 +by_2)^2) = \\
= (a^2 x_1^2,a^2 x_2^2) +(2abx_1 y_1,2abx_2 y_2) +(b^2 y_1^2,b^2 y_2^2) \neq aT(x_1,x_2) + bT(y_1,y_2)
\end{gathered}
\]
$T$ is not linear.  

\exercisehead{6} $T(x,y) = (e^x,e^y)$  
\[
T(a(x_1,x_2) +b(y_1,y_2)) = (e^{ax_1 + by_1}, e^{ax_2 +by_2}) \neq aT(x_1,x_2) + bT(y_1,y_2) 
\]
$T$ is not linear.  

\exercisehead{7} $T(x,y) = (x,1)$
\[
T(a(x_1,x_2) + b(y_1,y_2) ) = (ax_1 + by_1,1) \neq a(x_1,1) + b(y_1,1) = aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is not linear.  

\exercisehead{8} $T(x,y) = (x+1,y+1)$
\[
T(a(x_1,x_2) + b(y_1,y_2)) = (ax_1 + by_1 + 1, ax_2 + by_2,1) \neq aT(x_1,x_2) + bT(y_1,y_2)
\]
$T$ is not linear.  

\exercisehead{9} $T(x,y) = (x-y,x+y)$
\[
\begin{gathered}
T(a(x_1,x_2)+b(y_1,y_2)) = (ax_1+by_1-ax_2 - by_2,ax_1 + by_1 +ax_2 + by_2) =  \\
= a(x_1-x_2,x_1+x_2) + b(y_1-y_2,y_1+y_2) = aT(x_1,x_2) + bT(y_1,y_2)
\end{gathered}
\]
$T$ is linear.  

$T(x,y) = (x-y,x+y) = 0$ $\Longrightarrow x=y=0$, \quad  $nullspace{T} = \{ 0 \}$ \quad $ker{T}=1$ \\
$T(x,y) = (x-y,x+y) = x(1,1)+y(-1,1)$  \quad $range{T} = L(\{ (1,1),(-1,1) \})$.  $rank{T} =2$ 

\exercisehead{10} $T(x,y) = (2x-y,x+y)$
\[
\begin{gathered}
T(a(x_1,x_2)+b(y_1,y_2)) = (2(ax_1 + by_1) - (ax_2 + by_2), ax_1+by_1 + ax_2 +by_2) = \\
 = a(2x_1-x_2,x_1+x_2) + b(2y_1-y_2,y_1+y_2) = aT(x_1,x_2) + bT(y_1,y_2)
\end{gathered}
\]
$T$ is linear.  

$(2x-y,x+y) = 0$ \quad $nullspace{T} = \{ 0 \}$.  \quad $ker{T} =0$ \\
$x(2,1) + y(-1,1) = (2x-y,x+y)$ \quad $range{T} = L( \{ (2,1), (-1,1) \} )$.  $rank{T} = 2$

\exercisehead{11} $T$ rotates every point through the same angle $\phi$ about the origin.  That is, $T$ maps a point with polar coordinates $(r,\theta)$ onto the point with polar coordinates $(r,\theta + \phi)$, where $\phi$ is fixed.  Also, $T$ maps $0$ onto itself.  

Amazingly, $T$ \textbf{ is linear }.  What's required to show this is persistence.  

\[
\begin{gathered}
  \begin{aligned}
    x & = (r_1 \cos{\theta_1}, r_1 \sin{\theta_1} ) \\
    y & = (r_1,\sin{\theta_2}, r_2 \sin{\theta_2})  
\end{aligned} \\
  ax+by = (ar_1 \cos{\theta_1} + br_2 \cos{\theta_2}, ar_1 \sin{\theta_1} + br_2 \sin{\theta_2} ) \\
  \begin{aligned}
  |ax+by|^2 & = (ar_1c_1 + br_2 c_2)^2 + (ar_1s_1 + br_2s_2)^2 = \\
  & = a^2 r_1^2 c_1^2 + 2abr_1r_2 c_1c_2 + b^2 r_2^2 c_2^2 + a^2 r_1^2 s_1^2 + 2abr_1 s_1r_2 s_2 + b^2 r_2^2 s_2^2 = \\
  & = a^2 r_1^2 + b^2 r_2^2 + 2abr_1 r_2 c(\theta_1-\theta_2)
  \end{aligned} \\
  \text{ argument of } ax + by = \arctan{ \left( \frac{ar_1 s\theta_1 + br_2 s\theta_2}{ ar_1 c\theta_1 + br_2 c\theta_2} \right) }
\end{gathered}
\]
So $|T(ax+by)| = |ax+by|$, but the argument of $T(ax+by) = \arctan{ \left( \frac{ar_1 s\theta_1 + br_2 s\theta_2}{ ar_1 c\theta_1 + br_2 c\theta_2} \right) } + \phi$.  

Consider now $aT(x) + bT(y) = a(r_1,\theta_1+\phi) + b(r_2,\theta_2+\phi)$.
\begin{multline*}
  \sqrt{ (ar_1 c(\theta_1 + \phi) + br_2 c(\theta_2 + \phi))^2 + (ar_1 s(\theta_1+ \phi) + br_2 s(\theta_2 + \phi))^2 } = \\
  = \sqrt{ (ar_1)^2 + (br_2)^2 + 2abr_1r_2(c(\theta_1 + \phi)c(\theta_2 + \phi) + s(\theta_1 + \phi)s(\theta_2+\phi) ) } = \sqrt{ (ar_1)^2 + (br_2)^2 + 2abr_1r_2c(\theta_1 - \theta_2) }
\end{multline*}
The length is the same for $T(ax+by)$ and $aT(x) + bT(y)$. 

The argument of $aT(x) + bT(y)$ is the following: 
\begin{multline*}
  \frac{ar_1 (s\theta_1 c\phi + c\theta_1 s\phi) + br_2 (s\theta_2 c\phi + c\theta_2 s\phi) }{ ar_1 (c\theta_1 c\phi -s(\theta_1) s\phi) + br_2 (c\theta_2 c\phi - s\theta_2 s\phi) } = \frac{ar_1 (s\theta_1 + c\theta_1 \tan{\phi}) + br_2 (s\theta_2 + c\theta_2 \tan{\phi} )}{ ar_1 (c\theta_1 - s(\theta_1) \tan{\phi}) + br_2 (c\theta_2 - s\theta_2 \tan{\phi} ) } = \\
  = \frac{ ar_1 s\theta_1 + br_2 s\theta_2 + ar_1 c\theta_1 \tan{\phi} + br_2 c\theta_2 \tan{\phi} }{ ar_1 c\theta_1 + br_2 c\theta_1 - ar_1 s\theta_1 \tan{\phi} - br_2 s\theta_2 \tan{\phi} }
\end{multline*}

Beforehand, recall this trigonometric identity:
\[
\tan{(x+y)} = \frac{ \sin{(x+y)} }{\cos{ (x+y)} } = \frac{ \sin{x} \cos{y} + \sin{y} \cos{x} }{ \cos{x} \cos{y} - \sin{x} \sin{y} } = \frac{ \tan{x} + \tan{y} }{ 1 - \tan{x} \tan{y} }
\]

Thus 
\begin{multline*}
  \tan{ \left( \arctan{ \left( \frac{ar_1 s\theta_1 + br_2 s\theta_2}{ ar_1 c\theta_1 + br_2 c\theta_2} \right) } + \phi \right) } = \frac{ \frac{ ar_1 s\theta_1 + br_2 s\theta_2}{ ar_1 c\theta_1 + br_2 c\theta_2 } + \tan{\phi_1} }{ 1 - \left( \frac{ ar_1 s\theta_1 + br_2 s\theta_2}{ ar_1 c\theta_1 + br_2 c\theta_2 } \right) \tan{\phi} } = \\
  = \frac{ ar_1 s\theta_1 + br_2 s\theta_2 + ar_1 c\theta_1 \tan{\phi} + br_2 c\theta_2 \tan{\phi} }{ ar_1 c\theta_1 + br_2 c\theta_1 - ar_1 s\theta_1 \tan{\phi} - br_2 s\theta_2 \tan{\phi}} 
\end{multline*}
So the arguments for $T(ax+by)$ and $aT(x)+bT(y)$ are, amazingly, the same, modulo some $2\pi$ periodicity.    

Thus, \emph{rotations are linear transformations.}  

$nullspace{T} = \{ 0 \}$.  $null{T} =0$ \\
$range{T} = \{ (r,\theta) \}$.  $rank{T} = 2$

\exercisehead{12} $T$ maps each point onto its reflection with respect to a fixed line through the origin.  \\
We showed above that rotations are linear transformations.  Then without loss of generality, consider reflection about the $x$-axis.  
\[
\begin{gathered}
  T(a(x_1,x_2) + b(y_1,y_2)) = (ax_1 + by_1,-ax_2 -by_2) = a(x_1,-x_2) + b(y_1,-y_2) \\
  aT(x_1,x_2) + bT(y_1,y_2) = a(x_1,-x_2) + b(y_1,y-2)
\end{gathered}
\]
So reflection about the $x$ axis is linear.  \\
Suppose $R$ is the rotation of the fixed line into the $x$-axis and $R$ is length preserving.  Then for $R^{-1}TR$, reflection about any fixed axis, ($R^{-1}$ is linear too, since it's just a rotation in the opposite direction of $R$)
\[
R^{-1}TR(ax+by) = R^{-1}T(aRx+bRy) = R^{-1}(aTRx+bTRy) = aR^{-1}TRx + bR^{-1}TRy
\]
$T$ is linear. 

$null{T} = 0$  \quad $nullspace{T} =\{ 0 \}$ \\
$rank{T} =2$ \quad $range{T} = \{ (x,y) \}$

\exercisehead{13} $T$ maps every point onto the point $(1,1)$.  \\
$T(ax+by) = (1,1) \neq aT(x) + bT(y) = (a+b)(1,1)$ \\
$T$ is nonlinear.  

\exercisehead{14} $T(r,\theta) = (2r, \theta)$ \\
\[
\begin{gathered}
T(x_1)+T(x_2) = 2 r_1 e^{i \theta_1} + 2 r_2 e^{i \theta_2} = 2 (r_1 e^{i \theta} + r_2 e^{i \theta_2} ) \\
T(x_1+y_1) = T(r_1 e^{i \theta_1} + r_2 e^{i \theta_2} ) \text{ so } \\
|r_1 e^{i \theta_1} + r_2 e^{i \theta_2} | = \sqrt{ r_1^2 +r_2^2 + 2 r_1 r_2 \cos{(\theta_1 - \theta_2)} } = |T(x_1)+T(x_2)| \\
\text{ we see that the argument remains unchanged, while the magnitude is multiplied by $2$ in each case } \\
\begin{aligned}
  & null T = 0 \quad & nullspace T = \{ 0 \} \\
  & rank T = 2 \quad & range T = \{ (r,\theta) \} 
\end{aligned}
\end{gathered}
\]

\exercisehead{15} $T (a(r,\theta) ) = (ar, 2 \theta) = a(r,2 \theta) = a T(r,\theta) $.  \\
Consider this counterexample, where $x_1 = 1 \vec{e}_x, x_2 = 1 \vec{e}_x $.  Not linear.  

\exercisehead{16} $T(x,y,z) = (z,y,x)$.  
\[
\begin{gathered}
  T(ax) = aT(x), T(x_1+ x_2, y_1+y_2, z_1 +z_2) = (z_1,y_1,x_1) + (z_2, y_2,x_2) \Longrightarrow \text{ linear } \\ 
  T(x) = 0 \text{ when } x = 0 \\
  \begin{aligned}
    & nullspace T = \{ 0 \} \quad & range T = V_3  \\
    & null T = 0 & rank T = 3
  \end{aligned}
\end{gathered}
\]

\exercisehead{17} $T(x,y,z) = (x,y,0) $.  
\[
\begin{gathered}
\begin{aligned}
  T(a(x,y,z)) & = a(x,y,0) = aT(x,y,z); T(x_1+x_2, y_1 +y_2, z_1 +z_2 ) = \\ 
  & = (x_1 +x_2, y_1+y_2, 0) = T(x_1,y_1,z_1) = T(x_2,y_2,z_2) 
\end{aligned} \\ 
\Longrightarrow \text{ $T$ linear } \\
  T(x,y,z) = 0 \text{ if } x = y = 0 \\
\begin{aligned}
  & nullspace T = L(\{ (0,0,1) \}) \quad & null T = 1  \\
  & range T = L(\{ (1,0,0),(0,1,0) \}) & rank T = 2 
\end{aligned}
\end{gathered}
\]

\exercisehead{18} $T(x,y,z) = (x,2y,3z)$.  
\[
\begin{gathered}
  T(ax) = (ax, 2ay, 3az) = aT(x); T(x_1+x_2) = (x_1+ x_2, 2(y_1 +y_2), 3(z_1 +z_2)) = T(x_1)+T(x_2) \\
  T(x) = 0 \text{ when } x = y= z = 0 \\ 
  \begin{aligned}
&    nullspace T = \{ 0 \}  \quad & null T = 0 \\
    & range T = V_3 \quad & rank T = 3 
  \end{aligned}
\end{gathered}
\]

\exercisehead{19} $T(x,y,z) = (x,y,1)$.  \\
$T(x_1) + T(x_2)  = (x_1+x_2, y_1+y_2, 2) \neq T(x_1+x_2)$ 
$T$ is not linear.  

\exercisehead{20} $T(x,y,z) = (x+1,y+1,z-1)$
\[
\begin{gathered}
  T(ax+by) = (ax_1+by_1+1, ax_2 + by_2 +1, ax_3 + by_3 - 1) \neq aT(x)  +bT(y) = \\
  = a(x_1+1,x_2+1, x_3-1) + b(y_1 +1,y_2 + 1, y_3-1)
\end{gathered}
\]

\exercisehead{21} $T(x,y,z) = (x+1,y+2,z+3)$
\[
T(ax+by) = (ax_1+by_1+1,ax_2+by_2 +2,ax_3+by_3+3) \neq aT(x) + bT(y) = a(x_1+1,x_2+2,x_3+3) + b(y_1+1,y_2+2,y_3+3)
\]

\exercisehead{22} $T(x,y,z) = (x,y^2,z^3)$
\[
\begin{gathered}
  T(ax+by) = (ax_1+by_1,(ax_2+by_2)^2,(ax_3+by_3)^3) = (ax_1+by_1,a^2 x_2^2 + 2abx_2y_2 + b^2y_2^2, a^2x_3^2+2abx_3y_3+b^2y_3^2) \neq \\
  \neq aT(x) + bT(y)  = a(x_1,x_2^2,x_3^2) + b(y_1,y_2^2,y_3^2) 
\end{gathered}
\]

\exercisehead{23} $T(x,y,z) = (x+z,0,x+y)$
\[
T(ax+by) = (ax_1+by_1+ax_3 +by_3,0,ax_1+by_1+ax_2+by_2) = a(x_1+x_3,0,x_1+x_2) + b(y_1+y_3,0,y_1+y_2) = aT(x) + bT(y)
\]
$T$ is linear.  

$(x+z,0,x+y) =0$ \quad \, $\begin{aligned}
  x & = -z \\
  x & = -y
\end{aligned}$ \quad $(x,y,z) = x(1,-1,-1) \Longrightarrow nullspace{T} = L(\{ (1,-1,-1) \})$ \quad $ker{T} =1$ \\
$(x+z,0,x+y) = (x+z)(1,0,0) + (x+y)(0,0,1)$ \quad $range{T} = L(\{ (1,0,0),(0,0,1) \})$, \quad $rank{T} =2$

\exercisehead{24} \quad \\ $\begin{aligned}
  p(x) & = \sum_{j=0}^n a_j x^j \\
  q(x) & = \sum_{j=0}^n b_j x^j 
\end{aligned}$ \quad \quad $\begin{gathered}
  (p+q)(x) = \sum_{j=0}^n (a_j +b_j)x^j \\
  cp(x) = c\sum_{j=0}^n a_j x^j = \sum_{j=0}^n ca_j x^j
\end{gathered}$ \quad \quad \\ 
$\begin{gathered}
  T(p+q) = \sum_{j=0}^n (a_j +b_j)(x+1)^j = \sum_{j=0}^n a_j (x+1)^j + \sum_{j=0}^n b_j(x+1)^j = T(p) + T(q) \\
  T(cp) = \sum_{j=0}^n ca_j (x+1)^j = c \sum_{j=0}^n a_j(x+1)^j = cT(p)
\end{gathered}$\\
$T$ linear.  

Consider $\sum_{j=0}^n a_j (x+1)^j =0$.  Apply differentiation repeatedly to get $a_j =0, \, \forall \, j=0,\dots,n$.  \\ $nullspace{T} = \{ 0 \}$.  \quad $null{T} =0$.  \\
$\sum_{j=0}^n a_j(x+1)^j = \sum_{j=0}^n b_j x^j $.  $range{T} = L(\{(x+1)^j| j=0,\dots, n \})$;  \quad $rank{T} = n+1$

\exercisehead{25} On $(-1,1)$, $f \in V; \quad g = T(f)$, $g(x) = xf'(x)$ 
\[
\begin{gathered}
  T(f+g) = x(f'+g') = xf' + xg' = T(f) + T(g) \\
  T(af) = x(af)' = axf' = aT(f) 
\end{gathered}
\]
$T(f) = xf'(x) = 0$  $x$ is arbitrary, consider $x\neq 0$.  $f'(x) =0 \Longrightarrow f(x) = c_0$.   \\
$nullspace{T} = \{ 1 \}$, \quad $null{T} = 1$ \\
$range{T} = V$ \quad $rank{T} = dim{V} -1 \to \infty$

\exercisehead{26} $g(x) = \int_a^b f(t) \sin{ (x-t)} dt$ for $a\leq x \leq b$ 
\[
\begin{gathered}
  T(f+g) = \int_a^b (f(t)+g(t)) \sin{(x-t)} dt = \int_a^b f(t) \sin{(x-t)} dt + \int_a^b g(t) \sin{(x-t)} dt \\
  T(cf) = \int_a^b cf(t) \sin{(x-t)} dt 
\end{gathered}
\]
$T$ is linear.  

\[
\begin{gathered}
  g(x) = \int_a^b f(t) (s(x) c(t) - c(x) s(t))dt = s(x) \int_a^b f(t) c(t) dt - c(x) \int_a^b f(t) s(t) dt = k_1s(x) + k_2c(x)  \\
  Range{T} = L(\{ \sin{x},\cos{x} \}); \quad \, rank{T} = 2
\end{gathered}
\]
For the nullspace, now $g(x) = s(x) \int_a^b f(t) c(t) dt - c(x) \int_a^b f(t) s(t) dt$.  If we take a look at \textbf{ Exercise 29} of this section, then we see the \textbf{answer: by the orthogonality of $\sin$'s and $\cos$'s}, $\sin{nt}$ and $\cos{nt}$ will be orthogonal to $\cos{t}$ and $\sin{t}$ for $n =2,\dots$.  So depending upon $a$ and $b$, at least the integration over a period of $1$ will result in zero for both $\int f c$ and $\int f s$.  Then for the ``ends'' of the integration bound that don't make a full period, make $f(t) =0$.  Since $n=2,\dots \to \infty$ for $\sin{nt}$, $\cos{nt}$ for the choice of $f(t)$, \\
$nullspace{T} = L(\{ \sin{nt},\cos{nt}| n =2,\dots \})$, \quad \, $ker{T} = \infty$

\exercisehead{27} $T(y) = y'' + Py' + Qy$, $P,Q$ fixed constants.  \\
\begin{align*} 
 T(a y_1 + b y_2) & = a y_1'' + by_2 '' + P(ay_1' + by_2') + Q(ay_1 + by_2 ) = \\
 & a(y_1''+ Py_1' +Qy_1 ) + b(y_2''+Py_2' + Qy_2 ) = aT(y_1) +bT(y_2) \\ \\
 & \text{ $T$ is linear } \\
 & \begin{aligned}
   & nullspace T = L(\{ x,1 \}) \quad & null{T} = 2 \\
   & range T = V \quad & rank T = \infty 
\end{aligned}
\end{align*}

\exercisehead{28} If $x=x_k$ is a convergent sequence with limit $a$, by definition, 
\[
\forall n \in \mathbb{N}, \exists m = m(n) \in \mathbb{N} \text{ such that } |a -x_k| < \frac{1}{n} \, \forall k \geq m 
\]
\[
\begin{gathered}
  T(x) = y_k; cT(x) = cy_k = c(a- x_k) = ca - cx_k \\ 
  \text{ ($cx_k$ understood to mean that each $x_k$ term in the sequence is multiplied by $c$) } \\
  \begin{aligned}
    &\text{ Consider } |cx_k - ca | = |c| |x_k -a | < \frac{ |c| }{ n} \text{ for } k \geq m \\
    & \text{ Consider } \frac{n}{ |c|} = n_1.  \exists m_1 = m_1(n_1) \text{ such that } |cx_k - ca| < \frac{1}{n_1} 
  \end{aligned} \\
  \text{ Thus $cx_k$ is convergent with limit $ca$ and so $T(cx) = cT(x)$. }
\end{gathered}
\]
\[
\begin{gathered}
\text{ Consider two convergent sequences $x_k$ and $y_k$ with limits $a$ and $b$ respectively.  Then by definition, } \\
\begin{aligned}
  & \forall n \in \mathbb{N}, \exists m_1 = m_1(n) \in \mathbb{N}, |a-x_k| < \frac{1}{2n}, k \geq m_1 \\
  & \forall n \in \mathbb{N}, \exists m_2 = m_2(n) \in \mathbb{N}, |b-y_k| < \frac{1}{2n}, k \geq m_2
\end{aligned} \\
\text{ For } k \geq \max(m_1,m_2) \\ 
|a+b - (x_k + y_k) | = |(a- x_k) + (b- y_k )| \leq |a-x_k| + |b- y_k| < \frac{1}{2n} + \frac{1}{2n} = \frac{1}{n} \\
\text{ so when we consider $T(x+y)$, $T(x+y) = a+b - (x+y)$, } \\
\text{ with $a +b - (x+y)$ convergent sequence defined as above, with limit $0$. } \\
\text{ so } T(x+y) \text{ is convergent with limit $0$ just like $T(x)+T(y)$.  $T$ is linear. }
\end{gathered}
\]

We consider a convergent sequence to be a zero if it is an additive identity to each term in the sequence.  Then $nullspace T = \text{ space of all sequences consisting of the same term for each term }$.  Also, $range T =$ space of all convergent sequences with limit $0$. 

\exercisehead{29} 
\begin{enumerate}
\item \[
\begin{gathered}
  \text{ If } \int_{-\pi}^{\pi} f = \int_{-\pi}^{\pi} fc = \int_{-\pi}^{\pi} fs = 0 \text{ and } \int_{-\pi}^{\pi} g = \int_{-\pi}^{\pi} gc = \int_{-\pi}^{\pi} gs = 0 \\
  \int_{-\pi}^{\pi} f +g = \int_{-\pi}^{\pi} (f+g)c = \int_{-\pi}^{\pi} (f+g)s = 0 \text{ and } \int_{-\pi}^{\pi} kf = \int_{-\pi}^{\pi} kfc = \int_{-\pi}^{\pi} kfs = 0 
\end{gathered}
\]
(by linearity of integration operation).  Then $S$ is closed under addition and scalar multiplication.  $S$ is a subspace of $V$.  
\item \[
\begin{aligned}
  & \int_{-\pi}^{\pi} c(nt) = \left. \frac{1}{n} s(nt) \right|_{-\pi}^{\pi} = 0  \\
  & \int_{-\pi}^{\pi} s(nt) = \left. \frac{-c(nt)}{n} \right|_{-\pi}^{\pi} = \frac{ - (c(n\pi) - c(-n\pi))}{n} = 0 
\end{aligned}
\]
In general,
\[
\begin{aligned}
 & \int_{-\pi}^{\pi} c(nt) c(mt) = \int_{-\pi}^{\pi} \frac{1}{2} (\cos{(n-m)t} + \cos{(n+m)t} ) dt = 0 + 0 = 0  \\
 & \int_{-\pi}^{\pi} s(nt) c(mt) = \int_{-\pi}^{\pi} \frac{1}{2} (\sin{(n+m)t} + \sin{(n-m)t} ) dt = 0 + 0 = 0 \\
 & \int_{-\pi}^{\pi} s(nt) s(mt) = \int_{-\pi}^{\pi} \frac{1}{2} (\cos{(n-m)t} - \cos{(n+m)t} ) dt = 0 + 0 = 0 
\end{aligned}
\]
So $S$ contains the functions $f(x) = \cos{nx}$ and $f(x) = \sin{nx}$, since they satisfy the requirements.  
\item As seen above, the set $\mathcal{B}_S = \{ \sin{nx},\cos{nx} | n = 2, \dots \}$ consists of orthogonal functions with an inner product defined as $\int$ over a period.  Thus, they are independent of each other (orthogonal elements are independent).  They belong to $S$ and $S$, being a subspace, must include all linear combinations of them, and so $S$ is at least infinitely dimensional, since it must contain $\mathcal{B}_S$ in its basis.  
\item \[
\begin{aligned}
  T(V) & = g(x) = \int_{-\pi}^{\pi} (1+\cos{(x-t)})f(t) dt = \int_{-\pi}^{\pi} (1+\cos{x}\cos{t} + \sin{x}\sin{t})f(t) dt = \\
  & = \int_{-\pi}^{\pi} f(t) dt + \left( \int_{-\pi}^{\pi} \cos{t} f(t) dt \right) \cos{x} + \left( \int_{-\pi}^{\pi} f(t) \sin{t} dt \right) \sin{x} 
\end{aligned}
\]
$\mathcal{B}_{T(V)} = \{ 1, \cos{x}, \sin{x} \}$; \quad $rank{T(V)} = 3 $
\item $T(S) = 0 \Longrightarrow nullspace{T} = S$
\item $T(f) = cf$.  Note that $cf \in \mathcal{B}_{T(V)}$.  
\[
\boxed{
\begin{aligned}
  T(1) & = 2\pi (1) \\
  T(s) & = \pi s \\
  T(c) & = \pi c
\end{aligned}
}
\]
\end{enumerate}

\exercisehead{30} We want the following: Let $T: V\to W$ be a linear transformation of a linear space $V$ into a linear space $W$.  If $V$ is infinite-dimensional, prove that at least one of $T(V)$, or $N(T)$, is infinite-dimensional.  

Assume $dim{N(T)} = k, \, dim{T(V)} = r$.  \\
Let $e_1,\dots, e_k$ be a basis for $N(T)$.  \\
Let $e_1, \dots, e_k, e_{k+1}, \dots, e_{k+n}$ be independent elements in $V$, where $n>r$. \smallskip \\
Consider $x = \sum_{j=1}^{k+n} a_j e_j$
\[
T(x) = a_j \sum_{j=1}^{k+n} T(e_j) = a_j \sum_{j=k+1}^{k+n} T(e_j) (\text{since } e_1, \dots, e_k \in N(T) ) 
\]
$x\in V$, so $T(x) \in T(V)$.  Since $dim{T(V)} = r$, and $n>r$, $\{ T(e_j) | j = k+1, \dots, k+n \}$ must be dependent (Apostol's Thm.1.5 of Vol.2: any set of $r+1$ elements of a $dim = r$ space is dependent).  \smallskip \\
Then $\exists \, \{ a_j \}$, $a_j$'s not all zero, s.t. 
\[
\begin{gathered}
  \sum_{j=k+1}^{k+n} a_j T(e_j) = T \sum_{j=k+1}^{k+n} (a_j e_j) = 0 \\
 \Longrightarrow \sum_{j=k+1}^{k+n} a_j e_j \in N(T) \text{ so } \sum_{j=k+1}^{k+n} a_j e_J = \sum_{j=1}^n a_j e_j 
\end{gathered}
\]
 $\Longrightarrow \sum_{j=1}^{k+n} a_j e_j =0$ is a nontrivial representation of $0$.  Then $e_1, \dots, e_{k+n}$ are dependent.  Contradiction.  


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 2.8 Exercises - Introduction, Motivation for the choice of axioms for a determinant function, A set of axioms for a determinant function, Computation of determinants, }
%-----------------------------------%-----------------------------------%-----------------------------------
\exercisehead{1} $V = \{ 0,1 \}$
\[
\begin{aligned}
  T_1(0,1) & = 0,0 \\
 T_2(0,1) & = 0,1 \\
 T_3(0,1) & = 1,0 \\
 T_4(0,1) & = 1,1 
\end{aligned}
\quad \quad \quad 
\begin{matrix}
  0,1 & T_1 & T_2 & T_3 & T_4 \\
  T_1 & 0,0 & 0,0 & 1,0 & 0,0 \\
  T_2 & 0,0 & 0,1 & 1,0 & 1,1 \\
  T_3 & 1,1 & 1,0 & 0,1 & 0,0 \\
  T_4 & 1,1 & 1,1 & 1,1 & 1,1 
\end{matrix}
\]
$T_2, T_3$ are one-to-one, by inspection.  $T_2^{-1} = T_2$; $T_3^{-1} = T_3$

\exercisehead{2} $V = \{ 0,1,2 \}$.  Note, there are obviously $3^3 =27$ possible ranges and thus $27$ possible functions (since for each element in $V$, there are $3$ possible values it could be mapped to).  \\
Consider only the $6$ that are one-to-one (choice of $3$ values, then $2$ values, then $1$ value at each subsequent stage).  

\[
\begin{aligned}
  T_1(0,1,2) & = 0,1,2 \\
  T_2(0,1,2) & = 0,2,1 \\
  T_3(0,1,2) & = 1,0,2 \\
  T_4(0,1,2) & = 1,2,0 \\
  T_5(0,1,2) & = 2,0,1 \\
  T_6(0,1,2) & = 2,1,0 
\end{aligned}
\quad \quad \quad \begin{matrix}
  0,1,2 & T_1 & T_2 & T_3 & T_4 & T_5 & T_6 \\
  T_1 & 0,1,2 & 0,2,1 & 1,0,2 & 1,2,0 & 2,0,1 & 2,1,0 \\
  T_2 & 0,2,1 & 0,1,2 & 2,0,1 & 2,1,0 & 1,0,2 & 1,2,0 \\
  T_3 & 1,0,2 & 1,2,0 & 0,1,2 & 0,2,1 & 2,1,0 & 2,0,1 \\
  T_4 & 1,2,0 & 1,0,2 & 2,1,0 & 2,0,1 & 0,1,2 & 0,2,1 \\
  T_5 & 2,0,1 & 2,1,0 & 0,2,1 & 0,1,2 & 1,2,0 & 1,0,2 \\
  T_6 & 2,1,0 & 2,0,1 & 1,2,0 & 1,0,2 & 0,2,1 & 0,1,2 
\end{matrix}
\quad \quad \quad 
\begin{aligned}
T_1^{-1} & = T_1 \\
T_2^{-1} & = T_2 \\
T_3^{-1} & = T_3 \\
T_4^{-1} & = T_5 \\
T_5^{-1} & = T_4 \\
T_6^{-1} & = T_6 \\
\end{aligned}
\]

\exercisehead{3} $T(x,y) = (y,x)$
Suppose $T(x_1,y_1) = (y_1,x_1) = T(x_2,y_2) = (y_2,x_2)$.  \\
Then $y_1 = y_2$, $x_1 = x_2$ $\to (x_1,y_1) = (x_2,y_2)$

$\boxed{ T \text{ is one-to-one on $V$ }; \quad \quad T(V_2) = V_2, \, (u,v) = (y,x) }$ \\
$\boxed{ T^{-1} = T }$ (by inspection).  

\exercisehead{4} $T(x,y) = (x,-y)$ \\
Suppose $T(x_1,y_1) = (x_1,-y_1) = T(x_2,y_2) = (x_2,-y_2)$ \\
Then $x_1= x_2$, $-y_1 = -y_2$ or $y_1 = y_2$ $\Longrightarrow (x_1,y_1) = (x_2,y_2)$ \\
$\boxed{ T \text{ is one-to-one on $V$ }, \quad \quad T(V_2) = V_2, \, (u,v) = (x,-y) }$ \\
$\boxed{ T^{-1} = T }$

\exercisehead{5} $T(x,y) = (x,0)$.   \\
Note that $T(x,1) = (x,0) = T(x,2)$.  $T$ is not one-to-one.  

\exercisehead{6} $T(x,y) = (x,x)$.  Note that $T(x,1) = T(x,2) = (x,x)$.  $T$ is not one-to-one.  

\exercisehead{7} $T(x,y) = (x^2,y^2)$.  $T(x,y) = T(x,-y) = (x^2, (-y)^2) = (x^2, y^2)$.  $T$ is not one-to-one.  

\exercisehead{8} $T(x,y) = (e^x,e^y)$.  \\
Suppose $T(x_1,y_1) = T(x_2,y_2)$.  \\
Then $e^{x_1} = e^{x_2}$, $e^{y_1} = e^{y_2}$ and since $e^x$ is one-to-one, $\forall \, x \in \mathbb{R}$, $x_1 = x_2$.  \\
$\boxed{ \text{ $T$ is one-to-one }}$.  $u=e^x, \, v = e^y$, $u,v \in \mathbb{R}^+$.  $\boxed{ T^{-1}(x,y) = (\ln{x}, \ln{y}) }$

\exercisehead{9} $T(x,y) = (x,1)$
$T(x,1) = T(x,2) = (x,1)$, so $T$ is not one-to-one.  

\exercisehead{10} $T(x,y) = (x+1,y+1)$.  \\
If $T(x_1,y_1) = (x_1 + 1, y_1 + 1) = T(x_2,y_2) = (x_2 +1,y_2+1)$, \\
\quad then $x_1 = x_2, \, y_1 = y_2$, $(x_1,y_1) = (x_2,y_2)$.  $T$ is one-to-one.  \\
$u = x+1, \, v = y+1$.  $T^{-1}(x,y) = (x-1,y-1)$

\exercisehead{11} $T(x,y) = (x-y,x+y)$.   \\
If $T(x_1,y_1) = (x_1 - y_1, x_1 + y_1) = T(x_2,y_2) = (x_2 - y_2, x_2 + y_2)$  \\
$\begin{aligned}
  x_1 - y_1 & = x_2 - y_2 \\
  x_1 + y_1 & = x_2 + y_2 
\end{aligned}$ \quad then $x_1 = x_2, \, y_1 = y_2$.  $T$ is one-to-one.  

$\begin{aligned}
  u & = x - y \\
  v & = x+y 
\end{aligned}$ \quad $T(V_2) = L(\{ (1,1), (-1,1) \} )$; $T^{-1}(x,y) = \left( \frac{x+y}{2} , \frac{-x+y}{2} \right)$

\exercisehead{12} $T(x,y) = (2x- y, x+y)$ \\
If $T(x_1,y_1) = (2x_1 - y_1, x_1+ y_1) = T(x_2, y_2) = (2x_2 -y_2, x_2 + y_2) $  \\
$\begin{aligned}
  2x_1 - y_1 & = 2x_2 - y_2 \\
  x_1 + y_1 & = x_2 + y_2 
\end{aligned}$ \quad so $\begin{aligned}
  x_1 & = x_2 \\
 y_1 & = y_2 
\end{aligned}$ \quad $T$ is one-to-one.  

$\begin{aligned}
  u & = 2x -y \\
  v & = x+y 
\end{aligned}$ \quad $T(V_2) = L(\{ (2,1), (-1,1) \} )$.  $T^{-1}(x,y) = \left( \frac{x+y}{3} , \frac{x-2y}{-3} \right)$

\exercisehead{13} $T(x,y,z) = (z,y,x)$ \\
If $T(x_1,y_1,z_1) = (z_1,y_1,x_1) = T(x_2,y_2,z_2) = (z_2,y_2,x_2)$ \\
\quad then $\begin{aligned}
  z_1 & = z_2 \\
  y_1 & = y_2 \\
  x_1 & = x_2 
\end{aligned}$ \, $\Longrightarrow T$ is one-to-one.  \\
$T(V_3) = V_3$, $u=z, \, v = y, \, w = z$.  $T^{-1} = T$

\exercisehead{14} $T(x,y,z) = (x,y,0)$ \\
$T(x,y,1) = T(x,y,2) = (x,y,0)$.  $T$ is not one-to-one.  

\exercisehead{15} $T(x,y,z) = (x,2y, 3z)$ \\
$T(x_1,y_1,z_1) = (x_1,2y_1,3z_1) = T(x_2,y_2,z_2) = (x_2,2y_2,3z_2)$
\[
\begin{aligned}
  x_1 & = x_2 \\
  2y_1 & = 2y_2 \\
  3z_1 & = 3z_2 
\end{aligned}
\quad \Longrightarrow 
\begin{aligned}
  x_1 & = x_2 \\
  y_1 & = y_2 \\
  z_1 & = z_2 
\end{aligned} \quad \Longrightarrow \text{ $T$ is one-to-one }
\]
\[
\begin{aligned}
  u & = x \\
  v & = 2y \\
  w & = 3z 
\end{aligned} \quad T(V_3) = V_3 \quad T^{-1}(x,y,z) = \left( x, \frac{y}{2}, \frac{z}{3} \right)
\]

\exercisehead{16} $T(x,y,z) = (x,y,x+y+z)$
$T(x_1,y_1,z_1) = (x_1,y_1,x_1+ y_1+z_1) = T(x_2,y_2,z_2) = (x_2,y_2,x_2+y_2+z_2) $ \\
\[
\begin{aligned}
  x_1 & = x_2 \\
  y_1 & = y_2 \\
  x_1 + y_1 + z_1 & = x_2 + y_2 + z_2 
\end{aligned}
\quad \Longrightarrow z_1 = z_2 \text{ so $T$ is one-to-one }
\]

\exercisehead{17} $T(x,y,z) = (x+1,y+1,z-1)$ \\
$T(x_1,y_1,z_1) = (x_1 + 1, y_1 + 1 , z_1 -1) = T(x_2,y_2,z_2) = (x_2 + 1 , y_2 + 1 , z_2 - 1 )$ 
\[
\Longrightarrow \begin{aligned}
  x_1 & = x_2 \\
  y_1 & = y_2 \\
  z_1 & = z_2 
\end{aligned} \quad \, \text{ $T$ is one-to-one }
\]
$T(V_3) = V_3 + (1,1,-1)$; $\boxed{ T^{-1}(x,y,z) = (x-1,y-1,z+1) }$

\exercisehead{18} $T(x,y,z) = (x+1,y+2,z+3)$ \\
$T(x_1,y_1,z_1) = (x_1 + 1, y_1 + 2, z_1 + 3) = T(x_2,y_2,z_2) = (x_2 + 1, y_2 + 2, z_2 + 3)$
\[
\Longrightarrow \begin{aligned}
  x_1 & = x_2 \\
  y_1 & = y_2 \\
  z_1 & = z_2 
\end{aligned}
\quad \quad \text{ $T$ is one-to-one }
\]
$T(V_3) = V_3 + (1,2,3) $  \quad \, $\boxed{ T^{-1}(x,y,z) = (x-1,y-2,z-3) }$

\exercisehead{19} $T(x,y,z) = (x,x+y, x+y+z)$ \\
$T(x_1,y_1,z_1) = (x_1,x_1+ y_1, x_1+ y_1 + z_1) = T(x_2,y_2,z_2) = (x_2,x_2+y_2,x_2+y_2 + z_2)$
\[
\begin{aligned}
  x_1 & = x_2 \\
  y_1 & = y_2 \\
  z_1 & = z_2 
\end{aligned} \quad \text{ $T$ is one-to-one } \quad \quad \begin{gathered}
  T(V_3) = L( \{ (1,1,1), (0,1,1), (0,0,1) \} ) \\
  T^{-1}(x,y,z) = (x,y-x, z- y)
\end{gathered}
\]

\exercisehead{20} $T(x,y,z) = (x+y,y+z,x+z)$
\[
\begin{gathered}
  T(x_1,y_1,z_1) = (x_1 + y_1,y_1 + z_1,x_1 + z_1) = T(x_2,y_2,z_2) = (x_2 + y_2,y_2 + z_2, x_2 + z_2) \\
  \Longrightarrow \begin{aligned}
    x_1 + y_1 & = x_2 + y_2 \\
    y_1 + z_1 & = y_2 + z_2 \\
    x_1 + z_1 & = x_2 + z_2 
\end{aligned} \text{ or } \begin{aligned}
    x_1 - z_1 & = x_2  - z_2 \\
    x_1 + z_1 & = x_2 + z_2 
\end{aligned} \quad \Longrightarrow x_1 = x_2 , \, y_1  = y_2, \, z_1 = z_2 \text{ so that $T$ is one-to-one } \\
  T(V_3) = L(\{ (1,0,1), (1,1,0), (0,1,1) \} ) \\
 \boxed{ T^{-1}(x,y,z) = \left( \frac{x+z -y }{2}, \frac{x+y-z}{2}, \frac{y+z- x}{2} \right) }
\end{gathered}
\]

\exercisehead{21} 
\[
\begin{gathered}
  T^m T^n  = T^m T T^{n-1} = (T^m T) T^{n-1} = T^{m+1} T^{n-1} = \dots = T^{m+n} T^0 = T^{m+n} 1 = T^{m+n } \\
  \begin{aligned}
    (T^n)^{-1}T^n & = (T^{-1})^n T^n = (T^{-1})(T^{-1})^{n-1} T (T^{n-1}) = \dots = \\
    & = \underbrace{ (T^{-1})\dots (T^{-1})}_{n \text{ times }} \underbrace{ T \dots (T) }_{ n \text{ times } } = \underbrace{ (T^{-1}) \dots (T^{-1}) }_{ n -1 \text{ times } } (T^{-1} T ) \underbrace{ T \dots (T) }_{n -1 \text{ times } } = \underbrace{ (T^{-1}) \dots (T^{-1} ) }_{ n-1 \text{ times } } 1 \underbrace{ T \dots (T) }_{ n-1 \text{ times } } = \dots = T^{-1} T = 1
\end{aligned}
\end{gathered}
\]

\exercisehead{22} 
\[
\begin{aligned}
  (ST)^n & = (ST)(ST)^{n-1} = \dots = \underbrace{ (ST) \dots (ST)}_{ n \text{ times } } = \\
  & = (ST) \dots (ST)(ST) = (ST) \dots (S(TS)T) = (ST) \dots (ST)(SSTT) = \dots = \\
  & = SST(ST) \dots (ST)T = \dots = S^n T^n 
\end{aligned}
\]

\exercisehead{23} $(T^{-1}S^{-1})(ST) = T^{-1}S^{-1} ST = T^{-1} 1 T = 1$, so $(ST)^{-1} = T^{-1}S^{-1}$.  Its uniqueness is guaranteed by theorem (left inverses, if they exist, are unique).  

\exercisehead{24}   $(ST)^{-1}ST = (ST)^{-1} TS = 1$.  \\
\emph{ Since left inverses are unique }(this theorem is important to use here), then $(TS)^{-1} = (ST)^{-1} \Longrightarrow S^{-1}T^{-1} = T^{-1}S^{-1}$

\exercisehead{25} 
\[
\begin{gathered}
  (S+T)(S+T) = S^2 + ST + TS + T^2 = S^2 + 2ST + T^2 \\
  \begin{aligned}
    (S+T)^3 & = (S^2 + ST + TS + T^2)(S+T) = S^3 + STS + TS^2 + T^2 S + S^2 T + ST^2 + TST + T^3 = \\
    & = S^3 + 3S^2 T + 3T^2 S + T^3 
\end{aligned}
\end{gathered}
\]
\exercisehead{26} $\begin{aligned}
  S(x,y,z) & = (z,y,x) \\
  T(x,y,z) & = (x,x+y,x+y+z)
\end{aligned}$
\begin{enumerate}
\item \[
\begin{aligned}
  (ST) & = (x+y+z,x+y,x) \\
  (TS) & =  (z,z+y, x+y+z) \\
  ST- TS & =  (x+y,x-z,-y-z) \\
  S^2 & =  1  
  \end{aligned} \quad \quad \quad 
\begin{aligned}
  T^2 & =  (x,2x+y,3x+2y+z) \\
  (ST)^2 & =  (3x + 2y + z, 2x + 2y + z , x+y+z ) \\
  (TS)^2 & =  (x+y+z, x+2y + 2z, x + 2y + 3z ) \\
  (ST - TS)^2 & =  (2x + y- z, x+ 2y + z, -x + 2z + y ) 
\end{aligned}
\]
\item If $S(x_1,y_1,z_1) = (z_1,y_1, x_1) = S(x_2,y_2,z_2) = (z_2,y_2,x_2)$, then $z_1 = z_2, \, y_1 = y_2, \, x_1 = x_2 $ \\
  If $T(x_1,y_1,z_1) = (x_1,x_1 + y_1, x_1 + y_1 + z_1) = T(x_2,y_2,z_2) = (x_2, x_2 + y_2, x_2 + y_2 + z_2)$, then $x_1 = x_2, \, y_1 = y_2, \, z_1 = z_2 $.  Thus $S,T$ are one-to-one.  
\[
\begin{aligned}
  & (S^{-1}) = S \\ 
  & (T^{-1})(x,y,z) = (x,y-x, z-y) \\
  & (ST)^{-1} = T^{-1}S^{-1} = T^{-1} S \quad \quad & T^{-1}S(x,y,z) = (z,y-z,x-y) \\
  & (TS)^{-1} = S^{-1}T^{-1} \quad \quad & S^{-1} T^{-1}(x,y,z) = S(x,y-x,z-y) = (z-y, y-x,x)
\end{aligned}
\]
\item $\begin{aligned}
  (T-1)(x,y,z) & = (0,x,x+y) \\
  (T-1)^2(x,y,z) & = (0,0,x) \\
  (T-1)^3(x,y,z) & = (0,0,0) \text{ and for all higher powers }
\end{aligned}$
\end{enumerate}

\exercisehead{27} $T(p) = q(x) = \int_0^x p(t) dt $ 
\[
DT(p) = \frac{d}{dx} \int_0^x p(t) dt = p(x) \quad (\text{by first fundamental thm. of calculus})
\]
$TD(p) = \int_0^x dt p'(t)$ \\
Suppose $p=x+1$, $p' = 1$.  $\int_0^x dt 1 = x \neq p$
\[
\begin{aligned}
  & nullspace{TD} = \{ c_0 | \text{ where } c_0 \in \mathbb{R} \} \\
  & range{TD} = \{ \text{ all polynomials $p$ s.t. $p(0) = 0$ } \}
\end{aligned}
\]

\exercisehead{28} Let $V$ be linear space of all real polynomials $p(x)$.  \\
$\begin{aligned}
  & D \equiv \text{ differential operator } \\
  & T \text{ is a linear map from $p(x)$ onto $xp'(x)$ }
\end{aligned}$
\begin{enumerate}
  \item $p(x) = 2 + 3x - x^2 + 4x^3$ \\
    $D,T, DT, TD, DT-TD, T^2 D^2 - D^2 T^2$.  
\[
\begin{aligned}
  Dp & = 3 - 2x + 12x^2 \\
  Tp & = 3x - 2x^2 + 12 x^3 \\
  DTp & = 3 - 4x + 36 x^2 \\
  TDp & = -2x + 24x^2 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  DT - TD & = 3 - 2x + 12x^2 \\ 
  T^2 D^2 - D^2 T^2 & = 24x - (-8 + 216x ) = 8 - 192x 
\end{aligned}
\]
  \item We want $T(p) = p$.  Try $p = \sum_{j=0}^n a_j x^j$.  
\[
T(p) = x \sum_{j=0}^n j a_j x^{j-1} = \sum_{j=0}^n ja_j x^j = \sum_{j=0}^n a_j x^j \Longrightarrow \begin{aligned}
\sum_{j=0}^n a_j (j-1)x^j & = 0 \\
a_j(j-1) x^j & = 0 
\end{aligned} \Longrightarrow j = 1 
\]
$p=a_1 x$
  \item We want $(DT - 2D)(p) = 0$ or $DT(p) - 2D(p)$ 
\[
\begin{gathered}
DT(p) = \sum_{j=0}^n j^2 a_j x^{j-1} = 2\sum_{j=0}^n j a_j x^{j-1} \Longrightarrow \sum_{j=0}^n (j^2 - 2j)a_j x^{j-1} = \sum_{j=0}^n j (j-2) a_j x^{j-1} = 0  \\
j=2,0 \text{ so that } p = a_2 x^2 + a_0 
\end{gathered}
\]
\item We want $(DT - TD)^n(p) = D^n(p)$.  
\[
\begin{gathered}
\begin{aligned}
  & D\sum_{j=0}^n a_j x^j = \sum_{j=0}^n j a_j x^{j-1} \\
  & (DT) \sum_{j=0}^n a_j x^j = \sum_{j=0}^n j^2 a_j x^{j-1} \\
  & TD = \sum_{j=0}^n j(j-1) a_j x^{j-1}
\end{aligned} \quad \quad \quad (DT -TD)p = \sum_{j=0}^n j a_j x^{j-1} = Dp  \\
 D^n  = (DT- TD)^n \quad \forall \, p \in V
\end{gathered}
\]
\end{enumerate}

\exercisehead{29} $xp(x)$.  $T(p) = xp$.  \\
$\begin{aligned}
  DT(p) & = D(xp) = p + xp' \\
  TD(p) & = Tp' = xp' 
\end{aligned} \quad \Longrightarrow (DT- TD)(p) = p$
\[
\begin{gathered}
  T^n(p) = T^{n-1}(xp) = \dots = T(x^{n-1} p ) = x^n p \\
  \begin{aligned}
    DT^n(p) & = nx^{n-1} p + x^n p' \\
    T^n D(p) & = T^n(p') = T^{n-1} (xp')  = \dots = T(x^{n-1} p') = x^n p' 
\end{aligned} \quad \quad \, \Longrightarrow (DT^n - T^n D)(p) = nx^{n-1} p = nT^{n-1} (p)
\end{gathered}
\]

\exercisehead{30} 
\[
\begin{gathered}
\begin{aligned}
  & n =1 , \, ST-  TS = 1 \\
  & n=2 , \, ST^2 - T^2 S = ST^2 + T(1-ST) = T + T = 2T 
\end{aligned} \\
\text{ Assume the $n$th case, } ST^n - T^n S = nT^{n-1} \\
ST^{n+1} - T^{n+1}S = ST^n T + T^n(1-ST) = (nT^{n-1})T + T^n = (n+1)T^n 
\end{gathered}
\]

\exercisehead{31} $p(x) = \sum_{j=0}^n c_j x^j$.  \quad \, \\
$\begin{aligned}
  Rp & = r & = r(x) & = p(0) \\ 
  Sp & = s & = s(x) & = \sum_{k=1}^n c_k x^{k-1} \\
  Tp & = t & = t(x) & = \sum_{k=0}^n c_k x^{k+1} 
\end{aligned}$.  
\begin{enumerate}
\item $p(x) = 2 + 3x - x^2 + x^3$.  We want to know $R,S,T,ST,TS,(TS)^2,T^2 S^2, S^2 T^2, TRS, RST$.  
\[
\begin{aligned}
  Rp & = p(0) = 2 \\
  Sp & = 3 - x + x^2 \\ 
  Tp & = 2x + 3x^2 - x^3 + x^4 
\end{aligned} \quad \quad \, 
\begin{aligned}
ST(p) & = 2 + 3x - x^2 + x^3 \\ 
TS(p) & = 3x - x^2 + x^3 \\ 
(TS)^2(p) & = 3x - x^2 + x^3 
\end{aligned} \quad \quad \, 
\begin{aligned}
T^2 S^2 & = T^2 ( -1 + x) = - x^2 + x^3 \\
S^2 T^2 & = S^2 (2x^2 + 3x^3 - x^4 + x^5) = 2 + 3x - x^2 + x^3 \\
TRSp & = 3x \\
RSTp & = 2 
\end{aligned}
\]
\item $R,S,T$ linear?  
\[
  R(c_1 p_1 + c_2 p_2) = (c_1 p_1 + c_2 p_2)(0) = c_1 p_1(0) + c_2 p_2(0) = c_1 R(p_1) + c_2 R(p_2) 
 \]
\[
\begin{gathered}
  c_1 S(p_1) + c_2 S(p_2) = c_1 \sum_{j=1}^{n_1} a_j x^{j-1} + c_2 \sum_{j=1}^{n_2} b_j x^{j-1} = \sum_{j=1}^{n_2} h_j x^{j-1} = S(c_1 p_1 + c_2 p_2 ) \\
  \text{ where $n_2 \geq n_1$, without loss of generality, and } h_j  = \begin{cases} c_1 a_j + c_2 b_j & \text{ for } j = 0, \dots n_1 \\ 
    c_2 b_j & \text{ for } j = n_1 + 1 \dots n_2 
\end{cases} \\
  \text{ and indeed }, c_1 p_1 + c_2 p_2 = \sum_{j=0}^{n_2} h_j x^j  
\end{gathered}
\]
\[
\begin{gathered}
  c_1 p_1 + c_2 p_2  = c_1 \sum_{j=0}^n a_j x^j + c_2 \sum_{j=0}^{n_2} b_j x^j = \sum_{j=0}^{n_1} c_1 a_j x^j + \sum_{j=0}^{n_2} c_2 b_j x^j = \sum_{j=0}^{n_2} h_j x^j \\
  h_j = \begin{cases} c_1 a_j + c_2 b_j & \text{ for } j = 0, \dots , n_1 \\
    c_2 b_j & \text{ for } j = n_1 + 1, \dots n_2 
\end{cases} 
\end{gathered}
\]
\[
\begin{aligned}
  T(c_1p_1 + c_2 p_2) & = \sum_{j=0}^n h_j  x^{j+1} = \sum_{j=0}^{n_1} (c_1 a_j + c_2 b_j) x^{j+1} + \sum_{j=n_1+1}^{n_2} (c_2 b_j) x^{j+1} \\
  & = c_1 \sum_{j=0}^{n_1} a_j x^{j+1} + c_2 \sum_{j=0}^{n_2} b_j x^{j+1} = c_1 T(p_1) + c_2 T(p_2) 
\end{aligned}
\]
\item 
\[
Rp = p(0)  \Longrightarrow \begin{aligned}
  & nullspace{R} = \{ p | \text{ polynomial $p$ of degree $\geq 1$ } \} \\
  & range{R} = \{ c_0 | c_0 \in \mathbb{R} \}
\end{aligned}
\]
\[
Sp = \sum_{k=1}^n c_k x^{k-1} \quad \Longrightarrow \begin{aligned}
  & nullspace{S} = \{ c_0 | c_0 \in \mathbb{R} \} \\
  & range{S} = \{ p | \text{ polynomial $p$ of degree $n-1$ } \} = V 
\end{aligned}
\]
\[
Tp = \sum_{j=0}^n c_j x^{j+1} \quad \, \begin{aligned}
  & nullspace{T}  = 0 \\
  & range{T}  = \{ p | \text{ polynomial of degree } \geq 1 \}
\end{aligned}
\]
\item $T$ is linear.  $nullspace{T} = 0$.  By thm., $T$ is one-to-one.  This thm. for linear transformations is very useful because we simply need to check if the nullspace only contains $0$.  
\item If $n\geq 1$, $(TS)^n = \boxed{ (1-R)^n }$ since $TS(p) = p - R(p) = (1-R)(p)$.  \\
  $S^n T^n = 1$  
\end{enumerate}
\exercisehead{32} If $x = \{ x_j \}$ is a convergent sequence, $\lim_{j \to \infty} x_j = a$, let $T(x) = \{ y_n \}$, $y_n = a-x_n$ for $n\geq 1 $.  \\$V$ = linear space of all real convergent sequences $\{ x_j \}$.   \\
$T$ is linear, since 
\[
\begin{aligned}
T(c_1 x_1 + c_2 x_2) & = \{ c_1 a_1 + c_2 a_2 - (c_1 x_{1j} + c_2 x_{2j} ) \}= \{ c_1 ( a_1 - x_{1j}) + c_2 (a_2 - x_{2j}) \} = c_1 \{ (a_1 - x_{1j} ) \} + c_2 \{ (a_2 - x_{2j} ) \} = \\
& = c_1 T(x_1) + c_2 T(x_2) 
\end{aligned}
\]
where $\lim_{j\to \infty} (c_1 x_{1j} + c_2 x_{2j} ) = c_1 a_1 + c_2 a_2 $.   \\
Note that all sequences of a constant number, constant sequences, get mapped to the same sequence of zeroes.  Thus, $T$ is not one-to-one.  

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 2.12 Exercises - Linear transformations with prescribed values, Matrix representations of linear transformations, Construction of a matrix representation in diagonal form }
%-----------------------------------%-----------------------------------%-----------------------------------
\exercisehead{1}
\begin{enumerate}
  \item $a_{ij} = \delta_{ij}$
  \item  $a_{ij} =0 $ 
  \item  $a_{ij} = c\delta_{ij}$
\end{enumerate}

\exercisehead{2} 
\begin{enumerate}
\item $\left[ \begin{matrix} 1 & 0 & 0 \\ 0 & 1 & 0 \end{matrix} \right]$
\item $\left[ \begin{matrix} 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \end{matrix} \right]$
\item $\left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right]$
\end{enumerate}

\exercisehead{3} 
\begin{enumerate}
\item $\begin{aligned}
  T(3i - 4j) & = -5 i + 7 j \\
  T^2(3i -4j) & = 9i - 12 j 
\end{aligned}$
\item $T = \left[ \begin{matrix} 1 & 2 \\ 1 & -1 \end{matrix} \right]$ \quad \, $T^2 = \left[ \begin{matrix} 1 & 2 \\ 1 & -1 \end{matrix} \right]\left[ \begin{matrix} 1 & 2 \\ 1 & -1 \end{matrix} \right] = \left[ \begin{matrix} 3 & 0 \\ 0 & 3 \end{matrix} \right]$ 
\item 
\[
\begin{gathered}
  \begin{aligned}
    e_1 & = i - j \\
    e_2 & = 3i + j 
  \end{aligned} \\
  \begin{aligned}
    T(e_1) & = T(i-j) = i + j - 2i + j = -i + 2j = - \left( \frac{ e_1 + e_2 }{4} \right) + 2 \left( \frac{ e_2 - 3e_1 }{4} \right) & = \frac{ -7e_1 + e_2 }{4} \\
    T(e_2) & = T(3i+j) = 3i + 3j + 2i - j = 5i + 2j = 5 \left( \frac{ e_1 + e_2 }{4} \right) + 2 \left( \frac{ e_2 - 3e_1 }{4} \right) & = \frac{-e_1 + 7 e_2 }{4}
\end{aligned} \\
T = \frac{1}{4} \left[ \begin{matrix} -7 & -1 \\ 1 & 7 \end{matrix} \right], \quad \quad \, T^2 = 12 \left[ \begin{matrix} 1 & \\ & 1 \end{matrix} \right]
\end{gathered}
\]
\end{enumerate}

\exercisehead{4} 
\[
T = 2 \left[ \begin{matrix} -1 & 0 \\ 0 & 1 \end{matrix} \right] \quad \quad \quad T^2 = 4 \left[ \begin{matrix} 1 & \\ & 1 \end{matrix} \right]
\]

\exercisehead{5} $T:V_3 \to V_3$ be a linear transformation s.t. \\
\begin{enumerate} 
\item  $\begin{matrix}
  T(k) & = 2i + 3j + 5k \\ 
  T(j+k) & = i \\
  T(i+j+k) & = j -k
\end{matrix}$ \quad \quad \quad $\Longrightarrow T(i+2j + 3k) = \boxed{ 3i + 4j + 4k }$
\[
\begin{aligned}
  T(i) & = -i + j -k \\
  T(j) & = -i - 3j -5k \\
  T(k) & = 2i + 3j + 5k 
\end{aligned} 
\quad \quad \,
T(c_1 i + c_2 j + c_3 k ) = (-c_1 -c_2 + 2c_3)i + (c_1 - 3c_2 + 3c_3)j + (-c_1 -5 c_2 + 5c_3)k = 0 
\]
So we have a system of linear equations, \\
$\begin{aligned}
  & -c_1 - c_2 + 2c_3 = 0 \\
  & c_1 - 3c_2 + 3c_3 = 0 \\
  & -c_1 - 5c_2 + 5c_3 = 0 
\end{aligned}$ to solve, which could be done by Gauss-Jordan or simply to add them up cleverly to get $c_3 = 0$ first, and then $c_2,c_1 =0$.  \\
$\Longrightarrow nullspace{T} = 0, \quad null{T} = 0$.  $range{T} = V_3, \quad rank{T} = 3$
\item $T = \left[ \begin{matrix} -1 & -1 & 2 \\
    1 & -3 & 3 \\
    -1 & -5 & 5 \end{matrix} \right]$
\end{enumerate}

\exercisehead{6} 
\[
\begin{aligned}
  e_1 & = (2,3,5) \\
  e_2 & = (1,0,0) \\
  e_3 & = (0,1,-1)
\end{aligned} \quad \quad \quad 
\begin{aligned}
  T(e_1) & = 2(-1,1,-1) + 3(-1,-3,5) + 5(2,3,5) =(5,8,8) = 2e_1 + 2e_3+ e_2 \\
  T(e_2) & = (-1,1,-1) = -e_2 + e_3 \\
  T(e_3) & = (-1,-3,-5) + (-2,-3,-5) = (-3,-6,-10) = -2e_1 + 2 e_2
\end{aligned}
\]
\[
T = \left[ \begin{matrix} 2 & 0 & -2 \\
    1 & -1 & 1 \\
    2 & 1 & 0 
\end{matrix} \right]
\]

\exercisehead{7} Given $T(0)  = (0,0), \, T(j) = (1,1), \, T(k) = (1,-1)$
\begin{enumerate}
\item $T(4i - j + k ) = (-1,-1) + (1,-1) = (0,-2)$ \\
Determine the nullspace of $T$ by considering 
\[
T(x) = \left[ \begin{matrix} 0 & 1 & 1 \\
  0 & 1 & -1 \end{matrix} \right]\left[ \begin{matrix} c_1 \\ c_2 \\ c_3 \\ \end{matrix} \right] = 0 \Longrightarrow \left[ \begin{matrix} 0 & 1 & 0 \\
    0 & 0 & -2 \end{matrix} \right] = \left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right]
\]
So then $nullspace{T} = L(\{ (1,0,0) \} )$.  \\
$\begin{aligned}
  & null{T} = 1 \\
  & range{T} = 2 
\end{aligned}$ \quad \quad (by nullity-rank thm.)
\item $T = \left[ \begin{matrix} 0 & 1 & 1 \\
  0 & 1 & -1 \end{matrix} \right]$
\item $\begin{aligned}
  w_1 & = (1,1) \\
  w_2 & = (1,2)
\end{aligned}$ \quad \quad $\begin{aligned}
  & T(i) = 0 \\
  & T(j) = w_1 \\
  & T(k) = 3w_1 - 2w_2
\end{aligned}$ \quad \quad $T = \left[ \begin{matrix} 0 & 1 & 3 \\
0 & 0 & -2 \end{matrix} \right]$
\item 
\[
\boxed{ \begin{aligned}
    e_1 & = i \\
    e_2 & = j \\
    e_3 & = \frac{ 3j - k }{2}
\end{aligned} }
\]
\end{enumerate}

\exercisehead{8} Given $\begin{aligned} T(i) & = (1,0,1) \\ T(j) & = (-1,0,1) \end{aligned}$,
\begin{enumerate}
\item $T(2i - 3j) = (2,0,2) + (3,0,-3) = (5,0,-1)$.  
$\left[ \begin{matrix} 1 & -1 \\ 0 & 0 \\ 1 & 1 \end{matrix} \right] \xrightarrow{ \text{ Gauss-Jordan elimination } } \left[ \begin{matrix} 2 & 0 \\ 0 & 0 \\ 0 & 2 \end{matrix} \right] \left[ \begin{matrix} c_1 \\ c_2 \end{matrix} \right]$ $\Longrightarrow c_1 = c_2 =0$.  \\
So then $\begin{aligned}
  null{T} & = 0 \\
  rank{T} & = 2 
\end{aligned}$
\item Again, $T = \left[ \begin{matrix} 1 & -1 \\ 0 & 0 \\ 1 & 1 \end{matrix} \right]$
\item \[
\begin{aligned}
  e_1 & = \frac{ i - j }{2} \\
  e_2 & = \frac{ i + j }{2}
\end{aligned} \quad \quad \begin{aligned}
  T(e_1) = T\left( \frac{ i - j }{2} \right) & = (1,0,0) \\
  T\left( \frac{ i + j }{2} \right) & = (0,0,1) = w_2 = k 
\end{aligned} \quad \quad \, \begin{aligned}
  w_1 & = (1,0,0) \\
  w_2 & = (0,0,1) = k \\
  w_3 & = (0,1,0)
\end{aligned}
\]
\end{enumerate}

\exercisehead{9} Given \\
$\begin{aligned}
  T(i) & = (1,0,1) \\
  T(j) & = (1,1,1) 
\end{aligned}$ 
\begin{enumerate}
\item  $T(2i-3j) = (2,0,2) - (3,3,3) = (-1,-3,-1)$.  By inspection of the matrix for $T$, $\begin{aligned} null{T} & =0 \\ rank{T} & = 2 \end{aligned}$.  
\item $T = \left[ \begin{matrix} 1 & 1 \\ 0 & 1 \\ 1 & 1 \end{matrix} \right]$
\item Note that 
\[
\begin{aligned}
  T(j-i) & = (0,1,0) \\
  T(i) & = (1,0,1)
\end{aligned} \quad \quad \quad \begin{aligned}
  w_1 & = (1,0,1) \\
  w_2 & = (0,1,0) \\
  w_3 & = (0,0,1)
\end{aligned} \quad \quad \quad \Longrightarrow \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \\ 0 & 0 \end{matrix} \right]
\]
\end{enumerate}

\exercisehead{10} Let $V$ and $W$ be linear spaces, each with dimension $2$.  
\begin{enumerate}
\item Given $\begin{aligned}
  T(e_1 + e_2) & = 3e_1 + 9e_2 \\
  T(3e_1 + 2e_2) & = 7e_1 + 23 e_2 
\end{aligned}$, then $\begin{aligned}
  T(-e_2) & = -2e_1 + -4e_2 = -(2e_1 + 4 e_2) \\
  T(e_1) & = e_1 + 5 e_2 
\end{aligned}$, so that $\boxed{ T(e_2 - e_1) = e_1 - e_2 }$.  By inspection of matrix $T$, $\begin{aligned}
  null{T} & = 0 \\
  rank{T} & = 2 
\end{aligned}$
\item $T = \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right]$
\item With a basis of $(e_1,e_2)$ for $V$ and a desired basis of the form $(e_1 + ae_2, 2e_1 + be_2)$ for $W$, 
\[
\begin{aligned}
  T(e_1) & = e_1 + 5 e_2 \quad \quad & \Longrightarrow a = 5 \\
  T(e_2) & = 2e_1 + 4 e_2 \quad \quad & \Longrightarrow b =4 
\end{aligned}
\]
\end{enumerate}

\exercisehead{11} $(\sin{x}, \cos{x})$
\[
D(s,c) = (c,-s) \Longrightarrow D= \left[ \begin{matrix} 0 & -1 \\ 1 & 0 \end{matrix} \right] \quad \quad D^2 = \left[ \begin{matrix} -1 & 0 \\ 0 & -1 \end{matrix} \right]
\]

\exercisehead{12} $(1,x,e^x)$ \\
\[
D(1,x,e^x) = (0,1,e^x) \quad \quad \, D = \left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1 \end{matrix} \right] \quad \quad D^2 = \left[ \begin{matrix} & 1 & \\ & & \\ & & 1 \end{matrix} \right] \left[ \begin{matrix} & 1 & \\ & & \\ &  & 1 \end{matrix}\right] = \left[ \begin{matrix} & & \\ & & \\ & & 1 \end{matrix} \right]
\]

\exercisehead{13} $(1,1+x,1+x+e^x)$
\[
D(1,1+x,1+x+e^x) \quad \quad D= \left[ \begin{matrix} 0 & 1 & 1 \\ 0 & 0 & -1 \\ 0 & 0 & 1 \end{matrix} \right] \quad \quad \, D^2 = \left[ \begin{matrix} & 1 & 1 \\ & & -1 \\ &  & 1 \end{matrix} \right]\left[ \begin{matrix} & 1 & 1 \\ & & - 1 \\ & & 1 \end{matrix}\right] = \left[ \begin{matrix} & & \\ & & -1 \\ & & 1 \end{matrix} \right]
\]

\exercisehead{14} $(e^x,xe^x)$ 
\[
D(e^x,xe^x) = (e^x, e^x + xe^x) \quad \quad \, D = \left[ \begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix} \right] \quad \quad \, D^2  = \left[ \begin{matrix} 1 & 1 \\ & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & 1 \\ & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 2 \\ & 1 \end{matrix} \right]
\]

\exercisehead{15} $(-c,s)$.  
\[
D(-c,s) = (s,c) \quad \quad \, D = \left[ \begin{matrix} 0 & -1 \\ 1 & 0 \end{matrix} \right] \quad \quad \, D^2 = \left[ \begin{matrix} & -1 \\ 1 &  \end{matrix} \right]\left[ \begin{matrix} & -1 \\ 1 & \end{matrix} \right] = \left[ \begin{matrix} -1 & \\ & -1 \end{matrix} \right]
\]

\exercisehead{16} $(\sin{x},\cos{x} ,x \sin{x}, x\cos{x})$
\[
\begin{gathered}
D(s,c,xs,xc) = (c,-s,s+xc,c+-xs) \quad \quad \, \\
D= \left[ \begin{matrix} 0 & -1 & 1 & 0 \\ 1 & 0 & 0 & 1 \\ 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \end{matrix} \right] \quad \quad \, D^2 = \left[ \begin{matrix} & -1 & 1 & \\ 1 & & & 1 \\ & & & -1 \\ & & 1 & \end{matrix} \right]\left[ \begin{matrix} & -1 & 1 & \\ 1 & & & 1 \\ & & & -1 \\ & & 1 & \end{matrix} \right] = \left[ \begin{matrix} -1 & & -2 \\ & -1 & 2 \\ & & -1 & \\ & & & -1 \end{matrix} \right]
\end{gathered}
\]

\exercisehead{17} $(e^x \sin{x}, e^x \cos{x})$
\[
D(e^x s,e^x c) = (e^x s + e^x c, e^x c - e^x s) \quad \quad D = \left[ \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right] \quad \quad \, D^2 = \left[ \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right] = \left[ \begin{matrix} & -2 \\ 2 & \end{matrix} \right]
\]

\exercisehead{18} $(e^{2x} \sin{3x}, e^{2x} \cos{3x} )$
\[
D(e^{2x}s, e^{2x}c ) = (2e^{2x}s + 3e^{2x} c, 2e^{2x}c + - 3 e^{2x} s )  \quad \quad \, D = \left[ \begin{matrix} 2 & -3 \\ 3 & 2 \end{matrix} \right] \quad \quad \, D^2 = \left[ \begin{matrix} 2 & -3 \\ 3 & 2 \end{matrix} \right]\left[ \begin{matrix} 2 & -3 \\ 3 & 2 \end{matrix} \right] = \left[ \begin{matrix} -5 & -12 \\ 12 & -5 \end{matrix} \right]
\]

\exercisehead{19} $(1,x,x^2,x^3)$.  $T(p) = xp'$.   \\
$\begin{aligned}
  D(1,x,x^2,x^3) & = (0,1,2x,3x^2) \\
  T(1,x,x^2,x^3) &=  (0,x,2x^2, 3x^3) 
\end{aligned}$ 
\begin{enumerate}
\item $T = \left[ \begin{matrix} 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 2 & 0 \\ 0 & 0 & 0 & 3 \end{matrix} \right]$
\item $DT = \left[ \begin{matrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 4 & 0 \\ 0 & 0 & 0 & 9 \\ 0 & 0 & 0 & 0 \end{matrix} \right]$
\item $TD = \left[ \begin{matrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 2 & 0 \\ 0 & 0 & 0 & 6 \\ 0 & 0 & 0 & 0 \end{matrix} \right]$
\item $TD - DT = \left[ \begin{matrix} 0 & - 1 & 0 & 0 \\ 0 & 0 & -2 & 0 \\ 0 & 0 & 0 & -3 \\ 0 & 0 & 0 & 0 \end{matrix} \right]$ 
\item $T^2 = \left[ \begin{matrix} & & & \\ & 1 & &  \\ & & 2 & \\ & & & 3 \end{matrix} \right]\left[ \begin{matrix} & & & \\ & 1 & &  \\ & & 2 & \\ & & & 3 \end{matrix} \right] = \left[ \begin{matrix} & & & \\ & 1 & & \\ & & 4 & \\ & & & 9 \end{matrix} \right]$ 
\item \[
\begin{aligned}
  T^2 D^2 & = \left[ \begin{matrix} & & & \\ & 1 & & \\ & & 4 & \\ & & & 9 \end{matrix} \right]\left[ \begin{matrix} & & 2 & \\ & & 6 & \\ & & & \\ & & & \end{matrix} \right] = \left[ \begin{matrix} & & & \\ & & & 6 \\ & & & \\ & & & \end{matrix} \right] \\ 
  D^2 T^2 & = \left[ \begin{matrix} & & 2 & \\ & & & 6 \\ & & & \\ & & & \end{matrix} \right]\left[ \begin{matrix} & & & \\ & 1 & & \\ & & 4 & \\ & & & 9 \end{matrix} \right] = \left[ \begin{matrix} & & 8 & \\ & & & 54 \\ & & & \\ & & & \end{matrix} \right]
\end{aligned}
 \quad \quad T^2 D^2 - D^2 T^2 = \left[ \begin{matrix} & & -8 & \\ & & & -48 \\ & & & \\ & & & \end{matrix} \right]
\]
\end{enumerate}

\exercisehead{20} $TD = \left[ \begin{matrix} & & & \\ & & 2 & \\ & & & 6 \\ & & & \end{matrix} \right]$.  \\
Note that $(TD)(x^3,x^2,x,1) = (6x^2, 2x, 0 , 0)$, so if we let $\begin{aligned}
  w_1 & = x^2 \\ 
  w_2 & = x
\end{aligned}$, then $(TD) = \left[ \begin{matrix} 6 & & & \\ & 2 & & \end{matrix} \right] $

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 2.16 Exercises - Linear spaces of matrices, Isomorphism between linear transformations and matrices, Multiplication of matrices }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} $A = \left[ \begin{matrix} 1 & -4 & 2 \\ -1 & 4 & -2 \end{matrix} \right]$, \quad $B = \left[ \begin{matrix} 1 & 2 \\ -1 & 3 \\ 5 & -2 \end{matrix} \right]$, \quad $C = \left[ \begin{matrix} 2 & 2 \\ 1 & -1  \\ 1 & -3 \end{matrix} \right]$
\[
\begin{gathered}
  B+ C = \left[ \begin{matrix} 3 & 4 \\ 0 & 2 & 6 & -5 \end{matrix} \right] \\
  \begin{aligned}
    AB & = \left[ \begin{matrix} 1 & -4 & 2 \\ -1 & 4 & -2 \end{matrix} \right] \left[ \begin{matrix} 1 & 2 \\ -1 & 3 \\ 5 & -2 \end{matrix} \right] = \left[ \begin{matrix} 15 & - 14 \\ -15 & 14 \end{matrix} \right] \\
    BA & = \left[ \begin{matrix} 1 & 2 \\ -1 & 3 \\ 5 & -2 \end{matrix} \right] \left[ \begin{matrix} 1 & -4 & 2 \\ -1 & 4 & -2 \end{matrix} \right] = \left[ \begin{matrix} -1 & 4 & -2 \\ -4 & 16 & -8 \\ 7 & -28 & 14 \end{matrix} \right] \\
    \end{aligned} \quad \quad \quad 
  \begin{aligned}
    AC & = \left[ \begin{matrix} 1 & -4 & 2 \\ 
	-1 & 4 & -2 \end{matrix} \right] \left[ \begin{matrix} 2 & 2 \\
	 1 & -1 \\
	 1 & -3 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right] \\
    CA & = \left[ \begin{matrix} 2 & 2 \\ 1 & -1 \\ 1 & -3 \end{matrix} \right] \left[ \begin{matrix} 1 & -4 & 2 \\ -1 & 4 & -2 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 & 0 \\ 2 & -8 & 4 \\ 4 & - 16 & 8 \end{matrix} \right]
  \end{aligned} \\
A(2B-3C) = 2AB - 3AC = \left[ \begin{matrix} 30 & - 28 \\ -30 & 28 \end{matrix} \right] + \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right] = \left[ \begin{matrix} 30 & -28 \\ -30 & 28 \end{matrix} \right]  
\end{gathered}
\]

\exercisehead{2} $A = \left[ \begin{matrix} 0 & 1 \\ 0 & 2 \end{matrix} \right]$  
\begin{enumerate}
  \item $AB = \left[ \begin{matrix} & 1 \\ & 2 \end{matrix} \right] \left[ \begin{matrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{matrix} \right] = \left[ \begin{matrix} b_{21} & b_{22} \\ 2b_{21} & 2b_{22} \end{matrix} \right] = 0 $ \\
   $\Longrightarrow b_{21} = b_{22} =0$ or $\left[ \begin{matrix} b_{11} & 0 \\ b_{21} & 0 \end{matrix} \right]$
  \item $BA = \left[ \begin{matrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{matrix} \right]\left[ \begin{matrix} & 1 \\ & 2 \end{matrix} \right] = \left[ \begin{matrix} & b_{11} + 2b_{12} \\ & b_{21} + 2b_{22} \end{matrix} \right] \Longrightarrow \begin{aligned}
b_{11} & = -2b_{12} \\
b_{21} & = -2b_{22}
\end{aligned}$
\[
\left[ \begin{matrix} b_{11} & b_{11}/-2 \\ b_{21} & b_{21}/-2 \end{matrix} \right] = b_{11} \left[ \begin{matrix} 1 & -1/2 \\ 0 & 0 \end{matrix} \right] + b_{21} \left[ \begin{matrix} 0 & 0 \\ 1 & -1/2 \end{matrix} \right]
\]
\end{enumerate}

\exercisehead{3} 
\begin{enumerate}
\item $\left[ \begin{matrix} & & 1 & \\ 1 & & & \\ & 1 & & \\ & & & 1 \end{matrix} \right] \left[ \begin{matrix} a \\ b \\ c \\ d \end{matrix} \right] = \left[ \begin{matrix} 1 \\ 9 \\ 6 \\ 5 \end{matrix} \right] \Longrightarrow \begin{aligned} c & = 1 \\ a & = 9 \\ b & = 6 \\ d & = 5 \end{aligned}$
\item \[
\left[ \begin{matrix} a & b & c & d \\ 1 & 4 & 9 & 2 \end{matrix} \right] \left[ \begin{matrix} 1 & & 2 & \\ & & 1 & & \\ & 1 & & \\ & & 1 & \end{matrix} \right]  = \left[ \begin{matrix} 1 & & 6 & 6 \\ 1 & 9 & 8 & 4 \end{matrix} \right] \quad \quad \quad \begin{aligned} a & =1 \\ c & = 0 \\ b & = 6 \\ d & =-2 \end{aligned}
\]
\end{enumerate}

\exercisehead{4} $AB-BA$
\begin{enumerate}
\item \[ \begin{aligned}
  A & = \left[ \begin{matrix} 1 & 2 & 2 \\ 2 & 1 & 2  \\ 1 & 2 & 3 \end{matrix} \right] \\
  B & = \left[ \begin{matrix} 4 & 1 & 1 \\ -4 & 2 & 0 \\ 1 & 2 & 1 \end{matrix} \right] \end{aligned} \quad \quad \, \begin{aligned} BA & = \left[ \begin{matrix} 4 & 1 & 1 \\ -4 & 2 & 0 \\ 1 & 2 & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & 2 & 2 \\ 2 & 1 & 2 \\ 1 & 2 & 3 \end{matrix} \right] = \left[ \begin{matrix} 7 & 11 & 13 \\ & -6 & -4 \\ 6 & 6 & 9 \end{matrix} \right] \\
  AB & = \left[ \begin{matrix} -2 & 9 & 3 \\ 6 & 10 & 4 \\ -1 & 11 & 4 \end{matrix} \right] \\
 AB - BA & = \boxed{ \left[ \begin{matrix} -9 & -2 & -10 \\ 6 & 16 & 8 \\ -7 & 5 & -5 \end{matrix} \right] } \end{aligned} \]
\item \[ \begin{aligned}
  A & = \left[ \begin{matrix} 2 & 0 & 0 \\ 1 & 1 & 2 \\ -1 & 2 & 1 \end{matrix} \right] \\
  B & = \left[ \begin{matrix} 3 & 1 & -2 \\ 3 & -2 & 4 \\ -3 & 5 & 11 \end{matrix} \right]
\end{aligned} \quad \quad \,  \begin{aligned} AB & = \left[ \begin{matrix} 2 & 0 & 0 \\ 1 & 1 & 2 \\ -1 & 2 & 1 \end{matrix} \right] \left[ \begin{matrix} 3 & 1 & -2 \\ 3 & -2 & 4 \\ -3 & 5 & 11 \end{matrix} \right] = \left[ \begin{matrix} 6 & 2 & -4 \\ 0 & 9 & 24 \\ 0 & 0 & 21 \end{matrix} \right] \\
  BA & = \left[ \begin{matrix} 3 & 1 & -2 \\ 3 & -2 & 4 \\ -3 & 5 & 11 \end{matrix} \right]\left[ \begin{matrix} 2 & 0 & 0 \\ 1 & 1 & 2 \\ -1 & 2 & 1 \end{matrix} \right] = \left[ \begin{matrix} 9 & -3 & 0 \\ 0 & 6 & 0 \\ -12 & 27 & 21 \end{matrix} \right] \\
  AB - BA & = \left[ \begin{matrix} 6 & 2 & -4 \\ 0 & 9 & 24 \\ 0 & 0 & 21 \end{matrix} \right] - \left[ \begin{matrix} 9 & -3 & 0 \\ 0 &  6 & 0  \\ -12 & 27 & 21 \end{matrix} \right] = \left[ \begin{matrix} -3 & 5 & -4 \\ 0 & 3 & 24 \\ 12 & -27 & 0 \end{matrix} \right] \end{aligned} \] 
\end{enumerate}

\exercisehead{5} $A^n A^m = A^{m+n}$.  \\
Matrix multiplication is associative; $A^n A^m = A^{n-1} (AA^m) =A^{n-1} A^{m+1} = \dots = A^0 A^{m+n} = A^{m+n}$

\exercisehead{6} $A = \left[ \begin{matrix} 1 & 1 \\ & 1 \end{matrix} \right]$ \quad \quad $A^2 = \left[ \begin{matrix} 1 & 2 \\ & 1 \end{matrix} \right]$ \\
\[
\begin{gathered}
  A^3  = \left[ \begin{matrix} 1 & 2 \\ & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & 1 \\ & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 3 \\ & 1 \end{matrix} \right] \\
  \text{ Assume $n$th case is true } A^n = \left[ \begin{matrix} 1 & n \\ & 1 \end{matrix} \right] \quad \quad \, A^{n+1} = A A^n = \left[ \begin{matrix} 1 & 1 \\ & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & n \\ & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & n+1 \\ & 1 \end{matrix} \right]
\end{gathered}
\]

\exercisehead{7} $A = \left[ \begin{matrix} \cos{\theta} & -\sin{\theta} \\ \sin{\theta} & \cos{\theta} \end{matrix} \right]$ 
\[
\begin{gathered}
  A^2 = \left[ \begin{matrix} c & -s \\ s & c \end{matrix} \right] \left[ \begin{matrix} c & -s \\ s & c \end{matrix} \right] = \left[ \begin{matrix} c^2 - s^2 & -2sc \\ 2sc & -s^2 + c^2 \end{matrix} \right] = \left[ \begin{matrix} \cos{(2\theta)} & - \sin{(2\theta) } \\ \sin{(2\theta) } & \cos{(2\theta) } \end{matrix} \right] \\
  \text{ Assume $n$th case is true}: A^n = \left[ \begin{matrix} \cos{(n\theta)} & -\sin{(n\theta)} \\ \sin{(n\theta)} & \cos{(n\theta)} \end{matrix} \right] \\
  \begin{aligned}
  A^{n+1} & = \left[ \begin{matrix} \cos{\theta} & -\sin{\theta} \\ \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} \cos{ (n\theta)} & -\sin{ (n\theta) } \\ \sin{(n \theta) } & \cos{ (n\theta) } \end{matrix} \right] = \left[ \begin{matrix} \cos{(n\theta) } \cos{\theta} - \sin{(n\theta)} \sin{\theta} & -\cos{\theta}\sin{(n\theta)} - \sin{\theta} \cos{(n\theta)} \\
      \cos{(n\theta) }\sin{\theta} + \cos{\theta} \sin{(n\theta) } & - \sin{\theta} \sin{(n\theta)} + \cos{(n\theta)}\cos{\theta} \end{matrix} \right] \\
  & = \left[ \begin{matrix} \cos{ (n+1) \theta} & -\sin{ (n+1)\theta} \\ 
      \sin{(n+1)\theta} & \cos{(n+1)\theta} \end{matrix} \right]
  \end{aligned}
\end{gathered}
\]

\exercisehead{8} Let $A = \left[ \begin{matrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{matrix} \right]$ 
\[
\begin{aligned}
  A^2 & = \left[ \begin{matrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{matrix} \right] \left[ \begin{matrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{matrix} \right]  = \left[ \begin{matrix} 1 & 2 & 3 \\ 0 & 1 & 2 \\ 0 & 0 & 1 \end{matrix} \right] \\ 
  A^3 & = \left[ \begin{matrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{matrix} \right] \left[ \begin{matrix} 1 & 2 & 3 \\ 0 & 1 & 2 \\ 0 & 0 & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 3 & 6 \\ 0 & 1 & 3 \\ 0 & 0 & 1 \end{matrix} \right] \\
  A^4 & = \left[ \begin{matrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{matrix} \right] \left[ \begin{matrix} 1 & 3 & 6 \\ 0 & 1 & 3 \\ 0 & 0 & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 4 & 10 \\ 0 & 1 & 4 \\ 0 & 0 & 1 \end{matrix} \right] 
\end{aligned}
 \quad \quad 
\begin{aligned}
  & \text{ (Assume $n$th case is true ) } \\
  A^n & = \left[ \begin{matrix} 1 & n & \frac{ n(n+1)}{2} \\ & 1 & n \\ & & 1 \end{matrix} \right] \\
  A^{n+1} & = \left[ \begin{matrix} 1 & 1 & 1 \\ & 1 & 1 \\ & & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & n & \frac{n (n+1)}{2} \\ & 1 & n \\ & & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & n+1 & \frac{ n^2 + n}{2} + \frac{2n}{2} + \frac{2}{2} \\
      & 1 & n+1 \\
      & & 1 \end{matrix} \right] = \\
  & = \left[ \begin{matrix} 1 & n +1 & \frac{ (n+2)(n+1)}{2} \\ & 1 & n+1 \\ & & 1 \end{matrix} \right]
\end{aligned}
\]

\exercisehead{9} Given $\left[ \begin{matrix} 1 & 0 \\ -1 & 1 \end{matrix} \right]$ 
\[
A^2 = \left[ \begin{matrix} 1 & 0 \\ -1 & 1 \end{matrix} \right] \left[ \begin{matrix} 1 & 0 \\ -1 & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 \\ -2 & 1 \end{matrix} \right] = \left[ \begin{matrix} 2 & 0 \\ -2 & 2 \end{matrix} \right] - \left[ \begin{matrix} 1 & \\ & 1 \end{matrix} \right]
\]
Consider that 
\[
\begin{aligned}
  A^3 & = 2A^2 - A = 2(2A -1) - A = 3A - 2 \\
  A^4 & = (2A-1)(2A-1) = 4A^2 - 4A + 1 = 4(2A -1) - 4A + 1 = 4A -3 
\end{aligned}
\]
Then assume the $n$th case, that $A^n = nA - (n-1)$.  \\
\[
\begin{aligned}
  A^{n+1} & = nA^2 - (n-1)A = n(2A - 1) - (n-1)A = 2nA - n - nA + A = \\
  & = (n+1)A - n
\end{aligned}
\]
So for $n=100$, we have $A^{100} = \left[ \begin{matrix} 1 & \\ 100 & 1 \end{matrix} \right]$

\exercisehead{10} If $A = \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right]$, 
\[
A^2 = \left[ \begin{matrix} a^2 + bc & ab + bd \\ ac + cd & bc + d^2 \end{matrix} \right] = \left[ \begin{matrix} a^2 + bc & b(a+d) \\ (a+d)c & bc + d^2 \end{matrix} \right]
\]
If $b=0, d =0, a =0$, so $c=0$.  So the only other way for $A^2 = 0$ is for $a = -d \neq 0$.  $a^2 + bc = 0$ or $a^2 = -bc$.   \\
For instance,
\[
\left[ \begin{matrix} 1 & \pm 1 \\ \mp 1 & -1 \end{matrix} \right]\left[ \begin{matrix} 1 & \pm 1 \\ \mp 1 & - 1 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right]
\]

\exercisehead{11} Let \[
\begin{gathered}
  A_{ij} = a_{ij} \quad \quad \, \begin{aligned} (E_{11})_{ij} & = \delta_{1i} \delta_{1j} \\ 
 (E_{12})_{ij} & = \delta_{1i} \delta_{2j} \\ 
 (E_{21})_{ij} & = \delta_{2i} \delta_{1j} \\ 
 (E_{22})_{ij} & = \delta_{2i} \delta_{2j} \\ 
\end{aligned}
\end{gathered}
\]
\begin{enumerate}
\item If $AB-BA = [A,B] = 0$ \, $\forall \, B \in M_{22}$, then since $E_{ij} \in M_{22}$, $[A,E_{ij}] =0$ \, $\forall \, i = 1,2,3,4$.  \\

 If $[A,E_{ij}] = 0$, then since $\forall \, B \in M_{22}$, $B = \sum b_{ij} E_{ij}$, so that 
\[
[A,B] = [A, \sum b_{ij} E_{ij} ] = \sum b_{ij} [A,E_{ij} ] = 0 
\]
\item Given $[A,E_{ij}] = 0$, 
\[
\begin{aligned}
  (AE_{lm})_{ij} & = \sum_{k=1}^2 a_{ik} (E_{lm})_{kj} = \sum_{k=1}^2 a_{ik} \delta_{lk} \delta_{mj} = \\
  & = a_{il} \delta_{mj} \\
  (E_{lm} A)_{ij} & = \sum_{k=1}^2 (E_{lm})_{ik} a_{kj} = \sum_{k=1}^2 \delta_{li} \delta_{mk} a_{kj} = \\
  & = \delta_{li} a_{mj}
\end{aligned} \quad \quad \, \Longrightarrow (AE_{lm} - E_{lm} A)_{ij} = a_{il} \delta_{mj} - \delta_{li} a_{mj} = 0 \text{ or } a_{il} \delta_{mj} = \delta_{li} a_{mj} 
\]
\[
\begin{aligned}
  & \text{ if } m = j, \, a_{il} = \delta_{li} a_{jj}, \quad \, & \begin{aligned} & \text{ if } l = i, \, a_{ii} = a_{jj} \\ & \text{ if } l \neq i , \, a_{il} = 0 \end{aligned} \\ 
  & \text{ if } m \neq j , \, \delta_{li} a_{mj} = 0 , \quad \, & \begin{aligned} & \text{ if } l = i, \, a_{mj} = 0 \\ & \text{ if } l \neq i, \, a_{mj} \text{ unknown } \end{aligned}
\end{aligned}
\]
$i,j$ is completely arbitrary, and $(AE_{lm} - E_{lm} A)_{ij}  =0 $ must be true $\forall \, i = 1,2, \, j = 1,2$, then $\left[ \begin{matrix} a & 0 \\ 0 & a \end{matrix} \right] = a I $ is the $A$.  
\end{enumerate}

\exercisehead{12} Suppose $A$ s.t. $A^2 = I$. \\
$(A^2)_{ij} = \sum_{k=1}^2 a_{ik} a_{kj} = \delta_{ij}$ 
\[
\begin{aligned}
  & \text{ if } i = j, & \sum_{k=1}^2 a_{ik} a_{ki} = 1 & \Longrightarrow a_{i1} a_{1i} + a_{i2} a_{2i} = 1 \\
  & \text{ if } i \neq j, & \sum_{k=1}^2 a_{ik} a_{kj} = 0 & \Longrightarrow a_{i1} a_{1j} = -a_{i2} a_{2j} 
\end{aligned}
\]
If $a_{11} = 0$, $a_{12}a_{21} = 1$ but $0 = -a_{12} a_{21}$.  Similar if $a_{22} =0$.  Then $a_{11}, a_{22} \neq 0$ \\

If $a_{12} =0$, \\
\phantom{If }$\begin{aligned}
  a_{11}^2 & = 1 \\ 
 a_{22}^2 & = 1 
\end{aligned}$

\phantom{If } if $a_{21} =0 $, then $A = \pm \left[ \begin{matrix} 1 & 0 \\ 0 & -1 \end{matrix} \right]$, $\pm \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right]$ \\
\phantom{ If If } if $a_{21} \neq 0$, $a_{21}a_{11} = - a_{22} a_{21} \Longrightarrow a_{11} = -a_{22}$ \\
If $a_{21} =0$, $a_{11}^2 = a_{22}^2 = 1$ \\
\quad \, if $a_{21} \neq 0$, then $a_{11} a_{12} = -a_{12} a_{22} \Longrightarrow a_{11} = - a_{22}$ 

If $a_{12}, a_{21} \neq 0$, then \\
$\begin{aligned}
a_{11}^2 + a_{12}a_{21} &= 1
a_{22}^2 + a_{12}a_{21} &= 1
\end{aligned}$  
\[
\Longrightarrow \left[ \begin{matrix} \sqrt{ 1 - bc} & b \\ c & -\sqrt{ 1 - bc} \end{matrix} \right]
\]

\exercisehead{13} Given \\
$A = \left[ \begin{matrix} 2 & -1 \\ -2 & 3 \end{matrix} \right]$, \, $B = \left[ \begin{matrix} 7 & 6 \\ 9 & 8 \end{matrix} \right]$.  Find $2\times 2$ matrices $C$ and $D$ s.t. $\begin{aligned} AC & = B \\ DA & = B \end{aligned}$  
\[
A^{-1} = \frac{1}{4} \left[ \begin{matrix} 3 & 1 \\ 2 & 2 \end{matrix} \right] \quad \quad \, \begin{aligned} & A^{-1} AC = C = A^{-1} B \\ & DAA^{-1} = D = BA^{-1} \end{aligned} \quad \quad \, \begin{aligned} & \frac{1}{4} \left[ \begin{matrix} 3 & 1 \\ 2 & 2 \end{matrix} \right] \left[ \begin{matrix} 7 & 6 \\ 9 & 8 \end{matrix} \right] = \frac{1}{4} \left[ \begin{matrix} 30 & 26 \\ 32 & 28 \end{matrix} \right] & = C \\ & \left[ \begin{matrix} 7 & 6 \\ 9 & 8 \end{matrix} \right] \frac{1}{4} \left[ \begin{matrix} 3 & 1 \\ 2 & 2 \end{matrix} \right] = \frac{1}{4} \left[ \begin{matrix} 33 & 19 \\ 43 & 25 \end{matrix} \right] & = D
\end{aligned}
\]

\exercisehead{14} \begin{enumerate}
\item \[
\begin{aligned}
  AB & = \left[ \begin{matrix} 1 & -1 \\ 0 & 2 \end{matrix} \right]\left[ \begin{matrix} 1 & 0 \\ 1 & 2 \end{matrix} \right]  & = \left[ \begin{matrix} 0 & -2 \\ 2 & 4 \end{matrix} \right] \\ BA & = \left[ \begin{matrix} 1 & 0 \\ 1 & 2 \end{matrix} \right]\left[ \begin{matrix} 1 & - 1 \\ 0 & 2 \end{matrix} \right] & = \left[ \begin{matrix} 1 & -1 \\ 1 & 3 \end{matrix} \right] 
\end{aligned} \quad \quad \, AB \neq BA
\]
\item \[ \begin{aligned}
  & (A+B)^2  = A^2 + AB + BA + B^2 \\
  & (A+B)(A-B) = A^2 - AB + BA - B^2
\end{aligned}
\]
\item $[A,B] =0$
\end{enumerate}


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 2.20 Exercises - Systems of linear equations, Computation techniques, Inverses of square matrices }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} 
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & 1 & 3 \\ 2 & -1 & 4 \\ & -1 & 1 \end{matrix} \right] \left[ \begin{matrix} x \\ y \\ z \end{matrix} \right] = \left[ \begin{matrix} 5 \\ 11 \\ 3 \end{matrix} \right] \\
  \left[ \begin{matrix} 1 & 1 & 3 \\ 2 & -1 & 4  \\ & -1 & 1 \end{matrix} \right| \left. \begin{matrix} 5 \\ 11 \\3 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 4 \\ 2 & 0 & 3 \\ & -1 & 1 \end{matrix} \right| \left. \begin{matrix} 8 \\ 8 \\ 3 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 &  1 & 0 \end{matrix} \right| \left. \begin{matrix} 8/5 \\ 8/5 \\ -7/5 \end{matrix} \right]
\end{gathered}
\]

\exercisehead{2} Solution doesn't exist since 
\[
\begin{aligned}
  5x + 3y + 3z & = 2 \\
  3x + 2y + z & = 1 
\end{aligned} \quad \quad \, \Longrightarrow x+ y - z = 0 \text{ but } x + y - z = 1 
\]

\exercisehead{3}
\[
\left[ \begin{matrix} 3 & 2 & 1 \\ 5 & 3 & 3 \\ 7 & 4 & 5 \end{matrix} \right| \left. \begin{matrix} 1 \\ 2 \\ 3 \end{matrix} \right] = \left[ \begin{matrix} 0 & 2 & -8 \\ 0 & 3 & -12 \\ 1 & 0 & 3 \end{matrix} \right| \left. \begin{matrix} -2 \\ -3 \\ 1 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 & 0 \\ 0 & 1 & -4 \\ 1 & 0 & 3 \end{matrix} \right| \left. \begin{matrix} 0 \\ -1 \\ 1 \end{matrix} \right] 
\]
\[
\begin{aligned}
  x & = 1 - 3z \\
  y & = -1 + 4 z 
\end{aligned} \quad \Longrightarrow \boxed{\left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix} 1 \\ -1 \\ 0 \end{matrix} \right) + z \left( \begin{matrix} -3 \\ 4 \\ 1 \end{matrix} \right) }
\]

\exercisehead{4}
\[
\left[ \begin{matrix} 7 & 4 & 5 \\ 1 & 1 & -1 \end{matrix} \right| \left. \begin{matrix} 3 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 0 & -3 & 12 \\ 1 & 1 & -1 \end{matrix} \right| \left. \begin{matrix} 3 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 3 \\ 0 & 1 & -4 \end{matrix} \right| \left. \begin{matrix} 1 \\ -1 \end{matrix} \right]
\]
\[
\begin{aligned}
  x + 3z & = 1 \\
  y - 4 z & = -1 
\end{aligned} \quad \, \boxed{ \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix} 1 \\ -1 \\ 0 \end{matrix} \right) + z\left( \begin{matrix} -3 \\ 4 \\ 1 \end{matrix} \right) }
\]

\exercisehead{5} 
\[
\left[ \begin{matrix} 3 & -2 & 5 & 1 \\ 1 & 1 & -3 & 2 \\ 6 & 1 & -4 & 3 \end{matrix} \right| \left. \begin{matrix} 1 \\ 2 \ 7 \end{matrix} \right] = \left[ \begin{matrix} 0 & -5 & 14 & -5 \\ 1 & 1 & -3 & 2 \\ 0 & -5 & 14 & -9 \end{matrix} \right| \left. \begin{matrix} -5 \\ 2 \ -5 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 & 0 & 4 \\ 1 & 1 & -3 & 0 \\0 & -5 & 14 & 0 \end{matrix} \right| \left. \begin{matrix} 0 \\ 2 \ -5 \end{matrix} \right]  \quad \, \Longrightarrow \boxed{ \left( \begin{matrix} x \\ y \\ z \\ u \end{matrix} \right) = \left( \begin{matrix} 1 \\ 1 \\ 0 \\ \end{matrix} \right) + z \left( \begin{matrix} 1/5 \\ 14/5 \\ 1 \\ 0 \end{matrix} \right) }
\]

\exercisehead{6}
\[
\left[ \begin{matrix} 1 & 1 & -3 & 1 \\ 2 & -1 & 1 & -2 \\ 7 & 1 & -7 & 3  \end{matrix} \right| \left. \begin{matrix} 5 \\ 2 \\ 3 \end{matrix} \right] = 
\left[ \begin{matrix} 1 & 1 & -3 & 1 \\ 0 & -3 & 7 & -4 \\ 0 & -6 & 14 & -4  \end{matrix} \right| \left. \begin{matrix} 5 \\ -8 \\ -32 \end{matrix} \right] = \left[ \begin{matrix} 1 & 1 & -3 & 1 \\ 0 & 0 & 0 & -2 \\ 0 & -1 & 7/3 & -2/3  \end{matrix} \right| \left. \begin{matrix} 5 \\ 8 \\ -16/3 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & -2/3 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 1 & -7/3 & 0  \end{matrix} \right| \left. \begin{matrix} 1 \\ -4 \\ 8 \end{matrix} \right]
\]
\[
\begin{aligned}
  x + \frac{-2}{3} z & = 1 \\
  u & = -4 \\
  y - \frac{7}{3} z & = 8 
\end{aligned} \quad \, \boxed{ \left( \begin{matrix} x \\ y \\ z \\ u \end{matrix} \right)  = \left( \begin{matrix} 1 \\ 8 \ 0 \\ -4 \end{matrix} \right) + z \left( \begin{matrix} 2/3 \\ 7/3  \\ 1 \\ 0 \end{matrix} \right) }
\]

\exercisehead{7}
\[
\left[ \begin{matrix} 1 & 1 & 2 & 3 & 4 \\ 2& 2 & 7 & 11 & 14 \\ 3& 3& 6 & 10 & 15 \end{matrix} \right| \left. \begin{matrix} 0 \\ 0 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 1 & 1 & 2 & 3 & 4 \\ 0 & 0 & 3 & 5 & 6 \\ 0 & 0 & 0 & 1 & 3 \end{matrix} \right| \left. \begin{matrix} 0 \\ 0 \\ 0 \end{matrix} \right]  \Longrightarrow \begin{aligned} x + y & = -v \\ z & = 3v \\ u & = -3v \end{aligned} \Longrightarrow \boxed{ \left( \begin{matrix} x \\ y \\ z \\ u \\ v \end{matrix} \right) = x \left( \begin{matrix} 1 \\ - 1 \\ 0 \\ 0 \\ 0 \end{matrix} \right) + v \left( \begin{matrix} 0 \\ -1 \\ 3 \\ -3 \\ 1 \end{matrix} \right) } 
\]

\exercisehead{8} 
\[
\left[ \begin{matrix} 1 & -2 & 1 & 2 \\ 2 & 3 & -1 & -5 \\ 4 & -1 & 1 & -1 \\ 5 & -3 & 2 & 1 \end{matrix} \right| \left. \begin{matrix} -2 \\ 9 \\ 5 \\ 3 \end{matrix} \right] = \left[ \begin{matrix} 1 & -2 & 1 & 2 \\ 0 & 7 & -3 & -9 \\ 0 & 7 & -3 & -9 \\ 0 & 7 & -3 & -9 \end{matrix} \right| \left. \begin{matrix} -2 \\ 13 \\ 13 \\ 13 \end{matrix} \right] \Longrightarrow \begin{aligned} x + \frac{1}{7} z - \frac{4}{7} u & = \frac{12}{7} \\ y + \frac{-3}{7} z - \frac{9}{7} u & = \frac{13}{7} \end{aligned} \]
\[
\Longrightarrow \boxed{ \left[ \begin{matrix} x \\ y \\ z \\ u \end{matrix} \right] = \left( \begin{matrix} 12/7 \\ 13/7 \\ 0 \\ 0 \end{matrix} \right) + z \left( \begin{matrix} -1/7 \\ 3/7 \\ 1 \\ 0 \end{matrix} \right) + u \left( \begin{matrix} 4/7 \\ 9/7 \\ 0 \\ 1 \end{matrix} \right) }
\]

\exercisehead{9} 
\[
\left[ \begin{matrix} 1 & 1 & 2 \\ 2 & -1 & 3 \\ 5 & -1 & a \end{matrix} \right. \left| \begin{matrix} 2 \\ 2 \\ 6 \end{matrix} \right] = \left[ \begin{matrix} 1 & 1 & 2 \\ 0 & -3 \\ &  -1 \\ 0 & -6 & a - 10 \end{matrix} \right| \left. \begin{matrix} 2 \\ -2 \\ -4 \end{matrix} \right] \quad \, \text{ if } a - 8 \neq 0, \quad \, \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix} 4/3 \\ 2/3 \\ 0 \end{matrix} \right)
\]
\[
\text{ if } a = 8, \quad \, \left[ \begin{matrix} 1 & 1 & 2 \\ & -3 & -1 \end{matrix} \right| \left. \begin{matrix} 2 \\ -2 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 5/3 \\ & 1 & 1/3 \end{matrix} \right. \left| \begin{matrix} 4/3 \\ 2/3 \end{matrix} \right] \Longrightarrow \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = z \left( \begin{matrix} -5/3 \\ -1/3 \\ 1 \end{matrix} \right) + \left( \begin{matrix} 4/3 \\ 2/3 \\ 0 \end{matrix} \right) 
\]

\exercisehead{10} 
\begin{enumerate}
\item  \[
\left( \begin{matrix} x \\ y \\ z \\ u \end{matrix} \right) = \left( \begin{matrix} -5/7 \\ 9/7 \\ 0 \\ 0 \end{matrix} \right) + z \left( \begin{matrix} 4/7 \\ 11/7 \\ 1 \\ 0 \end{matrix} \right) +  u \left( \begin{matrix} 0 \\ -1 \\ 0 \\ 1 \end{matrix} \right)
\]
\item 
\[
\left[ \begin{matrix} 5 & 2 & -6 2 \\ 1 & -1 & 1 & -1 \\ 1 & 1 & 1 & 0 \end{matrix} \right| \left. \begin{matrix} -1 \\ -2 \\ 6 \end{matrix} \right] = \left[ \begin{matrix} 0 & -3 & -11 & 2 \\ 0 & -2 & 0 & -1 \\ 1 & 1 & 1 & 0 \end{matrix} \right. \left| \begin{matrix} -31 \\ -8 \\ 6 \end{matrix} \right] = \left[ \begin{matrix} 0 & 0 & -11 & 7/2 \\ 0 & 1 & 0 & 1/2 \\ 1 & 0 & 1 & -1/2 \end{matrix} \right. \left| \begin{matrix} -19 \\ 4 \\ 2 \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 0 & -2/11 \\ 0 & 1 & 0 & 1/2 \\ 0 & 0 & -1 & 7/22 \end{matrix} \right. \left| \begin{matrix} 3/11 \\ 4 \\ -19/11 \end{matrix} \right] \\
\]
\[
\boxed{ \left( \begin{matrix} x \\ y \\ z \\ u \end{matrix} \right) = \left( \begin{matrix} 3/11 \\ 4 \\ 19/11 \\ 0 \end{matrix} \right) + u \left( \begin{matrix} 2/11 \\ -1/2 \\ 7/22 \\ 1 \end{matrix} \right) }
\]
\end{enumerate}

\exercisehead{11} 
\[
\left[ \begin{matrix} a & b \\ c & d \end{matrix} \right] \left[ \begin{matrix} d & -b \\ -c & a \end{matrix} \right] = \left[ \begin{matrix} ad -bc & -ba + ba \\ cd -cd & -bc + ad \end{matrix} \right] = (ad-bc) I 
\] 
If $ad-bc \neq 0$, then for $A = \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right]$, 
\[
A^{-1} = \frac{1}{ad-bc} \left[ \begin{matrix} d & -b \\ -c & a \end{matrix} \right] 
\]
otherwise, if $ad-bc =0$, $\left[ \begin{matrix} a & b \\ c & d \end{matrix} \right] \left[ \begin{matrix} d & -b \\ -c & a \end{matrix} \right] = 0$ \\

Use thm. from determinants.
\[
\begin{gathered}
  det(AA^{-1}) = det{A} det{A^{-1}} = det{I} = 1 \\
  det{A}, \, det{A^{-1}} \neq 0 
\end{gathered}
\]

\exercisehead{12} $\left[ \begin{matrix} 2 & 3 & 4 \\ 2 & 1 & 1 \\ -1 & 1 & 2 \end{matrix} \right]$.  
\[
\begin{gathered}
  \left[ \begin{matrix} 2 & 3 & 4 \\ 2 & 1 & 1 \\ -1 & 1 & 2 \end{matrix} \right. \left| \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] =   \left[ \begin{matrix} 0 & 5 & 8 \\ 0 & 3 & 5 \\ -1 & 1 & 2 \end{matrix} \right. \left| \begin{matrix} 1 & & 2 \\ & 1 & 1 \\ & & 1 \end{matrix} \right] =   \left[ \begin{matrix} 0 & 1 & 8/5 \\ 0 & 0 & 1/5 \\ 1 & -1 & 2 \end{matrix} \right. \left| \begin{matrix} 1/5 & 0 & 2/5  \\ -3/5  & 1 & 4/5 \\ & & -1 \end{matrix} \right] = \\
=   \left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & -1 & 0 \end{matrix} \right. \left| \begin{matrix} 5 & -8 & -6 \\ -3 & 5 & 4 \\ -6 & 10 & 7 \end{matrix} \right] =   \left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{matrix} \right. \left| \begin{matrix} 5 & -8 & -6 \\ -3 & 5 & 4 \\ -3  & 5 & 4  \end{matrix} \right] =   
\end{gathered}
\]
\[
\Longrightarrow \boxed{ \left[ \begin{matrix} -1 & 2 & 1 \\ 5 & -8 & -6 \\ -3 & 5 & 4 \end{matrix} \right] }
\]

\exercisehead{13} 
\[
\begin{gathered}
    \left[ \begin{matrix} 1 & 2 & 2 \\ 2 & -1 & 1 \\ 1 & 3 & 2 \end{matrix} \right. \left| \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] = 
  \left[ \begin{matrix} 1 & 0 & 2 \\ 0 & -1 & -3 \\ 0 & 1 & 0 \end{matrix} \right. \left| \begin{matrix} 3 & & -2 \\ -6 & 1 & 4 \\ -1 & 0 & 1 \end{matrix} \right] = 
  \left[ \begin{matrix} 1 & 0 & 2 \\ 0 & 0 & -3 \\ 0 & 1 & 0 \end{matrix} \right. \left| \begin{matrix} 3 & & 2 \\ -7 & 1 & 5 \\ -1 & & 1 \end{matrix} \right] =
  \left[ \begin{matrix} 1 &  &  \\  &  & 1 \\  & 1 &  \end{matrix} \right. \left| \begin{matrix} -5/3 & 2/3 & 4/3 \\ 7/3 & -1/3 & -5/3 \\ -1 & & 1 \end{matrix} \right] \\
  \boxed{ \left[ \begin{matrix} \frac{-5}{3} & \frac{2}{3} & \frac{4}{3} \\ -1 & 0 & 1 \\ \frac{7}{3} & \frac{-1}{3} & \frac{-5}{3} \end{matrix} \right] }
\end{gathered}
\]

\exercisehead{14} 
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & -2 & 1 \\ -2 & 5 & -4 \\ 1 & -4 & 6 \end{matrix} \right. \left| \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] = 
    \left[ \begin{matrix} 1 & 0 & -3 \\ 0 & 1 & -2 \\ 0 & -2 & 5 \end{matrix} \right. \left| \begin{matrix} 5 & 2 & \\ 2 & 1 & \\ -1 & & 1 \end{matrix} \right] = 
  \left[ \begin{matrix} 1 &  &  \\  & 1 &  \\  &  & 1 \end{matrix} \right. \left| \begin{matrix} 14 & 8 & 3 \\ 8 & 5 & 2 \\ 3 & 2  & 1 \end{matrix} \right]  \\
  \boxed{ \left[ \begin{matrix} 14 & 8 & 3 \\ 8 & 5 & 2 \\ 3 & 2 & 1 \end{matrix} \right] }
\end{gathered}
\]

\exercisehead{15} 
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & 2 & 3 & 4 \\ & 1 & 2 & 3 \\ & & 1 & 2 \\ & & & 1 \end{matrix} \right. \left| \begin{matrix} 1 & & & \\ & 1 & & \\ & & 1 & \\ & & & 1 \end{matrix} \right] = 
  \left[ \begin{matrix} 1 &  & -1 & -2 \\ & 1 &  & -1 \\ & & 1 &  \\ & & & 1 \end{matrix} \right. \left| \begin{matrix} 1 & -2  & & \\ & 1 & -2 & \\ & & 1 & -2 \\ & & & 1 \end{matrix} \right] = 
  \left[ \begin{matrix} 1 &  &  & -2 \\ & 1 &  &  \\ & & 1 &  \\ & & & 1 \end{matrix} \right. \left| \begin{matrix} 1 & -2 & 1 & -2 \\ & 1 & -2 & 1 \\ & & 1 & -2 \\ & & & 1 \end{matrix} \right] = \\
 \boxed{ \left[ \begin{matrix} 1 & -2 & 1 & 0 \\ & 1 & -2 & 1 \\ & & 1 & -2 \\ 1 \end{matrix} \right] }
\end{gathered}
\]

\exercisehead{16} $\left[ \begin{matrix} & 1 & & & &  \\ 2 & 0 & 2 & & & \\ & 3 & & 1 & & \\ & & 1 & & 2 & \\ & & & 3 & & 1 \\ & & &  & 2 & \end{matrix} \right]^{-1} = \left[ \begin{matrix} & 1/2 & & -1 & & 1 \\ 1 & & & & & \\ & & & 1 & & -1 \\ -3 & & 1 & & & \\ & & & & & 1/2 \\ 9 & & -3 & & 1 & \end{matrix} \right] $


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 2.21 Miscellaneous exercises on matrices }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{3} Use the eigenvalue method.  
\[
\begin{aligned}
  \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right]\left[ \begin{matrix} x \\ y \end{matrix} \right] = -\left[ \begin{matrix} x \\ y \end{matrix} \right]  & \Longrightarrow \left[ \begin{matrix} x \\ y \end{matrix} \right] = \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right] \\
  \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right] \left[ \begin{matrix} x \\ y \end{matrix} \right] = 6 \left[ \begin{matrix} x \\ y \end{matrix} \right] & \Longrightarrow \begin{aligned} x + 2y & = 6x \\ 2y & = 5x \end{aligned} \quad \, \left[ \begin{matrix} x \\ y \end{matrix} \right] = \left[ \begin{matrix} 2 \\ 5 \end{matrix} \right] 
\end{aligned}
\]
Indeed, we obtain $P$ since
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right] \left[ \begin{matrix} \frac{2}{\sqrt{29} } & \frac{1}{\sqrt{2}} \\ \frac{5}{\sqrt{29}} & \frac{-1}{\sqrt{2}} \end{matrix} \right] = \left[ \begin{matrix} \frac{12}{\sqrt{29}} & \frac{-1}{\sqrt{2}} \\ \frac{30}{\sqrt{29}} & \frac{-1}{\sqrt{2}} \end{matrix} \right] \\
  \frac{1}{ \frac{-7 }{\sqrt{58}} } \left[ \begin{matrix} \frac{-1}{\sqrt{2}} & \frac{-1}{\sqrt{2}} \\ \frac{-5}{\sqrt{29}} & \frac{2}{\sqrt{29}} \end{matrix} \right] \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right] \left[ \begin{matrix} \frac{2}{\sqrt{29}} & \frac{1}{\sqrt{2}} \\ \frac{5}{\sqrt{29}} & \frac{-1}{\sqrt{2}}\end{matrix} \right] = \left[ \begin{matrix} 6 & \\ & -1 \end{matrix} \right] \\
\boxed{ P = \left[ \begin{matrix} \frac{2}{\sqrt{29}} & \frac{1}{\sqrt{2}} \\ \frac{5}{\sqrt{29}}  & \frac{-1}{\sqrt{2}} \end{matrix} \right] }
\end{gathered}
\]

\exercisehead{4} $(A^2)_{ij} = \sum_{k=1}^2 a_{ik} a_{kj} = a_{il} a_{1j} + a_{i2} a_{2j} = a_{ij} $ \\
If $i = j$, $a_{i1} a_{1i} + a_{i2} a_{2i} = a_{ii}$ \\
\quad \, it must be that $i=1$ or $i=2$.  Then rewrite as $a_{ii}^2 + a_{ij} a_{ji} = a_{ii}$ \\
If $i \neq j$.  $a_{i1} a_{1j} + a_{i2}a_{2j} = a_{ij}$ \\
\quad \, it must be that $i=1$ or $i=2$ and $j=2$ or $j=1$, respectively.  then 
\[
a_{ii} a_{ij} + a_{ij} a_{jj} = a_{ij}
\]
If $a_{ij} = 0$, $a_{ii}^2 = a_{ii}$.  \quad \, $a_{ii} = 1$
\[
\left[ \begin{matrix} 1 & a \\ 0 & 1 \end{matrix} \right] \left[ \begin{matrix} 1 & a \\ 0 & 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & 2a \\ 0 & 1 \end{matrix} \right] = A \Longrightarrow a = 2a, \text{ so } a =0
\]
If $a_{ij} \neq 0$, $a_{ii} + a_{jj} =1$ \\
Note that $a_{ij}, a_{ji}$ must be both nonzero for the following: 
\[
\begin{gathered}
  a_{ii}^2 - a_{ii} + a_{ij} a_{ji} = 0 \\
  \begin{aligned}
    a_{ii} & = \frac{ 1 \pm \sqrt{ 1 - 4 a_{ij} a_{ji} } }{ 2 } \\
    a_{jj} & = 1 - a_{ii} = \frac{ 1 \mp \sqrt{ 1 - 4a_{ij} a_{ji} } }{ 2}
\end{aligned}
\end{gathered}
\]

\exercisehead{5} $A^2 = A$
\[
\begin{aligned}
  (A+I)^2 & = 3A + I \\
  (A+I)^3 & = (3A+I)(A+I) = 7A + I \\
  (A+I)^{k+1} & = (I +(2^k - 1)A)(A+I) = A(1 + 2^k - 1) + I + (2^k -1)A = (2^{k+1} -1)A + I 
\end{aligned}
\]

\exercisehead{6} \quad \\ $\begin{aligned} x' & = a(x-vt) \\ y' & = y \\ z' & = z \\ t'  & = a(t-vx/c^2) \end{aligned}$ 
\[
\begin{aligned}
  L(v) & = a \left[ \begin{matrix} 1 & -v \\ -vc^{-2} & 1 \end{matrix} \right] \\
  L(v)L(u) & = a \left[ \begin{matrix} 1 & -v \\ -vc^{-2} & 1 \end{matrix} \right] b \left[ \begin{matrix} 1 & -u \\ -uc^{-2} & 1 \end{matrix} \right] = ab \left[ \begin{matrix} 1 + uv /c^2 & -u -v \\ \frac{ -v - u}{c^2} & \frac{uv}{c^2} + 1 \end{matrix} \right] \\
  & = \frac{c}{\sqrt{ c^2 - v^2} } \frac{c}{\sqrt{ c^2 - u^2} } \left( 1 + \frac{uv}{c^2} \right) \left[ \begin{matrix} 1 & \frac{ - (u+v)}{ 1 + uv/c^2 } \\ \frac{ -(u+v) }{ 1 + \frac{uv}{c^2} } & 1 \end{matrix} \right]
\end{aligned}
\]
\[
\begin{aligned}
\gamma & = \frac{1}{ \sqrt{ 1 - \left( \frac{w}{c} \right)^2 } } = \left( 1 - \left( \frac{ -(u+v) /c }{ (1 + \frac{uv}{c^2} ) }\right)^2 \right)^{-1/2}  = \left( \left( 1 + \frac{2uv}{c^2} + \frac{u^2 v^2 }{c^4} - \left( \frac{u^2 + 2uv + v^2}{c^2} \right) \right)/\left( 1 + \frac{uv}{c^2} \right)^2 \right)^{-1/2} =  \\
& = \left( \left( 1 + \frac{u^2 v^2}{c^2} - \frac{u^2}{c^2} - \frac{v^2}{c^2} \right)/\left( 1 + \frac{uv}{c^2} \right)^2 \right)^{-1/2}
\end{aligned}
\]


\exercisehead{7} \begin{enumerate} \item $(A^T)_{ij} = A_{ji}$ \\
$  (A^T)^T_{ij} = (A^T)_{ji} = A_{ij} \Longrightarrow (A^T)^T = A$
\item $(A+B)^T_{ij} = (A+B)_{ji} = A_{ji} + B_{ji} = A^T_{ij} + B^T_{ij} \Longrightarrow (A+B)^T = A^T + B^T$
\item $(cA)^T_{ij} = (cA)_{ji} = c_A{ji} = c(A^T)_{ij}$
\item $(AB)^T_{ij} = (AB)_{ji} = \sum_{k} a_{jk} b_{ki} = \sum_k b_{ki} a_{jk} = \sum_k (B^T)_{ik} (A^T)_{kj} = (B^T A^T)_{ij}$
\item $A^{-1}A =1 \Longrightarrow (A^{-1} A)^T = A^T (A^{-1})^T = 1$  then $(A^{-1})^T = (A^T)^{-1}$ (recall that a right inverse is also a left inverse).  
\end{enumerate}

\exercisehead{8} $\left[ \begin{matrix} \cos{\theta} & - \sin{\theta} \\ \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} \cos{\theta} & \sin{\theta} \\ -\sin{\theta} & \cos{\theta} \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right]$
\[
A_i A_j = \sum_{k=1}^n a_{ik} a_{jk} = \sum_{k=1}^n a_{ik} a_{kj}^T = (AA^T)_{ij} = \delta_{ij}
\]

\exercisehead{9} \begin{enumerate} \item If $\begin{aligned} AA^T & = 1 \\ BB^T & = 1 \end{aligned}$, \, $(A+B)(A+B)^T = 2 + BA^T + AB^T$ \item $(AB)(AB)^T = (AB)B^T A^T = 1$ \item $B$ is given to be orthogonal.\end{enumerate}

\exercisehead{10} 
\begin{enumerate}
  \item \[
\left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right]  \, \left[ \begin{matrix} 1 & 1 \\ -1 & 1 \end{matrix} \right]  \, \left[ \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right]  \, \left[ \begin{matrix} 1 & -1 \\ 1 & -1 \end{matrix} \right]  \, \left[ \begin{matrix} -1 & 1 \\ 1 & 1 \end{matrix} \right]  \, \left[ \begin{matrix} -1 & 1 \\ -1 & -1 \end{matrix} \right]  \, \left[ \begin{matrix} -1 & -1 \\ 1 & -1 \end{matrix} \right]  \, \left[ \begin{matrix} -1 & -1 \\ -1 & -1 \end{matrix} \right]  \,
\]
\item $(X+Y)\cdot (X+Z) = X^2 + X\cdot Z + Y \cdot X + Y \cdot Z = X^2 $ Lemma 1 is true.  \\
Lemma 2 \quad $(x_i + y_i)(x_i + z_i) = x_i^2 + x_i (z_i + y_i)  + y_i z_i $ 
\[
\begin{matrix}
 & x_i & y_i & z_i & \, \\
&  1 & 1 & 1 & 4 \\
&  1 & 1 & -1 & 0 \\
&  1 & -1 & -1 & 0 \\
&  1 & -1 & 1 & 0 \\
&  -1 & 1 & 1 & 0 \\
&  -1 & -1 & 1 & 0 \\
&  -1 & 1 & -1 & 0 \\
&  -1 & -1 & -1 & 4
\end{matrix}
\]
Assume $A$ is Hadamard.  \\
\quad Then by Lemma 1, $(A_i + A_j) \cdot (A_i + A_k) = A_i^2 = n $, \, $i,j,k$ distinct.  \[ \begin{aligned}
  (A_i + A_j) \cdot (A_i + A_k) & = A_i^2 + A_i \cdot A_k + A_j \cdot A_i + A_j \cdot A_k = \sum_{l=1}^n a_{il}^2 + \sum_{l=1}^n a_{il} a_{kl} + \sum_{l=1}^n a_{jl} a_{il} + \sum_{l=1}^n a_{jl} a_{kl} = \\
  & = \sum_{l=1}^n (a_{il} + a_{jl})(a_{il} + a_{kl})
\end{aligned}
\]
By Lemma 2, $(a_{il} + a{jl})(a_{il} + a_{kl}) = 0 \text{ or } 4 $ \\
\quad then $(A_i + A_j) \cdot (A_i + A_k) = \sum_{l=1}^n (a_{il} + a_{jl}) (a_{il} + a_{kl}) = 4m$, where $m\leq n $ \\
$\Longrightarrow \boxed{ n = 4m} $
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 3.6 Exercises - Introduction, Motivation for the choice of axioms for a determinant function, A set of axioms for a determinant function, Computation of determinants, }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} \begin{enumerate}
\item $\left| \begin{matrix} 2 & 1 & 1 \\ 1 & 4 & -4 \\ 1 & 0 & 2 \end{matrix} \right|$ 
\[
\left| \begin{matrix} 0 & 1 & -3 \\ 0 & 4 & -6 \\ 1 & 0 & 2 \end{matrix} \right| = \left| \begin{matrix} 0 & 1 & -3 \\ 0 & 0 & -6 \\ 1 & 0 & 2 \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 2 \\ 0 & 1 & -3 \\ 0 & 0 & -6 \end{matrix} \right| = \boxed{ 6 } 
\]
\item $ \left| \begin{matrix} 3 & 0 & 8 \\ 5 & 0 & 7 \\ -1 & 4 & 2 \end{matrix} \right| = 3(-28) + 8 (20) = 4 ( -3 (7) + 2 (20) ) = \boxed{ 76 } $
\item $\left| \begin{matrix} a & 1 & 0 \\ 2 & a & 2 \\ 0 & 1 & a \end{matrix} \right| = a(a^2 - 2) - 1 (2a) = a(a^2 -4) = a(a-2)(a+2)$
\end{enumerate}

\exercisehead{2} Given $det{ \left[ \begin{matrix} x & y & z \\ 3 & 0 & 2 \\ 1 & 1 & 1 \end{matrix} \right]} = 1$,  
\begin{enumerate}
\item $\left[ \begin{matrix} 2x & 2y & 2z \\ \frac{3}{2} & 0 & 1 \\ 1 & 1 & 1 \end{matrix} \right]$ 
\[
\left| \begin{matrix} 2x & 2y & 2z \\ \frac{3}{2} & 0 & 1 \\ 1 & 1 & 1 \end{matrix} \right| = 2\left( \frac{1}{2} \right) det{A} = 1 
\]
\item $\left[ \begin{matrix} x & y & z \\ 3x+3 & 3y & 3z + 2 \\ x + 1 & y + 1 & z + 1 \end{matrix} \right]$ 
\[
\left| \begin{matrix} x & y & z \\ 3x + 3 & 3y & 3z + 2 \\ x + 1 & y + 1 & z + 1 \end{matrix} \right| = \left| \begin{matrix} x & y & z \\ 3x + 3 & 3y & 3z + 2  \\ x & y & z \end{matrix} \right| + \left| \begin{matrix} x & y & z \\ 3x+ 3 & 3y & 3z + 2 \\ 1 & 1 & 1 \end{matrix} \right| = 0 + \left| \begin{matrix} x & y & z \\ 3x & 3y & 3z \\ 1 & 1 & 1 \end{matrix} \right| + \left| \begin{matrix} x & y & z \\ 3 & 0 & 2 \\ 1 & 1 & 1 \end{matrix} \right| = \boxed{ 1 } 
\]
\item $\left[ \begin{matrix} x - 1 & y -1 & z -1 \\ 4 & 1 & 3 \\ 1 & 1 & 1 \end{matrix} \right]$ 
\[
\left| \begin{matrix} x - 1 & y - 1 & z - 1 \\ 4 & 1 & 3 \\ 1 & 1 & 1 \end{matrix} \right| = \left| \begin{matrix} x & y & z \\ 4 & 1 & 3 \\ 1 & 1 & 1 \end{matrix} \right| + \left| \begin{matrix} -1 & - 1 & -1 \\ 4 & 1 & 3 \\ 1 & 1 & 1 \end{matrix} \right| = \left| \begin{matrix} x & y & z \\ 3 + 1 & 0 + 1 & 2 + 1 \\ 1 & 1 & 1 \end{matrix} \right| = \boxed{ 1 } 
\]
\end{enumerate}

\exercisehead{3}
\begin{enumerate}
\item \[
  \begin{gathered}
\left| \begin{matrix} 1 & 1 & 1 \\ 0 & b-a & c-a \\ 0 & b^2 - a^2 & c^2 - a^2 \end{matrix} \right| = \left| \begin{matrix} 1 & 1 & 1 \\ 0 & b-a & c-a \\ 0 & 0 & (c^2 - a^2)-(c-a)(b+a) \end{matrix} \right| = (b-a)((c-a)(c+a) - (c-a)(b+a)) = \\ 
= \boxed{ (b-a)(c-a)(c-b)  }
\end{gathered}
\]
\item \[
      \left| \begin{matrix} 1 & 1 & 1 \\ a & b & c \\ a^3 & b^3 & c^3 \end{matrix} \right|  = \left| \begin{matrix} 1 & 1 & 1 \\ 0 & b-a & c-a \\ 0 & b^3 -a^3 & c^3 -a^3 \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 0 \\ 0 & (b-a) & c-a \\ 0 & (b-a)(b^2 + ba + a^2) & (c-a)(c^2 + ca + a^2) \end{matrix} \right| \\
\]
\[
      \text{ subtract the second column off the third column modulo a factor }  \\
\]
\[
\begin{aligned}
 & \begin{gathered}
      \left( \begin{matrix} 0 - 0 \\ c-a - (c-a) \\ (c-a)( c^2 + ca + a^2 - (b^2 + ba +a^2) ) \end{matrix} \right)
\end{gathered} \\
    & = \left| \begin{matrix} 1 & 0 & 0 \\ 0 & (b-a) & 0 \\ 0 & (b-a)(b^2 +ba +a^2) & (c-a)(c^2 -b^2 +ca - ab) \end{matrix} \right|  = \quad \left| \begin{matrix} 1 & 0 & 0 \\ 0 & (b-a) & 0 \\ 0 & 0 & (c-a)(c-b)(c+b +a) \end{matrix} \right| \\
    & = (a+b+c)(c-a)(c-b)(b-a)
  \end{aligned}
  \]
\[
\begin{aligned}
\left| \begin{matrix} 1 & 1 & 1 \\ a^2 & b^2 & c^2 \\ a^3 & b^3 & c^3 \end{matrix} \right| & = \left| \begin{matrix} 1 & 1 & 1 \\ 0 & b^2 -a^2 & c^2 -a^2 \\ 0 & b^3 -a^3 & c^3 -a^3 \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 0 \\ 0 & (b-a)(b+a) & (c-a)(c+a) \\ 0 & (b-a)(b^2 +ba +a^2) & (c-a)(c^2 +ca +a^2) \end{matrix} \right|  \\
& \begin{gathered}
  \text{ subtract the second column off the third column modulo a factor } \\
  \left( \begin{matrix} 0 \\ (c-a)(c+a) \\ (c-a)(c^2 +ca +a^2) \end{matrix} \right) - \frac{ (c-a)(c+a)}{(b-a)(b+a)} \left( \begin{matrix} 0 \\ (b-a)(b+a) \\ (b-a)(b^2 +ba +a^2) \end{matrix} \right) = \\ 
  = \left( \begin{matrix} 0 \\ 0 \\ (c-a)(c^2 + ac + a^2 - \frac{ (c+a)}{(b+a)} (b^2 +ba +a^2) ) \end{matrix} \right) = \left( \begin{matrix} 0 \\ 0 \\ \frac{ (c-a)}{ (b+a)} (c-b)(ac +ab +bc) \end{matrix} \right) 
\end{gathered} \\
& = (b-a)(c-a)(c-b)(ac+ab+bc)
\end{aligned}
\]
\end{enumerate}

\exercisehead{4}
\begin{enumerate}
\item 
  \[
  \left| \begin{matrix} 1 & -1 & 1 & 1 \\ 1 & -1 & -1 & -1 \\ 1 & 1 & -1 & -1 \\ 1 & 1 & 1 & -1 \end{matrix} \right| = \left| \begin{matrix} 1 & 1 & 1 & 1 \\ -1 & -1 & 1 & 1 \\ 1 & -1 & -1 & 1 \\ 1 & -1 & -1 & -1 \end{matrix} \right| = \left| \begin{matrix} 1 & 1 & 1 & 1 \\ 0 & 0 & 2 & 2 \\ 2 & 0 & 0 & 2 \\ 2 & 0 & 0 & 0 \end{matrix} \right| = \left| \begin{matrix} 0 & 1 & 1 & 1 \\ 0 & 0 & 2 & 2 \\ 0 & 0 & 0 & 2 \\ 2 & 0 & 0 & 0 \end{matrix} \right| = (-1) 8
  \]
\item 
  \[
  \begin{aligned}
    \left| \begin{matrix} 1 & 1 & 1 & 1 \\ a & b & c & d \\ a^2 & b^2 & c^2 & d^2 \\ a^3 & b^3 & c^3 & d^3 \end{matrix} \right| & = \left| \begin{matrix} 1 & 1 & 1 & 1 \\ 0 & b-a & c-a & d-a \\ 0 & b^2 - a^2 & c^2 - a^2 & d^2 -a^2 \\ 0 & b^3 -a^3 & c^3 -a^3 & d^3 - a^3  \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & b-a & b^2 -a^2 & b^3 -a^3 \\ 0 & c-a & c^2 - a^2 & c^3 -a^2 \\ 0 & d-a & d^2 -a^2 & d^3 -a^3 \end{matrix} \right|  \\
      & = (b-a)(c-a)(d-a) \left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & 1 & (b+a) & b^2 + ba +a^2 \\ 0 & 1 & (c+a) & c^2 + ac + a^2 \\ 0 & 1 & (d+a) & d^2 + ad + a^2 \end{matrix} \right| = 
\end{aligned}
\]
\[
\begin{aligned}
      &  \text{ (Now I use the addition of column $ \begin{matrix} 0 \\ 1 \\ 1 \\ 1 \end{matrix} $, which doesn't change the determinant) } \\
 &   \quad \\ 
      & = (b-a)(c-a)(d-a) \left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & 1 & b & (b+a)b \\ 0 & 1 & c & (c+a)c \\ 0 & 1 & d & (d+a)d \end{matrix} \right|  = \\
    & \quad \quad = (b-a)(c-a)(d-a) \left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & 1  & 0 & 0 \\ 0 & 0 & c-b & (c+a)c - (b+a)b \\ 0 & 0 & d- b & (d+a)d - (b+a)b \end{matrix} \right| \\
\end{aligned}
\]
\[
\begin{aligned}
      & (b-a)(c-a)(d-a) \left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & c-b & c^2 - b^2 \\ 0 & 0 & d-b & d^2 - b^2 \end{matrix} \right| = \\
    & \quad \quad = (b-a)(c-a)(d-a)(c-b)(d-b)\left| \begin{matrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & c+b \\ 0 & 0 & 1 & d+b \end{matrix} \right| = \\
    & \boxed{ (b-a)(c-a)(d-a)(c-b)(d-b) (d-c) }
  \end{aligned} \]
\item 
\item \[
  \begin{aligned}
\left| \begin{matrix} a & 1 & 0 & 0 & 0 \\ 4 & a & 2 & 0 & 0 \\ 0 & 3 & a & 3 & 0 \\ 0 & 0 & 2 & a & 4 \\ 0 & 0 & 0 & 1 & a \end{matrix} \right| & = \left| \begin{matrix} a & 1 & & & \\ & a-\frac{4}{a} & 2 & & \\ & 3 & a & 3 & \\ & & 2 & a & 4 \\ & & & 1 & a \end{matrix} \right| = \left|  \begin{matrix} a & 0 & & & \\ & a-\frac{4}{a} & 2 & & \\ & 3 & a & 3 & \\ & & 2 & a - \frac{4}{a} & 4 \\ & & & 0  & a \end{matrix} \right|  \\
& = \left|  \begin{matrix} a &  & & & \\ & a-\frac{4}{a} &  & & \\ & 0 & a-\frac{12}{a-\frac{4}{a}} & 0 & \\ & & 0 & a-\frac{4}{a} & 0 \\ & & & 0 & a \end{matrix} \right| = \\ 
& = a^2 (a-\frac{4}{a})^2 \left( a - \frac{12}{a-\frac{4}{a}} \right) = a^2 (a-\frac{4}{a})(a^2 -4 - 12 )  \\
& = a(a^2 - 4)(a^2 -16)
  \end{aligned}
\]
\item \[
  \begin{aligned}
    \left| \begin{matrix} 1 & 1 & 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & -1 & -1 & -1 \\ 1 & 1 & -1 & -1 & 1 & 1 \\ 1 & -1 & -1 & 1 & -1 & 1 \\ 1 & -1 & 1 & -1 & 1 & 1 \\ 1 & -1 & -1 & 1 & 1 & -1 \end{matrix} \right|  & = \left| \begin{matrix} 1 & & & & & \\ 0 & 0 & 0 & -2 & -2 & -2 \\ & & -2 & -2 & & \\ & -2 & -2 & & -2 & \\ & -2 & & -2 & & \\ & -2 & -2 & & & -2 \end{matrix} \right| = \left| \begin{matrix} 1 & & & & & \\ & 2 & 2 & -2 & -2 & 0 \\ & & -2 & -2 & & \\ & -2 & -2 & & -2 &  \\ & -2 & & -2 & & \\ & 0 & 0 & & & -2 \end{matrix} \right|  \\
    & = \left| \begin{matrix} 1 & & & & & \\ & 2 & & & & \\ & & -2 & -2 & & \\ & & & -2 & -4 &  \\ & & 0 & -6 & -2 & \\ 0 & & 0 &  & & -2 \end{matrix} \right| = (1)(2)(-2)(-2)(10)(-2) = -160
  \end{aligned}
  \] 
\end{enumerate}

\exercisehead{5}  Consider $A = (a_{ij})$ s.t. $a_{ij} = 0$ whenever $i<j$.   \\
Suppose $a_{11} = 0$.  Then $a_{1j} = 0$, $\forall \, j \leq n$, since a row of $A$ is entirely zero, by homogeneity property of determinants, $det{A} =0$.   \\
Suppose $a_{ii} =0$ for some $1 < i \leq n$.  \\
\quad \, then $i$ rows have $n-(i-1)$ components equal to zero.  Therefore, these $i$ rows can span a psace of at most $i-1$ dimensions.  \\
\quad \quad \, then the $i$ rows are dependent.  Then $det{A} =0 $ by Thm. (the determinant vanishes if its rows are dependent).   \\
\quad Then assume $a_{ii}$ nonzero $\forall \, i \leq n$ \\

Let $A_n = B_n + C_n$, where $B_n = \left[ \begin{matrix} 0 & 0 & \dots & 0 & a_{nn} \end{matrix} \right]$ and $C_n = \left[ \begin{matrix} a_{n1} & a_{n2} & \dots & a_{n, \, n-1} & 0 \end{matrix} \right]$ 
\[
\begin{aligned}
  det{(A)} & = det{ (A_1, A_2, \dots, A_n) } = det{ ( A_1, \, A_2, \dots, B_n + C_n) } = det{(A_1, A_2, \dots, B_n)} + det{ (A_1, A_2, \dots, C_n) } = \\
  & = det{( A_1, A_2, \dots , B_n ) }
\end{aligned}
\]
Also, $A_{n-1} = B_{n-1} + C_{n-1}$, where $B_{n-1} = \left[ \begin{matrix} 0 & 0 & \dots & a_{n-1,n-1} & 0 \end{matrix} \right]$ and $C_{n-1} = \left[ \begin{matrix} a_{n-1,1} & a_{n-1,2} & \dots & a_{n-1, \, n-2} & 0 & 0 \end{matrix} \right]$ 
\[
\begin{aligned}
  det{(A)} & = det{ (A_1, A_2, \dots, A_{n-1}, B_n ) } = det{ ( A_1, \, A_2, \dots, B_{n-1} + C_{n-1}, B_n) } = \\ 
  & = det{(A_1, A_2, \dots, B_{n-1}, B_n)} + det{ (A_1, A_2, \dots, C_{n-1}, B_n) } = \\
  & = det{( A_1, A_2, \dots , B_{n-1}, B_n ) }
\end{aligned}
\]
Then $det{A} = det{ (B_1, B_2, \dots, B_n) }$.  \\
By homogeneity of determinants, $det{A} = \prod{i=1}^n a_{ii} det{I} = \prod_{i=1}^n a_{ii}$

\exercisehead{6} \[
\begin{aligned}
  F & = f_1 g_2 - f_2 g_1 \\
  F' & = f_1' g_2 + f_1 g_2' - f_2' g_1 - f_2 g_1' = f_1' g_2 - f_2' g_1 + f_1 g_2' - f_2 g_1' = \\
  & = \left| \begin{matrix} f_1' & f_2' \\ g_1 & g_2 \end{matrix} \right| + \left| \begin{matrix} f_1 & f_2 \\ g_1' & g_2' \end{matrix} \right|
\end{aligned}
\]

\exercisehead{7} 
\[
\begin{aligned}
  F & = f_1 \left| \begin{matrix} g_2 & g_3 \\ h_2 & h_3 \end{matrix} \right| - f_2 \left| \begin{matrix} g_1 & g_3 \\ h_1 & h_3 \end{matrix} \right| + f_3 \left| \begin{matrix} g_1 & g_2 \\ h_1 & h_2 \end{matrix} \right| \\
  F' &  = \left| \begin{matrix} f_1' & f_2' & f_3' \\ g_1 & g_2 & g_3 \\ h_1 & h_2 & h_3 \end{matrix} \right| + f_1 \left( \left| \begin{matrix} g_2' & g_3' \\ h_2 & h_3 \end{matrix} \right| + \left| \begin{matrix} g_2 & g_3 \\ h_2' & h_3' \end{matrix} \right| \right) - f_2 \left( \left| \begin{matrix} g_1' & g_3' \\ h_1 & h_3 \end{matrix} \right| + \left| \begin{matrix} g_1 & g_3 \\ h_1' & h_3' \end{matrix} \right| \right) + f_3 \left( \left| \begin{matrix} g_1' & g_2' \\ h_1 & h_2 \end{matrix} \right| + \left| \begin{matrix} g_1 & g_2 \\ h_1' & h_2' \end{matrix} \right| \right) = \\
  & = \left| \begin{matrix} f_1' & f_2' & f_3' \\ g_1 & g_2 & g_3 \\ h_1 & h_2 & h_3 \end{matrix} \right| + \left| \begin{matrix} f_1 & f_2 & f_3 \\ g_1' & g_2' & g_3' \\ h_1 & h_2 & h_3 \end{matrix} \right| + \left| \begin{matrix} f_1 & f_2 & f_3  \\ g_1 & g_2 & g_3 \\ h_1' & h_2' & h_3' \end{matrix} \right|
\end{aligned}
\]

\exercisehead{8} Using the previous results:
\begin{enumerate}
\item \[
F' = \left| \begin{matrix} f_1' & f_2' \\ f_1' & f_2' \end{matrix} \right| + \left| \begin{matrix} f_1 & g_1 \\ f_2'' & g_2'' \end{matrix} \right| = \boxed{ \left| \begin{matrix} f_1 & g_1 \\ f_2'' & g_2'' \end{matrix} \right| }
\]
\item
\[
\begin{aligned}
  F = \left| \begin{matrix} f_1 & f_2 & f_3 \\ f_1' & f_2' & f_3' \\ f_1'' & f_2'' & f_3'' \end{matrix} \right| ] \Longrightarrow  \left| \begin{matrix} f_1 & f_2 & f_3 \\ f_1' & f_2' & f_3' \\ f_1'' & f_2'' & f_3'' \end{matrix} \right|
\end{aligned}
\]
\end{enumerate}


\exercisehead{9}
\begin{enumerate}
\item \[ 
  \begin{aligned}
    & ( U +V)_{ij} = u_{ij} + v_{ij} = \begin{cases} u_{ij} & \text{ if $i < j$ }  \\ 0 & \text{ otherwise } \end{cases} +  \begin{cases} v_{ij} & \text{ if $i < j$ }  \\ 0 & \text{ otherwise } \end{cases} =  \begin{cases} u_{ij} +v_{ij} & \text{ if $i < j$ }  \\ 0 & \text{ otherwise } \end{cases}  \\
    & (UV)_{ij} = \sum_{k=1}^n u_{ik} v_{kj} \sum_{i<k} u_{ik} v_{kj} = \sum_{i<k, k<j} u_{ik} v_{kj} = \begin{cases} \sum_{i<k, k<j} u_{ik} v_{kj} & \text{ if $ i \leq j$ } \\ 0 & \text{ otherwise } \end{cases}
  \end{aligned} \]
\item \[ det(UV) = \prod_{i=1}^n \left( \sum_{i<k, k<j}^n u_{ik} v_{ki} \right) = \prod_{i=1}^n u_{ii}v_{ii} = \left( \prod_{i=1}^n u_{ii} \right)\left( \prod_{i=1}^n v_{ii} \right) = det U det V \]
\item Suppose $U U^{-1} = 1$.  
\[x
det 1 = 1 = (det U)(det U^{-1}), \text{ $U$ and $1$ are 2 $n \times n$ triangular matrices }
\]
$U^{-1}$ exists since $det U \neq 0$.  
\[
det U^{-1} = 1/ det U
\]
\end{enumerate}

\exercisehead{10}
Use the cofactor matrix to get the inverse, that $\frac{ (cof A)^T }{det A} = A^{-1}$.  
\[
\begin{gathered}
det A = 16, \quad det A^{-1} = \frac{1}{16} \\
\left( \begin{matrix} \frac{1}{2} & \frac{-3}{4} & \frac{1}{8} & \frac{1}{16} \\ 0 & \frac{1}{2} & \frac{-3}{4} & \frac{1}{8} \\ 0 & 0 & \frac{1}{2} & \frac{-3}{4} \\ 0 & 0 & 0 & \frac{1}{2} \end{matrix} \right) \left( \begin{matrix} 2 & 3 & 4 & 5 \\ 0 & 2 & 3 & 4 \\ 0 & 0 & 2 & 3 \\ 0 & 0 & 0 & 2 \end{matrix} \right)
\end{gathered}
\]

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 3.11 Exercises - The product formula for determinants, The determinant of the inverse of a nonsingular matrix, Determinants and independence of vectors, The determinant of a block-diagonal matrix }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1}
\begin{enumerate}
\item If $A = \left[ \begin{matrix} 1 & 3 \\ 2 & 5 \end{matrix} \right]$; $B = \left[ \begin{matrix} -4 & 2 \\ 3 & 6 \end{matrix} \right]$; $A+B = \left[ \begin{matrix} -3 & 5 \\ 5 & 11 \end{matrix} \right]$  $\begin{aligned} det{A} & = -1 \\ det{B} & = -30 \end{aligned}$  $det{(A+B)} = -58$
\item $det{(A+B)^2} = det{(A+B)(A+B)} = det{(A+B)} det{(A+B)} = (det{(A+B)})^2$
\item If $A =\left[ \begin{matrix} 1 & 1 \\ -1 & 1 \end{matrix} \right]$; $B = \left[ \begin{matrix} -1 & 2 \\ 1 & -1 \end{matrix} \right]$, $A+B = \left[ \begin{matrix} 0 & 3 \\ 0 & 0 \end{matrix} \right]$  
\[
\begin{gathered}
  \begin{aligned}
    A^2 & = \left[ \begin{matrix} 1 & 1 \\ -1 & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & 1 \\ -1 & 1 \end{matrix} \right] = \left[ \begin{matrix} 0 & 2 \\ -2 & 0 \end{matrix} \right] \\
    B^2 & = \left[ \begin{matrix} -1 & 2 \\ 1 & -2 \end{matrix} \right]  \left[ \begin{matrix} -1 & 2 \\ 1 & -2 \end{matrix} \right] = \left[ \begin{matrix} 3 & -4 \\ -2 & 3 \end{matrix} \right]
\end{aligned} \quad \quad \, A^2 + 2AB + B^2 = \left[ \begin{matrix} 0 & 2 \\ -2 & 0 \end{matrix} \right] + 2 \left[ \begin{matrix} 0 & 1 \\ 2 & -3 \end{matrix} \right] + \left[ \begin{matrix} 3 & -4 \\ -2 & 3 \end{matrix} \right] = \left[ \begin{matrix} 0 & 2 \\ -2 & 0 \end{matrix} \right] + \left[ \begin{matrix} 0 & 2 \\ 4 & -6 \end{matrix} \right] + \left[ \begin{matrix} 3 & -4 \\ -2 & 3 \end{matrix} \right] = \left[ \begin{matrix} 3 & 0 \\ 0 & -3 \end{matrix} \right] \\
\Longrightarrow det{(A^2 + 2AB + B^2)} = -9
\end{gathered}
\]
\item likewise, $det{(A^2 + B^2)} = det{ \left[ \begin{matrix} 3 & -2 \\ -4 & 3 \end{matrix} \right]} = 1$
\end{enumerate}

\exercisehead{2} \begin{enumerate}
\item Assume $A$ is $n\times n$, $B$ is $m\times m$, and $C$ is $p \times p$.  \\
$\left[ \begin{matrix} A & 0 \\ 0 & B \end{matrix} \right]$ is a $n+m \times n+m$ matrix, $D$.  \smallskip \\
\quad $\left[ \begin{matrix} A & & \\ & B & \\ & & C \end{matrix} \right] = \left[ \begin{matrix} D & \\ & C \end{matrix} \right]$.  Then by Thm. 3.7, $det{\left[ \begin{matrix} D & 0 \\ 0 & C \end{matrix} \right]}  = det{D} det{C}$ \smallskip \\
$det{D} = det{ \left[ \begin{matrix} A & 0 \\ 0 & B \end{matrix} \right]} = det{A} det{B} $ \, (by Thm. 3.7).  Then $det{ \left[ \begin{matrix} A & & \\ & B & \\ & & C \end{matrix} \right]} = det{A} det{B} det{C}$
\item Assume $det{\left[ \begin{matrix} A_1 & & & \\ & A_2 & & \\ & & \ddots & \\ & & & A_n \end{matrix} \right]} = \prod_{i=1}^n det{A_i}$.  \smallskip \\

Consider $det{ \left[ \begin{matrix} A_1 & & & \\ & A_2 & & \\ & & \ddots & \\ & & & A_{n+1} \end{matrix} \right]}$ \\
Now $\left[ \begin{matrix} A_1 & & & \\ & A_2 & & \\ & & \ddots & \\ & & & A_n \end{matrix} \right] = D_n$, a square matrix of size $\sum_{i=1}^n N_i \times \sum_{i=1}^n N_i$ where $N_i = $ size of matrix $A_i$.  \\
$det{\left[ \begin{matrix} D_n & \\ & A_{n+1} \end{matrix} \right]} = det{D_n}det{A_{n+1}}$ by Thm. 3.7.  $det{D_n}$, by induction assumption, is $det{D_n} = \prod_{i=1}^n det{A_i}$.  $\Longrightarrow det{ \left[ \begin{matrix} A_1 & & & \\ & A_2 && \\ & & \ddots & \\ & & & A_{n+1} \end{matrix} \right]} = \prod_{i=1}^{n+1} det{A_i}$
\end{enumerate}

\exercisehead{3} \[
\begin{aligned}
  & det{A} = det{ \left[ \begin{matrix} 1 & & & \\ & 1 & &  \\ a & b & c & d \\ e & f & g & h \end{matrix} \right]} = det{ \left[ \begin{matrix} 1 & & & \\ & 1 & & \\ & & c & d \\ & & g & h \end{matrix} \right]} =det{\left[ \begin{matrix} c & d \\ g & h \end{matrix}\right]} \\
  & det{B} = det{ \left[ \begin{matrix} a & b & c & d \\ e & f & g & h \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{matrix} \right]} = \left| \begin{matrix} a & b & & \\ e & f & & \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{matrix} \right| = det{ \left[ \begin{matrix} a & b \\ e & f \end{matrix} \right]}
\end{aligned}
\]

\exercisehead{4} If $X = \left[ \begin{matrix} & A & \\ & & I_m \end{matrix} \right]$ where $A$ is $(n-m) \times n$ and $I$ is $m \times m$, then $\forall \, a_{ij}$ entry, $(n-m) + 1 \leq i \leq n$, $(n-m) + 1 \leq j \leq n$.  

$[0 \, 0 \, \ldots \, 0, \, -a_{ij}, \, 0, \dots \, 0 ]$ could be added to the $i$th row since Gauss-Jordan row operations do not change the determinant, by determinant properties.  Then $det{X} = \left[ \begin{matrix} A_{n-m} & \\ & I_m \end{matrix} \right]$.  By Thm. 3.7, $det{X} = det{A_{n-m}}$.  \\

Similarly for $Y = \left[ \begin{matrix} I_m & \\ & A \end{matrix} \right]$.

\exercisehead{5} $ A = \left[ \begin{matrix} a & b & 0 & 0 \\ c & d & 0 & 0 \\ e & f & g & h \\ x & y & z & w \end{matrix} \right]$  \quad \, $det{A} = det{ \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right]}det{\left[ \begin{matrix} g & h \\ z & w \end{matrix} \right]}$

\exercisehead{6} $A = \left[ \begin{matrix} B & 0 \\ C & D \end{matrix} \right]$ where $B$ is $m\times m$, $C,D$ are $(n-m)\times (n-m)$.  
\[
\begin{gathered}
  det{A} = f(A_1, A_2, \dots, A_n), \quad \, A_i = C_i + D_i, \quad m+1 \leq i \leq n \\
  det{A} = f(A_1, A_2, \dots, A_n) = f(A_1, A_2, \dots, C_{m+1} + D_{m+1}, \dots, A_n) = \\
  = f(A_1, A_2, \dots, C_{m+1}, \dots, A_n) + f(A_1, A_2, \dots, D_{m+1}, \dots , A_n)
\end{gathered}
\]
Consider $A_1, A_2, \dots, C_{m+1}$, $m+1$ rows with $m$ possibly nonzero components.  Then $A_1, \dots, C_{m+1}$ span at most a $dim{m}$ subspace.  Then $A_1, \dots, C_{m+1}$ dependent.  By Thm., $f(A_1, A_2, \dots, C_{m+1}, \dots, A_n) =0$
\[
det{A} = f(A_1, A_2, \dots, D_{m+1}, \dots, A_n)
\]
Likewise for $i = m +2, \dots, n$
\[
\Longrightarrow det{A} = f(A_1, A_2, \dots, D_{m+1}, \dots , D_n) = det{B}det{D}
\]
(By Thm. for det of block-diagonal matrices)

\exercisehead{7} \begin{enumerate}
\item $\left| \begin{matrix} 1 & -1 & 0 \\ 0 & 1 & -1 \\ 2 & 3 & -1 \end{matrix} \right| = \left| \begin{matrix} 1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 5 & -1 \end{matrix} \right| = \left| \begin{matrix} 1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 4 \end{matrix} \right| =4 $
\item $\left| \begin{matrix} 1 & -1 & 2 & 1 \\ -1 & 2 & -1 & 0 \\ 3 & -1 & 1 & 0 \\ 1 & 0 & 0 & 1 \end{matrix} \right| = \left| \begin{matrix} 0 & -1 & 2 & 0 \\ 0 & 2 & -1 & 1 \\ 0 & -1 & 1 & -3 \\ 1 & 0 & 0 & 1 \end{matrix} \right| = \left| \begin{matrix} 0 & -1 & 2 & 0 \\ 0 & 0 & 3 & 1 \\ 0 & 0 & -1 & -3 \\ 1 & 0 & 0 & 1 \end{matrix} \right| = \left| \begin{matrix} 0 & -1 & 2 & 0 \\ 0 & 0 & 0 & -8 \\ 0 & 0 & -1 & -3 \\ 1 & 0 & 0 & 1 \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 0 & 1 \\ 0 & -1 & 0 & 0 \\ 0 & 0 & -1 & -3 \\ 0 & 0 & 0 & -8 \end{matrix} \right| = -8$
\item $\left| \begin{matrix} 1 & 0 & 0 & 0 1 \\ 1 & 1 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 & 1 \\ 1 & 1 & 0 & 1 & 1 \\ 0 & 1 & 0 & 1 & 0 \end{matrix} \right| = \left| \begin{matrix} 0 & 0 & 0 & 0 & 1 \\ 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 1 \\ 0 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 1 & 0 \end{matrix} \right| = \left| \begin{matrix} 0 & 0 & 0 & 0 & 1 \\ 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 1 & 0 \end{matrix} \right| = 0 $
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 3.17 Exercises - Expansion formulas for determinants.  Minors and cofactors.  3.13 Existence of the determinant function, The determinant of a transpose, The cofactor matrix, Cramer's rule }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} \begin{enumerate}
\item $\left[ \begin{matrix} 1 & 2 \\ 3 & 4 \end{matrix} \right]$ \quad \quad \, $cof{A} = \left[ \begin{matrix} 4 & -3 \\ -2 & 1 \end{matrix} \right]$
\item $\left[ \begin{matrix} 2 & -1 & 3 \\ 0 & 1 & 1 \\ -1 & -2 & 0 \end{matrix} \right]$  \quad \quad \, $cof{A} =  \left[ \begin{matrix} 2 & -1 & 1 \\ -6 & 3 & 5 \\ -4 & -2 & 2 \end{matrix} \right]$
\item $\left[ \begin{matrix} 3 & 1 & 2 & 4 \\ 2 & 0 & 5 & 1 \\ 1 & -1 & -2 & 6 \\ -2 & 3 & 2 & 3 \end{matrix} \right]$ \quad \quad \, $cof{A} = \left[ \begin{matrix} 109 & 113 & -41 & -13 \\ -40 & -92 & 74 & 16 \\ -41 & -79 & 7 & -47 \\ -50 & 38 & 16 & 20 \end{matrix} \right]$
\end{enumerate}

\exercisehead{2} \begin{enumerate}
\item $\frac{1}{-2} \left[ \begin{matrix} 4 & -3 \\ -2 & 1 \end{matrix} \right]$ 
\item $\frac{1}{8} \left[ \begin{matrix} 2 & -6 & -4 \\ -1 & 3 & -2 \\ 1 & 5 & 2 \end{matrix} \right]$
\item $\frac{1}{184} \left[ \begin{matrix} 109 & -40 & -41 & -50 \\ 113 & -92 & 79 & 38 \\ -41 & 74 & 7 & 16 \\ -13 & 16 & -47 & 20 \end{matrix} \right]$
\end{enumerate}

\exercisehead{3} Note that for $\lambda I - A$, $det{(\lambda I - A) } = 0 = det{(A - \lambda I)}$ \begin{enumerate}
\item \[
\left| \begin{matrix} - \lambda & 3 \\ 2 & -1 - \lambda \end{matrix} \right| = 0 \Longrightarrow \lambda + \lambda^2 - 6 = 0 = (\lambda + 3)(\lambda - 2) = 0
\]
\item \[
\begin{gathered}
  \left[ \begin{matrix} 1 & 0 & 2 \\ 0 & -1 & -2 \\ 2 & -2 & 0 \end{matrix} \right]  \\
  \begin{aligned}
  \left| \begin{matrix} 1 - \lambda & & 2 \\ & -1 -\lambda & -2 \\ 2 & -2 & -\lambda \end{matrix} \right| & = (1-\lambda) (\lambda ( 1 + \lambda ) -4 ) + 2 ( 2 (1+ \lambda ) ) = \\
  & = (1 - \lambda ) ( \lambda^2 + \lambda - 4) + 4 (1 + \lambda ) = (1- \lambda) ( \lambda^2 + \lambda - 4) + 4 (1+ \lambda ) = \\
  & = -\lambda^3 + 9 \lambda = \lambda ( -\lambda^2 + 9) \Longrightarrow \boxed{ \lambda = \pm 3, 0 }
\end{aligned}
\end{gathered}
\]
\item \[
\begin{gathered}
\left| \begin{matrix} 11 - \lambda & -2 & 8 \\ 19 & -3-\lambda & 14 \\ -8 & 2 & -5 - \lambda \end{matrix} \right| = \left| \begin{matrix} 3 - \lambda & 0 & 3 - \lambda \\ 19 & -3 -\lambda & 14 \\ -8 & 2 & -5 - \lambda \end{matrix} \right| = \left| \begin{matrix} 0 & 0 & 3 - \lambda \\ 5 & -3 - \lambda & 14 \\ \lambda - 3 & 2 & -5 - \lambda \end{matrix} \right| \\ 
= (3- \lambda ) (10 + \lambda^2 - 9 ) = (3-\lambda ) (1 + \lambda^2) \\
\boxed{ \lambda = 3 , \pm i }
\end{gathered}
\]
\end{enumerate}

\exercisehead{4} 
\begin{enumerate}
\item $((cof{A})^T)_{ij} = (cof{A})_{ji} = (-1)^{i+j} det{A_{ji}} = (-1)^{i+j}det{(A_{ji})^T} = (-1)^{i+j} det{(A^T)_{ij}} = cof{(A^T)_{ij}}$
\item See Part (c), and then use $A(cof{A})^T = (det{A})I$, Thm. 3.12.  
\item $((cof{A})^T A)_{ij} = \sum_k (cof{A})^T_{ik} a_{kj} = \sum_k a_{kj} (cof{A})_{ki}$ \smallskip \\
Recall that column expansions can be done on determinants, and that $det{A} = det{A^T}$.  \\

Consider $B$ matrix whose $j$th column is equal to the $i$th column for some $j\neq i$, \\
\quad but remaining rows are the same as $A$.  \\
\quad \, then $det{B} =0$ 
\[
\begin{gathered}
\begin{aligned}
  det{B} & = \sum_{k}^n b_{kj} cof{b_{kj}} \quad \, \text{ ($j$th column expansion of $B$) } \\
  b_{kj} & = a_{ij} \\ 
  cof{b_{kj}} & = cof{a_{kj}} \quad \, \text{ (since $B$ differs from $A$ only in the $j$th column) }
\end{aligned} \\
\Longrightarrow \sum_k^n a_{ij} cof{a_{kj}} = 0 
\end{gathered}
\]
If $i=j$, $\sum_k a_{ki} (cof{A})_{ki} = det{A}$ (by $i$th column expansion of $det{A}$)
\end{enumerate}

\exercisehead{5}\begin{enumerate}
\item $\begin{aligned}
  x + 2y + 3z & = 8 \\
  2x -y + 4z & = 7 \\
  -y + z & = 1 
\end{aligned}$ $\Longrightarrow \left[ \begin{matrix} 1 & 2 & 3 \\ 2 & -1 & 4 \\ & -1 & 1 \end{matrix} \right]\left[ \begin{matrix} x \\ y \\ z \end{matrix} \right] = \left[ \begin{matrix} 8 \\ 7 \\ 1 \end{matrix} \right]$ 
\[
\begin{aligned}
x & =\frac{1}{-7} \left| \begin{matrix} 8 & 2 & 3 \\ 7 & -1 & 4 \\ 1 & -1 & 1 \end{matrix} \right| = \frac{1}{-7} \left| \begin{matrix} 0 & 10 & -5 \\ 0 & 6 & -3  \\ 1 & -1 & 1 \end{matrix} \right| = \frac{1}{-7} \left| \begin{matrix} 1 & -1 & 1 \\ 0 & 10 & -5 \\ 0 & 6 & -3 \end{matrix} \right| = 0 \\
y & = \frac{1}{-7} \left| \begin{matrix} 1 & 8 & 3 \\ 2 & 7 & 4 \\ & 1 & 1 \end{matrix} \right| = \frac{1}{-7} \left| \begin{matrix} 1 & 0 & -5 \\ 2 & 0 & -3 \\ & 1 & 0 \end{matrix} \right| = -7 /-7 = 1 \\
z & = \frac{1}{-7} \left| \begin{matrix} 1 & 2 & 8 \\ 2 & -1 & 7 \\ & -1 & 1 \end{matrix} \right| = \frac{-1}{7} \left| \begin{matrix} 1 & 0 & 10 \\ 0 & -1 & -13 \\ & - 1 & 1 \end{matrix} \right| = \frac{-14}{-7} = 2 
\end{aligned}
\]
\item $\begin{aligned}
  x + y + 2z & = 0 \\
  3x - y -z & = 3 \\
  2x + 5y + 3z & =4 
\end{aligned}$ $\Longrightarrow \left[ \begin{matrix} 1 & 1 & 2 \\ 3 & -1 & -1 \\ 2 & 5  & 3 \end{matrix} \right]\left[ \begin{matrix} x \\ y \\ z \end{matrix} \right] = \left[ \begin{matrix} 0 \\ 3 \\ 4 \end{matrix} \right]$ 
\[
\begin{gathered}
  \left| \begin{matrix} 1 & 1 & 2 \\ 3 & -1 & -1 \\ 2 & 5 & 3 \end{matrix} \right| = \left| \begin{matrix} 1 & 1 & 2 \\ 0 & -4 & -7 \\ 0 & 3 & -1 \end{matrix} \right| = 25 \\
  \begin{aligned}
    & \left| \begin{matrix} 0 & 1 & 2 \\ 3 & -1 & -1 \\ 4 & 5 & 3 \end{matrix} \right| = \left| \begin{matrix} 0 & 1 & 2 \\ 3 & 0 & 1 \\ 4 & 0 & -7 \end{matrix} \right| = -(-21 -4) = 25 & \Longrightarrow \boxed{ x = 1 } \\ 
    & \left| \begin{matrix} 1 & 0 & 2 \\ 3 & 3 & -1 \\ 2 & 4 & 3 \end{matrix} \right| = \left| \begin{matrix} 1 & 0 & 2 \\ 0 & 3 & -7 \\ 0 & 4 & -1 \end{matrix} \right| = 25 & \Longrightarrow \boxed{ y = 1 }
\end{aligned} \\
  \boxed{ z = -1 }
\end{gathered}
\]
\end{enumerate}

\exercisehead{6} 
\begin{enumerate}
\item Vector form of lines: $tA + P_1= X$; \, $A = P_2 - P_1$.  
\[
\begin{gathered}
  \begin{aligned}
    & t \left( \begin{matrix} x_2 - x_1 \\ y_2 - y_1 \end{matrix} \right) + \left( \begin{matrix} x_1 \\ y_1 \end{matrix}\right) = \left( \begin{matrix} x \\ y \end{matrix} \right) \\
    & t \left( \begin{matrix} x_2 - x_1 \\ y_2 - y_1 \end{matrix} \right) + -\left( \begin{matrix} x-x_1 \\ y-y_1 \end{matrix} \right) = 0  
\end{aligned}
\end{gathered}
\]
Then $A, X-P_1$ are linearly dependent.  \\
Then if $A$, $X-P_1$ form rows of a matrix, 
\[
\left| \begin{matrix} x-x_1 & y-y_1 \\ x_2-x_1 & y_2 - y_1 \end{matrix} \right| = 0 
\]
Also
\[
t \left( \begin{matrix} x_2 \\ t_2 \end{matrix} \right) + (1-t)\left( \begin{matrix} x_1 \\ t_1 \end{matrix} \right) - \left( \begin{matrix} x \\ y \end{matrix} \right) = 0 
\]
we can extend this to say
\[
\begin{aligned}
  t \left( \begin{matrix} x_2 \\ y_2 \\ 1 \end{matrix} \right) + (1-t) \left( \begin{matrix} x_1 \\ y_1 \\ 1 \end{matrix} \right) - \left( \begin{matrix} x_1 \\ y_1 \\ 1 \end{matrix} \right) & = 0 = \\
  = tX_2 + (1-t)X_1 - X & = 0 
\end{aligned}
\]
$X,X_1,X_2$ are dependent, and so if $X,X_1,X_2$ form rows of a matrix, then 
\[
\left| \begin{matrix} x & y & 1 \\ x_1 & y_1 & 1 \\ x_2 & y_2 & 1 \end{matrix} \right| = 0 
\]
\item Recall the vector form for planes: $P = \{ X | X = P + sA + tB \}$, $A,B$ are independent.  
\[
\begin{gathered}
X = \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \end{matrix} \right) + s \left( \begin{matrix} x_1 - x_0 \\ y_1 - y_0 \\ z_1 - z_0 \end{matrix} \right) + t \left( \begin{matrix} x_2 - x_0 \\ y_2 - y_0 \\ z_2 - z_0 \end{matrix} \right) = P + sA + tB \\
0 = P-X + sA + tB
\end{gathered}
\] 
$P-X, A,B$ are dependent.  Then consider $P-X,A,B$ to be rows of a matrix.  Then 
\[
\left| \begin{matrix} x_0 - x & y_0 - y & z_0 - z \\ x_1 - x_0 & y_1 - y_0 & z_1 - z_0 \\ x_2 - x_0 & y_2 - y_0 & z_2 - z_0 \end{matrix} \right| = 0 
\]
We could also rewrite this equation like this:
\[
\begin{gathered}
  \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) - \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \end{matrix} \right) - s \left( \begin{matrix} x_1 \\ y_1 \\ z_1 \end{matrix} \right) + s \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \end{matrix} \right) - t \left( \begin{matrix} x_2 \\ y_2 \\ z_2 \end{matrix} \right)  + t \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \end{matrix} \right) = 0 \\
  \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) + (t+s-1) \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \end{matrix} \right) -t \left( \begin{matrix} x_2 \\ y_2 \\ z_2 \end{matrix} \right) - s\left( \begin{matrix} x_1 \\ y_1 \\ z_1 \end{matrix} \right) = 0 
\end{gathered}
\]
Extend by $1$ for a new row.  
\[
  \left( \begin{matrix} x \\ y \\ z \\ 1 \end{matrix} \right) + (t+s-1) \left( \begin{matrix} x_0 \\ y_0 \\ z_0 \\ 1 \end{matrix} \right) -t \left( \begin{matrix} x_2 \\ y_2 \\ z_2 \\ 1 \end{matrix} \right) - s\left( \begin{matrix} x_1 \\ y_1 \\ z_1 \\ 1 \end{matrix} \right) = 0 
\]
This shows that these 4 vectors are linearly dependent.  Consider the vectors as rows of matrix to obtain:
\[
\left| \begin{matrix} x & y & z & 1 \\ x_0 & y_0 & z_0 & 1 \\ x_1 & y_1 & z_1 & 1 \\ x_2 & y_2 & z_2 & 1 \end{matrix} \right| = 0 
\]
\item We have 3 noncollinear points that satisfy some specific equation for a circle in the $x-y$ plane.  
\[
(x-x_0)^2 + (y-y_0)^2 = \rho^2 = (x^2 - 2xx_0 + x_0^2) + (y^2 - 2yy_0 + y_0^2) \text{ or } x^2 - 2x_0 x + y^2 - 2y_0 y - (\rho^2 - x_0^2 - y_0^2) = 0
\]
So $x_0, y_0$, the coordinates for the origin, and $\rho$, the radius of the circle, are 3 unknowns and 3 equations are needed.  To fix the ``scale'' of the coordinates, we need a 4th equation.  
\[
\Longrightarrow \begin{aligned} x_1^2 - 2x_0 x_1 + y_1^2 - 2y_0 y_1 - (\rho^2 - x_0^2 - y_0^2) & = 0 \\
  x_2^2 - 2x_0 x_2 + y_2^2 - 2y_0 y_2 - (\rho^2 - x_0^2 - y_0^2) & = 0 \\
x_3^2 - 2x_0 x_3 + y_3^2 - 2y_0 y_3 - (\rho^2 - x_0^2 - y_0^2) & = 0 \\
x^2 - 2x_0 x + y^2 - 2y_0 y - (\rho^2 - x_0^2 - y_0^2) & = 0
\end{aligned} \quad \, \Longrightarrow \left( \begin{matrix} x^2 + y^2 \\ x_1^2 + y_1^2 \\ x_2^2 + y_2^2 \\ x_3^2 + y_3^2 \end{matrix} \right) -2x_0 \left( \begin{matrix} x \\ x_1 \\ x_2 \\ x_3 \end{matrix} \right) - 2y_0 \left( \begin{matrix} y \\ y_1 \\ y_2 \\ y_3 \end{matrix} \right) - (\rho^2 - x_0^2 - y_0^2) \left( \begin{matrix} 1 \\ 1 \\ 1 \\ 1 \end{matrix} \right) = 0 
\]
\textbf{Notice} how $x_j^2$ and $y_j^2$ must be ``\emph{correlated}'' in that their relative values are not independent, but must be $1$ to $1$.   \\

We can also consider ``getting rid'' of the $\rho^2$ unknown by taking an equation minus the previous equation:
\[
\begin{aligned}
  x_1^2 - 2x_1 x_0 + x_0^2 + y_1^2 -2y_1 y_0 + y_0^2 & = \rho^2 \\ 
  - (x^2 - 2x x_0 + x_0^2 + y^2 - 2y y_0 + y_0^2 & = \rho^2 ) \\
  \Longrightarrow x_1^2 - x^2 + -2x_0(x_1-x) + y_1^2 - y^2 + -2y_0(y_1-y) & = 0
\end{aligned}
\]
So that we get
\[
\begin{aligned}
\left( \begin{matrix} x_1^2 - x^2 \\ x_2^2 - x_1^2 \\ x_3^2 - x_2^2 \\ x^2 - x_3^2 \end{matrix} \right) + -2x_0 \left( \begin{matrix} x_1 - x \\ x_2 - x_1 \\ x_3 - x_2 \\ x - x_3 \end{matrix} \right) + \left( \begin{matrix} y_1^2 - y^2 \\ y_2^2 - y_1^2 \\ y_3^2 - y_2^2 \\ y^2 - y_3^2 \end{matrix} \right) + -2y_0 \left( \begin{matrix} y_1 - y \\ y_2 - y_1 \\ y_3 - y_2 \\ y - y_3 \end{matrix} \right) = 0 
\end{aligned}
\]
\end{enumerate}
Thus, these 4 vectors above are linearly dependent, which implies
\[
\boxed{ \left| \begin{matrix}  x_1^2 - x^2 & x_2^2 - x_1^2 & x_3^2 - x_2^2 & x^2 - x_3^2 \\ x_1 - x & x_2 - x_1 & x_3 - x_2 & x - x_3 \\ y_1^2 - y^2 & y_2^2 - y_1^2 & y_3^2 - y_2^2 & y^2 - y_3^2 \\ y_1 -y & y_2 - y_1 & y_3 - y_2 & y - y_3  \end{matrix} \right| = 0 }
\]

\exercisehead{7} $F(x) = det{ [f_{ij}(x)]}$  
\[
\begin{aligned}
  & i= 1 \quad \, & f_{11} \Longrightarrow |f_{11}| = F(x) \quad \, \Longrightarrow F'(x)  = f'_{11} = det{A_1} \\
  & i = 2  \quad \, & \left| \begin{matrix} f_{11} & f_{12} \\ f_{21} & f_{22} \end{matrix} \right| = f_{11} f_{22} - f_{12} f_{21} = F(x) \\ 
  & \quad \, & \begin{gathered}
    F'(x) = f_{11}' f_{22} + f_{11}f_{22}'  -f_{12}'f_{21} -f_{12} f_{21}' \\
    \left| \begin{matrix} f_{11}' & f_{12}' \\ f_{21} & f_{22} \end{matrix} \right| + \left| \begin{matrix} f_{11} & f_{12} \\ f_{21}' & f_{22}' \end{matrix} \right| = |A_1| + |A_2| = f_{11}' f_{22} - f_{21}f_{12}' + f_{11}f_{22}' - f_{12}f_{21}' = F'(x)
\end{gathered}
\end{aligned}
\]
Assume $n$ case is true.  
\[
\begin{aligned}
  F(x) & = det{ (f_{ij}(x))} = \sum_{k=1}^{n+1} f_{n+1,\, k} (-1)^{n+1+k} det{(f)_{n+1, \, k} } \\
  F'(x) & = \sum_{k=1}^{n+1}f_{n+1,k}' cof{(f)_{n+1,k}} + \sum_{k=1}^{n+1} f_{n+1,k}(-1)^{n+1+k} (det{(f)_{n+1,k}})'
\end{aligned}
\]
$\sum_{k=1}^{n+1} f_{n+1,k}' cof{(f)_{n+1,k}} = det{A_{n+1}}$, matrix obtained by differentiating the $n+1$ row of $[f_{ij}]$ \\
$(det{(f)_{n+1,k}})' = \sum_{l=1}^n det{B_l}$ where $B_l$ is the matrix obtained by differentiating the $l$th row of $(f)_{n+1,k}$, $l=1,\dots, n$
\[
\begin{gathered}
\begin{aligned}
  \sum_{k=1}^{n+1} f_{n+1,k}(-1)^{n+1+k} (det{(f)_{n+1,k}})' & = \sum_{k=1}^{n+1}f_{n+1,k}(-1)^{n+1+k} \sum_{l=1}^n det{B_l} = \sum_{l=1}^n \sum_{k=1}^{n+1} f_{n+1,k}(-1)^{n+k+1} det{B_l} = \\
  & = \sum_{l=1}^n det{A_l} 
\end{aligned} \\
\Longrightarrow F'(x) = det{A_{n+1}} + \sum_{l=1}^n det{A_l} = \boxed{ \sum_{l=1}^{n+1} det{A_l} }
\end{gathered}
\]

\exercisehead{8} Consider $W(x) = [u_j^{(i-1)}(x)]$.  \\
$|W(x)| = |[ u_j^{(i-1)}(x)]|$
Use Ex.7: $F'(x) = \sum_{i=1}^n det{A_i(x)}$, where $A_i(x)$ is the matrix obtained by differentiating the functions in the $i$th row of $[f_{ij}(x)]$, then \\

$|W(x)|' = \sum_{i=1}^n det{A_i(x)}$, where $A_i(x)$ is the matrix obtained by differentiating the functions in the $i$th row of $[u_j^{(i-1)}(x)]$.  \smallskip \\

For $i=1, \dots, n-1$, $i+1 = 2,\dots, n$ and there's a $k=i+1$ row s.t. $k=2,\dots, n$ so that $det{A_i}=0$,  \smallskip \\

For $i=n$, $[u_j^{(n-1)}(x)]' = [u_j^{(n)}(x)]$ and for $k=1,\dots, n-1$, $[u_j^{(k-1)}(x)]$ is different from $[u_j^{(n)}(x)]$.  \\
$\Longrightarrow |W(x)|' = det{A_n(x)}$, where $A_n(x)$ is the matrix obtained by differentiating the functions in the $n$th row of $[u_j^{(i-1)}(x)]$

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 4.4 Exercises - Linear transformations with diagonal matrix representations, Eigenvectors and eigenvalues of a linear transformations, Linear independence of eigenvectors corresponding to distinct eigenvalues }
%-----------------------------------%-----------------------------------%-----------------------------------
\exercisehead{1} \begin{enumerate}
\item $\begin{aligned} T(x) & = \lambda x \\ aT(x) & = (a\lambda)x \end{aligned}$
\item $\begin{aligned} T_1(x) & = \lambda_1 x \\ T_2(x) & = \lambda_2 x \end{aligned} \quad \, (aT_1 + bT_2)(x) = a\lambda_1 x + b\lambda_2 x = (a\lambda_1 + b\lambda_2)x$
\end{enumerate}

\exercisehead{2} \[
\begin{aligned}
  T(x) & = \lambda x \\ 
  T^2(x) & = T(T(x)) = T(\lambda x) = \lambda T(x) = \lambda^2 x \\
  T^n(x) & = \lambda^n x \\
  T^{n+1}(x) & = T(T^n(x)) = T(\lambda^n x) = \lambda^n \lambda x = \lambda^{n+1} x 
\end{aligned}
\]
Let $P(x) = \sum_{j=0}^N a_j x^j$ \\
\phantom{Let} $P(T)(x) = \sum_{j=0}^N a_j T^j(x)$. \\

If $x$ is an eigenvector, $P(T)(x) = \sum_{j=0}^N a_j T^j(x) = \sum_{j=0}^N a_j \lambda^j (x) = P(\lambda)x$.  

\exercisehead{3} $V = V_2(\mathbb{R})$, plane as a real linear space.  \\
$T = $ rotation of $V$ through an angle of $\frac{\pi}{2}$ radians.  
\[
\begin{gathered} 
  T = \left[ \begin{matrix} 0 & - 1 \\ 1 & 0 \end{matrix} \right] \text{ or } \begin{aligned} T(e_1) & = e_2 \\ T(e_2) & = -e_1 \end{aligned} \quad \quad \, \Longrightarrow \begin{aligned} T^2(x) & = T^2(x_1 e_1 + x_2 e_2 ) = T(x_1 e_2 + x_2 (-e_1)) = \\ & = -x_1 e_1 + x_2 (-e_2) = -x \end{aligned}
\end{gathered}
\]

\exercisehead{4} \[
\begin{gathered} 
  \begin{aligned} T^2x_{\lambda} & = \lambda^2 x_{\lambda} \\ T^2 - \lambda^2 I = (T+\lambda I)(T- \lambda I)  \end{aligned} \\
  det{(T^2 - \lambda^2 I) } = 0 = det{(T+\lambda I)} det{(T-\lambda I) } = 0 
\end{gathered}
\]
$det{(T+\lambda I)}$ or $det{(T-\lambda I)}$ is zero, so $\lambda$ or $-\lambda$ is an eigenvalue of $T$.  

\exercisehead{5} Let $V$ be the linear space of all real functions differentiable on $(0,1)$.  \\
Let $f \in V$.  \\
Define $g = T(f)$ s.t. $g(t) = tf'(t)$ $\, \forall \, t \in (0,1)$ \\
Suppose $f$ is an eigenfunction of $T$.  
\[
g(t) = T(f)(t) = tf'(t)  = \lambda f(t) \Longrightarrow \boxed{ f(t) = c_0 t^{\lambda} }
\]
In solving this ordinary differential equation, $\lambda \in \mathbb{R}$

\exercisehead{6} $V = p(x)$ of degree $\leq n$.  \\
$p \in V$, $q = T(p)$ s.t. $q(t) = p(t+1)$ $\, \forall \, t$ 
\[
\begin{gathered}
  p(t) = \sum_{j=0}^N a_j t^j \\
  T(p(t)) = q(t) = p(x+1) = \sum_{j=0}^N a_j(t+1)^j  = \lambda \sum_{j=0}^N a_j t^j 
\end{gathered}
\]

\[
\begin{aligned}
  & N =0 \quad & a_0 = \lambda a_0  \Longrightarrow \lambda =1 \\
  & \quad \\
  & N =1 \quad & \begin{gathered} 
    \begin{aligned} 
      & a_1 (t+1) + a_0 = \lambda (a_1 t + a_0 ) \\
      & t (a_1 (1-\lambda)) + a_1 + a_0 (1-\lambda) = 0 
\end{aligned} \\
    \begin{aligned} & \text{ if } a_1 = 0, \, \text{ then } a_0  =0 \text{ or } \lambda = 1 \\
      & \text{ if } \lambda = 1, \, a_1 = 0 
\end{aligned}
\end{gathered} \\ 
  & \quad \\
  & N = 2 \quad & \begin{gathered}
\begin{aligned} 
  & a_2 (t+1)^2 + a_1 (t+1) + a_0 = \lambda (a_2 t^2 + a_1 t + a_0 ) \\
  & a_2 (t^2 + 2t + 1) + a_1 (t+1) + a_0 = \lambda (a_2 t^2 + a_1 t + a_0 ) \\
  & t^2 (a_2 (1-\lambda)) + t (2a_2 + a_1(1-\lambda) ) +a_2 + a_1 + (1-\lambda)a_0 = 0 
\end{aligned} \\
\begin{aligned}
  \text{ if } a_2 = 0, \, \text{ we're left with $N=1$ case } \\
  \text{ if } \lambda =1, \, a_2 = 0; \, \text{ we're left with $N=1$ case.}
\end{aligned}
\end{gathered}
\end{aligned}
\]
Assume $\sum_{j=0}^N a_j(t+1)^j = \lambda \sum_{j=0}^N a_j t^j, \, a_j =0 \quad \forall \, j = 1,\dots N$
\[
\begin{gathered}
  \sum_{j=0}^{N+1} a_j (t+1)^j = \lambda \sum_{j=0}^{N+1} a_j t^j \\
  \sum_{j=0}^{N+1} a_j \sum_{k=0}^j \binom{j}{k} t^k = \lambda \sum_{j=0}^{N+1} a_j t^j \\
  \sum_{j=0}^{N+1} a_j \sum_{k=0}^j \binom{j}{k} t^k - \lambda a_j t^j = 0 
\end{gathered}
\]
$a_{N+1}(1-\lambda) =0$.  \\
If $\lambda = 1$, $t^N: \, a_{N+1}(N+1) + a_N - \lambda a_N = 0$; \quad $a_{N+1} =0$, and then we could rewrite the equation, and coefficients, as $N$th case, which we've shown to yield only $a_0$ to be nonzero.  

\exercisehead{7} Let $V = $ linear space of functions continuous on $(-\infty, \infty)$ s.t. $\exists \, \int_{-\infty}^x f(t) dt $ $\quad \forall \, x \in \mathbb{R}$  \\
If $f \in V$, let $g= T(f)$ s.t. $g(x) = \int_{-\infty}^x f(t) dt $  
\[
\begin{gathered}
  T(f)(x) = g(x) = \int_{-\infty}^x f(t) dt = \lambda f(x) \\
  \Longrightarrow f(x) = \lambda f'(x)  \Longrightarrow \boxed{ f(x) = c_0e^{\lambda x} } \\
  \int_{-\infty}^x f(t) dt = \left. \left( \frac{ c_0 e^{\lambda t} }{ \lambda } \right) \right|_{-\infty}^x = \frac{c_0 e^{\lambda x} }{\lambda} - \lim_{t \to -\infty} \frac{c_0 e^{\lambda t}}{\lambda} 
\end{gathered}
\]
A limit only exists if $\lambda > 0$.

\exercisehead{8} \[
\begin{gathered}
  g(x) = T(f)(x) = \int_{-\infty}^x tf(t) dt = \lambda f(x)  \\
  xf(x) = \lambda f'(x) \\
 \text{ if } \lambda \neq 0, \,  \ln{ \left( \frac{ f(x) }{ f(0) } \right) } = \frac{ \frac{1}{2} x^2 }{ \lambda } \, \Longrightarrow \boxed{ f(x) = c_0 e^{ \frac{x^2 }{ 2 \lambda } } } \\
 \int_{-\infty}^x t c_0 e^{ t^2 / 2\lambda } dt = c_0 e^{ x^2 / 2 \lambda } - \lim_{t \in - \infty} c_0 e^{t^2 / 2\lambda } 
\end{gathered}
\]
Limit only exists if $\lambda < 0$.

\exercisehead{9} \[
\begin{aligned}
  T(f) & = f'' = \lambda f \\
  f(t) & = c_n \sin{nt} \quad \, f(0) = f(\pi) =0  \\
  f''(t) & = -n^2 c_n \sin{nt} = \lambda f \quad \, \Longrightarrow \lambda_n =-n^2
\end{aligned}
\]

\exercisehead{10} $T(x) = (y_n)$.  $y_n = a-x_n$; \quad $n\geq 1$  \\
$T((x_n)) = (a-x_n) = \lambda(x_n)$ \\

The sequences are equal, so $a-x_n = \lambda x_n$ or $a= (\lambda +1)x_n$.  \\
$(x_n)$ is a convergent sequence, so 
\[
x_n - a= x_n - (\lambda +1)x_n = -\lambda x_n \text{ must go to zero }
\]
So $\lim_{n\to \infty} x_n =0 , \, a=0$.  Then by $a = (\lambda +1)x_n$, $\lambda = -1$ for nonzero $x_n$.  
\[
\boxed{ \lambda = -1, \, (x_n) \text{ s.t. } \lim_{n\to \infty} x_n = 0 \text{ and } x_n \text{ nonconstant } }
\]
If $x_n$ is constant, $a= (\lambda +1)a \, \Longrightarrow \lambda =0$.  
\[
\boxed{ \lambda = 0, \quad \, x_n = a , \, (x_n) \text{ is a constant sequence } }
\]

\exercisehead{11}$T(x) = \lambda x$; $T(y) = \mu y$.  
\[
\begin{gathered}
  T(ax+ by) = \beta(ax+ by) = a\lambda x + b \mu y  \\
  a(\beta - \lambda) x + b(\beta - \mu) y = 0 
\end{gathered}
\]
Use Thm., Thm. 4.2: Let $u_1, u_2, \dots, u_k$ be eigenvectors of linear linear transformation $T: S \to V$.  \\
Assume corresponding eigenvalues $\lambda_1, \lambda_2, \dots, \lambda_k$ distinct.  \\
\quad Then $u_1, u_2, \dots, u_k$ are independent.  
\[
\Longrightarrow x,y \text{ independent }  \quad \, \beta- \lambda = \beta - \mu = 0 
\] 
If $\lambda = \beta, \, \mu \neq \beta$ or  $\mu = \beta, \, \lambda \neq \beta$.  (given that $\lambda, \mu$ distinct).  

\exercisehead{12} Suppose $x,y \in S$, so $\begin{aligned} T(x) & = \lambda x \\ T(y) & = \mu y \end{aligned}$  \\
Suppose $\lambda \neq \mu$.  \\
Suppose $ax + by \in S$ for some $a,b \in \mathbb{R}$.  Then by definition of $S$, $ax+ by$ is an eigenvector of $T$.  \\
\quad Then by Exercise 11, $a$ or $b$ is zero.  Suppose $b=0$.  
\[
\begin{aligned}
  & T(ax+by) = \beta(ax+by) = aT(x) + bT(y) = a\lambda x + b \mu y \\
  & T(ax) = \beta (ax) = a\lambda x = \lambda (ax) 
\end{aligned}
\]
$ax$ nonzero, so $\beta = \lambda$.  \\

So if $x\in S$, so is $ax \in S$, $a\neq 0$ and $T(x) = cx = T(ax) = c(ax)$  \\
\quad This must be true $\forall \, x \in S \Longrightarrow T(x) = cx \quad \, \forall \, x \in S$.  

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 4.8 Exercises - The finite-dimensional case.  Characteristic polynomials.  Calculation of eigenvalues and eigenvectors in the finite-dimensional case.  Trace of a matrix }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} \begin{enumerate}
\item $\left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right]$  $\lambda_{1,2} = 1$  \quad \, $\zeta_{\lambda=1} = \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right], \, \left[ \begin{matrix} 0 \\ 1 \end{matrix} \right]$; \quad \, $E(1) = 2$
\item $\left[ \begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix} \right]$
\[
\begin{gathered}
  \left| \begin{matrix} \lambda -1 & - 1 \\ 0 & \lambda - 1 \end{matrix} \right| = (\lambda -1)^2 = 0 \\
  \left[ \begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] \quad \, \Longrightarrow \zeta_{\lambda =1} = \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right]; \quad \, E(1) = 1 
\end{gathered}
\]
\item $\left[ \begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix} \right]$  
\[
\begin{gathered}
  \left| \begin{matrix} \lambda -1 & 0 \\ -1 & \lambda - 1 \end{matrix} \right| = (\lambda -1)^2 = 0 \\
  \boxed{ \lambda =1, \quad \, \zeta_{\lambda =1 } = \left[ \begin{matrix} 0 \\ 1 \end{matrix} \right]; \quad \, E(1) = 1 }
\end{gathered}
\]
\item $\left[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \right]$
\[
\begin{gathered}
  \left| \begin{matrix} \lambda - 1 & -1 \\ -1 & \lambda - 1 \end{matrix} \right| = (\lambda -1)^2 - 1 = (\lambda -2)\lambda = 0 ; \quad \, \lambda = 0, \, 2 \\
  \begin{aligned} \lambda & = 2, \, \zeta_{\lambda =2 } = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right]; \quad \, & E(2) & = 1 \\ 
    \lambda & = 0, \, \zeta_{\lambda =0} = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right]; \quad \, & E(0) & =1 \end{aligned}
\end{gathered}
\]
\end{enumerate}

\exercisehead{2} $\left[ \begin{matrix} 1 & a \\ b & 1 \end{matrix} \right]$; \, $a>0 , \, b>0$ 
\[
\begin{gathered}
  \left| \begin{matrix} \lambda - 1 & -a \\ -b & \lambda -1 \end{matrix} \right| = (\lambda -1)^2 -ab = \lambda^2 - 2\lambda + 1 -ab =0 \quad \quad \, \lambda_{\pm} = \frac{ 2 \pm \sqrt{ 4 - 4(1)(1-ab) }}{2} = 1 \pm \sqrt{ab} \\
 \quad \, \\
 \left[ \begin{matrix} 1 & a \\ b & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = (1 \pm \sqrt{ab} )\left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] \Longrightarrow \begin{aligned} x_1 + a x_2 & = (1 \pm \sqrt{ab} ) x_1 \\ bx_1 + x_2 & = (1\pm \sqrt{ab})x_2 \end{aligned} \\
 \quad \, \\
 \boxed{ \lambda_{\pm} = 1 \pm \sqrt{ab}; \quad \, \zeta_{\lambda = 1 \pm \sqrt{ab}} = \left( \begin{matrix} \sqrt{a} \\ \pm \sqrt{b} \end{matrix} \right) \quad \, E(1 \pm \sqrt{ab}) = 1  }
\end{gathered}
\]

\exercisehead{3} $\left[ \begin{matrix} c{\theta} & - s{\theta} \\ s{\theta} & c{\theta} \end{matrix} \right]$
\[
\left| \begin{matrix} \lambda - c{\theta} & s{\theta} \\ -s{\theta} & \lambda - c{\theta} \end{matrix} \right| = \lambda^2  -2\lambda c{\theta} + 1 = 0 \Longrightarrow \lambda = c{\theta} \pm i s{\theta}
\]
\[
\begin{aligned}
  & \text{ if } \theta = 2\pi n, \quad & \lambda = 1, \, \xi_{\lambda =1} = \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right], \, \left[ \begin{matrix} 0 \\ 1 \end{matrix} \right] \\ 
  & \text{ if } \theta \neq 2 \pi n, \quad & \lambda = e^{-\pm i \theta} \quad \begin{gathered}
    \left[ \begin{matrix} c{\theta} & -s{\theta} \\ s{\theta} & c{\theta} \end{matrix} \right] \left[ \begin{matrix} x \\ y \end{matrix} \right] = e^{ \pm i \theta} \left[ \begin{matrix} x \\ y \end{matrix} \right] \Longrightarrow \xi_{\lambda = e^{\pm i \theta} } = 1/\sqrt{2} \left[ \begin{matrix} 1 \\ \pm i \end{matrix} \right]
\end{gathered}
\end{aligned}
\]

\exercisehead{4} $A = \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right]$ 
\[
\begin{aligned}
  P_1 & = \left[ \begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix} \right] \\ 
  P_2 & = \left[ \begin{matrix} 0 & -i \\ i & 0 \end{matrix} \right] \\ 
  P_3 & = \left[ \begin{matrix} 1 & 0 \\ 0 & -1 \end{matrix} \right]
\end{aligned} \quad \quad \, \begin{aligned}
  |\lambda I - P_1 | & = \lambda^2 - 1 = 0 \\ 
  |\lambda I - P_2 | & = \lambda^2 - 1 = 0 \\ 
  |\lambda I - P_3 | & = (\lambda -1)(\lambda +1) = 0 
\end{aligned}
\]
\[
\begin{gathered}
  \left| \begin{matrix} \lambda - a & -b \\ -c & \lambda -a \end{matrix} \right| = \lambda^2 - (a+d)\lambda + (ad-bc) = 0 = (\lambda -\lambda_1)(\lambda - \lambda_2) = \lambda^2 - (\lambda_1 + \lambda_2) \lambda + \lambda_1 \lambda_2 \\
  \Delta = ad-bc = -1 \Longrightarrow a=-d \\
  \boxed{ A = \left[ \begin{matrix} a & b \\ c & -a \end{matrix} \right] } \text{ where } a^2 + bc = 1 
\end{gathered}
\]

\exercisehead{5}
\[
\begin{gathered}
  det{(A -\lambda I)} = \lambda^2 - (a+d)\lambda + (ad-bc) = 0 \Longrightarrow \lambda = \frac{ (a+d) \pm \sqrt{ (a+d)^2 - 4(1)(ad-bc) } }{ 2} \\ 
  \begin{aligned}
    & \text{ if } \sqrt{ (a+d)^2 - 4(ad-bc) } > 0, \, \lambda \text{ real and distinct } \\ 
    & \text{ if } \sqrt{ (a+d)^2 - 4(ad-bc) } = 0, \, \lambda \text{ real and equal } \\ 
    & \text{ if } \sqrt{ (a+d)^2 - 4(ad-bc) } < 0, \, \lambda \text{ complex conjugates }
\end{aligned}
\end{gathered}
\]

\exercisehead{6} \[
\begin{aligned}
  & \left[ \begin{matrix} 1 & 1 & 1 \\ a & b & c \\ d & e & f \end{matrix} \right] \left[ \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right] = 3 \left[ \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right] & \quad \, \begin{aligned} a + b+ c & = 3 \\ d + e + f & = 3 \end{aligned} \\
  & \left[ \begin{matrix} 1 & 1 & 1 \\ a & b & c \\ d & e & f \end{matrix} \right] \left[ \begin{matrix} 1 \\ 0 \\ -1 \end{matrix} \right] = 0 \left[ \begin{matrix} 1  \\ 0 \\ -1 \end{matrix} \right] & \quad \, \begin{aligned} a - c & = 0 \\ d - f & = 0 \end{aligned} \quad \, \begin{aligned} a & = c \\ d & = f \end{aligned} \\
  & \left[ \begin{matrix} 1 & 1 & 1 \\ a & b & c \\ d & e & f \end{matrix} \right] \left[ \begin{matrix} 1 \\ -1 \\ 0 \end{matrix} \right] = 0 \left[ \begin{matrix} 1 \\ -1 \\ 0 \end{matrix} \right] & \quad \, \begin{aligned} a & = b \\ d & = e \end{aligned}
\end{aligned}
\]
\[
a = b= c = d = e = f = 1 
\]

\exercisehead{7} \begin{enumerate}
\item $\left[ \begin{matrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 4 & -7 & 1 \end{matrix} \right]$
\[
\left| \begin{matrix} 1 - \lambda & & \\ -3 & 1-\lambda & \\ 4 & -7 & 1- \lambda \end{matrix}  \right| = \left| \begin{matrix} 1 - \lambda & & \\ & 1- \lambda & \\ & & 1- \lambda \end{matrix} \right| = 0 \,  \quad \Longrightarrow \lambda =1
\]
\[
\left[ \begin{matrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 4 & -7 & 1 \end{matrix} \right]\left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] = \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right]  \quad \, \Longrightarrow \begin{aligned} x_1 & = 0 \\ x_2 & =0 \\ x_3 & = 1 \end{aligned} \quad \, \Longrightarrow \zeta_{\lambda =1} = \left[ \begin{matrix} 0 \\ 0 \\ 1 \end{matrix} \right]
\]
\item $\left[ \begin{matrix} 2 & 1 & 3 \\ 1 & 2 & 3 \\ 3 & 3 & 20 \end{matrix} \right]$
\[
\left| \begin{matrix} 2- \lambda & 1 & 3 \\ 1 & 2-\lambda & 3 \\ 3 & 3 & 20 - \lambda \end{matrix} \right| = \left| \begin{matrix} 1 - \lambda & 1 & 3 \\ -1 + \lambda & 2 - \lambda & 3 \\ 0 & 3 & 20-\lambda \end{matrix} \right| = \left| \begin{matrix} 1 - \lambda & 1 & 3 \\ 0 & 3-\lambda & 6 \\ 0 & 3 & 20 -\lambda \end{matrix} \right| = \left| \begin{matrix} 1-\lambda & & \\ & 3- \lambda & 6 \\ & 3 & 20 - \lambda \end{matrix} \right|
\]
\[
\begin{gathered}
(1-\lambda)((3-\lambda)(20-\lambda) -18) = (1-\lambda)(60 - 23 \lambda + \lambda^2 - 18) = (1-\lambda)(42 -23 \lambda + \lambda^2) = (1-\lambda)(\lambda -21)(\lambda - 2) = 0 \\
  \Longrightarrow \lambda = 1, \, 2, \, 21 
\end{gathered}
\]
\item $\left[ \begin{matrix} 5 & -6 & -6 \\ -1 & 4 & 2 \\ 3 & -6 & -4 \end{matrix} \right]$ 
\[
\begin{gathered}
  \left| \begin{matrix} \lambda -5 & 6 & 6 \\ 1 & \lambda -4 & -2 \\ -3 & 6 & \lambda +4 \end{matrix} \right| = \left| \begin{matrix} \lambda -2 & 0 & -\lambda + 2 \\ 0 & \lambda -4 & -1 \\ 0 & 6 & \lambda + 1 \end{matrix} \right| = (\lambda -2)^2 (\lambda -1 ) \\ 
  \Longrightarrow \xi_{\lambda =1} = \frac{1}{\sqrt{19}} \left[ \begin{matrix} 3 \\ -1 \\ 3 \end{matrix} \right] , \, \xi_{\lambda =2} = \frac{1}{\sqrt{18}} \left[ \begin{matrix} 4 \\ 1 \\ 1 \end{matrix} \right], \, \frac{1}{\sqrt{2}} \left[ \begin{matrix} 0 \\ 1 \\ -1 \end{matrix} \right]
\end{gathered}
\] 
\end{enumerate}

\exercisehead{8} \begin{enumerate}
\item $\left[ \begin{matrix} & & 1 & \\ & & & 1 \\ 1 & & & \\ & 1 & & \end{matrix} \right]$
\[
\left| \begin{matrix} -\lambda & & 1 & \\ & -\lambda & & 1 \\ 1 & & -\lambda & \\ & 1 & & -\lambda \end{matrix} \right|  = \left| \begin{matrix} -\lambda & & 1 - \lambda^2 & \\ & -\lambda & & 1-\lambda^2 \\ 1 & & 0 & \\ & 1 & & 0 \end{matrix} \right| = (1-\lambda^2)^2 \Longrightarrow \lambda = \pm 1
\]
\item $\left[ \begin{matrix} 1 & & & \\ & 1 & & \\ & & -1 & \\ & & & -1 \end{matrix} \right]$ \quad $\Longrightarrow (\lambda-1)^2(\lambda+1)^2 = 0 \text{ so } \lambda = \pm 1$
\item $\left[ \begin{matrix} & 1 & & \\ 1 & & & \\ & & & 1 \\ & & 1 & \end{matrix} \right]$ 
\[
\left| \begin{matrix} \lambda & -1  & & \\ -1 & \lambda & & \\ & & \lambda & -1  \\ & & -1 & \lambda \end{matrix} \right| = (\lambda^2-1)(\lambda^2 -1) \Longrightarrow \lambda = \pm 1 
\]
\item $\left[ \begin{matrix} & -i & & \\ i & & & \\ & & & -i \\ & & i & \end{matrix} \right]$ 
\[
\left| \begin{matrix} -\lambda & -i & & \\ - & -\lambda & & \\ & & -\lambda & -i \\ & & i & -\lambda \end{matrix} \right| = \left| \begin{matrix} -\lambda & -i \\ i & -\lambda \end{matrix} \right|^2 = (\lambda^2 - 1)^2 
\]
\item $\left[ \begin{matrix} 1 & & & \\ & -1 & & \\ & & 1 & \\ & & & -1 \end{matrix} \right] \Longrightarrow ((\lambda +1)(\lambda - 1))^2 = 0$
\end{enumerate}

\exercisehead{10}

\exercisehead{11} Let $(AB)x = \lambda x$
\[
A^{-1}(AB)x = \lambda (A^{-1}x) = BX
\]
Let $x= Ay$
\[
\lambda (A^{-1} A y) = BA y = \lambda y 
\]
So if $\lambda$ is eigenvalue of $AB$, $\lambda$ is also an eigenvalue of $BA$ ($A$ is invertible).

\exercisehead{13}

\exercisehead{14} \begin{enumerate}
\item \[
tr{(A+B)} = \sum_{i=1}^N (A+B)_{ii} = \sum_{i=1}^N (a_{ii} + b_{ii}) = \sum_{i=1}^N a_{ii} + \sum_{i=1}^N b_{ii} = tr{A} + tr{B}
\]
\item \[
tr{(cA)} = \sum_{i=1}^N (cA)_{ii} = \sum_{i=1}^N c a_{ii} = c\sum_{i=1}^N a_{ii} = c tr{A}
\]
\item $tr{(AB)} = \sum_{j=1}^N (AB)_{jj} = \sum_{j=1}^N \sum_{k=1}^N a_{jk}b_{kj} = \sum_{k=1}^N \sum_{j=1}^N b_{kj} a_{jk} = \sum_{j=1}^N (BA)_{jj} = tr{(BA)}$
\item $tr{A^T} = \sum_{j=1}^N (A^T)_{jj} = \sum_{j=1}^N a_{jj} = tr{A}$
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 4.10 Exercises - Matrices representing the same linear transformation.  Similar matrices. }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} Given 
\[
\begin{aligned}
  A & = \left[ \begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix} \right] \\
  B & = \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right]
\end{aligned} \quad \, \begin{aligned} f(\lambda) & = \lambda^2 - 2\lambda + 1 \\ g(\lambda) & = (\lambda -1)^2 \end{aligned} 
 \quad \, \begin{gathered} \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right] = x_{\lambda =1 } \\ \zeta_{\lambda =1 } = \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right], \, \left[ \begin{matrix} 0 \\ 1 \end{matrix} \right] \end{gathered}
\]

Suppose $C^{-1}BC = A$.  \smallskip \\
\quad \quad $ C^{-1}C = I = A$.  But $A \neq I$.  \\
\quad Contradiction.  So $\nexists$ $C$ invertible s.t. $C^{-1}BC =A$  

\exercisehead{2} \begin{enumerate}
\item $A = \left[ \begin{matrix} 1 & 0 \\ 1 & 3 \end{matrix} \right]$ 
\[
\begin{gathered}
  \left| \begin{matrix} \lambda - 1 & \\ -1 & \lambda -3 \end{matrix} \right| = (\lambda - 1)( \lambda -3 ) \quad \quad \, \Longrightarrow \begin{aligned} \xi_{\lambda = 1} & = \frac{2}{ \sqrt{5}} \left[ \begin{matrix} 1 \\ -1/2 \end{matrix} \right] \\ \xi_{\lambda =3} & = \left[ \begin{matrix} 0 \\ 1 \end{matrix} \right] \end{aligned} \\ 
  \boxed{ C = \left[ \begin{matrix} 2 /\sqrt{5} & 0 \\ -1/\sqrt{5} & 1 \end{matrix} \right] }  
\end{gathered}
\]
\[
\begin{gathered}
 \text{ indeed, } \frac{1}{ 2/\sqrt{5}} \left[ \begin{matrix} 1 & 0 \\ 1/\sqrt{5} & 2/\sqrt{5} \end{matrix} \right] \left[ \begin{matrix} 1 & \\ 1 & 3 \end{matrix} \right] C = I 
\end{gathered}
\]
\item \[
\begin{gathered}
  A = \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right] \\
  \left| \begin{matrix} \lambda - 1 & -2 \\ -5 & \lambda -4 \end{matrix} \right| = \lambda^2 - 5\lambda +4 -10 = (\lambda - 6)(\lambda + 1) \\ 
  \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = -1,6 \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] \quad \Longrightarrow \begin{aligned} \xi_{\lambda = -1} & = \frac{1}{ \sqrt{2}} \left[ \begin{matrix} 1 \\ & -1 \end{matrix} \right] \\ \xi_{\lambda =6} & = \frac{1}{ \sqrt{29}} \left[ \begin{matrix} 2 \\ 5 \end{matrix} \right] \end{aligned} 
\end{gathered}
\]
\[
\begin{gathered}
  C = \left[ \begin{matrix} 1/\sqrt{2} & 2/\sqrt{29} \\ -1/\sqrt{2} & 5/\sqrt{29} \end{matrix} \right] \\
  \text{ indeed, } 1/(7/\sqrt{2}\sqrt{29}) \left[ \begin{matrix} 5/\sqrt{29} & -2/\sqrt{29} \\ 1/\sqrt{2} & 1/\sqrt{2} \end{matrix} \right] \left[ \begin{matrix} 1 & 2 \\ 5 & 4 \end{matrix} \right]C = \left[ \begin{matrix} -1 & \\ & 6 \end{matrix} \right] 
\end{gathered}
\]
\item $A = \left[ \begin{matrix} 2 & 1 \\ -1 & 4 \end{matrix} \right]$
\[
\begin{gathered}
  \left| \begin{matrix} \lambda - 2 & -1 \\ 1 & \lambda -4 \end{matrix} \right| = (\lambda -3)^2 \\  
\end{gathered}
\]
Suppose nonsingular $C$ exists, s.t. $C^{-1}AC =3 I \Longrightarrow A = 3I$.  Contradiction.  
\item \[
\begin{gathered}
  A = \left[ \begin{matrix} 2 & 1 \\ -1 & 0 \end{matrix} \right] \quad \quad \, \Longrightarrow \left| \begin{matrix} \lambda -2 & -1 \\ 1 & \lambda \end{matrix} \right| = \lambda^2 - 2\lambda + 1 = (\lambda -1)^2
\end{gathered}
\]
Suppose nonsingular $C$ exists s.t. $C^{-1}AC = I \Longrightarrow A = I$.  Contradiction.  
\end{enumerate}

\exercisehead{3} \[
\begin{aligned}
  & [y_1,y_2] = [x_1,x_2]A \\ 
  & [z_1,z_2] = [x_1,x_2]B \\ 
  & [z_1,z_2] = [y_1,y_2]C = [x_1,x_2]B = [x_1,x_2]AC 
\end{aligned} \quad \quad \, \begin{aligned} B & = AC \\ A^{-1} B & = C \end{aligned} 
\]

\exercisehead{4} 
\begin{enumerate}
\item \[
  \begin{gathered}
    A = \left[ \begin{matrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \end{matrix} \right] \quad \quad \, \Longrightarrow \left| \begin{matrix} \lambda & 0 & -1 \\ 0 & \lambda - 1 & 0 \\ -1 & 0 & \lambda \end{matrix} \right| = \lambda^3 - \lambda^2 - \lambda +1 \\
    \lambda^3 - \lambda^2 - \lambda +1 = (\lambda-1)^2 (\lambda +1)
\end{gathered}
\]
Note that we could still obtain the following independent eigenvectors: $ \left[ \begin{matrix} 1 \\ 0 \\ 1 \end{matrix} \right], \,  \left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right], \,  \left[ \begin{matrix} 1 \\ 0 \\ -11 \end{matrix} \right]$ 
\item \[
\begin{gathered}
  A = \left[ \begin{matrix} 1 & -1 & -1 \\ 1 & 3 & 1 \\ -1 & -1 & 1 \end{matrix} \right] \quad \quad \, \Longrightarrow f(\lambda) = \lambda^3 - 5 \lambda^2 + 8 \lambda -4 = \\
  = (\lambda^2 - 4 \lambda +4)(\lambda -1) = (\lambda -2)^2 (\lambda-1) 
\end{gathered}
\]
\[
\Longrightarrow x_{\lambda =2} = \left[ \begin{matrix} 1 \\ -1 \\ 0 \end{matrix} \right], \quad \, x_{\lambda =2} = \left[ \begin{matrix} 1 \\ 0 \\ -1 \end{matrix} \right], \quad \, x_{\lambda =1} = \left[ \begin{matrix} -1 \\ 1 \\ -1 \end{matrix} \right]
\]
\end{enumerate}

\exercisehead{5} Generally, we'll have 
\[
C^{-1}AC = \lambda I + \left[ \begin{matrix} & \\ 1 & \end{matrix} \right] \Longrightarrow A = \lambda I + C \left[ \begin{matrix} & \\ 1 & \end{matrix} \right] C^{-1}
\]
\[
\begin{gathered}
  \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right] \left[ \begin{matrix} & \\ 1 & \end{matrix} \right] C^{-1} = \left[ \begin{matrix} b & 0 \\ d & 0 \end{matrix} \right] \frac{1}{det{C}} \left[ \begin{matrix} d & -b \\ -c & a \end{matrix} \right] = \\
  = \frac{1}{det{C}} \left[ \begin{matrix} bd & -d^2 \\ d^2 & -bd \end{matrix} \right]
\end{gathered}
\]
\begin{enumerate}
\item So for $A = \left[ \begin{matrix} 2 & -1 \\ 0 & 2 \end{matrix} \right]$.  Then $d=0, \, b = 1, \, c=-1$ for $C$.  
\item For $A = \left[ \begin{matrix} 2 & 1 \\ -1 & 4 \end{matrix} \right] \Longrightarrow \lambda = 3$.  So $bd =-1$, \, $ad-bc = -1$.  
\[
\begin{aligned}
  & \text{ if $b=1$, \, $d = -1$, \, $-a-c=-1$ } \quad a+c=1 \\
  & \text{ if $b=-1$, \, $d=1$, \, $a+c=-1$ } 
\end{aligned}
\]
\end{enumerate}

\exercisehead{6} \[
\begin{gathered}
  \left[ \begin{matrix} 0 & -1 & \\ & & 1 \\ -1 & -3 & 5 \end{matrix} \right] \Longrightarrow \left| \begin{matrix} \lambda & 1 & \\ & \lambda & -1 \\ 1 & 3 & \lambda -3 \end{matrix} \right| = (\lambda -1)^3 \\ 
  \Longrightarrow \frac{1}{\sqrt{3}} \left[ \begin{matrix} 1 \\ -1 \\ -1 \end{matrix} \right]
\end{gathered}
\]
Suppose $C^{-1}AC = I$.  $A=CC^{-1} = 1$ so diagonalizing matrix cannot exist for this $A$.  

\textbf{CHECK} this result.  

\exercisehead{7}\begin{enumerate}
\item $\forall$ matrix $A$, we can always consider the characteristic polynomial $|\lambda I -A| = f(\lambda)$.  So $\exists \, n$ roots, $\lambda_j \in \mathbb{C}$ 
If $\lambda_j \neq 0$, \, $\forall \, j=1,\dots, n$, then $det{(C^{-1}AC)} = det{A} = det{(\Lambda)} = \prod_{j=1} \lambda_j \neq 0$.  So $A$ nonsingular.  

If $A$ nonsingular, $det{A} \neq 0$, so 
\[
det{A} = det{ (C^{-1}AC)} = det{\Lambda \neq 0} \quad \, \Longrightarrow \lambda_j \neq \, \forall \, j
\]
\item $A$ nonsingular, 
\[
det{(AA^{-1})}= det{A}det{A^{-1}} = det{C^{-1}AC} det{D^{-1}AD} = det{\Lambda_A}det{\Lambda_A} = \prod_{j=1}^n \lambda_j \prod_{k=1}^n b_k = 1
\]
$\lambda_j$, $b_k$ distinct, so $b_k = \frac{1}{ \lambda_j}$
\end{enumerate}

\exercisehead{8}
\begin{enumerate}
\item $A^2=-1$ so $A^{-1} = -A$, so $A$ nonsingular.  
\item $det{A^2} = (det{A})^2 = (-1)^n$.  $(det{A})^2 >0$, so $(-1)^n = 1$; \, $n$ even.  
\item $A x= \lambda x$ \\
  $A^2 x = -x = \lambda^2 x$ \quad $\lambda^2 = -1$
\item $det{A} =1$  From fundamental theorem of algebra, roots of the characteristic polynomial must come in complex conjugate pairs.  We already showed that the eigenvalues are purely imaginary.  So there must be a whole number of pairs of complex conjugate eigenvalues that multiply together to get ${-1}$.  \textbf{CHECK} this result.  
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 5.5 Exercises - Eigenvalues and inner products, Hermitian and skew-Hermitian transformations, Eigenvalues and eigenvectors of Hermitian and skew-Hermitian operators, Orthogonality of eigenvectors corresponding to distinct eigenvalues }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1}
\[
\begin{aligned}
  & \text{ if } T(x) = \lambda x, (T(x),y) = (\lambda x, y) = \lambda (x,y) \, \forall y \in E \\
  & \text{ if } (T(x),y) = (\lambda x,y) \, \forall y \in E \\
  & \quad \Longrightarrow (T(x) - \lambda x,y) = 0 \, \forall y \in E \\
  & \quad \quad \Longrightarrow T(x) = \lambda x
\end{aligned}
\]

\exercisehead{2}
\[
\begin{aligned}
  & (T(x),y) = (cx,y) = c(x,y) \\
  & (x,T(y)) = (x,cy) = \bar{c} (x,y) \\
  & \text{ since $V$ is a real Euclidean space $c \in \mathbb{R}$ for $(T(x),y), (x,T(y)) \in \mathbb{R}$ }
\end{aligned}
\]

\exercisehead{3}
\begin{enumerate}
\item \quad Assume $T:V \to V$ is a Hermitian transformation.   \\

Use induction: 
\[
\begin{aligned}
  (Tx,y) & = (x,Ty) \\
  (T^2 x,y) & = (Tx,Ty) = (x,T^2 y) \\
  (T^{n+1} x, y ) & = (Tx,T^n y) = (x,T^{n+1} y) 
\end{aligned}
\]
$T^{-1}$ is Hermitian since
\[
  (T^{-1}x,y) = (T^{-1}x, TT^{-1} y) = (TT^{-1} x, T^{-1} y) = (x,T^{-1}y)
\]
\emph{Neat trick, no?}
\item $  (T(x),y) = -(x,T(y)) $.  Now $(T^2(x),y) = - (T(x),T(y)) = (-1)^2 (x,T^2(y)) $.  \\
Assume the $n$th case, $(T^n(x),y) = (-1)^n(x,T^n(y))$, i.e. $T^n$ is Hermitian (skew-Hermitian) if $n$ is even (odd).  Then consider that
\[
(T^{n+1}(x),y) = -(T^n(x),T(y)) = - (-1)^{n} (x,T^{n+1}(y)) = (-1)^{n+1} (x,T^{n+1}(y))
\]
\[
(T^{-1}(x), y) = (T^{-1}(x), TT^{-1}y) = -(TT^{-1}(x), T^{-1}(y)) = -(x,T^{-1}(y))
\]
So $T^{-1}$ is skew-Hermitian.  
\end{enumerate}

\exercisehead{4} 
\begin{enumerate} 
\item \[
  \begin{aligned} ((aT_1+bT_2)(x),y) & = (aT_1(x)+bT_2(x),y) = a(T_1(x),y) + b(T_2(x),y) = (x,(aT_1)(y)) + (x,(bT_2)y) = \\ 
& = (x, (aT)(y) + (bT_2)(y))  = (x,(aT_1+bT_2)y) 
  \end{aligned}
  \]
\item \[
\begin{gathered}
  (T_1 T_2(x),y) = (T_2(x),T_1(y)) = (x,T_2 T_1(y)) \\
\text{ if } T_1 T_2 =T_2 T_1; T_1 T_2 \text{ is Hermitian } 
\end{gathered}
\]
\end{enumerate}

\exercisehead{5}
Let $V = V_3(\mathbb{R})$.  
\[
\begin{aligned}
  (T(x),y) &= \sum_{j=1}^3 (T(x))_j y_j = x_1 y_1 + x_2 y_2 -x_3 y_3  \\
  & = x_1 y_1 + x_2 y_2 +x_3 (-y_3) = (x,T(y))
\end{aligned}
\]

  \exercisehead{6}
$\int_0^1 f(t)dt = F(1)-F(0) = 0, F(1)= F(0)$, likewise, for $g \in V$, $\int_0^1 g(t)dt = G(1)-G(0) = 0, G(1)= G(0)$.  
The trick is to use integration by parts
\[
\begin{aligned}
  (Tf,g) & = \int_0^1 (Tf)(t)g(t) dt = \int_0^1 \int_0^t f(x)dx g(t) dt = \\ 
& = \int_0^1 F(t)g(t) dt - F(0) \int_0^1 g(t)dt = \left. F(t)G(t) \right|_0^1 - \int_0^1 f(t)G(t) dt = -(f,Tg)
\end{aligned}
\]

\exercisehead{7}
\begin{enumerate}
  \item \[ \begin{aligned} (Tf,g) & = \int_{-1}^1 Tf(t)g(t) dt = \int_{-1}^1 f(-t)g(t) dt = \int_1^{-1}f(t)g(-t)(-dt) = \int_{-1}^1 f(t)g(-t)dt = \\
    & = (f,Tg) \\
  \end{aligned} \] 
    \item \[
      \begin{gathered}
	(Tf,g) = \int_{-1}^1 f(t)f(-t)g(t) dt \text{ but } (f,Tg) = \int_{-1}^1 f(t)g(t)g(-t) dt \\
	\Longrightarrow \text{ Neither symmetric nor skew-symmetric (choose different coefficients for $f$ and $g$ ) } 
      \end{gathered}
      \]
    \item \[
\begin{aligned}
  (Tf,g) & = \int_{-1}^1 Tf(t) g(t) dt = \int_{-1}^1 (f(t) + f(-t)) g(t) dt = \int_{-1}^1 fg + - \int_1^{-1} f(t)g(-t)dt = \\
  & = \int_{-1}^1 f(t)(g(t) + g(-t))dt = (f,Tg) 
\end{aligned}
\]  Hermitian.  
    \item \[
\begin{aligned}
  (Tf,g) & = \int_{-1}^1 (f(t)-f(-t)) g(t) dt = \int_{-1}^1 fg - \int_{-1}^1 f(-t)g(t) dt = \\
  & = \int_{-1}^1 fg - \int_1^{-1} f(t) g(-t) (-dt) = \int_{-1}^1 f(g(t) - g(-t)) dt = (f,Tg)
\end{aligned}
\] Hermitian.  
\end{enumerate}

\exercisehead{8} Given $(f,g) = \int_a^b f(t)g(t) w(t) dt$, $T(f)  = \frac{ (pf')' + qf }{ w } $ 
\[
\begin{gathered}
  (Tf,g) = \int_a^b (Tf)(t) g(t) w(t) dt = \int_a^b \frac{ (pf')'(t) + q(t)f(t) }{w(t) } g(t) w(t) dt = \int_a^b ((pf')'+qf )g \\
  \int_a^b (pf')'g = \left. (pf')g \right|_a^b - \int_a^b (pf')g' = - \int_a^b (pf')g' \\
  \quad \\ 
  \text{ since $f,g$ satisfy } \begin{aligned} p(a) f(a) & = 0 \\
    p(b) f(b) & = 0 \end{aligned} \\
  \quad \\
  \int_a^b (pf')g' = \left. pg' f \right|_a^b - \int_a^b (pg')' f = 0 - \int_a^b (pg')'f \\
\Longrightarrow (Tf,g) = \int_a^b (pg')'f + qfg = \int_a^b wf \frac{ ((pg')' +qg )}{w} = (f,Tg)
\end{gathered}
\]
\exercisehead{9} Let $V$ be a subspace of a complex Euclidean space $E$.  \\
Let $T: V \to E$ be a linear transformation and define a scalar-valued function $Q$ on $V$ as follows: 
\[
Q(x) = (T(x),x) \quad \, \forall \, x \in V
\]
\begin{enumerate}
\item $T$ Hermitian.  
\[
(Tx,x) = (x,Tx) = \overline{ (Tx,x)} = \overline{Q(x)} = Q(x) \Longrightarrow Q(x) \in \mathbb{R}
\]
\item 
\[
(Tx,x) = - (x,Tx) = - \overline{(Tx,x)} = - \overline{Q(x)} = Q(x) \Longrightarrow Q(x) \text{ pure imaginary }
\]
\item 
\[
\begin{aligned}
  Q(tx) & = (T(tx),tx) = (tTx,tx) \quad \, \text{(since $T$ is linear)} \\
  Q(tx) & = t(Tx,tx) = t\overline{(tx,Tx)} = t\overline{t} (Tx,x) = t\overline{t}Q(x)
\end{aligned}
\]
\item \[
\begin{gathered}
  \begin{aligned} Q(x+y) & = (T(x+y),x+y) = (Tx+Ty,x+y) = (Tx,x+y) + (Ty,x+y) = \\
    & = \overline{(x+y,Tx)} + \overline{(x+y,Ty)} = \overline{(x,Tx)} + \overline{(y,Tx)} + \overline{(x,Ty)} + \overline{(y,Ty)} = \\
    & = (Tx,x) + (Tx,y) + (Ty,x) + (Ty,y) = Q(x) + Q(y) + (T(x),y) + (T(y),x) 
\end{aligned} \\
  \begin{aligned}
Q(x+ty)  = Q(x) + Q(ty) + (T(x),ty) +(T(ty),x) = Q(x) + t\overline{t}Q(y) + \overline{t}(T(x),y) + t(T(y),x)
\end{aligned}
\end{gathered}
\]
\item Suppose $T(x) = y \neq 0$ for some $x \in V$, \, $y \in E$, \, $x \neq 0$ 
\[
(T(x),x) = (y,x) = 0 
\]
$y\neq x$, otherwise $(x,x) = 0$; \, $x = 0$.  Contradiction.  Done.  
\[
\begin{gathered}
  \begin{aligned}
    Q(ax+by) & = (T(ax+by),ax+by) = |a|^2(T(x),x) + \overline{b}a(T(x),y) + b\overline{a}(T(y),x) + |b|^2 (T(y),y) \\ & = a\overline{b}(T(x),y) + b\overline{a}(T(y),x) = 0 \end{aligned} \\
  \begin{aligned}
     \text{ Let } &  a = 1, \, b = -1 \\
     & -(T(x),y) = (T(y),x)  = (y,y) > 0 \\
     \text{ Let } & a\overline{b} = i \\
     & (T(x),y) = (T(y),x) = (y,y) > 0 
  \end{aligned}
\end{gathered}
\]
Contradiction.  Thus $y=0$.  
\item \[
\begin{gathered}
  Q(x+ty) = Q(x) + t\overline{t}Q(y) + \overline{t}(T(x),y) + t(T(y),x) \\
  Q \in \mathbb{R} \Longrightarrow  \overline{Q(x+ty)} = Q(x+ty) \Longrightarrow t(y,T(x)) + \overline{t} (x,T(y)) = \overline{t} (T(x),y) + t(T(y),x) \\
  \Longrightarrow t((y,T(x)) - (T(y),x)) + \overline{t} ((x,T(y)) - (T(x),y)) = 0  \\
\quad \\
\text{ Suppose $t = a+bi$, $a,b$ arbitrary } \\
\Longrightarrow \begin{aligned} 
  (y,T(x)) - (T(y),x) + ((x,T(y))- (T(x),y)) &= 0 \\ 
  (y,T(x)) - (T(y),x) - ((x,T(y))- (T(x),y)) &= 0 \\
\end{aligned} \quad \, \Longrightarrow (y,T(x)) - (T(y),x) = 0 \text{ so $T$ is Hermitian.}
\end{gathered}
\]
\end{enumerate}

\exercisehead{10} Legendre polynomials: 
\[
P_n(t) = \frac{1}{2^n n!} f_n^{(n)}(t) \text{ where } f_n(t) = (t^2-1)^n 
\]
\begin{enumerate}
\item \[
(t^2-1)f_n'(t) = (t^2 -1)(n)(t^2-1)^{n-1}(2t) = 2nt(t^2-1)^n = 2ntf_n(t)
\]
\item Leibniz's formula.  If $h(x) = f(x)g(x)$, prove that the $n$th derivative of $n$ is given by the formula.
\[
h^{(n)}(x) = \sum_{k=0}^n \binom{n}{k} f^{(k)}(x) g^{(n-k)}(x)
\]
so then
\[
\begin{gathered}
  \begin{aligned} 
    ((t^2-1)f_n'(t))^{(n+1)} & = \sum_{k=0}^{n+1} \binom{n+1}{k} (t^2-1)^{(k)} (f_n'(t))^{(n+1-k)} = \\
    & = (t^2-1)f_n^{(n+2)}(t) + (n+1)2t f_n^{(n+1)}(t) + \frac{(n+1)n}{2} 2 f_n^{(n)}(t) 
  \end{aligned} \quad \quad \quad \, \begin{aligned} (t^2-1)' &= 2t \\ (t^2-1)'' & = 2 \\ (t^2-1)'' & = 0 \end{aligned} \\
  \quad \\ 
  (2ntf_n(t))^{(n+1)} = (2n)(t(f_n(t))^{(n+1)} + (n+1)(f_n(t))^{(n)}) \\
  \Longrightarrow (t^2-1)f_n^{(n+2)}(t) + 2t (n+1)f_n^{(n+1)}(t) + (n+1)nf_n^{(n)}(t) = (2n) (tf_n^{(n+1)}(t) + (n+1)(f_n(t))^{(n)})
\end{gathered}
\]
\item $P_n(t) = \frac{1}{2^n n!}f_n^{(n)}(t) $ 
\[
\begin{gathered}
  \Longrightarrow (t^2-1)P_n'' + 2t(n+1)P_n' + (n+1)nP_n = (2n)(tP_n' + (n+1)P_n) \\
  \Longrightarrow (t^2-1)P_n'' + 2tP_n' - (n+1)nP_n = 0 \text{ or } \boxed{ ((t^2-1)P_n')' = n(n+1)P_n }
\end{gathered}
\]
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 5.11 Exercises - Existence of an orthonormal set of eigenvectors for Hermitian and skew-Hermitian operators acting on finite-dimensional spaces; Matrix representations for Hermitian and skew-Hermitian operators;  Hermitian and skew-Hermitian matrices.  The adjoint of a matrix;  Diagonalization of a Hermitian or skew-Hermitian matrix; Unitary matrices.  Orthogonal matrices }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1}\begin{enumerate}
\item $\left[ \begin{matrix} 0 & 1 & 2 \\ 1 & 0 & 3 \\ 2 & 3 & 4 \end{matrix} \right]$.  Symmetric.  Hermitian.  
\item $\left[ \begin{matrix} 0 & i & 2 \\ i & 0 & 3 \\ -2 & -3 & 4i \end{matrix} \right]$.  Skew-Hermitian.  
\item $\left[ \begin{matrix} 0 & i & 2 \\ -i & 0 & 3 \\ -2 & -3 & 0 \end{matrix} \right]$.  Skew-symmetric.
\item $\left[ \begin{matrix} 0 & 1 & 2 \\ -1 & 0 & 3 \\ -2 & -3 & 0 \end{matrix} \right]$.  Skew-Hermitian.  Skew-symmetric.  
\end{enumerate}

\exercisehead{2} 
\begin{enumerate}
\item \[
  \left[ \begin{matrix} \cos{\theta} & - \sin{\theta} \\ \sin{\theta} & \cos{\theta} \end{matrix} \right]   \left[ \begin{matrix} \cos{\theta} &  \sin{\theta} \\ -\sin{\theta} & \cos{\theta} \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right] 
\]
\item \[   \left[ \begin{matrix} \cos{\theta} & - \sin{\theta} \\ \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} r \cos{\alpha} \\ r\sin{\alpha} \end{matrix} \right] = \left[ \begin{matrix} r \cos{\alpha} \cos{\theta} - r \sin{\alpha} \sin{\theta} \\ r \cos{\alpha} \sin{\theta} + r \sin{\alpha} \cos{\theta} \end{matrix} \right] = r \left[ \begin{matrix} \cos{ (\alpha + \theta) } \\ \sin{ (\alpha + \theta) } \end{matrix} \right] 
\]
\end{enumerate}

\exercisehead{3} 
\begin{enumerate}
\item $\left[ \begin{matrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -1 \end{matrix} \right]$ (reflection in the $xy$-plane).  
  \[
  \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & - 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] \quad \quad \, 
  \begin{aligned} 
    & \left[ \begin{matrix} 1 &  & \\ & 1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right]  \\ 
    & \left[ \begin{matrix} 1 &  & \\ & 1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right] \\ 
    & \left[ \begin{matrix} 1 &  & \\ & 1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 0 \\ 0 \\ 1 \end{matrix} \right] = \left[ \begin{matrix} 0 \\ 0 \\ -1 \end{matrix} \right] 
    \end{aligned} 
\]
  \item $\left[ \begin{matrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & -1 \end{matrix} \right]$ (reflection through the $x$-plane).  
    \[
    \left[ \begin{matrix} 1 & & \\ & -1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 1 & & \\ & -1 & \\ & & - 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] \quad \quad \, 
    \begin{aligned} 
      & \left[ \begin{matrix} 1 &  & \\ & -1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right]  \\ & \left[ \begin{matrix} 1 &  & \\ & -1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right] = -\left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right] \\ 
      & \left[ \begin{matrix} 1 &  & \\ & -1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} 0 \\ 0 \\ 1 \end{matrix} \right] = \left[ \begin{matrix} 0 \\ 0 \\ -1 \end{matrix} \right] 
\end{aligned}
\]
\item $\left[ \begin{matrix} -1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & -1 \end{matrix} \right]$ (reflection through the origin).  
  \[
  \left[ \begin{matrix} -1 & & \\ & -1 & \\ & & -1 \end{matrix} \right] \left[ \begin{matrix} -1 & & \\ & -1 & \\ & & - 1 \end{matrix} \right] = \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right] \quad \quad \, \left[ \begin{matrix} -1 & & \\ & -1 & \\ & & -1 \end{matrix} \right] i,j,k = -i,j,k)
\]
\item $\left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & -\sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right]$ (rotation about the $x$-axis).  
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & + \sin{\theta} \\ 0 & -\sin{ \theta} & \cos{\theta} \end{matrix} \right] = \left[ \begin{matrix} 1 & 0 & 0 \\  0 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] \\
  \begin{aligned}
    & \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 1 \\ 0 \\ 0 \end{matrix} \right] \\
    & \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} 0 \\ 1 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} 0 \\ \cos{\theta} \\ \sin{\theta} \end{matrix} \right] \\ 
    & \left[ \begin{matrix} 1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right] \left[ \begin{matrix} 0 \\ 0 \\ 1 \end{matrix} \right] = \left[ \begin{matrix} 0 \\ -\sin{\theta} \\ \cos{\theta} \end{matrix} \right]
  \end{aligned}
\end{gathered}
\]
\item $\left[ \begin{matrix} -1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right]$ (rotation about $x$-axis followed by reflection in the $yz$-plane).  
\[
\begin{gathered}
  \left[ \begin{matrix} -1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right]\left[ \begin{matrix} -1 & 0 & 0 \\ 0 & \cos{\theta} & \sin{\theta} \\ 0 & -\sin{\theta} & \cos{\theta} \end{matrix} \right] = \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right]
  \left[ \begin{matrix} -1 & & \\ & 1 & \\ & & 1 \end{matrix} \right]\left[ \begin{matrix} 1 & & \\ & c_{\theta} & -s_{\theta} \\ & s_{\theta} & c_{\theta} \end{matrix} \right] = \left[ \begin{matrix} -1 & 0 & 0 \\ 0 & \cos{\theta} & - \sin{\theta} \\ 0 & \sin{\theta} & \cos{\theta} \end{matrix} \right] = \\ = \text{(reflection in the $yz$-plane)}\text{(rotation about $x$-axis)}
\end{gathered}
\]
\end{enumerate}

\exercisehead{4} A real orthogonal matrix $A$ is called \emph{proper} if $det{A} =1$, and \emph{improper} if $det{A} =-1$.  
\begin{enumerate}
\item \[
\begin{gathered}
  \left[ \begin{matrix} a & b \\ c & d \end{matrix} \right]  \left[ \begin{matrix} a & c \\ b & d \end{matrix} \right] = \left[ \begin{matrix}a^2 + b^2 & ac + bd \\ ac+ bd & c^2 + d^2 \end{matrix} \right] \Longrightarrow \begin{aligned} ac + bd & = 0 \\ a^2 + b^2 & =1 \\ ad-bc & =1 \end{aligned} \\
  \quad \\
\Longrightarrow  \cos^2{\theta} \left( \frac{-c}{\sin{\theta}} \right) - \sin{\theta} c = 1 \quad \, \Longrightarrow \begin{aligned} a & = \cos{\theta} \\ b & = \sin{\theta} \\ c & = -\sin{\theta} \\ d & = \cos{\theta} \end{aligned}
\end{gathered}
\]
\item \[
\begin{aligned}
  \left[ \begin{matrix} 1 & \\ & -1 \end{matrix} \right]   \left[ \begin{matrix} 1 & \\ & -1 \end{matrix} \right] & =   \left[ \begin{matrix} 1 & \\ & 1 \end{matrix} \right] \\ 
    \left[ \begin{matrix} -1 & \\ & 1 \end{matrix} \right]   \left[ \begin{matrix} -1 & \\ & 1 \end{matrix} \right] & =   \left[ \begin{matrix} 1 & \\ & 1 \end{matrix} \right] \\ 
\end{aligned} \quad \quad \, \begin{aligned}
  & det{ \left[ \begin{matrix} 1 & 0 \\ 0 & -1 \end{matrix} \right]} = -1 \\ 
  &  det{ \left[ \begin{matrix} -1 & 0 \\ 0 & 1 \end{matrix} \right]} = -1 
\end{aligned}
\]
From previous part, all improper $2\times 2$ matrices: \[
\left[ \begin{matrix} \cos{\theta} & \sin{\theta} \\ \sin{\theta} & -\cos{\theta} \end{matrix} \right]
\]
\end{enumerate}

\exercisehead{13} If $A$ is a real skew-symmetric matrix, prove that both $I-A$ and $I+A$ are nonsingular and that $(I-A)(I+A)^{-1}$ is orthogonal.  \\

Note: Notice the difference between skew-Hermitian and skew symmetric and use eignevalue eqn. and one-to-one.  \\

Skew-Hermitian matrices must be square matrices (from how Skew-Hermitian operators, $T$, are defined as $T:V\to V$).  \\
For skew-symmetric matrices, eigenvalues must equal zero, since $-\lambda = \overline{\lambda}$

\[
\begin{gathered}
  C^{-1}AC = \Lambda =0  \\
  \begin{aligned}
    det{(1 \pm A)} & = det{ (C^{-1} C)}det{(1\pm A)} = det{(C^{-1})} det{(1\pm A)} det{C} = \\
    & = det{( 1 \pm C^{-1}AC)}= det{(1\pm 0)} = \boxed{ 1}
  \end{aligned}
\end{gathered}
\]
To prove orthogonality of $(I-A)(I+A)^{-1}$, use $(AB)^T = B^T A^T$ extensively.  

We know that $A$ is real skew-symmetric, so that $A = -A^T$.  
\[
\begin{aligned}
  (1+A)(1+A)^{-1} & =1 \\ 
  ((1+A)(1+A)^{-1})^T = ((1+A)^{-1})^T (1+A^T)  = 1^T = 1
\end{aligned}
\]
Thus,
\[
\begin{gathered}
  (1-A)(1+A)^{-1}((1+A)^{-1}(1-A))^T = \\ 
  \begin{aligned}
    & = (1-A)(1+A)^{-1}(1-A^T)((1+A)^{-1})^T = (1-A) \left( (1+A)^{-1} (1+A) \right) ((1+A)^{-1})^T = \\
    & = (1-A) ((1+A)^{-1})^T = (1+A^T)((1+A)^{-1})^T = (1+A)^T((1+A)^{-1})^T = ((1+A)^{-1}(1+A))^T = 1^T = 1
  \end{aligned}
\end{gathered}
\]
Note that we have $((1-A)(1+A)^{-1})^T = ((1+A)^{-1}(1-A))^T$ because if $(1+A)^{-1} = B$, 
\[
\begin{gathered}
  \begin{aligned}
  (1+A)B & = B + AB = 1 \\
  B(1+A) & = B + BA = 1 \quad \, \text{(since a left inverse is a right inverse)} 
\end{aligned} \quad \quad \, \Longrightarrow BA = AB \\
  (1-A)(1+A)^{-1} = (1-A)B = B - AB = B - BA = B(1-A) = (1+A)^{-1}(1-A)
\end{gathered}
\]

\exercisehead{14} \begin{enumerate}
\item Counterexample: \[
\begin{gathered}
  \begin{aligned}
    A & = \left[ \begin{matrix} 1 & \\ & e^{-i 2\pi /3} \end{matrix} \right]  \\
    A^* & = \left[ \begin{matrix} 1 & \\ & e^{i 2\pi /3 } \end{matrix} \right]
  \end{aligned} \quad \quad \, 
  \begin{aligned}
    B & = \left[ \begin{matrix} e^{i 2\pi/3} & \\ & 1 \end{matrix} \right] \\
    B^* & = \left[ \begin{matrix} e^{ -i 2\pi /3} & \\  & 1 \end{matrix} \right]
  \end{aligned} 
\quad \quad \, 
\begin{aligned}
  (A+B) & =  \left[ \begin{matrix} 1 + e^{i 2\pi /3} & \\ & 1 + e^{-i2\pi/3} \end{matrix} \right] \\
  A^*+B^* = (A+B)^* & = \left[ \begin{matrix} 1 + e^{-i 2\pi/3} & \\ & 1 + e^{i2\pi/3} \end{matrix} \right]
\end{aligned} \\ 
(A+B)(A^* +B^*) = \left[ \begin{matrix} 2 + e^{i2\pi/3} + e^{-i2\pi/3} & \\ & 2 + e^{i2\pi/3} + e^{-i2\pi/3} \end{matrix} \right]
\end{gathered}
\]
\item If $A$ and $B$ are unitary, then $AB$ is unitary.  \[
\begin{gathered}
  AA^* = BB^* = 1 \\
  (AB)(AB)^* = (AB) B^* A^* = A(BB^*)A^* = A1A^* = 1
\end{gathered}
\]
\item 
\item
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 5.15 Exercises - Quadratic forms, Reduction of a real quadratic form to a diagonal form, Applications to analytic geometry }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} $4x_1^2 + 4 x_1 x_2 + x_2^2$.  $ \left[ \begin{matrix} 4 & 2 \\ 2 & 1 \end{matrix} \right] = A$
\[
\begin{gathered}
  \left| \begin{matrix} 4-\lambda & 2 \\ 2 & 1-\lambda \end{matrix} \right| = 4 - 5 \lambda + \lambda^2 -4 = \lambda (\lambda -5) \\
  \xi_{\lambda =5} = \left[ \begin{matrix} 2/\sqrt{5} \\ 1/\sqrt{5} \end{matrix} \right]; \quad \xi_{\lambda=0} = \left[ \begin{matrix} 1/\sqrt{5} \\ -2/\sqrt{5} \end{matrix} \right] \\
  C = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} 2 & 1 \\ 1 & -2 \end{matrix} \right]
\end{gathered}
\]

\exercisehead{2} $\quad x_1 x_2$  $\quad \quad A= \left[ \begin{matrix} 0 & 1/2 \\ 1/2 & 0 \end{matrix} \right]$.  $\lambda = \frac{1}{2}, -\frac{1}{2}$.  \medskip \\
$\quad \xi_{\lambda = 1/2} = \left[ \begin{matrix} 1/\sqrt{2} \\ 1/\sqrt{2} \end{matrix} \right], \quad \xi_{\lambda = -1/2} = \left[ \begin{matrix} 1/\sqrt{2} \\ -1/\sqrt{2} \end{matrix} \right]$


\exercisehead{3} $x_1^2 + 2x_1 x_2 - x_2^2$.  $A = \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right]$  

\exercisehead{4} $34 x_1^2 -24 x_1 x_2 + 41 x_2^2$.  $\quad A = \left[ \begin{matrix} 34 & -12 \\ -12 & 41 \end{matrix} \right]$.  \\

$\left| \begin{matrix} \lambda -34 & 12 \\ 12 & \lambda -41 \end{matrix} \right| = \lambda^2 - 75 \lambda + 34(41) - 144 = \lambda^2 - 75 \lambda +1250 $.  $\boxed{ \lambda = 50,25 }$  
\[
\boxed{ 
\begin{aligned}
  \xi_{\lambda =50} & = \frac{1}{5} \left[ \begin{matrix} 3 \\ -4 \end{matrix} \right] \\
  \xi_{\lambda =25} & = \frac{1}{5} \left[ \begin{matrix} 4 \\ 3 \end{matrix} \right] 
\end{aligned}
\quad \quad \quad C = \frac{1}{5} \left[ \begin{matrix}
    3 & 4 \\
    -4 & 3 
\end{matrix} \right] }
\]
\exercisehead{5} $x_1^2 + x_1 x_2 + x_1 x_3 + x_2 x_3$.  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 1 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{matrix} \right] \quad \, \Longrightarrow \left| \begin{matrix} \lambda - 1 & -1 & -1 \\ -1 & \lambda & -1 \\ -1 & -1 & \lambda \end{matrix} \right| = \left| \begin{matrix} \lambda & -1 & 0 \\ -1 & \lambda - 2 & 0 \\ & 0 & \lambda + 1 \end{matrix} \right| = (\lambda + 1)(\lambda^2 - 2\lambda - 1) \\
  \begin{aligned}
    \xi_{\lambda = -1} & = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 0 \\ 1 \\ -1 \end{matrix} \right] \\
    \xi_{\lambda = 1 \pm \sqrt{2}} & = \frac{1}{2} \left[ \begin{matrix} \pm \sqrt{2} \\ 1 \\ 1 \end{matrix} \right] 
  \end{aligned} \quad \quad \, 
  C = \left[ \begin{matrix} 0 & \sqrt{2}/2 & -\sqrt{2}/2 \\ 1/\sqrt{2} & 1/2 & 1/2 \\ -1/\sqrt{2} & 1/2 & 1/2 \end{matrix} \right]
\end{gathered}
\]

\exercisehead{6} $2x_1^2 + 4x_1 x_3 + x_2^2 - x_3^2$
\[
\begin{gathered}
A =   \left[ \begin{matrix} 2 & & 2 \\ & 1 & \\ 2 & & -1 \end{matrix} \right]  \quad \, \Longrightarrow \left| \begin{matrix} \lambda - 2 & & -2 \\ & \lambda - 1 & \\ -2 & & \lambda + 1 \end{matrix} \right| = (\lambda -1)(\lambda - 3)(\lambda + 2) \\ 
\quad  \\
\begin{aligned}
  \xi_{\lambda = 1} = (0,1,0) \\
  \xi_{\lambda =3} = \frac{1}{\sqrt{5}} (2,0,1) \\
  \xi_{\lambda =-2} = \frac{1}{\sqrt{5}}(1,0,-2) 
\end{aligned} \quad \, \Longrightarrow C = \left[ \begin{matrix} 0 & 2/\sqrt{5} & 1/\sqrt{5} \\ 1 & 0 & 0 \\ 0 & 1/\sqrt{5} & -2/\sqrt{5} \end{matrix} \right]
\end{gathered}
\]


\exercisehead{7} $3x_1^2 + 4x_1 x_@ + 8 x_1 x_3 + 4 x_2 x_3 + 3x_3^2$.  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 3 & 2 & 4 \\ 2 & 0 & 2 \\ 4 & 2 & 3 \end{matrix} \right] \\
  \begin{aligned}
  det{ (\lambda I -A)} & = \left| \begin{matrix} \lambda - 3 &  -2 & -4 \\ -2 & \lambda & -2 \\ -4 & -2 & \lambda -3 \end{matrix} \right|  = \left| \begin{matrix} \lambda + 1 & -2 & 0 \\ -2 \lambda -2 & \lambda & -2 \lambda -2 \\ 0 & -2 & \lambda + 1 \end{matrix} \right| = \left| \begin{matrix} \lambda +1 & -2 & 0 \\ -2 \lambda -2 & \lambda -4 & 0 \\ 0 & -2 & \lambda + 1 \end{matrix} \right| = \\
  & = (\lambda +1)(\lambda -4) (\lambda +1) + 2 (\lambda+1)(-2\lambda -2) = (\lambda +1)(\lambda^2 - 3 \lambda -4 -4 \lambda -4 ) = (\lambda+1)^2(\lambda -8) 
  \end{aligned} 
\end{gathered}
\]
\[
\begin{aligned}
  & \left[ \begin{matrix} 3 & 2 & 4 \\ 2 & 0 & 2 \\ 4 & 2 & 3 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] = -1 \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] \quad \, \Longrightarrow \begin{aligned} 4 x_1 + 2 x_2 + 4 x_3 & = 0 \\ 2 x_1 + x_2 + 2x_3 & = 0 \end{aligned} \quad \, \\
  & \Longrightarrow \xi_{\lambda =-1}  = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ 0 \\ -1 \end{matrix} \right] \\
  & \left[ \begin{matrix} 3 & 2 & 4 \\ 2 & 0 & 2 \\ 4 & 2 & 3 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] = 9 \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] \quad \, \Longrightarrow \left| \begin{matrix} -5 & 2 & 4 \\ 2 & -8 & 2 \\ 4 & 2 & -5 \end{matrix} \right| = \left| \begin{matrix} 0 & -18 & 9 \\ 1 & -4 & 1 \\ 0 & 18 & -9 \end{matrix} \right| = \left| \begin{matrix} & 2 & -1 \\ 1 & 0 & -1 \\ & & \end{matrix} \right| \\
  & \Longrightarrow \xi_{\lambda = 8}  = \frac{1}{3} \left[ \begin{matrix} 2 \\ 1 \\ 2 \end{matrix} \right] \\
  & \left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 0 & -1 \\ 2 & 1 & 2 \end{matrix} \right| = (1,-4,1) \Longrightarrow \xi_{\lambda = -1} = \frac{1}{3\sqrt{2}} \left[ \begin{matrix} 1 \\ -4 \\ 1 \end{matrix} \right]
\end{aligned}
\]
\[
\boxed{ C = \left[ \begin{matrix} 1 /\sqrt{2} & 1 /3\sqrt{2} & 2/3 \\ 0 & -4/3\sqrt{2} & 1/3 \\ -1/\sqrt{2} & 1/3\sqrt{2} & 2/3 \end{matrix} \right] }
\]
\exercisehead{8} $y^2 - 2xy + 2x^2 - 5 = 0$.  
\[
\begin{gathered}
  \left[ \begin{matrix} 2 & -1 \\ -1 & 1 \end{matrix} \right]  \quad \, \Longrightarrow \left| \begin{matrix} \lambda -2 & 1 \\ 1 & \lambda - 1 \end{matrix} \right| = \lambda^2 -3 \lambda + 1 = 0 \\
  \Longrightarrow \lambda = \frac{3 \pm \sqrt{5}}{2} \\ 
  \quad \, \\
  \left[ \begin{matrix} 2 & -1 \\ -1 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{3 \pm \sqrt{5}}{2} \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right]  \Longrightarrow \begin{aligned} \xi_{\lambda = \frac{ 3 + \sqrt{5}}{2} } & = \frac{1}{ \sqrt{ \frac{ 5 - \sqrt{5}}{2} } } \left[ \begin{matrix} 1 \\ \frac{1- \sqrt{5}}{2} \end{matrix} \right]  \\
    \xi_{ \lambda = \frac{3- \sqrt{3}}{2} } & = \frac{1}{ \sqrt{ 5 + \sqrt{5}}{2} } \left[ \begin{matrix} 1 \\ \frac{1 + \sqrt{5}}{2} \end{matrix} \right] \\
\end{aligned} \\
  \Longrightarrow C = \left[ \begin{matrix} \frac{1 }{\sqrt{ \frac{ 5 - \sqrt{5}}{2} }} & \frac{1}{ \sqrt{ \frac{ 5 + \sqrt{5}}{2} } } \\ \sqrt{ \frac{2}{ 5 - \sqrt{5}} } \left( \frac{1 - \sqrt{5}}{2} \right) & \sqrt{\frac{2}{5 + \sqrt{5}} } \frac{1+ \sqrt{5}}{2} \end{matrix} \right]
\end{gathered}
\]
\[
\Longrightarrow \frac{3+\sqrt{5}}{2} x^2 + \frac{ 3 - \sqrt{5}}{2} y^2 = 5 
\]
Ellipse centered about $(0,0)$.  

\exercisehead{9} $y^2 - 2xy + 5x = 0$ 
\[
\begin{gathered}
  \left[ \begin{matrix} 0 & -1 \\ -1 & 1 \end{matrix} \right] = A \\
  | \lambda I -A | = \left| \begin{matrix} \lambda & 1 \\ 1 & \lambda - 1 \end{matrix} \right| = \lambda^2 - \lambda - 1  \quad \, \Longrightarrow \lambda = \frac{ 1 \pm \sqrt{ 1 - 4 (1)(-1) } }{2} = \frac{ 1 \pm \sqrt{5}}{2} \\
  \left[ \begin{matrix} 0 & -1 \\ -1 & 1 \end{matrix} \right]\left[ \begin{matrix} x \\ y \end{matrix} \right] = \frac{ 1 +\sqrt{5} }{2} \left[ \begin{matrix} x \\ y \end{matrix} \right] \quad \, \Longrightarrow \xi_{\lambda = \frac{1 + \sqrt{5}}{2}} = \frac{1}{\sqrt{ \frac{ 5 + \sqrt{5} }{2} }} \left[ \begin{matrix} 1 \\ \frac{ 1 + \sqrt{5}}{ -2} \end{matrix} \right] \\
    \left[ \begin{matrix} 0 & -1 \\ -1 & 1 \end{matrix} \right]\left[ \begin{matrix} x \\ y \end{matrix} \right] = \frac{1 - \sqrt{5}}{2} \left[ \begin{matrix} x \\ y \end{matrix} \right] \quad \Longrightarrow \xi_{\lambda = \frac{ 1 - \sqrt{5}}{2}} = \frac{1}{ \sqrt{ \frac{5 - \sqrt{5}}{2}} } \left[ \begin{matrix} 1 \\ \frac{-1 + \sqrt{5} }{2} \end{matrix} \right]  
\end{gathered}
\]
\[
\Longrightarrow C = \left[ \begin{matrix} \sqrt{ \frac{2}{ 5+ \sqrt{5}} } & \sqrt{ \frac{2}{ 5 - \sqrt{5}} } \\ \sqrt{ \frac{2}{ 5+ \sqrt{5}} } \left( \frac{ 1 + \sqrt{ 5 } }{-2} \right) & \sqrt{ \frac{ 2}{ 5- \sqrt{5}} } \left( \frac{ -1 + \sqrt{5}}{2} \right)  \end{matrix} \right]
\]
\[
\begin{gathered}
  y^2 - 2xy + 5x = 0 \Longrightarrow \\ 
  \frac{ 1 + \sqrt{5}}{2} x^2 + \frac{ 1 - \sqrt{5}}{2} y^2 + 5 \left( \sqrt{ \frac{2}{ 5 + \sqrt{5}} } x + \sqrt{ \frac{2}{ 5 - \sqrt{5}} } y \right) = \frac{1 + \sqrt{5}}{2} x^2+ 5 \sqrt{ \frac{2}{ 5 + \sqrt{5}}} x + \frac{1 - \sqrt{5}}{2} y^2 + 5 \sqrt{ \frac{2}{ 5 - \sqrt{5}} } y = 0 = \\
    = \frac{ 1 + \sqrt{5}}{2} \left( x^2 + 5 \sqrt{ \frac{2}{ 5 + \sqrt{5}}} \left( \frac{2}{ 1 + \sqrt{5}} \right) x \right) + \frac{ 1- \sqrt{5}}{2} \left( y^2 + 5 \sqrt{ \frac{2}{ 5- \sqrt{5}}} \left( \frac{2}{ 1 - \sqrt{5} } \right) y \right) = 0 \\ 
    \Longrightarrow \frac{ 1 + \sqrt{5}}{2} \left( x + 5 \sqrt{ \frac{ 2 }{5 + \sqrt{5}}} \left( \frac{1}{ 1 + \sqrt{5}} \right) \right)^2 + \left( \frac{ 1 - \sqrt{5}}{2} \right)\left( y + 5 \sqrt{ \frac{2}{5- \sqrt{5}} } \left( \frac{1}{ 1 - \sqrt{5}} \right) \right)^2 = \\
    = \frac{ 1 + \sqrt{5}}{40 + 16 \sqrt{5}} 5^2 + \frac{ (1- \sqrt{5}) 5^2 }{ 40 - 16 \sqrt{5}} \\
    CY = X \Longrightarrow C \left[ \begin{matrix} -5 \sqrt{ \frac{ 2}{ 5 + \sqrt{5}}} \left( \frac{1}{ 1 + \sqrt{5}} \right) \\ -5 \sqrt{ \frac{ 2}{ 5- \sqrt{5}} } \left( \frac{1 }{ 1 - \sqrt{5}} \right) \end{matrix} \right] = \left[ \begin{matrix} \frac{5}{2} \\ \frac{5}{2} \end{matrix} \right]
\end{gathered}
\]
Ellipse centered at $(5/2,5/2)$.  

\exercisehead{10} $y^2 -2xy + x^2 - 5x = 0$.  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 1 & -1 \\ -1 & 1 \end{matrix} \right] \\
  \left| \begin{matrix} 1-\lambda & -1 \\ -1 & 1-\lambda \end{matrix} \right| = 1 - 2\lambda + \lambda^2 - 1 = \lambda( \lambda -2) \Longrightarrow \lambda = 0,2 \\
  \left[ \begin{matrix} 1 & -1 \\ -1 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = 0 \Longrightarrow \xi_{\lambda =0 } = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right] \\
  \text{ similarly, } \xi_{\lambda = 2 }  = \frac{1}{\sqrt{2} } \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right] \\
  C = \frac{1}{\sqrt{2} }\left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \Longrightarrow 2x_2^2 - \frac{5x_2}{\sqrt{2}} = \frac{5}{\sqrt{2}} x_1 \\
    \Longrightarrow \boxed{ \frac{2\sqrt{2}}{5} \left( x_2 - \frac{5}{ 4 \sqrt{2}} \right)^2 = x_1 + \frac{5}{ 8\sqrt{2}} } \\
    C \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \left[ \begin{matrix} x \\ y \end{matrix} \right] = C \left[ \begin{matrix} -\frac{5}{8\sqrt{2}} \\ \frac{5}{4 \sqrt{2}} \end{matrix} \right] \\
 \Longrightarrow   (x,y) = \left( \frac{5}{16}, \frac{-15}{16} \right)
\end{gathered}
\]
The vertex of the parabola in $(x,y)$ coordinates is $\left( \frac{5}{16}, \frac{-15}{16} \right)$.

\exercisehead{11} $5x^2 - 4xy + 2y^2 -6 = 0$.  \medskip \\
$\left[ \begin{matrix} 5 & -2 \\ -2 & 2 \end{matrix} \right] = A \quad $ $\quad \left| \begin{matrix} 5 - \lambda & -2 \\ -2 & 2-\lambda \end{matrix} \right| = 10 - 7 \lambda + \lambda^2 -4 = (\lambda-6)(\lambda -1 )$  

\[
\begin{aligned}
  \lambda = 1 & \quad \left[ \begin{matrix} 4 & -2 \\ -2 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = 0 & \xi_{\lambda = 1 } = \frac{1}{ \sqrt{5} } \left[ \begin{matrix} 1 \\ 2 \end{matrix} \right] \\
  \lambda = 6 & \quad \left[ \begin{matrix} -1 & -2 \\ -2 & -4 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = 0 & \xi_{  \lambda = 6 } = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} 2 \\ -1 \end{matrix} \right] 
\end{aligned}
\]

\[
\begin{gathered}
  x_1^2 + 6x_2^2 = 6 \\
  \frac{x_1^2}{ 6 } + x_2^2  = 1 
\end{gathered}
\]
Ellipse centered at $(0,0)$ in both sets of coordinates.  

\exercisehead{12} $19 x^2 + 4xy + 16 y^2 -212 x + 104y =356$.  
\[
\begin{gathered}
  \left[ \begin{matrix} 19 & 2 \\ 2 & 16 \end{matrix} \right] \quad \left| \begin{matrix} 19-\lambda & 2 \\ 2 & 16 -\lambda \end{matrix} \right| = (\lambda -15)(\lambda-20) \\
  \begin{aligned}
  \xi_{\lambda = 15} & = \frac{1}{\sqrt{5}} \left[ \begin{matrix} -1 \\ 2 \end{matrix} \right] \\ 
  \xi_{\lambda = 20 } & = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} 2 \\ 1 \end{matrix} \right]  
  \end{aligned} \\
  YC^{-1} = X \text{ so } \\
  [x \quad  y ] = [ x_1 \quad x_2 ] \frac{1}{ \sqrt{5}} \left[ \begin{matrix} -1 & 2 \\ 2 & 1 \end{matrix} \right] = \left[ \frac{ -x_1 + 2x_2}{ \sqrt{5}}, \, \frac{2x_1 + x_2}{ \sqrt{5}} \right] \\
  \Longrightarrow 15 x_1^2 + 20 x_2^2 + -212 \left( \frac{ -x_1 + 2x_2 }{ \sqrt{5}} \right) + 104 \left( \frac{2x_1 + x_2}{ \sqrt{5}} \right) =356 \\
  \Longrightarrow \frac{ \left( x_1 + \frac{14}{\sqrt{5}} \right)^2 }{ \left( \frac{403}{5} \right)} + \frac{ \left( x_2 - \frac{8}{\sqrt{5}} \right)^2 }{ \left( \frac{1209}{20} \right) } =1 
\end{gathered}
\]
Suppose we want to know what the center is in terms of the original $(x,y)$ coordinates.  Use $C$.  
\[
\begin{gathered}
C \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{5}} \left[ \begin{matrix} -1 & 2 \\ 2  & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{5}} \left[ \begin{matrix} -x_1 + 2x_2 \\ 2x_1 + x_2 \end{matrix} \right] = \\
\xrightarrow{ (x_1,x_2) = \left( \frac{-14}{ \sqrt{5}}, \frac{8}{\sqrt{5}} \right)} = \left[ \begin{matrix} 6 \\ -4 \end{matrix} \right]
\end{gathered}
\]
Thus, we have an ellipse centered at $(6,-4)$.  

\exercisehead{13} $9x^2 + 24xy +16 y^2 - 52 x + 14y = 6$  \medskip \\
$\left[ \begin{matrix} 9 & 12 \\ 12 & 16 \end{matrix} \right]$  $\quad \quad \xi_{\lambda = 25} = \frac{1}{5} \left[ \begin{matrix} 3 \\ 4 \end{matrix} \right]; \quad \xi_{\lambda = 0 } = \frac{1}{5} \left[ \begin{matrix} 4 \\ -3 \end{matrix} \right]$  

\[
\begin{gathered}
  X = YC^{-1} \Longrightarrow [ x \quad y ] = [ x_1 \quad x_2 ] \frac{1}{5} \left[ \begin{matrix} 4 & -3 \\ 3 & 4 \end{matrix} \right] = \frac{1}{5} [ 4 x_1 + 3 x_2, \quad -3x_1 + 4 x_2 ] \\
  \Longrightarrow 25 x_2^2 - 52 \left( \frac{ 4x_1 + 3x_2}{ 5 } \right) + 14 \left( \frac{-3x_1 + 4x_2}{ 5 } \right) = 6 \\
  \Longrightarrow \frac{1}{2} (x_2 - \frac{12}{5} )^2 = \frac{1}{5} + x_1 
\end{gathered}
\]
To get the center in terms of the $(x,y)$ original coordinates,
\[
\begin{gathered}
C \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{5} \left[ \begin{matrix} 4 & 3 \\ -3 & 4 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{5} \left[ \begin{matrix} 4 x_1 + 3 x_2 \\ -3 x_1 + 4 x_2 \end{matrix} \right] \\
\xrightarrow{ (x_1,x_2) = \left( \frac{-1}{5} , \frac{2}{5} \right)} = \left[ \begin{matrix} 2/25 \\ 11/25 \end{matrix} \right]
\end{gathered}
\]
Thus we have a parabola centered at $\left( \frac{2}{25}, \frac{11}{25} \right)$.  

\exercisehead{14} $5x^2 + 6xy + 5y^2 - 2 =0$  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 5 & 3 \\ 3 & 5 \end{matrix} \right] \\
  \lambda = 2, 8 \quad \quad \xi_{\lambda = 2 } = \frac{1}{ \sqrt{2}} \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right] \quad \xi_{\lambda = 8 } = \frac{1}{ \sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right] \\
  \Longrightarrow  2x_1^2 + 8 x_2^2 - 2 = 0  \\
  \Longrightarrow \boxed{ x_1^2 + 4 x_2^2 = 1 } 
\end{gathered}
\]
Thus we have an ellipse centered about the origin in both coordinate axes.  

\exercisehead{15} $x^2 + 2xy + y^2 -2x + 2y + 3 =0$  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \right] \quad \quad \left| \begin{matrix} 1-\lambda & 1 \\ 1 & 1 - \lambda \end{matrix} \right| = \lambda ( \lambda - 2 ) \\
  \text{ Directly from the characteristic function, } \\
  \Longrightarrow 
  \begin{aligned} 
    \left[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = 0 & \quad \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right] = \xi_{\lambda =0 } \\
    \left[ \begin{matrix} -1 & 1 \\ 1 & -1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = 0 & \quad \xi_{\lambda = 2 } = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right]  
  \end{aligned} \\
  YC^T = X = [x \quad y ] = [x_1 \quad x_2 ] \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right] = \begin{cases} x & = \frac{1}{\sqrt{2}} (x_1 + x_2 ) \\ y & = \frac{1}{\sqrt{2}} (-x_1 + x_2) \end{cases} \\
  \Longrightarrow 2x_2^2 + -\frac{2}{\sqrt{2}} (x_1 + x_2 ) + \frac{2}{\sqrt{2}} (-x_1 +x_2 ) + 3 = 0 \\
  \boxed{ \frac{\sqrt{2}}{ 2 } x_2^2 + \frac{3\sqrt{2}}{ 4} = x_1 }
\end{gathered}
\]

\[
C\left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ -1 & 1 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{2}} \left[ \begin{matrix} x_1 + x_2 \\ -x_1 + x_2 \end{matrix} \right] = \left[ \begin{matrix} x \\ y \end{matrix} \right] 
\]
For vertex at $\left( \frac{3\sqrt{2}}{4} , 0 \right)$ in $(x_1,x_2)$ coordinates, vertex has $\left( \frac{3}{4} , \frac{-3}{4} \right)$ as $(x,y)$ coordinates. 

\exercisehead{16} $2x^2 + 4xy + 5 y^2 - 2x - y -4 = 0$.  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 2 & 2 \\ 2 & 5 \end{matrix} \right] \\
  \begin{aligned}
    \left| \begin{matrix} 2 - \lambda & 2 \\ 2 & 5 - \lambda \end{matrix} \right| & = (2-\lambda)(5- \lambda) - 4 = 10 - 7\lambda + \lambda^2 -4 = 6 - 7 \lambda + \lambda^2 = (\lambda - 6 )(\lambda -1 ) \\
  \end{aligned} \\
    \xi_{\lambda = 1 } = \frac{1}{\sqrt{5}} \left[ \begin{matrix} 2 \\ -1 \end{matrix} \right] \quad \xi_{\lambda =6} = \frac{1}{\sqrt{5}} \left[ \begin{matrix} 1 \\ 2 \end{matrix} \right] \\
    C = \frac{1}{\sqrt{5}} \left[ \begin{matrix} 2 & 1 \\ -1 & 2 \end{matrix} \right] \\
    YC^T = X = [ 2x_1 + x_2 , \quad -x_1 + 2x_2 ] \frac{1}{\sqrt{5}} \\
    x_1^2 + 6x_2^2 - 2 \left( \frac{ 2x_1 + x_2 }{ \sqrt{5}} \right) - \left( \frac{ -x_1 + 2 x_2 }{ \sqrt{5}} \right) - 4 = 0 \\
    \Longrightarrow x_1^2 - \frac{3x_1}{\sqrt{5}} + 6 x_2^2 - \frac{4 x_2}{\sqrt{5}} = 4 \Longrightarrow \frac{ \left( x_1 - \frac{3}{ 2\sqrt{5}} \right)^2}{ \left( \frac{55}{12} \right)} +  \frac{ \left( x_2 - \frac{1}{3\sqrt{5}} \right)^2  }{ \left( \frac{55}{72} \right) } = 1 
\end{gathered}
\]

To find the center of the ellipse in terms of $(x,y)$, 
\[
\begin{gathered}
  C \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{5}} \left[ \begin{matrix} 2 & 1 \\ -1 & 2 \end{matrix} \right] \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \frac{1}{\sqrt{5}} \left[ \begin{matrix} 2x_1 + x_2 \\ -x_1 + 2x_2 \end{matrix} \right] = \left[ \begin{matrix} x \\ y \end{matrix} \right] \\
  \xrightarrow{ (x_1,x_2) = \left( \frac{3}{2\sqrt{5}}, \frac{1}{3\sqrt{5}} \right) } \, \left( \frac{2}{3}, \frac{-1}{6} \right)
\end{gathered}
\]
For the center of an ellipse at $\left( \frac{3}{2\sqrt{5}}, \frac{1}{3\sqrt{5}} \right)$ in $(x_1,x_2)$ coordinates, the center of the ellipse in $(x,y)$ coordinates is $\left( \frac{2}{3}, - \frac{1}{6} \right)$.  


\exercisehead{17} $x^2 + 4xy -2y^2 - 12 =0$  \\
$\left[ \begin{matrix} 1 & 2 \\ 2 & -2 \end{matrix} \right]$  $\left| \begin{matrix} 1 - \lambda & 2 \\ 2 & -2 -\lambda \end{matrix} \right| = (1-\lambda)(-2-\lambda) - 4 = (\lambda+3)(\lambda-2)$.  \medskip \\
$\lambda = 2,-3$  $\quad \quad \xi_{\lambda =2} = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} 2 \\ 1 \end{matrix} \right] \quad \xi_{\lambda =-3} = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} -1 \\ 2 \end{matrix} \right]$.  
\[
\begin{gathered}
  C = \frac{1}{ \sqrt{5}} \left[ \begin{matrix} 2 & -1 \\ 1 & 2 \end{matrix} \right] \\
  YC^{-1} = X = [x \, y ] = [ x_1 \, x_2 ] C = \frac{1}{ \sqrt{5}} [ 2x_1 - x_2 , x_1 + 2x_2 ] \\
  \Longrightarrow 2x_1^2 - 3x_2^2 - 12 = 0 \Longrightarrow \boxed{ \frac{x_1^2}{6} - \frac{x_2^2}{ 4 } = 1 }
\end{gathered}
\]

\exercisehead{18} $xy + y - 2x - 2 = 0$  
\[
\begin{gathered}
  A = \left[ \begin{matrix} 0  & 1/2 \\ 1/2 & 0 \end{matrix} \right] \quad \quad \left| \begin{matrix} - \lambda & 1/2 \\ 1/2 & -\lambda \end{matrix} \right| = \lambda^2 - \frac{1}{4} = 0 \quad \quad \\ 
  \lambda = \pm 1/2 \quad \quad \xi_{\lambda = 1/2} = \frac{1}{ \sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right] \quad \xi_{\lambda = -1/2} = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right]  \\
    \begin{aligned}
      C & = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \\
      & YC^{-1} = X = [x \, y ] = [ x_1 \, x_2 ] \frac{1}{ \sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] = \left( \frac{ x_1 + x_2 }{ \sqrt{2} }, \frac{ x_1 - x_2}{ \sqrt{2}} \right) 
    \end{aligned} \\
    \Longrightarrow \frac{1}{2} x_1^2 + \frac{-1}{2} x_2^2 + \frac{x_1 - x_2}{ \sqrt{2} } - 2 \left( \frac{ x_1 + x_2}{ \sqrt{2} }\right) = 2 \\
    \Longrightarrow \left( x_1 - \frac{1}{\sqrt{2}} \right)^2 + - \left( x_2 + \frac{3}{\sqrt{2}} \right)^2 = 4 + \frac{1}{2} - \frac{9}{2} = 0 \\
 \text{ Suppose two lines are the asymptotic limit of a hyperbola.  Then these lines are ``hyperbolas.''  } \\
 \boxed{ \pm \left( x_1 - \frac{1}{ \sqrt{2}} \right) = \left( x_2 + \frac{3}{\sqrt{2}} \right) }
\end{gathered}
\]
If we want to get what the center of this ``hyperbola'' is in terms of coordinates in the original $x,y$ axis (we already have them for $(x_1,x_2)=Y$ and that is $\left( \frac{1}{\sqrt{2}}, -\frac{3}{\sqrt{2}} \right)$, then apply $C$ as a transformation.  
\[
C (x_1, x_2) = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ -3 \end{matrix} \right] = \left[ \begin{matrix} -1 \\ 2 \end{matrix} \right]
\]
The center is $(-1,2)$ in $(x,y)$ coordinates.  

\exercisehead{19} $2xy - 4x + 7y + c =0$.  
\[
\begin{gathered}
  \left[ \begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix} \right] \\
  \left| \begin{matrix} \lambda & -1 \\ -1 & \lambda \end{matrix} \right| = \lambda^2 - 1 = 0 \quad \quad \, \begin{aligned} \xi_{\lambda = 1} & = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ 1 \end{matrix} \right] \\ \xi_{\lambda = -1} & = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 \\ -1 \end{matrix} \right] \end{aligned} \quad \,   \Longrightarrow C = \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \\
  \xrightarrow{ CY = X} \frac{1}{\sqrt{2}} \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \left[ \begin{matrix} y_1 \\ y_2 \end{matrix} \right] = \left[ \begin{matrix} x_1 \\ x_2 \end{matrix} \right] = \left( \begin{matrix} \frac{1}{\sqrt{2}} (y_1 + y_2) \\ \frac{1}{\sqrt{2}} (y_1 - y_2) \end{matrix} \right) \\ 
x^2 + - y^2 - 4 \left( \frac{1}{\sqrt{2}} (x+y)\right) + 7 \frac{1}{\sqrt{2}} (x-y) + c = x^2 + \frac{3}{\sqrt{2}} x + - y^2 - \frac{11}{\sqrt{2}} y + c = 0 \\
\left( x+ \frac{3}{2 \sqrt{2}} \right)^2 - \left( y + \frac{11}{2 \sqrt{2}} \right)^2 + c =0 \quad \Longrightarrow \boxed{ c = -14 }
\end{gathered}
\]

\exercisehead{20} Note that 
\[
ax^2 +bxy +cy^2 = 1 = X AX^T \text{ where} A = \left[ \begin{matrix} a & b/2 \\ b/2 & c \end{matrix} \right], \quad X = \left[ \begin{matrix} x & y \end{matrix} \right]
\]
$A$ symmetric, by theorem, $A$ can be diagonalized into its eigenvalues.  By thm., $XAX^T = Y\Lambda Y^T$ where $Y$ is an orthonormal coordinate transformation.  
\[
|\lambda -A | = (\lambda - a)(\lambda - c) - \frac{b^2}{4} = (\lambda - \lambda_+)(\lambda - \lambda_-)
\]
So $\lambda_+ \lambda_- = ac - \frac{b^2}{4}$ (this had been the smart way to see this: you can do algebra to get)
\[
\lambda_{\pm} = \frac{ (a+c) \pm \sqrt{ (a-c)^2 + b^2 }}{2} 
\]
Then using eigenvectors as basis,
\[
ax^2  + bxy + cy^2 = \frac{ z^2}{ 1/ \lambda_+} + \frac{ w^2 }{ 1/\lambda_-} = 1
\]
From geometry, the area of an ellipse is $\pi ab$, where $a,(b)$ is the half of semi-major (minor) axis
\[
\text{ ellipse area } = \pi \sqrt{ \frac{1}{ \lambda_+ } }\sqrt{ \frac{1}{ \lambda_-} } = \pi \frac{1}{ \sqrt{ ac - \frac{b^2}{4} } } = \frac{ 2 \pi }{ \sqrt{ 4ac - b^2} }
\]


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 5.20 Exercises - Eigenvalues of a symmetric transformation obtained as values of its quadratic form; Extremal properties of eigenvalues of a symmetric transformation; The finite-dimensional case; Unitary transformations }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} \begin{enumerate}
\item \[
\begin{gathered}
  (T(x),T(x)) = (x,x) = |c|^2(x,x) \\
  (x,x) > 0 \text{ if } x \neq 0, \, \text{ so } \boxed{ |c|^2 = 1  }
\end{gathered}
\]
\item $V$ one-dim.  $T:V \to V$.  \\
  $T$ unitary, $T$ linear.  $x \in V$; \, $x = ae_1$; $T(x) = T(ae_1) = aT(e_1)$.  $T(e_1) \in V$; \, $T(e_1) = \mu e_1$.   \smallskip \\
  $T(x) = a\mu e_1 = \mu x$.  Since $T$ unitary, by above $|\mu | =1$.  If $V$ real, $\mu$ real, so $\mu = \pm 1$.  
\end{enumerate}

\exercisehead{2} 
\begin{enumerate}
\item $A$ real, orthogonal.  $AA^* = A\overline{A}^T = AA^T = 1$.  Thus, $A$ unitary.  \\
  $\Longrightarrow$ eigenvalue $\lambda$ of $A$ s.t. $|\lambda| =1$.  \\
  If $\lambda \in \mathbb{R}$, \, $\lambda = \pm 1$.  
\item 
\item If $n=2s +1$ odd, suppose $\lambda_1$ is eigenvalue of $A$.  If $\lambda_1$ real, done.  If $\lambda_1$ non-real, \smallskip \\
  \quad \quad \, then $\overline{\lambda_1}$ is an eigenvalue (by previous part).  \smallskip \\
  \quad \quad Continue, until $n$th eigenvalue (we've already checked $s$ pairs of eigenvalues to be non-real).  If $\lambda_n$ non-real, $\overline{\lambda}_n$ is an eigenvalue.  Then there are $2s+2$ eigenvalues.  But we're given that $n$ odd.  Contradiction.  Thus $\lambda_n$ real.  
\end{enumerate}

\exercisehead{3}$T$ or thogonal.  Then $m(T) = A$ has at least one real eigenvalue, $|\lambda_n| = 1$. 
\[
\begin{gathered}
\text{Given } det{A} = 1, \, det{A} = 1 = \left( \prod_{i=1}^s |\lambda_i|^2 \right) \lambda_n = (1) \lambda_n
\end{gathered}
\]
Since suppose there are $s$ complex eigenvalues.  Then there are $s$ complex conjugate eigenvalues.  Then there are at most $n-2s = (\text{odd}-\text{even}) = \text{odd}$ number of real eigenvalues.  Since $det{A} =1$, and $\left( \prod_{i=1}^s |\lambda_i|^2 \right) =1$ already ($T$ orthogonal), there can only be an even number of real eigenvalues equal to $-1$.  Then there must be at least one eigenvalue equal to $1$.  

\exercisehead{4} $A$ real, orthogonal, then $A$ unitary.  Then for eigenvalues $\lambda$ of $A$, $|\lambda|=1$.  Consider all complex $\lambda$ of $A$; they come in complex conjugate pairs, and so if there are $s$ conjugate pairs, $\prod_{i=1}^s |\lambda_s|^2 = 1$.  

Consider all real eigenvalues of $A$.  Then $\lambda =\pm 1$.  If $-1$ is an eigenvalue of multiplicity of $k$, then there are $k$ diagonal entries of $-1$ for diagonalized $A$.  Thus, all possible eigenvalues are considered, so $det{A} = \prod_{i=1}^s |\lambda_s|^2 (1)(-1)^k = 1(1)(-1)^k = (-1)^k$  

\exercisehead{5} Given that $T$ linear and norm-preserving,
\[
\begin{gathered}
  \begin{aligned}
  (T(x+by),T(x+by)) & = \| T(x) \|^2 + b(T(y),T(x)) + \overline{b}(T(x),T(y)) + |b|^2 \| T(t) \|^2 = \| T(x+by) \|^2 = \\
    = \| x + by \|^2 & = \| x\|^2 + \overline{b} (x,y) + b(y,x) + |b|^2 \|y \|^2
  \end{aligned} \\
\quad \, \\
\begin{aligned}
  \| T(x) \|^2 & = \| x \|^2  \\
  \| T(y) \|^2 & = \| y \|^2
\end{aligned} \quad \, \text{ as well } \Longrightarrow b \left( (T(y),T(x)) - (y,x) \right) + \overline{b} \left( (T(x),T(y)) - (x,y) \right) = 0 
\end{gathered}
\]
$b$, $\overline{b}$ are independent since $b=s+ti$ and $s,t$ are two arbitrary real numbers.  So $(T(x),T(y)) = (x,y)$, so $T$ unitary.  

\exercisehead{6}  $T:V \to V$ unitary, Hermitian.  
\[
\begin{gathered}
  (T(x),y) = (x,T(y)) \quad \, \text{(Hermitian)} \\
  (T^2(x),y) = (T(x),T(y)) = (x,T^2(y)) = (x,y) \quad \, \Longrightarrow (T^2(x) - x, y) =0 
\end{gathered}
\]
Let $y=x$.  
\[
((T^2-I)(x),x) = Q_1(x) =0 \quad \, \forall \, x \in V
\]
Then $T^2 - I = 0$ (as previously shown for $Q_1(x) =0 \, \forall \, x \in V$), or $T^2 -I$.  

\exercisehead{7} $(e_1, \dots, e_n), \, (u_1, \dots, u_n)$ are 2 orthonormal bases for Euclidean space $V$.  \smallskip \\
$e_j \in V$ so $e_j \sum_{k=1}^n a_{jk} u_k$.  
\[
\begin{aligned}
  (e_i,e_j) & = (e_j,e_i) = \left( \sum_{l=1}^n a_{il} u_l , \sum_{k=1}^n a_{jk} u_k \right) = \sum_{l=1}^n \sum_{k=1}^n a_{il} \overline{a}_{jk} (u_l,u_k)  = \\ 
    & = \sum_{k=1}^n a_{ik} \overline{a}_{jk}
\end{aligned}
\]
$\Longrightarrow \, A$ is unitary, $T$ s.t. $m(T) = A$ is unitary (isomorphism).  

\exercisehead{8} $\left[ \begin{matrix} a & \frac{1}{2}i & \frac{1}{2} a(2i-1) \\ ia & \frac{1}{2} (1+i) & \frac{1}{2}a (1-i) \\ a & \frac{-1}{2} & \frac{1}{2} a(2-i) \end{matrix} \right]$  
\[
\sum_{k=1}^n a_{ki} \overline{a}_{kj} = \sum_{k=1}^3 a_{ki} \overline{a}_{kj} = (e_i,e_j)
\]
\[
a^2 + ia(-ia) + a^2 = 3 a^2 = 1 \quad \, \Longrightarrow a^2 = \frac{1}{3} 
\]
$(a,ia,a)$, $\left( \frac{1}{2} i , \frac{1}{2} (1+ i) , \frac{-1}{2} \right)$, $\frac{a}{2} \left( 2i -1, 1-i, 2- i \right)$ are orthogonal to each other through $(x,y)$ inner product on complex Euclidean $V$.   If $a= \pm \sqrt{1/3}$, columsn of $A$ will be normalized.  \smallskip \\
$\Longrightarrow A^T A = I$, so $A$ unitary.  

\exercisehead{9} $A$ skew-Hermitian, $\Lambda = C^* AC$.  
\[
\begin{aligned}
  det{(1 \pm A)}  = det{(C^*C)} det{(1 \pm A)} = det{(1 \pm C^*AC)} = det{(1\pm A)} = \prod_{j=1}^n (1 \pm \lambda_j)
\end{aligned}
\]
If $\lambda_j \in \mathbb{C}$, $\lambda_j$ purely imaginary and $\overline{\lambda}_j$ is also an eigenvalue.  
\[
(1\pm \lambda_j)(1 \pm \overline{\lambda}_j) = 1 \pm (\lambda_j + \overline{\lambda}_j) + |\lambda_j|^2 = 2
\]
If $\lambda_j \in \mathbb{R}$, $\lambda_j = 0$.  $1 \pm \lambda_j =1$
\[
\Longrightarrow det{(1\pm A)} \neq 0 \text{ so } 1 \pm A \text{ nonsingular}
\]

Let $B = (1+ A)^{-1}$.  Use the fact that a left inverse is also a right inverse (theorem) extensively.  
\[
\begin{aligned}
  (1+A)B = B + AB & = 1 \\ 
  B(1+A) = B + BA & = 1 
\end{aligned} \quad \Longrightarrow AB = BA \quad \quad \, \begin{aligned}
  ((1+A)B)* = B^*(1+A^*) = B^* + B^*A^* &  = 1 \\ 
  (B(1+A))^* = (1+A^*)B^* = B^* + A^*B^* & = 1
\end{aligned} \quad \Longrightarrow B^*A^* = A^*B^*
\]
so
\[
B(1-A) = B - BA = B - AB = (1-A)B
\]
Thus, using $A = -A^*$, since $A$ skew-Hermitian,
\[
\begin{gathered}
  (1-A)(1+A)^{-1}((1-A)(1+A)^{-1})* = (1-A)B((B(1-A))^*) = (1-A)B(1-A^*)B^* = (1-A)B(1+A)B^* = \\
  = (1-A)B^* = (1+A^*)B^* = 1
\end{gathered}
\]
$(1-A)(1+A)^{-1}$ unitary.  

\exercisehead{10} $A$ unitary, $I+A$ nonsingular.  Let $(1+A)^{-1} = B$.  
Using this fact
\[
\begin{gathered}
  B(1+A) = B(AA^* + A) = BA(1+A^*) = 1 = 1* = (1+A)(A^*B^*) \\
  \Longrightarrow A^*B^* = B^*A^*= B
\end{gathered}
\]
Then 
\[
((1-A)B)^* = B^*(1-A^*) = B^* - A^* B^* = (A-1)A^*B^* = -(1-A)B^*A^* = -(1-A)B
\]
Thus $(1-A)B$ is skew-Hermitian.  

\exercisehead{11} $A$ Hermitian, so $A = A^*$.  Let $B = (A-i)^{-1}$
\[
\begin{gathered}
  B(A-i) = 1= (A-i)B \Longrightarrow AB = BA \\
  (B(A-i))^* = 1 = (A^* +i )B^* = A^* B^* + i B^* = B^* A^* + i B^* \quad \, \Longrightarrow A^*B^* = B^*A^*
\end{gathered}
\]
Then
\[
\begin{gathered}
  B(A+i)(B(A+i))^* = (A+i)B(A+i)^*B^* = (A+i)B(A-i)B^* = (A^*+i)1B^* = 1
\end{gathered}
\]

\exercisehead{12} $A$ unitary, so by theorem, there exists a complete set of orthonormal eigenvectors that form a basis for $V$, $\{ u_1, \dots, u_n \}$.  \\
Suppose $A$ was defined in the $\{ e_1, \dots, e_n \}$ basis.  Then they are related through some matrix $C$ (most general assumption to make):
\[
[ u_1 , \dots, u_n ] = [ e_1, \dots, e_n ]C  \quad \, \Longrightarrow u_j = \sum_{i=1}^n \sum_{i=1}^n c_{ij} e_i
\]  
\[
\begin{aligned}
  (u_j,u_k) & = \left( \sum_{i=1}^n c_{ij} e_i, \sum_{l=1}^n c_{lk} e_l \right) = \sum_{i=1}^n \sum_{l=1}^n c_{ij} \overline{c}_{lk} (e_i,e_l) = \sum_{i=1}^n c_{ij} \overline{c}_{ik} = \\
  & = \sum_{l=1}^n (C^*)_{kl} c_{lj} = (u_k,u_j)
\end{aligned}
\]
Hence $C^*C=1$, so $C$ is unitary.  \\
Recall what the entries of matrix $A$ are, evaluated from the inner product in a certain chosen basis:
\[
\begin{gathered}
  Ae_l = \sum_{m=1}^n a_{lm} e_m \\
  (Ae_k,e_l) = \left( \sum_{m=1}^n a_{km} e_m, e_l \right) = a_{kl}
\end{gathered}
\]
Thus,
\[
\begin{aligned}
  (CAC^*)_{ij} \sum_{k=1}^n C_{ik} (AC^*)_{kj} & = \sum_{k=1}^n C_{ik} \sum_{l=1}^n a_{kl} \overline{C}_{jl} = \sum_{k=1}^n \sum_{l=1}^n c_{ik} a_{kl} \overline{c}_{jl} = \sum_{k=1}^n \sum_{l=1}^n c_{ik} (Ae_k,e_l)\overline{c}_{jl} = \\ 
  & = \left( A\sum_{k=1}^n c_{ik}e_k, \sum_{l=1}^n c_{jl} e_l \right) = \left( Au_i \right)
\end{aligned}
\]

\exercisehead{13} A square matrix is called \emph{normal} if $AA^* = A^*A$.  Determine which of the following types of matrices are normal.  
\begin{enumerate}
\item Hermitian matrices.  $AA^* = A^*A$ since $A=A*$
\item Skew-Hermitian matrices.  $AA^* = -A^*(-A) = A^* A$
\item Symmetric matrices.  
\item Skew-symmetric matrices.  
\item Unitary matrices.  
\item
\end{enumerate}

\exercisehead{14} If $A$ is a normal matrix ($AA^* = A*A$) and if $U$ is a unitary matrix, prove that $U^*AU$ is normal.  
\[
\begin{aligned}
  (U^*AU)(U^*AU)^* & = U^*AUU^*A^*U = U^*AA^*U = U^*A^*AU = U^*A^*UU^*AU = \\
  & = (U^*AU)^*(U^*AU)
\end{aligned}
\]

















\section*{ 6.21 Exercises - Linear equations of second order with analytic coefficients, The Legendre equation, The Legendre polynomials, rodrigues' formula for the Legendre polynomials }

\exercisehead{1} 
\begin{itemize}
\item[a.]From (6.35) $(1-x^2)y'' - 2xy' + \alpha (\alpha +1) y=0$.  \\
If $\alpha =0$, $(1-x^2)y'' - 2xy' =0$, $y'=v$, so $\frac{v'}{v} = \frac{2x}{1-x^2} $ \, $\Longrightarrow \ln{ \left( \frac{v}{v_0} \right)} = -\ln{ ( 1 - x^2) }$ or $\frac{v}{v_0} = \frac{1}{1-x^2} $

\[
y- y_0 = + v_0 \int \frac{1}{1-x^2} dx = +v_0 \left( \ln{ \left( \frac{x}{\sqrt{ 1-x^2} } + \frac{1}{\sqrt{1- x^2} } \right) }\right) = \frac{v_0}{2} \ln{ \left( \frac{1+x}{1-x} \right) }
\]
We did this integral by considering the following: $\begin{aligned}x &= \sin{\theta} \\ dx & =\cos{\theta} d\theta \end{aligned}$.  So 
\[
\int \frac{1}{1-x^2} dx = \int \frac{ c(\theta) d\theta }{ \cos^2{\theta} } = \int \sec{\theta} d\theta = \ln{ (\tan{\theta} + \sec{\theta} ) }
\] 
since $(\ln{(\tan{\theta} + \sec{\theta} ) } )' = \left( \frac{1}{ \tan{\theta} + \sec{\theta} } \right) (\sec^2{\theta} + \tan{\theta} \sec{\theta} )$

Now by Apostol's notation, \\
$u_1$ is the power series solution with $a_0 =1, \, a_1 =0$ \\ 
$u_2$ is the power series solution with $a_0 =0, \, a_1 =1$ \\

My notation:\\
$u_1$ is the power series solution with $a_0 =0, \, a_1 =1$ \\ 
$u_2$ is the power series solution with $a_0 =1, \, a_1 =0$ \\ 

Since $(1-x^2)y'' - 2xy'=0$, $1-x^2, -2x$ analytic (have power series representation).  

\[
\begin{aligned}
  y & = \sum_{n=0}^{\infty} a_n x^n \\
  y' & = \sum_{n=1}^{\infty} na_n x^{n-1} \\ 
  y'' & = \sum_{n=2}^{\infty} n (n-1) a_n x^{n-2} = \sum_{n=0}^{\infty} (n+2)(n+1)a_{n+2}x^n 
\end{aligned}
\]
\[
\Longrightarrow
\begin{gathered}
  2a_2 + 2(3) a_3x + \sum_{n=2}^{\infty} ((n+2)(n+1) a_{n+2} - n(n-1)a_n) x^n = 2 \sum_{n=1}^{\infty} n a_n x^n \\ 
  \text{ or } 2a_2 + 2 (3a_3 - a_1) x = \sum_{n=2}^{\infty} ((n+2)(n+1) a_{n+2} - n(n+1)a_n) x^n = 0 
\end{gathered}
\]
So $a_2=0$, $a_3 = a_1/3$, $a_{n+2} = \frac{na_n}{n+2}$.  
\[
a_{2m+1} = \frac{(2m-1)a_{2m-1} }{2m+1} = \frac{ (2m-1)}{2m+1} \frac{2m-3}{2m-1} a_{2m-3} = \frac{1}{2m+1} a_1 
\]
\[
\Longrightarrow \boxed{ y = a_1 \sum_{m=0}^{\infty} \frac{x^{2m+1}}{2m+1} }
\]
Indeed, since 
\[
\begin{aligned}
  \int \frac{1}{1+x} & = \ln{(1+x)} = \int \sum (-x)^j = \sum \frac{(-1)^j x^{j+1} }{ j+1} \\
  \int \frac{1}{1-x} & = - \ln{ (1-x)} = \int \sum (x^j) = \sum \frac{ x^{j+1}}{ j+1}
\end{aligned}
\]
So that
\[
\frac{1}{2} ( \ln{(1+x)} - \ln{(1-x)} ) = \frac{1}{2} \sum_{m=0}^{\infty} \frac{2x^{2m+1} }{ 2m+1} 
\]
\item[b.] 
\[
\begin{aligned}
  u_2'  = \frac{1}{2} \left( \frac{1}{1+x} + \frac{1}{1-x} \right) = \frac{1}{2} \left( \frac{ 1 - x + 1 + x}{1-x^2} \right) = \frac{1}{1-x^2} 
\end{aligned}
\]
\[
\begin{aligned}
  u_2'' & = \frac{1}{2} \left( \frac{-1}{ (1+x)^2} + \frac{1}{ (1-x)^2} \right) \\ 
  (1-x^2) u_2'' & = \frac{1}{2} \left( \frac{-1(1-x)}{1+x} + \frac{1+x}{1-x} \right) = \frac{1}{2} \left( \frac{ -(1-2x + x^2) + 1 + 2x + x^2  }{ 1-x^2} \right) = \frac{2x}{1-x^2}
\end{aligned}
\]
\end{itemize}

\exercisehead{2} Let $\alpha =1$.  Then $(1-x^2)y'' - 2xy' +2y =0$.  
\[
\begin{aligned}
  f(x) & = 1 - \frac{x}{2} \log{ \frac{1+x}{1-x} } \\ 
  f'(x) & = - \frac{1}{2} \log{ \frac{ 1 + x}{1-x} } - \frac{x}{1-x^2} \\ 
  f''(x) & = \frac{-1}{1-x^2} - \frac{1}{1-x^2} + \frac{ - 2x^2}{(1-x^2)^2} = \frac{-2}{1-x^2} + \frac{-2x^2}{(1-x^2)^2}
\end{aligned}
\]
\[
\Longrightarrow \frac{-2}{1-x^2} + \frac{-2x^2}{ (1-x^2)^2} + \frac{2x^2}{1-x^2} + \frac{ 2x^4}{ (1-x^2)^2} + \frac{2x^2}{1-x^2} + x\log{ \frac{1+x}{1-x} } + \frac{2x^2}{1-x^2} + 2 - x \log{ \frac{1+x}{1-x} } = 0 
\]
Consider the general theory for Legendre equation: $ (1-x^2)y'' - 2xy' + \alpha (\alpha +1) y=0$.  Let $\lambda = \alpha (\alpha +1)$.  $1-x^2,-2x,\lambda$ analytic, so $\exists \, y = \sum_{n=0}^{\infty} a_n x^n$.  
\[
\begin{gathered}
  \Longrightarrow 2a_2 + 3(2) a_3 x + \sum_{n=2}^{\infty} ((n+2)(n+1)a_{n+2} - n(n-1) a_n) x^n + \sum_{n=2}^{\infty} \lambda a_n x^n + \lambda a_1 x + \lambda a_0 = \\
  = 2 \sum_{n=1}^{\infty} n a_n x^n = 2 \sum_{n=2}^{\infty} n a_n x^n + 2a_1 x
\end{gathered}
\]
\[
\Longrightarrow \begin{aligned} a_2 & = \frac{-\lambda a_0 }{2} \\ a_3 & = \frac{ (2-\lambda) a_1}{6} \end{aligned} \quad \, a_{n+2} = \frac{ (n(n+1)- \lambda )a_n}{ (n+2)(n+1)} = \frac{(n-\alpha)(n+1 + \alpha)a_n}{(n+2)(n+1)}
\]

If $\alpha =1$, $\lambda =2$, 
\[
a_{n+2} = \frac{n-1}{n+1} a_n, \quad \, a_3 =0, \quad a_2 = -a_0 \Longrightarrow a_{2m} = \frac{1}{2m-1} (-a_0)
\]
So that
\[
 y = -a_0 \sum_{m=0}^{\infty} \frac{x^{2m}}{ 2m-1} 
\]
Indeed,
\[
\frac{x}{2} \log{ \left( \frac{1+x}{1-x} \right) } = \frac{x}{2} \sum_{m=0}^{\infty} \frac{ 2x^{2m+1}}{ 2m+1} = \sum_{m=1}^{\infty} \frac{x^{2m}}{ 2m-1}, 
\]
so $f(x) = -\sum_{m=0}^{\infty} \frac{x^{2m}}{2m-1}$.  

\exercisehead{3} 
\begin{itemize}
\item[a.]
\[
((x-a)(x-b)y')' - cy =0 = ((At + B -a)(At + B-b)y')' -cy = 0 
\]
Let $x = At + B$, $c = \alpha (\alpha +1)$, \, $\frac{1}{A} = \frac{dt}{dx}$.  

\[
(At)^2 + 2ABt + B^2 - (At+B)(b+a) + ab = A^2 ( t^2-1)
\]
\[
\Longrightarrow 2AB - A(b+a) = 0 = A(2B- (b+a)) \quad \, \Longrightarrow \boxed{ B = \frac{b+a}{2}, \, A = \frac{b-a}{2} }
\]
since 
\[
\begin{gathered}
  B^2 - B(b+a) + ab = -A^2 \\ 
  \Longrightarrow \frac{ (b+a)^2}{4} - \frac{ (b+a)^2}{2} + ab = \frac{ - (b^2 + 2ab + a^2)}{4} = ab = \frac{ - (b^2 + -2ab+a^2) }{4} = \frac{ -(b-a)^2}{4} = -A^2
\end{gathered}
\]
\item[b.] \[
x(x-1)y'' + (2x-1) y' - 2y = 0 = ((x^2-x)y')' - 2y = (x(x-1)y')' - 2y
\]
for $x = \frac{t+1}{2}$
\[
\Longrightarrow ((t^2-1)y')' - 2y = 0
\]
\end{itemize}

\exercisehead{4} $y'' - 2xy' + 2\alpha y=0$
\[
\sum_{n=0}^{\infty} ((n+2)(n+1) a_{n+2} - 2na_n + 2\alpha a_n)x^n \Longrightarrow a_{n+2} = \frac{ 2(n-\alpha) a_n}{(n+2)(n+1)}
\]
For $n= 2m$
\[
\begin{aligned}
a_{2m} & = \frac{ 2(2m-2-\alpha) a_{2m-2}}{ (2m)(2m-1)} = \frac{ -2( \alpha - 2(m-1) )}{ (2m)(2m-1) } a_{2(m-1)} = \\
& = \frac{ (-2)^m ( \alpha - 2(m-1))( \alpha - 2(m-2) ) \dots \alpha }{ (2m)!} a_0 
\end{aligned}
\]

For $n=2m+1$
\[
\begin{aligned}
  a_{2m+1} & = \frac{ 2 ( 2m-1 - \alpha) a_{2m-1} }{ (2m+1)(2m) } = \frac{ (-2)( \alpha - (2m-1)) a_{2m-1}}{ (2m+1)(2m) } = \\
  & = \frac{ (-2)^m ( \alpha - (2m-1))(\alpha - (2m-3))\dots (\alpha -1) a_1 }{ (2m+1)! }
\end{aligned}
\]
\[
\begin{aligned}
  y & = u_1 + u_2 \\ 
  & = \boxed{ \sum_{m=1}^{\infty} \frac{ (-2)^m (\alpha - (2m-1))(\alpha - (2m-3)) \dots ( \alpha - 1)}{ (2m+1)! } x^{2m+1} + \sum_{m=0}^{\infty} \frac{ (-2)^m (\alpha - 2(m-1))(\alpha - 2(m-2)) \dots \alpha}{ (2m+2)!} x^{2m} }
\end{aligned} 
\]

$u_1$ has $a_0=0$, $u_2$ has $a_1 =0$.  

Since
\[
\begin{aligned}
u_1(0) & = 0 \\
u_1'(0) & = 1 
\end{aligned} \quad \, \begin{aligned} u_2(0) & = 1 \\ u_2'(0) & = 0 \end{aligned}
\]
when $\alpha \in \mathbb{Z}^+$, then one of these $u_1, u_2$ is a polynomial, since $a_{n+2} = \frac{ 2(n-\alpha) a_n }{ (n+2)(n+1) }$  

\exercisehead{5} For $xy'' + (3+x^3)y' + 3x^2 y =0$, assume an analytic expansion.  
\[
\begin{aligned}
  y & = \sum_{n=0}^{\infty} a_n x^n = \sum_{n=2}^{\infty} a_{n-2} x^{n-2} \\ 
  y' & = \sum_{n=1}^{\infty} a_n n x^{n-1} = \sum_{n=3}^{\infty} a_{n-2} (n-2) x^{n-3} = \sum_{n=0}^{\infty} a_{n+1} ( n+1) x^n \\ 
  y'' & = \sum_{n=2}^{\infty} n (n-1) a_n x^{n-2} = \sum_{n=1}^{\infty} ( n+1)n a_{n+1} x^{n-1} 
\end{aligned}
\]

\[
\begin{gathered}
  2a_2 x + 3(2) a_3 x^2 + 3a_1 + 3a_2 ( 2) x + 3a_3 (3) x^2 + 3a_0 x^2 + \sum_{n=3}^{\infty} \left( (n+1) n a_{n+1} + 3a_{n+1} (n+1) + a_{n-2} ( n-2) + 3a_{n-2} \right) x^n = 0 
\end{gathered}
\]
\[
\Longrightarrow \begin{gathered}
 a_1 = 0 \\
8a_2 = 0 \\
(15 a_3 + 3a_0) = 0 \text{ or } a_3 = \frac{-a}{5}
\end{gathered} \quad \quad \, \begin{aligned} (n+1)(n+3) a_{n+1} & = -a_{n-2} (n+1) \\
  a_{n+1} & = \frac{-a_{n-2} }{n+3}
\end{aligned}
\]
\[
\Longrightarrow a_{3j} = \frac{-a_{3(j-1)} }{3j+2} = \frac{ (-1)^2 a_{3(j-2) } }{ (3j+2) (3j-1) } = \frac{ (-1)^j a_0 }{ (3j+2) (3j-1) \dots (8)(5) }
\]
\[
\boxed{ y = a_0 \lbrace 1  + \sum_{j=1}^{\infty} \frac{ (-1)^j }{ (3j+2)(3j-1)\dots (8)(5) } x^{3j} \rbrace}
\]

%Now for 
%\[
%\begin{aligned}
%  y & = x^{-2} \sum_{n=0}^{\infty} a_n x^n \\ 
%  y' & = -2x^{-3} \sum_{n=0}^{\infty} a_n x^n  + x^{-2} \sum_{n=1}^{\infty} n a_n x^{n-1} = -2 \sum_{n=-3}^{\infty} a_{n+3} x^n + \sum_{n=-2}^{\infty} (n+3) a_{n+3} x^n \\
%  y'' & = 6x^{-4} \sum_{n=0}^{\infty} a_n x^n + -4 x^{-3} \sum_{n=1}^{\infty} na_n x^{n-1} + x^{-2} \sum_{n=2}^{\infty} n (n-1) a_n x^{n-2} = \\
%  & = 6 \sum_{n=-3}^{\infty} a_{n+3} x^{n-1} - 4 \sum_{n=-2}^{\infty} (n+3) a_{n+3} x^{n-1} + \sum_{n=-1}^{\infty} (n+3)(n+2) a_{n+3} x^{n-1}
%\end{aligned}
%\]
%Writing out the terms, I obtained
%\[
%\begin{gathered}
%  a_0 = 0 \\
%a_1 = 0 \\
%a_3 + a_0 = 0 
%\end{gathered}
%\quad \quad \, \begin{aligned}
%  a_{n+3} & = \frac{-a_n}{n+3} \\ 
%  a_{3j+2} & = \frac{ -a_{3j-1} }{ 3j+2} = \frac{ (-1)^2 a_{3(j-2) + 2} }{(3j+2)(3 (j-1) +2) } = \frac{ (-1)^j a_2 }{ (3j+2)(3j-1) \dots (8)(5) }
%\end{aligned}
%\]
%
%\[
%\boxed{ y = x^{-2} a_2 \lbrace \sum_{j=0}^{\infty} \frac{ (-1)^j }{ (3j+2)(3j-1)\dots (8)(5) }x^{3j+2} \rbrace }
%\]

%Essentially the same answer was obtained.  

To obtain the solution with even-powered terms, consider first possible simple pole at 0 from the form of the differential equation:
\[
y'' + \left( \frac{3}{x} + x^2 \right)y' + 3xy = 0 
\]
Then consider the following:
\[
\begin{aligned}
  y & = \sum_{n=0}^{\infty} a_n x^{n-2} = \sum_{n=-1}^{\infty} a_{n+1} x^{n-1} \\ 
  y' & = \sum{n=-1}^{\infty} ( n-1) a_{n+1} x^{n-2} = \sum_{n=-4}^{\infty} (n+2) a_{n+4} x^{n+1} \\ 
  y'' & = \sum_{n=-4}^{\infty} (n+2)(n+1) a_{n+4} x^{n+1}
\end{aligned}
\]
Then for the first few terms,
\[
\begin{gathered}
  (-2)(-3) a_0 x^{-4} + (-1)(-2)a_1 x^{-3} + 3(-2) a_0 x^{-4} + 3(-1)a_1 x^{-3} 3a^3 x^{-1} + (-2a_0)x^{-1} + 3a_0 x^{-1} = 0 \\
  \Longrightarrow a_1 = 0, \quad \, a_3 = \frac{- a_0 }{ 3}
\end{gathered}
\]
\[
\boxed{ y = x^{-2} a_0 \left( 1 + \sum_{j=1}^{\infty} \frac{ (-1)^j }{ 3^j j! } x^{3j} \right) }
\]

\exercisehead{6} $x^2 y'' + x^2 y' - ( \alpha x + 2)y =0$.  $\left( \frac{ \alpha x + 2}{x^2} \right)$ analytic except at $x=0$.  
\[
\begin{aligned}
  y & = \sum_{n=0}^{\infty} a_n x^n = \sum_{n=1}^{\infty} a_{n-1} x^{n-1} \\ 
  y' & = \sum_{n=1}^{\infty} n a_n x^{n-1}  = \sum_{n=2}^{\infty} (n-1) a_{n-1} x^{n-2} \\ 
  y'' & = \sum_{n=2}^{\infty} n (n-1) a_n x^{n-2} 
\end{aligned}
\]
\[
\begin{gathered}
  \sum_{n=2}^{\infty} (n(n-1) a_n + (n-1)a_{n-1} )x^n = \sum_{n=1}^{\infty} \alpha a_{n-1} x^n + \sum_{n=0}^{\infty} 2a_n x^n  = \\
  = \sum_{n=2}^{\infty} (\alpha a_{n-1} + 2a_n)x^n + \alpha a_1 x + 2a_1 x + 2a_0 
\end{gathered}
\]
\[
(n-2)(n+1) a_n = (\alpha + -n) a_{n-1} \text{ or } a_n = \frac{ (\alpha + 1 - n) a_{n-1}}{ (n-2)(n+1) }
\]
$\frac{a_n}{a_{n-1}} = \frac{ \alpha - (n-1) }{ (n-2 )(n+1) } \to 0$ as $n \to \infty$, so this power series converges $\forall \, x$.  

Also $a_0 = a_1 =0$.  

By recursion,
\[
a_n = \frac{ (\alpha + 1 - n )(\alpha + 2 - n) \dot ( \alpha -2) }{ (n-2)! (n+1)! } (3(2)) a_2
\]
Then,
\[
\begin{aligned}
  y & = a_2 \left( x^2 + \sum_{n=3}^{\infty} \frac{ ( \alpha + 1 - n)(\alpha + 2 -n) \dot (\alpha -2) }{ (n-2)! (n+1)! } 6 x^n \right)  = a_2 \left( x^2 + \sum_{n=1}^{\infty} \frac{ (\alpha - n - 1) (\alpha -n) \dots (\alpha -2)}{ n! (n+3)! } 6 x^{n+2} \right) = \\
  & = \boxed{ a_2 x^2 \left( 1 + \sum_{n=1}^{\infty} \frac{ (\alpha - n -1) (\alpha -n) \dots ( \alpha -2) }{ n! ( n+3)!}  6 x^n \right) }
\end{aligned}
\]

\exercisehead{7} Leibniz's formula for $n$th derivative of a product is the following: if $h(x) = f(x) g(x)$, then
\[
h^{(n)}(x)  = \sum_{k=0}^n \binom{n}{k} f^{(k)}(x) g^{(n-k)}(x)
\]
\begin{itemize}
  \item[a.] For
\[
\begin{aligned}
  A(x) & = \sum_{n=0}^{\infty} a_n (x-x_0)^n \\ 
  B(x) & = \sum_{n=0}^{\infty} b_n (x-x_0)^n 
\end{aligned}
\]
and $C(x) = A(X) B(x)$, then
\[
C^{(n)}(x) = \sum_{k=0}^n \binom{n}{k} A^{(k)}(x) B^{(n-k)}(x)
\]
  \item[b.] Given that 
\[
\begin{aligned}
  A^{(k)}(x_0) & = k! a_k \\ 
  B^{(n-k)}(x_0) & = (n-k)! b_{n-k}
\end{aligned}
\]
Then 
\[
C^{(n)}(x_0) = \sum_{k=0}^n \binom{n}{k} k! a_k (n-k)! b_{n-k} = n! \sum_{k=0}^n a_k b_{n-k}
\]
\[
C^{(n)}(x_0) = n! c_n \text{ so } c_n = \sum_{k=0}^n a-k b_{n-k}
\]
\end{itemize}

\exercisehead{8}
\begin{itemize}
\item[a.] By Rodrigues' formula, $P_n(x) = \frac{1}{2^n n!} \frac{d^n}{dx^n} (x^2-1)^n $.  $(x^2-1) = (x-1)(x+1)$.  By Leibniz's formula,
\[
\frac{d^n}{dx^n} (x-1)^n(x+1)^n = \sum_{k=0}^n \binom{n}{k} \frac{d^k}{dx^k}(x-1)^n \frac{d^{n-k}}{dx^{n-k}} (x+1)^n
\]
\[
P_n(x) = \frac{1}{2^n} (x+1)^n + \frac{1}{2^n n!} \sum_{k=0}^{n-1} \frac{d^k}{dx^k}(x-1)^n \frac{d^{n-k}}{dx^{n-k} }(x+1)^n = \frac{ (x+1)^n}{ 2^n} + (x-1)Q_n(x)
\]
$Q_n(x)$ is a polynomial.  
\item[b.] $P_n(1) = 1$.  $P_n(-1) = 0 + \frac{1}{2^n n!}(-2)^n n! = (-1)^n$ where we considered when $k=0$, for $\frac{d^n}{dx^n}(x+1)^n = n!$.  
\item[c.]
\end{itemize}

\exercisehead{9} \begin{itemize}
\item[a.] Now $(1-x^2)y'' + -2xy' + \alpha (\alpha +1) y=0$, or $((1-x^2)y')' = -\alpha (\alpha +1)y$.  
\[
\begin{aligned}
  & -m (m+1) P_m = ((1-x^2)P_m')' \\ 
  & -m(m+1) P_m P_n = ((1-x^2)P_m')' P_n = ((1-x^2)P_m'P_n)' - (1-x^2)P_m' P_n'
\end{aligned}
\]
\[
\begin{aligned}
  & n(n+1)P_n P_m = -((1-x^2)P_n' P_m)' + (1-x^2)P_n' P_m' \\ 
  & \Longrightarrow ((1-x^2)(P_nP_m' - P_n'P_m))' = (n(n+1)- m(m+1))P_n P_m
\end{aligned}
\]
\item[b.] If $n\neq m$, $\int_{-1}^1 P_n P_m = 0$
\end{itemize}

\exercisehead{10} \begin{itemize}
\item[a.] $f(x) = (x^2-1)^n = (x-1)^n (x+1)^n$.  Using Leibniz's rule again,
\[
f^{(n-1)} = \sum_{k=0}^{n-1} \frac{d^k}{dx^k} (x-1)^n \frac{d^{n-1 +k}}{ dx^{n-1+k}} (x+1)^n
\]
For $f^{(n-1)}(1)=0$, $f^{(n-1)}(-1)=0$.  Then
\[
\int_{-1}^1 f^{(n)} f^{(n)} = \left. f^{(n-1)}f^{(n)} \right|_{-1}^1 - \int_{-1}^1 f^{(n-1)} f^{(n+1)} = -\int_{-1}^1 f^{(n-1)} f^{(n+1)}
\]

Now
\[
f^(2n)(x) = \frac{d^{2n}}{ dx^{2n}} (x^2-1)^n = \sum_{k=0}^{2n} \binom{2n}{k} \frac{d^k }{dx^k}(x-1)^n \frac{d^{2n-k}}{ dx^{2n-k}} (x+1)^n = (2n)!
\]
for the $k=n$ term.  
\[
\int_{-1}^1 f^{(n)} f^{(n)} = \int_{-1}^1 f^{(2n)} f^{(0)} (-1)^n = (2n)! \int_{-1}^1 (1-x^2)^n dx = 2(2n)! \int_0^1 (1-x^2)^n dx
\]
\item[b.] Now $P_n(x) = \frac{1}{2^n n!} \frac{d^n}{dx^n} ( x^2-1)^n$.  
\[
\begin{aligned}
  \int_{-1}^1 (P_n(x))^2 dx &= \frac{1}{ 2^{2n} (n!)^2} \int_{-1}^1 f^{(n)}f^{(n)} = \frac{1}{ 2^{2n}(n!)^2} 2(2n)! \int_0^1 (1-x^2)^n dx  = \frac{2 (2n)! }{2^{2n} (n!)^2} \int_0^{\pi/2} \sin^{2n+1}{t} dt = \\
  & = \frac{2 (2n)!}{ 2^{2n} (n!)^2} \frac{ (2n)!!}{ (2n+1)!!} = \frac{2(2n)! 2^n n! 2^{n+1}}{ 2^{2n}(n!)^2 (2n+2)! } (n+1)! = \frac{ 2^2(n+1)}{(2n+2)(2n+1)} = \\
  & = \boxed{ \frac{2}{2n+1}}
\end{aligned}
\]
\end{itemize}




















\section*{ 6.24 Exercises - The method of Frobenius, The Bessel equation }

\exercisehead{1} \begin{itemize}
\item[(a)] Given $g(x) = x^{1/2} f(x)$, \, $x^2 y'' + xy' + (x^2 - \alpha^2)y=0$ that $f$ must satisfy, \\
$\begin{aligned} g' & = \frac{1}{2} x^{-1/2} f + x^{1/2} f' \\ y'' & = \frac{-1}{4} x^{-3/2} f + x^{-1/2} f' + x^{1/2} f'' \end{aligned}$, we want $g$ to satisfy $y'' + \left( 1 + \frac{1- 4 \alpha^2}{4x^2} \right) y =0$.  

Now 
\[
\begin{gathered}
  f'' + \frac{f'}{x} + \left( 1 - \frac{\alpha^2}{x^2} \right) f = 0 \\
  g'' = \frac{-1}{4x^{-3/2}} f + x^{1/2} \left( \frac{ \alpha^2}{x^2} - 1 \right) f \\
    g'' + g = x^{1/2} \left( \frac{\alpha^2}{x^2} - \frac{1}{4 x^2} \right) f = g \left( \frac{4\alpha^2 - 1 }{ 4 x^2} \right)
\end{gathered}
\]
\item[(b)]
\item[(c)] $J_p(x) = \left( \frac{x}{2} \right)^p \sum_{n=0}^{\infty} \frac{(-1)^n}{n! \Gamma(n+1+\alpha) } \left( \frac{x}{2} \right)^{2n}$.  Also, \\
$\Gamma\left( n+1 + \frac{1}{2} \right) = \left( n+\frac{1}{2}\right)\left( n-1 + \frac{1}{2} \right) \dots \left( 1+ \frac{1}{2} \right) \left( \frac{1}{2} \right) \Gamma\left( \frac{1}{2} \right)$

\[
\begin{aligned}
  J_{1/2}(x) & = \left( \frac{2}{x} \right)^{1/2} \sum_{n=0}^{\infty} \frac{(-1)^n }{ n! (n+\frac{1}{2}) (n-1 + \frac{1}{2} )\dots ( 1 + \frac{1}{2} )( \frac{1}{2} ) \Gamma\left( \frac{1}{2} \right) } \left( \frac{x}{2} \right)^{2n+1} = \\
  & = \left( \frac{2}{\pi x} \right)^{1/2} \sum_{n=0}^{\infty} \frac{ (-1)^n }{ (2n+1)!}x^{2n+1} = \left( \frac{2}{\pi x} \right)^{1/2} \sin{x}
\end{aligned}
\]

Now for $\alpha = \frac{-1}{2}$, consider \\
$\Gamma(n+1 - 1/2) = \Gamma\left( n+\frac{1}{2} \right) = \left( n + \frac{1}{2} - 1 \right) \left( n -2 + \frac{1}{2} \right) \dots \left( 2 + \frac{1}{2} \right) \left( 1 + \frac{1}{2} \right) \left( \frac{1}{2} \right) \Gamma\left( \frac{1}{2} \right)$
\[
\begin{aligned}
  J_{-1/2}(x) = \left( \frac{2}{x} \right)^{1/2} \sum_{n=0}^{\infty} \frac{(-1)^n }{ n! \Gamma\left( n + \frac{1}{2} \right) } \left( \frac{x}{2} \right)^{2n} = \left( \frac{2}{x} \right)^{1/2} \sum_{n=0}^{\infty} \frac{ (-1)^n  x^{2n} }{ (2n)! \Gamma(1/2)} = \left( \frac{2}{\pi x} \right)^{1/2} \cos{x}
\end{aligned}
\]
\end{itemize}



%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 8.3 Exercises - Functions from $\mathbb{R}^n$ to $\mathbb{R}^m$.  Scalar and vector fields, Open balls and Open sets } 
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1}
Let $f$ be a scalar field defined on a set $S$ and let $c$ be a given real number.  The set of all points $x$ in $S$ such that $f(x) = c$ is called a level set of $f$.  \\
\phantom{ Let f} See sketch.  

\exercisehead{2} Let $S$ be the set of all points $(x,y)$ in the plane satisfying the given inequalities.  \\
\phantom{Exercise head Let S } See sketch.  

\exercisehead{3} \emph{Proofs are hard!}  I \emph{read} the \emph{examples at the end of Section 8.2}, particularly the example on the 2-dim. \emph{Cartesian product}: it helps.  In fact, we'll review it right now.  \bigskip \\ 
$A_1, A_2 \subseteq \mathbb{R}^1 $ \\
\quad \quad $A_1 \times A_2 = \{ (a_1,a_2) | a_1 \in A_1, \, A_2 \in A_2 \}$ \\
If $A_1, \, A_2$ are open subsets of $\mathbb{R}^1$, \\
\quad \phantom{ If } Choose any $a \in A_1 \times A_2$ \medskip \\
\emph{ Want:} $a$ is an int. pt. of $A_1 \times A_2$ \bigskip \\

Since \\
\phantom{ Sinc } $A_1, A_2$ open in $\mathbb{R}^1$, $\exists \, B(a_1;r_1)$, $\exists \, B(a_2;r_2)$ \\
\phantom{ Sinc } Let $r = min\{ r_1, r_2 \}$ \medskip \\
\emph{ Want:} $B(a;r) \subseteq A_1 \times A_2$  \bigskip \\

If $(x_1,x_2) = x \in B(a;r)$, \\
\phantom{ If } $\| x - a \| < r $, so $|x_1 - a_1| < r$, $|x_2 - a_2 | < r_2$, \\
\quad \phantom{ If } then $\begin{aligned}
  & x_1 \in B(a_1;r_1) \\
  & x_2 \in B(a_2; r_2) 
\end{aligned} $ \quad $\Longrightarrow \begin{aligned}
  & x_1 \in A_1 \\
  & x_2 \in A_2 
\end{aligned}$ \bigskip \\
We then get what we want: $(x_1,x_2) \in A_1 \times A_2$ so that any $x \in B(a;r)$ belongs in $S$, which means, by def., that $B(a;r) \subseteq S$  \\

Onward with the problem:  \\

Let $S$ be the set of all points $(x,y,z)$ in 3-space.  \begin{enumerate}
\item $z^2 - x^2 - y^2 - 1 > 0 $
\item $ |x| < 1, \, |y| <1 , \, $ and $|z| < 1$ Consider $a \in S$
We must use the fact that an open rectangular box is a basic open set.  

Let $a \in S$, $a = (a_1,a_2,a_3)$ \\
Let $\rho_i = \begin{cases} 1 - a_i & \text{ if } a_i \geq 0 \\ |-1-a_i| & \text{ if } a_i < 0 \end{cases}$ and $R_a = \prod_{i=1}^3 (a_i - \rho_i, a_i + \rho_i)$  \\

Consider $b \in R_a$.  \\

If $a_i \geq 0$,  \\
\quad \, if $b_i \geq a_i$, $b_i - a_i < 1 - a_i$ or $b_i < 1$ \\
\quad \, if $b_i < a_i$, $\begin{aligned} & \text{ if } b_i > 0, & a_i - b_i > 0 \text{ or } 1 > a_i > b_i \\
  & \text{ if } b_i < 0, & -b_i < a_i - b_i < 1 - a_i < 1 \end{aligned}$ \\

If $a_i < 0$, \\
\quad \, if $b_i > a_i$, $\begin{aligned} & \text{ if } b_i > 0, & b_i - a_i < 1 +  a_i \text{ or } b_i < 1 + 2a_i < 1 \\
  & \text{ if } b_i < 0, & -b_i < -a < 1 \, (\text{since} |a_i|<1) \end{aligned}$
\quad \, if $b_i < a_i$, $a_i - b_i < 1+a_i$ or $-b_i < a_i -b_i < 1 + a_i <1$. \\

Then, $\boxed{ |b_i|<1 }$ for \emph{each and every possible case}.  Then $R_a \subseteq S$, so $\forall \, a \in S$ is an int. pt. (since $\forall \, a$, $\exists$ open rectangle $R_a$, that is completely contained in $S$).  Then $S$ is open.  

%\[
%\begin{gathered}
%  \| x - a \|^2 = (x_1-a_1)^2 + (x_2 - a_2)^2 + (x_3 - a_3)^2 \\
%  x_1^2 - 2x_1 a_1 + a_1^2 < 2 (1- x_1 a_1) < 4 \quad \, \text{ (since $2 > 1 - x_1 a_1 > 0 $ ) }
%\end{gathered}
%\]
\item $x+y+z < 1$
\item $|x| \leq 1, \, |y| < 1$, and $|z| < 1$  \medskip \\
Consider $a_0 = (1,a_2,a_3)$, $1 > a_2,a_3 > 0$.  \\
$a_0 \in S$, but for $B(a_0,1/2)$, $(5/4,a_2,a_3) \in B(a_0,1/2)$ and $(5/4,a_2,a_3) \notin S$.  $\boxed{ \text{ So $S$ is not open. }}$   \\

Or\dots \\

An open set has every element to be interior to it (definition).  \\
An interior pt. is a pt. s.t. $\exists$ some open basic set containing the pt. and is a subset of the set.  \\

We must show $\nexists$ any open basic set for a pt. in this set.  \\
Since every open rectangle contains an open ball and every open ball contains an open rectangle, we only need to consider open rectangles.   \\

Consider $(1,y_0,z_0)\in S$. \\
Consider open rectangle containing $1$.  I claim that at best, $\left( 1 - \frac{1}{n}, 1 + \frac{1}{n} \right), \, n\in \mathbb{Z}^+$, since by Archimedes property of real numbers,

\begin{theorem}[Apostol's Archimedes property of real numbers, pp. 26, Thm. 1.30, Vol. 1] If $x>0$ and if $y$ is an arbitrary real number, $\exists \, n\in \mathbb{Z}^+$ s.t. $nx > y$.  We want $i \in (a_i, b_i)$ i.e. $a_i < 1 < b_i$
\end{theorem}
Consider open interval containing $1$; $1 \in (a_i,b_i)$.  Then $a_i < 1 < b_i$.  But $(a_i,b_i)$ always contains pts. not belonging to $S_i$: $nx <y$ (existence of $n$ \emph{ guaranteed by Archimedes prop. of reals thm.}).  
\[
nb_i > (n+1) \Longrightarrow b_i > 1 + \frac{1}{n} > 1
\]
Then $\nexists$ open interval containing $1$ completely contained in $S$.  $(1,y_0,z_0)$ is not an interior pt.  $S$ is not open.  



%$a\in S$.  Then $|a_{1,2,3}| < 1$.  \medskip \\
%$r^2 > 0$, so we can say $r^2 = r_1^2 + r_2^2 + r_3^2$  \bigskip \\
%Consider $|x-a_1| < r_1^2$, just one component, without loss of generality.  
%\[
%|x - a_1 | > ||x|-|a_1|| = \begin{cases} 
%  |x|-|a_1| & \text{ if } |x| >|a_1| \\
%  |a_1|-|x| & \text{ if } |a_1| > |x| 
%\end{cases}
%\]
%If $|a_1| > |x|$, we're done, since $1 > |a_1| > |x|$ (and so we get what we want, $1 > |x|$ ). \\
%If $|x| > |a_1|$, then consider $r_1 > |x-a_1| > |x| - |a_1| \Longrightarrow r_1 + |a_1| > |x|$.  Let $r_1 = 1 - |a_1|$, which is okay, since $|a_1|<1$, so that $r_1>0$ and $r$ \textbf{ can depend upon } $a$, \textbf{ just not } $x$, because $x$ \textbf{ must be completely arbitrary}. \medskip \\
%$r_1 + |a_1| = 1 - |a_1| + |a_1| =1 > |x|$ \medskip \\
%This must be true for all three components of $x \in B(a;r)$; so we've found a $B(a;r)$ s.t. $\forall \, x \in B(a;r)$, $x \in S$, so then $B(a;r) \subseteq S$, so then $S$ is an open set.  
%  For $a \in S$, consider $B(a;r)$ $\Longrightarrow \|x - a \| < r$ or $(x_1 -a_1)^2 + (x_2 -a_2)^2 + (x_3 -a_3)^2 < r^2$
%\[
%\begin{gathered}
%  |a_2|,|a_3| < 1, \text{ so then } |x_2 -a_2| > ||x_2|-|a_2|| > \begin{
%
%
%\end{gathered}
%\]
\item $x+y+z < 1$ and $x>0, \, y > 0 , \, z>0$ \\

Consider $x \in S$.  Then $x+y+z <1$.  \\
Consider $\prod_{j=1}^3 (x_j - \delta_j, x_j+\delta_j)$.  
\[
\begin{gathered}
  \sum_{j=1}^3 x_j + \delta_j = \sum_{j=1}^3 x_j + \sum_{j=1}^3 \delta_j \\
  0 < x + y + z < 1 \text{ so let } 1 - \sum_{j=1}^3 (x_j) = \epsilon(x) > 0 \\
    \text{ We can choose } \sum_{j=1}^3 \delta_j = \delta \text{ s.t. } \epsilon(x) > \delta > 0 
\end{gathered}
\]
Furthermore, by Archimedes axiom, we can choose $\delta_j >0$ s.t. $x_j - \delta_j >0$ \\
$\Longrightarrow \, \forall \, x \in S$, we can construct an open rectangle $\prod_{j=1}^3 (x_j-\delta_j, x_j+ \delta_j) = R(x)$ s.t. $R(x) \subseteq S$.
\item $x^2 +4y^2 +4z^2 - 2x + 16y + 40z + 113 < 0$
\[
\begin{gathered}
  x^2 + 4 y^2 + 4 z^2 - 2x + 16y + 40 z + 113 = (x-1)^2 -1 + 4 (y+2)^2-16 + 4(z+5)^2 - 100 + 113 = \\
   = (x-1)^2 + 4(y+2)^2 +4 (z+5)^2 -4 < 0 \quad   \Longrightarrow \frac{ (x-1)^2 }{2^2 } + (y+2)^2 + (z+5)^2 < 1 
\end{gathered}
\]
Thus, $S$ is, by definition, a \textbf{basic open set}, a basic open sphere.  By theorem, \textbf{a basic open sphere is an open set}.
\end{enumerate}

\exercisehead{4} 
\begin{enumerate}
\item $A$ is an open set in $n$-space and $x \in A$.  Given $A$ is open, $A - \{ x\} \subset A$.  \medskip \\
Consider $a \in A - \{ x \}$.  Then $a \in A$ so, $\exists B_a(a,r_a) \subseteq A$.  \\
\quad \quad \, If $x \notin B_a(a,r_a)$, we're done.  \\
\quad \quad \, If $x \in B_a(a,r_a)$, consider $r_{ax} = \| a- x \|$ \\
\quad \quad \quad \, $\forall \, x_a \in B_a(a,r_{ax})$, $\| x_a - a \| < r_{ax}$ also $\| x_a - a \| < r_{ax} < r_a$, so $x_a \in A$ \\
$\Longrightarrow B_a(a,r_{ax}) \subseteq A$ and $B_a(a,r_{ax}) \subseteq A - \{ x \}$ since we constructed $B_a$ s.t. $x \notin B_a$
\item $A$ open.  Let $B$ have endpoints $b_1,\, b_2$ \medskip \\
  $A-\{ b_1 \}$ open.  $A - \{ b_1 \} - \{ b_2 \} = A'$ open.  \\
  $A' - int{B} = A-B$ open since open set minus an open set is open, since union of $2$ open sets is an open set.  

We could also directly say, since we're dealing with intervals in one-dimension, $A=(a_A, b_A)$, $B = [a_B, b_B]$.  $\begin{aligned}
  & b_B < b_A \\
  & a_A < a_B
\end{aligned}$.  \smallskip \\
$B$ is a closed subinterval of $A$.  \\
$A-B = (a_A,a_B) \bigcup (b_B,b_A)$
\item $\forall \, x \in A \bigcup B$, $x \in A$ or $x \in B$.  Since $A,B$ are open, $x$ is int. to $A$, or int. to $B$. \\
Explicitly, if $\exists \, B(x,r) \subseteq A, \, B$ then $B(x,r) \subseteq A, \, B \subseteq A \bigcup B$.  \\
Then $x$ is interior to $A\bigcup B$.  $\Longrightarrow A \bigcup B$ open.  

$\forall \, x \in A \bigcap B$, $x \in A$ and $x \in B$.  \\
\quad Since $x \in A$ and $x \in B$, $\exists \, B(x,r_A) \subseteq A$; \, $B(x,r_B) \subseteq B$ or \\
\quad \quad \quad \, $(x-r_A,x+r_A) \subseteq A$ ; \quad \, $(x-r_B, x+r_B) \subseteq B$ \smallskip \\
Let $r_m = \min{ (r_A,r_B) }$ \\
So then $(x-r_m,x+r_m) \subseteq A$ and $(x-r_m,x+r_m) \subseteq B$ $\Longrightarrow (x-r_m,x+r_m) \subseteq A \bigcap B$
\item $\mathbb{R}^1$ is open (since $\forall \, B(x;r) \subseteq \mathbb{R}^1$ ) \\
  $A = [a_A,b_A]$ is a closed interval.  \\
  Let $\mathbb{R}^1 - A = \mathbb{R}^-$ \\
  $\forall \, x \in \mathbb{R}^-$, $x \in \mathbb{R}^1$ so $B(x;r) \subseteq \mathbb{R}^1$.  \medskip \\
  Suppose $x \in \mathbb{R}^-$, so $x > b_A$ or $x < a_A$ (otherwise $x \in A$).  \medskip \\
  \quad \quad If $x > b_A$, then let $r_1 = x - b_A$, \\
  $(x-r_1,x+r_1) \subseteq \mathbb{R}^-$ since $(x-r_1,x+r_1) \subseteq \mathbb{R}$ and $\forall \, x_1 \in (x-r_1, x+r_1)$, $x_1 > b_A$ \\
  \quad \quad If $x < a_A$, then let $r_1 = a_A - x$ \\
  $(x-r_1,x+r_1) \subseteq \mathbb{R}^-$ since $(x-r_1,x+r_1) \subseteq \mathbb{R}$ and $\forall \, x_1 \in (x-r_1, x+r_1)$, $x_1 < a_A$
\end{enumerate} 

\exercisehead{5} Prove the following properties of open sets in $\mathbb{R}^n$
\begin{enumerate}
\item The empty set $\emptyset$ is open.  \medskip \\
Let $a \in \emptyset$ \\
\phantom{ Let } Then $B(a;r) \subseteq \emptyset$ since there are no $a \in \emptyset$,  $\Longrightarrow \, a$ is an interior pt. of $\emptyset$.  \\

Or \dots \\

Consider $a \in \emptyset$ \\
Consider $B(a;r) = \emptyset$.  Then $B(a;r) \subseteq \emptyset$.  So $\emptyset$ is open.
\item $\mathbb{R}^n$ is open.  \bigskip \\
  Consider $a \in \mathbb{R}^n$.  Consider $B(a;r)$.  So for $x \in B(a;r)$, then $\| x-a \| < r$.  \\
  $\Longrightarrow |x_j - a_j| < r_j$ \\
  $x_j \in \mathbb{R}$ \quad \, $\forall \, x_j $ s.t. $|x_j - a_j| < r_j$ defines an open interval on $\mathbb{R}^1$, and so by induction, the Cartesian product of $n$ open intervals is an open $n$-ball.  So $\mathbb{R}^n$ is open.  \\

Or \dots \\

Consider $a \in \mathbb{R}^n$.  \\
Consider $B(a;r)$.  Since $\forall \, y \in B(a;r)$, $y\in \mathbb{R}^n$.  $B(a;r) \subseteq \mathbb{R}^n$.  $\mathbb{R}^n$ open.  
\item Consider $\{ W_j \}$, collection of open sets.  \\
Consider $y\in \bigcup_j W_j$.  Then $y \in W_j$ for some $j$.  Since $W_j$ open, $\exists \, B(y;\rho) \subseteq W_j$.  \\
$W_j \subseteq \bigcup_j W_j$, so $B(y,\rho) \subseteq \bigcup_j W_j$.  $\bigcup_j W_j$ is open.  
\item Consider $\{ W_j | j =1, \dots, n\}$, finite collection of open sets.    \\
  Consider $ y \in \bigcap_{j=1}^n W_j$.  \\
$y \in W_i$, \, $\forall \, i =1, \dots, n$.  Then since $\forall \, i$, $W_i$ open, $\exists \, B_i(y,\rho_i) \subseteq W_i$.  \\
  By Thm., $\exists$ \, open set $B(y,\rho) \subseteq \bigcap_{i=1}^n B_i(y, \rho_i)$.  Then $B(y,\rho) \subseteq \bigcap_{i=1}^n B_i(y,\rho_i) = \bigcap_{i=1}^n W_i $
\item Let $W_k = \left( \frac{-1}{k}, \frac{1}{k} \right)$; $k \geq 1$ \\
Then $\bigcap_k W_k = \{ 0 \}$, which is not open.  
\end{enumerate}

\exercisehead{7} \begin{enumerate}
\item $(A \bigcup \{ x \})^c = A^c \bigcup (\mathbb{R} - x)$ \\
  $A^c$ open.  $\mathbb{R}^n - x$ open.  (since $\{ x \}$ is closed).  Then, by thm., the intersection of these two open sets, $A^c \bigcap (\mathbb{R} - x)$ is open.  Then, by definition, $A \bigcup \{ x \}$ is closed.  
\item $\mathbb{R} - [a,b] = [a,b]^c$.  \\
  Consider $y \in \mathbb{R} - [a,b]$ \smallskip \\
If $y > b$, then  \\
\quad \, $ y -b > 0$, so $\exists \, N \in \mathbb{Z}^+$ s.t. $y-b > \frac{1}{N}$.  $y > \frac{1}{N} + b$ (Archimedes prop. of real numbers).   \\
\quad \quad \, $ y \in \left( \frac{1}{N} + b, y+1 \right)$ is open and $\left( \frac{1}{N} + b, y +1 \right) \subseteq \mathbb{R} - [a,b]$   \smallskip \\
If $y<a$, then \\
\quad \, $a - y >0$, so $\exists \, N \in \mathbb{Z}^+$ s.t. $a-y > \frac{1}{N}$ or $a - \frac{1}{N} >y$ \\
\quad \, $y \in \left( y -1, a-\frac{1}{N} \right) \subseteq \mathbb{R} - [a,b]$ \\
then $\mathbb{R} - [a,b]$ open.  $[a,b]$ closed (by definition).  
\item $(A \bigcup B)^c = A^c \bigcap B^c$.  $A,B$ closed, so $A^c$, $B^c$ open.  $A^c \bigcap B^c$, intersection of 2 open sets, is open.  \\
  \quad \, then $A \bigcup B$ closed.  \smallskip \\
$(A \bigcap B)^c = A^c \bigcap B^c$.  $A^c, B^c$ open.  $A^c \bigcup B^c$ open.  Then $(A \bigcap B)$ closed.  
\end{enumerate}

\exercisehead{8} \begin{enumerate}
\item $\emptyset^c = \mathbb{R}^n$ and $\mathbb{R}^n$ open.  $\emptyset$ closed.  
\item $(\mathbb{R}^n)^c = \emptyset$ and $\emptyset$ open.  $\mathbb{R}^n$ closed.  
\item $(\bigcap_i A_i)^c = \bigcup_i A_i^c$.  $A_i^c$ open, so $\bigcup_i A_i^c$ open.  $\bigcap_i A_i$ closed.  
\item $(\bigcup_{i=1}^n A_i)^c = \bigcap_{i=1}^n A_i^c$.  $A_i^c$ open, so $\bigcap_{i=1}^n A_i^c$ open.  $\bigcup_{i=1}^n A_i$ closed.  
\item $\bigcup_{i=1}^{\infty} \{ i \} = \mathbb{Z}^+$ is closed since $\left( \bigcup_{i=1}^{\infty} \{ i \} \right)^c = \bigcup_{i=1}^{\infty} (i,i+1)$ is open.  
\end{enumerate}

\exercisehead{9} Let $S$ be a subset of $\mathbb{R}^n$ 
\begin{enumerate}
\item Prove that both $int{S}$ and $ext{S}$ are open sets.  \medskip \\
%If $int{S} = \emptyset$, $\emptyset$ is open; done.  \smallskip \\
%Consider $a \in int{S}$ \\
%\phantom{Consider} By def. of $int{S}$, $\exists \, B(a;r)$ s.t. $B(a;r) \subseteq int{S}$.  Then $int{S}$ open.  \medskip \\
%If $ext{S} = \emptyset$, $\emptyset$ is open; done.  \smallskip \\
%$\forall \, b \in ext{S}$, $\exists \, B(b;r)$ s.t. $a \notin B(b;r)$ where $a \in S$ \\
%$b$ itself must be $b \notin S$, otherwise $b \in B(b;r)$ and $b \in S$  \medskip \\
%If $x_b \in B(b;r)$, consider $r_{xb} = \| x_b - b \|, \, B(x_b;r_{xb})$ \smallskip \\
%$B(x_b;r_{xb}) \subseteq B(b;r)$ since $\| x_b - b_b \| < r_{xb} = \| x_b - b \| < r$ so $b_b \in B(x_b;r_{xb})$, $b_b \notin S$ \smallskip \\
%$\Longrightarrow B(x_b,r_{xb})$ contains no pts. in $S$ $\Longrightarrow x_b \in ext{S}$ \\
%\quad \quad \, $\Longrightarrow B(b;r)$ contains only pts. in $ext{S}$, i.e. $B(b;r) \subseteq ext{S} \xrightarrow{ \text{ (by def. of open set) } } ext{S}$ open.  
\emph{Want}: $int{S}$ is open, i.e. $\forall \, a \in int{S}$, $\exists \, B(a;r) \subseteq int{S}$ i.e. \\
\quad \quad $\forall \, x_1 \in B(a;r), \, x_1 \in int{S}$ \\
\quad \quad $x_1 \in int{S}$ if $\exists \, B(x_1;r_1) \subseteq S$ \smallskip \\

Consider $a\in int{S}$, then $\exists \, B(a;r) \subseteq S$  \\
\quad \, Consider $x_1 \in B(a;r)$.  If $\| x_1 - a\| < r$ consider $\forall \, x_2$ s.t. $\| x_2 - x_1 \| < \| x_1 - a \| = r_1 <r$.  \\
\quad \quad Then $x_2 \in B(a;r)$, so $B(x_1,r_1) \subseteq B(a;r) \subseteq S$ \\
\quad \quad \, $\Longrightarrow \forall \, x_1 \in int{S}$ for $x_1 \in B(a;r)$, so $B(a;r) \subseteq int{S}$.  \medskip \\

\emph{Want}: $ext{S}$ is open, i.e. $\forall \, a \in ext{S}$, $\exists \, B(a;r) \subseteq ext{S}$ i.e. \\
\quad \quad $\forall \, x_1 \in B(a;r), \, x_1 \in ext{S}$ \\
\quad \quad $x_1 \in ext{S}$ if $\exists \, B(x_1;r_1)$ s.t. $\forall \, x_2 \in B(x_1,r_1)$, $x_2 \notin S$.  \smallskip \\

Consider $a\in ext{S}$, then $\exists \, B(a;r)$ s.t. $\forall \, x_1 \in B(a,r)$, $x_1 \notin S$  \\
\quad \, Consider $x_1 \in B(a;r)$.  If $\| x_1 - a\| < r$ consider $\forall \, x_2$ s.t. $\| x_2 - x_1 \| < \| x_1 - a \| = r_1 <r$.  \\
\quad \quad Then $x_2 \in B(a;r)$, so $x_2 \notin S$.  so then $\exists \, B(x_1,r_1)$ s.t. $\forall \, x_2 \in B(x_1,r_1)$, $x_2 \notin S$ \\
\quad \quad \, $\Longrightarrow \forall \, x_1 \in ext{S}$, so $B(a;r) \subseteq ext{S}$.  $ext{S}$ open.   
\item Prove that $\mathbb{R}^n = (int{S}) \bigcup (ext{S}) \bigcup \partial S$, a union of disjoint sets, and use this to deduce that boundary $\partial S$ is always a closed set.  \medskip \\

Suppose $a_e \in ext{S}$.  Then $\exists \, B(a_e,r)$ s.t. $\forall \, x_e \in B(a_e,r)$, $x_e \notin S$.  \\
Then $\forall \, R > 0$, $B(a_e, R)$ will contain $x_{eR} \in B(a_e,R)$ s.t. $x_{eR} \notin S$. (all open $n$-balls will either contain $B(a_e,r)$ or be a part of $B(a_e,r)$).  So $\nexists \, B(a_e,R)$ s.t. $B(a_e,r) \subseteq S$.  $a_e \notin int{S}$ \smallskip \\

If $a_{in} \in int{S}$, suppose $a_{in} \in  ext{S}$.  Then $a_{in} \notin int{S}$.  Contradiction.  $a_{in} \notin ext{S}$.  \medskip \\
\quad \quad $int{S}, \, ext{S}$ are open and disjoint.  \medskip \\

Suppose $a_{bd} \in \partial S$.  $\begin{aligned}
  & \text{ $a_{bd}$ is not interior to $S$, so $a_{bd} \notin int{S}$ }\\
  & \text{ $a_{bd}$ is not exterior to $S$, so $a_{bd} \notin ext{S}$}
\end{aligned} $

Let $x \in \mathbb{R}^n$.  Consider $B(x,r_0)$.  If $B(x,r_0) \subseteq S$, then $x\in int{S}$.  If $\forall \, x_1 \in B(x,r_0)$, $x_1 \notin S$.  Then $x\in ext{S}$.  \smallskip \\
\quad \quad Otherwise, $B(x,r_0)$ may contain $x_{1a} \in S$ and $x_{1b} \in S^c$.  Then $x$ is neither interior or exterior to $S$.  So $x \in \partial S$ \smallskip \\

$\Longrightarrow x \in int{S} \bigcup ext{S} \bigcup \partial S$, $\mathbb{R}^n \subseteq int{S} \bigcup ext{S} \bigcup \partial S$.  \medskip \\
Since $\forall \, x \in int{S} \bigcup ext{S} \bigcup \partial S$, $x \in \mathbb{R}^n$, then $int{S} \bigcup ext{S} \bigcup \partial S \subseteq \mathbb{R}^n$.  \smallskip \\
\quad \quad \quad $\Longrightarrow \mathbb{R}^n = int{S} \bigcup ext{S} \bigcup \partial S$ a union of disjoint sets.  \smallskip \\

$(int{S} \bigcup ext{S})^c = \partial S$, $int{S} \bigcup ext{S}$ is open so $\partial S$ is closed, since its complement is open.  
\end{enumerate}

\exercisehead{10} \textbf{Want:} $x =$ boundary pt. of $S$ $=$ b.p. of $S$, neither interior nor exterior to $S$.  \smallskip \\
$\forall \, B(x)$, $\exists \, a_i \in B(x)$, s.t. $a_i \in int{S} \subseteq S$.  Then $x$ cannot be an exterior pt.  \\
$\forall \, B(x)$, $\exists \, a_e \in B(x)$, s.t. $a_e \in ext{S}$.  Then $a_e \notin S$ and so $x$ is not interior, by definition.  $x$ is a boundary pt.  

\exercisehead{11} $\mathbb{R}^n - S = S^c$.  \\
Let $x \in int{S^c}$.  Then $\exists$ open $V$ s.t. $x\in V$ and $V \subseteq S^c$.   \smallskip \\
Then $\forall \, x_1 \in V$, $x_1 \notin S$, so $x$ is an exterior pt. to $S$.  $x \in ext{S}$, so $int{S^c} \subseteq ext{S}$.  \\
Let $x \in ext{S}$.  Then $\exists \, B(x)$ s.t. $B(x) \subseteq S^c$.  By def., $x \in int{S}^c$. \\
\quad \, $ext{S} \subseteq int{S^c}$
\[
\Longrightarrow ext{S} = int{S^c}
\]

\exercisehead{12}  Suppose $S$ closed.  Let $y$ be a boundary pt. of $S$.  \\
Suppose $y \notin S$.  Then $y\in S^c$, $S^c$ open.  \\
\quad So by def. of open set, $\exists \, U$ s.t. $y\in U$ and $U \subseteq S^c$.  But $y$ is then an exterior pt., contradicting the definition of a boundary pt. for $y$.   \smallskip \\
Then $y \in S$, so that $S = int{S} \bigcup \partial S$ \\

Suppose $int{S} \bigcup \partial S =S$ \\
\quad Consider any $z \in S^c$.  \\
Then $z$ has to be either a boundary pt. of $S^c$ or interior pt. of $S^c$.  \\
\quad $z$ cannot be a boundary pt. of $S^c$ (we already showed that $\begin{aligned} ext{S} & = int{S^c} \\ ext{S^c} & = int{S} \end{aligned}$), because then $z\in \partial S$ and hence belong to $S$.  \\
Then $z$ is interior to $S^c$.  $S^c = int{S^c}$, so $S^c$ open.  $S$ closed.  


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 8.5 Exercises - Limits and continuity }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} 
\begin{enumerate}
  \item $f(x,y)$ is continuous $\forall \, (x,y) \in \mathbb{R}^2$ 
  \item $(x,y) \neq (0,0)$
  \item $y\neq 0$
\item $y\neq 0$, $\frac{x^2}{y} \neq \frac{\pi}{2} + \pi k$, $k \in \mathbb{Z}$
\item $x\neq 0$
\item $(x,y) \neq (0,0)$
\item $\frac{x+y}{1 - xy} \neq \frac{\pi}{2} + \pi k$, \, $k\in \mathbb{Z}$, $xy\neq 1$
\item $(x,y) \neq (0,0)$
\item $f = \exp{(y^2 \ln{x}) }$, $x\neq 0$
\item $ y \neq 0$, $\frac{x}{y} \geq 0$
\end{enumerate}

\exercisehead{2}$ \lim_{x\to a} f(x,y), \, \lim_{y\to b} f(x,y)$ exist, so $\lim_{x\to a} f(x,y) =f(a,y)$ and $\lim_{y\to b} f(x,y) = f(x,b)$.  \medskip \\
Since $\lim_{x\to x_0} f(x) = f(x_0)$, where $x_0 = (a,b)$, which is equivalent to saying 
\[
\forall \, \epsilon > 0, \, \exists \, \delta > 0 \text{ s.t. } |f(x) -L| < \epsilon \text{ if } \| x - x_0 \| < \delta
\]
then \\
Consider $\frac{\epsilon }{2} > 0$.  $\exists \, \delta_y > 0$ s.t. $|f(x,y) - f(x,b)| < \frac{ \epsilon}{2}$ if $|y-b| <\delta_y$ (since $\lim_{y\to b} f(x,y)$ exists).   \\
Consider $\frac{\epsilon }{2} > 0$.  $\exists \, \delta_{xy} > 0$ s.t. $|f(x,y) - L| < \frac{ \epsilon}{2}$ if $\| (x,y) - (a,b) \| <\delta_{xy}$ (since $\lim_{x\to x_0} f(x)=L$).  
\[
\begin{gathered}
  |f(x,b)-L| = |f(x,b) -f(x,y) + f(x,y) - L | < |f(x,y) - f(x,b) | + |f(x,y) - L | < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon \text{ whenever } \\
  |y-b| < \delta_y \text{ and } \sqrt{ (x-a)^2 + (y-b)^2 } < \delta_{xy} \\
  \text{ then } |x-a| < \delta_{xy}
\end{gathered}
\]
So $\forall \, \epsilon > 0$, $\exists \, \delta_{xy} = \delta_x(\epsilon)$ s.t. $|f(x,b)-L| <\epsilon$ whenever $|x-a| < \delta_x(\epsilon)$.  \\
\phantom{ So } We just proved $\lim_{x\to a} \lim_{y\to b} f(x,y) = \lim_{x\to a} f(x,b) = L$

Similarly, we get the same result for $lim_{y\ to b} f(a,y)$.  Thus, $\lim_{x\to a} \lim_{y\to b} f(x,y) = \lim_{y\to b} \lim_{x\to a} f(x,y) = L$ whenever $\lim_{x\to x_0} f(x) = L$

\exercisehead{3} $f(x,y) = \frac{(x-y)}{x+y}$ 
\[
\begin{aligned}
  & \lim_{y\to 0} f = 1 \\
  & \lim_{x\to 0} f = -1
\end{aligned}
\]

\exercisehead{4} $f(x,y) = \frac{x^2 y^2}{ x^2 y^2 + (x-y)^2 }$ 
\[
\begin{aligned}
  & \lim_{x\to 0} f = 0 \\
  & \lim_{y \to 0} f = 0 
\end{aligned}\quad \quad \quad \text{ but if } y = x, f = \frac{x^4}{x^4 + 0} = 1
\]

\exercisehead{5} $0 < x \sin{\frac{1}{y}} < x$ \quad $x \to 0$, so by squeeze principle, $x \sin{\frac{1}{y}} \to 0$.  \\
\quad \quad $\to \lim_{x\to 0} f =0$

$\lim_{y\to 0} f$ undefined, since \\
\quad Consider $|y| < \frac{1}{n}$ or $n < \frac{1}{|y|}$ \\
\quad \quad For $y >0$, $\sin{\frac{1}{y}} > \sin{n}$ \\
\quad \quad For $y <0$, $|\sin{\frac{1}{y}}| = \sin{ \frac{-1}{y} } > \sin{n}$ 

$\forall \, \delta = \frac{1}{n}, \exists \, \epsilon = \epsilon(\delta) = \sin{(1/\delta)}$ s.t. $|\sin{1/y}| > \epsilon$ if $|y| < \frac{1}{n}$ \\
\quad Then $\lim_{y\to 0} \lim_{x\to 0} f = 0 \neq \lim_{x\to 0} \lim_{y\to 0} f$

\exercisehead{6} $(x,y) \neq (0,0)$, let $f(x,y) = \frac{ x^2 - y^2}{x^2 + y^2}$ \\
If $y=mx$, $f\to \frac{ x^2 (1-m^2)}{ x^2(1+m^2)} = \frac{1-m^2}{1+m^2}$.  If $y=0$, $f = 1$.  If $x=0$, $f=-1$, so there's no way to define $f(0,0)$ to be single valued.  

\exercisehead{7} Consider $y=kx$; $k\in \mathbb{R}$. \\
For $k=0$, $y=0$ and $f(x,y) =0$, if $y=0$ \\
For $k \gtrless 0$, $x \lessgtr 0$, $y<0$, so $f(x,y) =0$.  \medskip \\
Consider the limit as $x \to 0$.  $\epsilon$ can be as small as you want. \\
\quad \quad Then we must have $|x| < \epsilon < |k|$.  \\
\quad \quad \quad then $x^2 < kx$ \\
\quad Thus $y=kx > x^2$, so $f(x,y) =0$ for any straight line through the origin.  

Consider $|x| < \epsilon =1$ 
\[
x^4 < x^2
\]
So $y= x^4 < x^2 \to f(x,y) = 1$ \\
\quad So, $f$ is discontinuous at $(0,0)$.  $f(0,0)$ depends upon path taken.  

\exercisehead{8} Change to polar coordinates.  Then 
\[
f(x,y) = \frac{ \sin{(x^2 + y^2)} }{ (x^2 + y^2)} = f(r,\theta) = \frac{ \sin{ r^2}}{r^2}
\]
Then regardless of what value of $\theta$, $\lim_{r\to 0} \frac{\sin{r^2}}{r^2} = \boxed{1}$.  

\exercisehead{9} Let $f$ be a scalar field continuous at an interior pt. $a$ of a set $S$ in $\mathbb{R}^n$.  $f(a) \neq 0$ (given).  

Continuity of $f$ at $a$ means that 
\[
\lim_{x\to a} f(x) = f(a) \Longrightarrow \forall \, \epsilon > 0, \, \exists \, \delta > 0 \text{ s.t. } | f(x)  - f(a) | < \epsilon \text{ whenever } \| x- a\| < \delta 
\]
Let $\epsilon = \frac{f(a)}{2}$, $\exists \, \delta = \delta(\epsilon; a)$ s.t. $\begin{cases} f(x) -f(a) < \frac{f(a)}{2} & \text{ if } f(x) > f(a) \\ -f(x) + f(a) < \frac{ f(a)}{2} & \text{ if } f(x) < f(a) \end{cases}$,  \smallskip \\
\quad \quad so $\frac{f(a)}{2} < f(x) < \frac{3f(a)}{2}$ for $\forall \, x$ s.t. $\| x- a\| < \delta(\epsilon; a)$.  \medskip \\
$\delta(\epsilon;a)$ defines a $B(a) \subseteq \mathbb{R}^n$ s.t. $f(x)$ has the same sign as $f(a)$.  


%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 8.9 Exercises - The derivative of a scalar field with respect to a vector, Directional derivatives and partial derivatives, Partial derivatives of higher order }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} $f(x) = a\cdot x$
\[
f'(x;y) = \lim_{h\to 0} \frac{ f(x+hy) - f(x)}{h} = \lim_{h\to 0} \frac{ a\cdot (x+hy) - a\cdot x }{ h } = \boxed{ a\cdot y}
\]

\exercisehead{2} $f(x) = \| x \|^4$ 
\begin{enumerate}
\item \[
  f'(x,y) = \lim_{h\to 0} \frac{f(x+hy) -f(x) }{h} = \lim_{h\to 0} \frac{ \|x+h y\|^4 - \| x \|^4 }{h} = \boxed{ 4 x^2 (x\cdot y) }
\]
\item $n=2$
\[
f'(2i+3j; xi +yj)= 6 = 4(13) (2x+3y) \Longrightarrow \frac{3}{26} = 2x + 3y \Longrightarrow \boxed{ y= \frac{-2x}{3} + \frac{1}{26} }
\]
\item $n=3$
\[
f'(i+2j+3k;xi +yj+zk) = 0 =4 (1^2 + 2^2 + 9)(x+2y+3z) \Longrightarrow \boxed{ x+2y+ 3z =0}
\]
\end{enumerate}

\exercisehead{3} 
\[
\begin{aligned}
f'(x,y) & = \lim_{h\to 0} \frac{f(x+hy)-f(x)}{h} = \lim_{h\to 0} \frac{ (x+hy)\cdot T(x+hy) - x\cdot T(x)}{h} = \lim_{h\to 0} \frac{ (x+hy) \cdot (T(x) + hT(y) ) - x\cdot T(x) }{h} = \\
& = \lim_{h\to 0} \frac{ hy\cdot T(x) + hx\cdot T(y) + h^2 y T(y) }{h} = \boxed{ y\cdot T(x) + x\cdot T(y) }
\end{aligned}
\]

\exercisehead{4} $f(x,y) = x^2 + y^2 \sin{(xy)}$
\[
\begin{aligned}
  & \partial_x f = 2x + y^3 \cos{(xy)} \\
  & \partial_y f = 2y \sin{(xy)} + xy^2 \cos{(xy)}
\end{aligned}
\]

\exercisehead{5} $f(x,y) = \sqrt{ x^2 + y^2 }$ 
\[
  \partial_x f = \frac{x}{f}; \quad \partial_y f = \frac{y}{f}
\]

\exercisehead{6} $f(x,y) = \frac{x}{\sqrt{ x^2+ y^2 }}$ 
\[
\begin{aligned}
  & \partial_x f = \frac{1}{f} + \frac{-x^2}{(x^2 + y^2)^{3/2} } \\
  & \partial_y f = \frac{-xy}{ (x^2 +y^2)^{3/2} }
\end{aligned}
\]

\exercisehead{7} $f(x,y) = \frac{x+y}{x-y}$, \quad $x \neq y$
\[
\begin{aligned}
  & \partial_x f = \frac{1}{x-y} + \frac{-(x+y)}{(x-y)^2} = \frac{-2y}{(x-y)^2} \\
  & \partial_y f = \frac{1}{x-y} + \frac{-(x+y)}{(x-y)^2}(-1) = \boxed{ \frac{2x}{(x-y)^2} }
\end{aligned}
\]

\exercisehead{8} $f(x) = a\cdot x$; $a$ fixed.  
\[
\boxed{ \partial_{x_j} f = a_j }
\]

\exercisehead{9} $f(x) = \sum_{i=1}^n \sum_{j=1}^n a_{ij} x_i x_j$, $a_{ij} = a_{ji}$
\[
\partial_{x_k} f(x) = \sum_{i=1}^n \sum_{j=1}^n a_{ij} \delta_{ik} x_j + \sum_{i=1}^n \sum_{j=1}^n a_{ij} x_i \delta_{jk} = \sum_{j=1}^n a_{kj} x_j + \sum_{i=1}^n a_{ik}x_i = \boxed{ 2 \sum_{j=1}^n a_{kj} x_j }
\]

\exercisehead{10} $f(x,y) = x^4+y^4 - 4x^2 y^2$
\[
\begin{aligned}
  & \partial_x f = 4x^3 - 8xy^2 \\
   & \partial_y f = 4 y^3 - 8x^2 y
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \partial_{yx}^2 f = -16 xy \\
  & \partial_{xy}^2 f = -16 xy 
\end{aligned}
\]

\exercisehead{11} $f(x,y) = \log{(x^2 + y^2)}$ 
\[
\begin{aligned}
  & \partial_x f = \frac{2x}{x^2 +y^2} \\
  & \partial_y f = \frac{2y}{x^2 + y^2}
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \partial_{yx} f = \frac{-4xy}{ (x^2 +y^2)^2 } \\
  & \partial_{xy} f = \frac{-4xy}{ (x^2 +y^2)^2 }
\end{aligned}
\]

\exercisehead{12} $f(x,y) = \frac{1}{y} \cos{x^2}$ ; \, $y\neq 0$ 
\[
\begin{aligned}
  & \partial_x f = \frac{-2x \sin{x^2}}{y } \\
  & \partial_y f = \frac{-1}{y^2} \cos{x^2} 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \partial_{yx} f = \frac{2x \sin{x^2}}{y^2} \\
  & \partial_{xy} f = \frac{2x \sin{x^2}}{y^2 }
\end{aligned}
\]

\exercisehead{13} $f(x,y) = \tan{(x^2/y)}$; \, $y\neq 0$ 
\[
\begin{aligned}
  & \partial_x f = \frac{2x}{y} \sec{ (x^2/y)} \\
  & \partial_y f = \frac{-x^2}{y^2} \sec{ (x^2/y)}
\end{aligned}
\]

\exercisehead{14} $f(x,y) = \arctan{ (y/x)}$ 
\[
\begin{aligned}
  & \partial_x f = \frac{1}{1 + (y/x)^2} \left( \frac{-y}{x^2} \right) \\
  & \partial_y f = \frac{1}{ 1 + (y/x)^2 } \left( \frac{1}{x} \right)
\end{aligned}
\]

\exercisehead{15} $f(x,y) = \arctan{ \left( \frac{x+y}{ 1-xy } \right) }$
\[
\begin{gathered}
  \partial_x f = \frac{1}{ 1 + \left( \frac{ x+y}{ 1-xy} \right)^2 } = \left( \frac{1}{1-xy} + \frac{ -(x+y)}{(1-xy)^2} ((-y) \right) = \frac{ 1 - xy + xy + y^2 }{ 1 + x^2 y^2 + x^2 + y^2 } = \frac{ 1  +y^2}{ 1 + x^2 y^2 + x^2 + y^2 } \\
  \partial_y f = \frac{ 1 + x^2 }{ 1 + x^2 y^2 + x^2 + y^2 } \quad \text{ (by label symmetry!) }
\end{gathered}
\]

\exercisehead{16} $f(x,y) = e^{y^2} \ln{x}$ \, $x>0$
\[
\begin{aligned}
  \partial_x f = y^2 x^{y^2 - 1} \\
  \partial_y f = x^{y^2} 2y \ln{x}
\end{aligned}
\]

\exercisehead{17} $f(x,y) = \arccos{ \sqrt{x/y}}$; \, $y\neq 0$ 
\[
\begin{aligned}
  & \partial_x f = \frac{-1}{ \sqrt{ 1 - x/y} } \frac{ 1/2}{ \sqrt{ xy}} = \frac{-1/2}{ \sqrt{ xy - x^2 }} \\
  & \partial_y f = \frac{ -1}{ \sqrt{ 1 - x/y} } \frac{ \sqrt{x} (-1/2)}{ y^{3/2}} = \frac{ (1/2) \sqrt{x}/y}{ \sqrt{ y- x} }
\end{aligned}
\]

\exercisehead{18} $v(r,t) = t^n e^{-r^2/4t}$ 
\[
\begin{gathered}
  \partial_r v = \frac{-1r}{2t} t^n e^{-r^2/4t} = \frac{-r}{2t} t^n e^{-r^2/4t} \\
  r^2 \partial_r v = \frac{-r^3}{2t} t^n e^{-r^2/4t} \\
  \partial_r (r^2 \partial_r v ) = \frac{-3r^2}{2t} t^n e^{-r^2/4t} + \frac{-r^3}{2t} t^n \left( \frac{-r}{2t} \right) e^{-r^2/4t} \\
  \frac{1}{r^2} \partial_r (r^2 \partial_r v) = \frac{-3}{2t} t^n e^{-r^2/4t} + \frac{r^2 t^n }{4t^2} e^{-r^2/4t} 
\end{gathered} \quad \quad \quad 
\begin{gathered}
  \partial_t v = nt^{n-1} e^{-r^2/4t} + t^n \left( \frac{r^2}{4t^2} \right) e^{-r^2/4t} \\
  \boxed{ n = -3/2 }
\end{gathered}
\]

\exercisehead{19} $z = u(x,y) e^{ax+by}$; \, $\frac{\partial^2 u}{ \partial x \partial y} = 0$ 
\[
\begin{aligned}
  & \partial_x z = \partial_x u e^{ax + by} + az \\
  & \partial_y z = (\partial_y u)e^{ax + by} + bz \\
  & \partial_{xy}^2 z = a(\partial_y u) e^{ax+by} + b(\partial_x u) e^{ax+ by} + bau e^{ax+by} \\
  & \partial_{xy}^2 z - \partial_x z - \partial_y z + z = a (\partial_y u )e^{ax + by} + b(\partial_x u )+abz - (\partial_x u)e^{ax+ by} - az - (\partial_y u) e^{ax+by} - bz + z = 0  \\
  & \boxed{ a = 1; \, b=1 }
\end{aligned}
\]

\exercisehead{20} 
\begin{enumerate}
\item $f'(x,y) = 0$ \, $\forall \, x \in B(a)$ \, $\forall \, y$ \\
Recall Thm. 8.4, Mean-value Thm. for derivatives of scalar fields.  Assume $\exists \, f'(a+ty;y)$ \, $\forall \, t \in [0,1]$.  Then $\exists \, $ some $\theta \in (0,1)$ s.t. 
\[
f(a+y) - f(a) = f'(z;y), \text{ where } z = a+\theta y
\]
\begin{proof}
  Let $g(t) = f(a+ty)$ \\
  \phantom{ Let } Use one-dim. mean-value thm. to $g$ on $[0,1]$. 
\[
g(1) - g(0) = g'(\theta), \, \theta \in (0,1)
\]
\end{proof}
\[
\begin{gathered}
  x = a +y \\
  y = x'; \quad 0 \leq |x'| < r \\
  \exists \, f'(x,y) = f'(a+ty;y) \, \forall \, t \in [0,1] \\
  (\text{ since } |ty| = t|y| < tr < r ) \\
  \Longrightarrow f'(a+ty; y) = 0 = f(a+y) - f(a) \\
  f(a) = f(x), \forall \, x \in B(a)
\end{gathered}
\]
\item Suppose we consider $x = a+ x'$ where $|x'| < r$ and $x' \parallel y$.  
\[
\begin{aligned}
  f'(x,y) & = f'(a+x',y) = f'(a+|x'|\frac{y}{|y|},y ) = \\
  & = \lim_{h \to 0} \frac{ f(a+ |x'|e_y, +h|y|e_y ) - f(a + |x'|e_y ) }{ h }  = \lim_{ |y|h \to 0} \frac{ f(a+ |x'|e_y + (h|y| )e_y ) - f(a + |x'|e_y) }{ h|y|/|y| } = \\
  & = |y| f'(a+ |x'|e_y, e_y)
\end{aligned}
\]
\[
\begin{gathered}
  \exists \, |y| f'(a + t|x'| e_y, e_y) \, \forall \, t \in [0,1], \text{ since } f'(x,y) = 0 \quad \forall \, x \in B(a) \\
  0 = |y| f'(a+ t |x'|e_y,e_y) = f(a+ |x'|e_y) - f(a) \Longrightarrow f(a+|x'|e_y) = f(a)
\end{gathered}
\]
$f = f(a) = $ constant $\forall \, x \in B(a)$ s.t. $x= a+ke_y$ \quad $0 \leq |k| < r$
\end{enumerate}

\exercisehead{21}
\begin{enumerate}
\item A set $S$ in $\mathbb{R}^n$ is convex if $\forall \, a,b \in S$, 
\[
ta + (1-t) b \in S \quad \forall \, t \in [0,1]
\]

Consider $x_1,x_2 \in b(a)$; \quad $\begin{aligned}
  & x_1 = a+x_1' \\
  & x_2 = a+x_2'
\end{aligned}$ \quad and \quad $\begin{aligned}
  & \| x_1 - a \| < r \\
  & \| x_2 - a \| < r
\end{aligned}$
\[
\begin{gathered}
  \begin{aligned}
    tx_2 + (1-t)x_1 - a & = t(a+x_2') + (1-t)(a+x_1') - a = at + x_2' t + a - at + x_1' - tx_1' - a = \\
    & = x_1'(1-t) + x_2' t 
  \end{aligned} \\
  \| tx_2 + (1-t)x_1 -a \| = \| x_1' (1-t) + x_2' t \| \leq  (1-t) \| x_1' \| + t \| x_2' \| < (1-t) r + tr = r  
\end{gathered}
\]
So $tx_2 + (1-t)x_1 \in S$ \quad $\forall \, t \in [0,1]$.  So an $n$-ball is a convex set.  
\item Consider $x\in S$.  Then for some $a,b \in S$, $k\in [0,1]$, $x = a + k(b-a)$.  
\[
\begin{gathered}
  f'(x;y) = f'(a+k(b-a),y) \xrightarrow{ \text{ choose } y = b-a } f'(a+ k (b-a), b-a) \text{ exists } \\
  \Longrightarrow f'(a + \theta(b-a),b-a) = 0 = f(b) -f(a) \Longrightarrow f(b) = f(a)
\end{gathered}
\]
This must be true for all pairs of $a,b \in S$ since $x$ was arbitrarily chosen from $S$.  $f$ is constant on $S$.  
\end{enumerate}

\exercisehead{22}
\begin{enumerate}
\item 
\[
\begin{gathered}
  f'(a;y) = \lim_{ h \to 0 } \frac{ f(a+hy) - f(a) }{h } \\
  f'(a,-y) = \lim_{h\to 0} \frac{ f(a-hy) - f(a) }{h} = - \lim_{-h \to 0} \frac{ f(a+(-h)y ) - f(a) }{-h} = -f'(a,y) \\
  \text{ so if } f'(a,y) > 0, \quad f'(a,-y) < 0 
\end{gathered}
\]
\item $f(x) = x\cdot y$ because 
\[
f'(x;y) = \lim_{h\to 0 } \frac{ f(x+hy) - f(x) }{h} = \lim_{h\to 0} \frac{ x\cdot y + hy^2 - x\cdot y}{h} = y^2 > 0
\]
\end{enumerate}

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 8.14 Exercises - Directional derivatives and continuity, The total derivative, The gradient of a scalar field, A sufficient condition for differentiability } 
%-----------------------------------%-----------------------------------%-----------------------------------

Let's review a number of important concepts with $R^n$ fields.  Differentiability must be redefined through a $n-dim$ Taylor expansion.    

\begin{definition}[Definition of a Differentiable Scalar Field] \quad \\
Let $f:S \to \mathbb{R}$ \\
Let $a$ be an int. pt. of $S$.  \\
Let $B(a;r)$ s.t. $B(a;r) \subseteq S$ \\
Let $v$ s.t. $\| v \| < r$, so $a+v \in B(a;r)$  Then \medskip \\
$f$ diff. at $a$ \\
\phantom{ f diff} if $\exists \, T_a, \, E$ s.t. \\
\phantom{ f diff if } linear $T_a:\mathbb{R}^n \to \mathbb{R}$ \\
\phantom{ f diff if } scalar $E(a,v), \, E(a,v) \to 0$ as $\| v \| \to 0$  and 
\begin{equation}
  f(a+v) = f(a) + T_a(v) + \| v\| E(a,v)
\end{equation}
\end{definition}

The next theorem shows that if the total derivative exists, it is unique.  It also tells us how to compute $T_a(y), \, \forall \, y \in \mathbb{R}^n$.  

\begin{theorem}[Uniqueness of total derivative]
Assume $f$ diff. at $a$ with total derivative $T_a$ \\
\phantom{Assu} Then $\exists \, f'(a;y) \, \forall y \in \mathbb{R}^n$ and 
\[
T_a(y) = f'(a;y)
\]
Also, 
\[
\begin{gathered}
  f'(a;y) = \sum_{j=1}^{n} D_j f(a) y_j \text{ for } \\
  y = (y_1 , \dots , y_j , \dots , y_n) 
\end{gathered}
\]
\end{theorem}

\begin{proof} \quad \\
  If $y=0$, \quad \, $T_a(0) = 0$ and $f'(a;0)=0$.  Done.  \bigskip \\
  Suppose $y\neq 0$ \\
  \[
\begin{gathered}
  f(a+v) = f(a) +T_a(v) + \| v \| E(a,v) \quad \quad \, \text{ (since we assume $f$ diff. ) } \medskip \\
  v = hy \\
\Longrightarrow \frac{ f(a+hy) - f(a) }{ h } = \frac{1}{h} T_a(hy) + \frac{ \| hy \| }{ h } E(a,hy) \xrightarrow{ h\to 0 } f'(a,y)  = T_a(y)  + 0 \\
\end{gathered}
\]
Now use linearity of $T_a$: \[ T_a(y) = \sum T_a (y_j e_j) = \sum y_j T_a(e_j) = \sum y_j f'(a;e_j) = \sum y_j D_j f(a) \]
\end{proof}

Then the gradient was introduced, $\nabla f(a) = (\partial_1 f(a), \dots, \partial_n f(a) )$ so that \\
$f'(a;y) = \sum_{j=1}^n \partial_j f(a) y_j =\nabla f(a) \cdot y $  so then also
\[
\Longrightarrow f(a+v) = f(a) + \nabla f(a) \cdot v + \| v \| E(a;v)
\]

\begin{theorem}[Differentiability implies Continuity] \quad \\
If a scalar field $f$ is differentiable at $a$, then $f$ is cont. at $a$
\end{theorem}

\begin{proof}
  Since $f$ is diff. \\
$|f(a+v) -f(a)| = |\nabla f(a) \cdot v + \| v \| E(a,v) | $\\
By Cauchy-Schwarz inequality, \medskip \\
$0\leq | f(a+v) -f(a) | \leq \| \nabla f(a) \| \| v \| + \| v \| |E(a;v) |$ \medskip \\
As $v\to 0$, $|f(a+v) - f(a)| \to 0$ so $f$ cont. at $a$.  
\end{proof}

\quad \bigskip \\
If $f$ is diff. at $a$, then all its partials exist (but the converse isn't true).  \\
\phantom{If} existence of partials doesn't necessarily imply $f$ is diff. \\
e.g. $f(x,y) = \frac{ xy^2}{ x^2 + y^4}$ \quad \bigskip \\

\begin{theorem}[Sufficient Condition for Differentiability] \quad \\
Assume $\exists \, \partial_1 f , \dots , \partial_n f$ in some $n$-ball $B(a)$ and are cont. at $a$.  Then $f$ diff. at $a$.  
\end{theorem}

\begin{proof} \quad \\
Let $\lambda = \| v \|$; then $v = \lambda u$, \quad $\| u \| = 1$ \\
Express $f(a+v) -f(a)$ as a telescoping sum.  
\[
f(a+v)-f(a) = f(a + \lambda u ) -f(a) = \sum_{k=1}^n \left( f(a+\lambda v_k) - f(a+\lambda v_{k-1}) \right) 
\]\quad \\
where $\{ v_k \}$ s.t. $\begin{aligned}
    v_0 & = 0 \\
    v_n & = u 
  \end{aligned}$.  Then choose the $v_k$'s s.t. 
\[
\begin{gathered}
  v_k = v_{k-1} + u_k e_k \\
 \quad \quad \quad \, v_1 = u_1 e_1; \quad v_2 = u_1 e_1 + u_2 e_2 , \dots , \, v_n = u_1 e_1 + \dots + u_n e_n  \\
  \begin{aligned}
f(a+\lambda v_k) - f(a+\lambda v_{k-1} )  & = f(a+ \lambda v_{k-1} + \lambda u_k e_k) - f(a+\lambda v_{k-1} ) = \\
& = f(b_k + \lambda u_k e_k) - f(b_k)
\end{aligned} 
\end{gathered}
\]
$b_k, \, b_k + \lambda u_k e_k$ differ only by their $k$th component so apply the mean value theorem 
\[
\begin{gathered}
  \Longrightarrow f(b_k + \lambda u_k e_k) - f(b_k) = (\lambda u_k) \partial_k f(c_k) \\
\quad \\
\text{ as $b_k \to a$, as $\lambda \to 0$, so $c_k \to a$ } \\
\Longrightarrow f(a+v) -f(a) = \lambda \sum_{k=1}^n u_k \partial_k f(c_k) 
\end{gathered}
\]
\quad \\
Now $\nabla f(a) \cdot v = \lambda \sum u_k \partial_k f(a) $.  \\
$\Longrightarrow f(a+v) -f(a) - \nabla f(a) \cdot v = \lambda \sum u_k (\partial_k f(c_k) - \partial_k f(a) ) = E(a,v)$ \medskip \\
$c_k \to a$ as $\| v \| \to 0$, and given $\partial_k f$ are cont., $E(a,v) \to 0$ as $\| v \| \to 0$.  \\
By def. of diff., $f$ is diff.  
\end{proof}

\exercisehead{1} 
\begin{enumerate}
  \item $f(x,y) = x^2 +y^2 \sin{(xy)}$ 
\[
\nabla f = (2x+y^2 \cos{(xy)}, 2y \sin{(xy)} + y^2 x \cos{(xy)} )
\]
  \item $f(x,y) = e^x \cos{y}$ 
\[
\nabla f = (e^x \cos{y}, -e^x \sin{y} )
\]
  \item $f(x,y,z) = x^2 y^3 z^4 $
\[
\nabla f = (2xy^3 z^4, 3x^2 y^2 z^4, 4x^2 y^3 z^3 )
\]
  \item $f(x,y,z) = x^2 - y^2 + 2z^2$ 
\[
\nabla f = (2x,-2y,4z)
\]
  \item $f(x,y,z) = \log{(x^2 + 2y^2 - 3z^2)}$
\[
\nabla f  = \frac{1}{f} (2x,4y, -6z)
\]
  \item $f(x,y,z) = e^{(ln{x}) e^{z \ln{y}} }$
\[
\nabla f = f \left( \frac{e^z \ln{y}}{x} , (\ln{x}) e^{z\ln{y}} \left( \frac{z}{y} \right), (\ln{x})(\ln{y}) e^{z\ln{y}} \right)
\]
\end{enumerate}

\exercisehead{2} 
\begin{enumerate}
\item $f(x,y,z) = x^2 + 2y^2 + 3z^2$ at $(1,1,0)$ in the direction of $i-j+2k$.  
\[
f'(a,y) = \nabla f(a) \cdot y 
\]
\item $\nabla f = (2x,4y,6z)$  $\nabla f(1,1,0) = (2,4,0)$.  $\nabla f(a) \cdot y = \boxed{ -2} $
\end{enumerate}

\exercisehead{3} $f(x,y) = 3x^2 +y^2$; $x^2 + y^2 = 1$ 
\[
\begin{gathered}
  (\nabla f)\cdot y = |\nabla f||y| \cos{\theta} \\
  |\nabla f| = \sqrt{ 36x^2 + 4(1-x^2)} = \sqrt{ 32 x^2 +4 } = 2 \sqrt{ 8x^2 + 1}; \quad |\nabla f| \text{ maximized when $x = \pm 1 $ } \\
  (\pm 1,0), \quad y \parallel (\pm 1,0)
\end{gathered}
\]

\exercisehead{4} $(1,2)$, $+2$ towards $(2,2)$; $-2$ towards $(1,1)$.  
\[
\begin{gathered}
  \nabla f(a) \cdot y = \nabla f(a) \cdot (1,0) = 2; \quad \nabla f(a) \cdot (0,-1) = -2 \Longrightarrow \nabla f(a) = 2(1,1) \\
  \nabla f(a) \cdot \frac{ (4,6) - (1,2) }{5} = \nabla f (a) \cdot (3,4)/5 = \boxed{ \frac{14}{5} }
\end{gathered}
\]

\exercisehead{5} $a,b,c$ s.t. $f(x,y,z) = axy^2 + byz + cz^2 x^3 $, \quad $(1,2,-1)$
\[
\begin{gathered}
  \nabla f = (ay^2 + 3cz^2 x^2 , 2axy + bz, by + 2czx^3) \\
  \nabla f(1,2,-1) = (4a + 3c, 4a +-b, 2b - 2c ) \\
  \nabla f(1,2-1) \cdot e_z = 2b - 2c = 64 \Longrightarrow b-c = 32 
\end{gathered}
\]
\textbf{ Maximum value means $\nabla f$ only has components in the $z$-direction}.
\[
\begin{aligned}
  & \partial_x f = 4a + 3c = 0  \\
  & \partial_y f = 4a - b = 0 
\end{aligned} \quad \quad \quad 
\boxed{ c=-8; \quad b = 24; \quad a =6 }
\]

\exercisehead{6} $f'(a,y) = 1$; $f'(a,z)=2$ where $y = 2i + 3j$, $z = i + j$
\[
\begin{aligned}
  & (\partial_x f)(2) + (\partial_y f)(3) = 1 \\
  & (\partial_x f)(1) + (\partial_y f)(1) = 2 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \partial_y f = -3 \\
  & \partial_x f = 5
\end{aligned}
\]

\exercisehead{7} Let $f$ and $g$ denote scalar fields that are differentiable on an open set $S$.  
\begin{enumerate}
  \item 
\[
\begin{gathered}
  \nabla f(a) = \sum (\partial_j f)(a) e_j \\
  (\partial_j f)(a) = f'(a_j e_j) \\
  \text{ if $f$ const., $f'(a;e_j) = 0$ } \\
  \Longrightarrow \nabla f(a) = 0 
\end{gathered}
\]
We can also do the following: if $\nabla f = 0$, $f'(a;y) = \nabla f(a) \cdot y = 0$, \, $\forall \, y$.  Then, from Exercise 20 of Sec. 8.9, $f$ is constant on this open set $S$. 

If $f$ is constant on $S$, $f(a+v) = f(a)$ for $f(a+v) = f(a) + T_a(v) + \| v \| E(a,v)$
\[
\begin{gathered}
  T_a(y) = - \| y \| E(a,y) \\
  E(a,y) \to 0 \text{ as } y\to 0 
\end{gathered}
\]
By uniqueness of the total derivative, $\nabla f(a) = 0$, \, $\forall \, a \in S$.  
  \item $\nabla$ is a linear transformation.  $\Longrightarrow \nabla (f+g) = \nabla f + \nabla g$ 
  \item $\nabla$ is a linear transformation.  $\Longrightarrow \nabla (cf) = c \nabla f $
  \item 
\[
\begin{gathered}
  (fg)(a+v) -(fg)(a) = \nabla (fg)(a) \cdot v + E_{fg}(a;v) = f(a+v)g(a+v) - f(a)g(a) = \\
  \begin{aligned}
    & = f(a+v)g(a+v) - f(a)g(a+v) + f(a) g(a+v) - f(a)g(a) = \\ 
    & = g(a+v)(f(a+v) - f(a)) + f(a)(g(a+v) - g(a)) = \\
    & = g(a+v) ( (\nabla f)(a) + E_f(a;v) ) + f(a) ((\nabla g) (a) + E_g(a;v) ) 
  \end{aligned} \\
\text{ Let $\| v \| \to 0$, so that $(\nabla(fg))(a) = g(a) (\nabla f)(a) + f(a) (\nabla g)(a) $ }
\end{gathered}
\]
  \item 
\[
\begin{gathered}
\begin{aligned}  
  \left( \frac{f}{g} \right)(a+v) - \left(\frac{f}{g} \right)(a) & = \frac{ f(a+v)}{ g(a+v)} - \frac{ f(a) }{ g(a) } = \frac{ g(a) f(a+v) - g(a+v)f(a) }{ g(a)g(a+v) } = \\
  &  = \frac{ g(a) f(a+v) - g(a) f(a) + g(a) f(a) - g(a+v)f(a) }{ g(a)g(a+v) } = \\
  & = \frac{ g(a) ( (\nabla f)(a) \cdot v + E_f(a;v) ) - f(a)( (\nabla g)(a) \cdot v + E_g (a;v) ) }{ g(a) g(a+v) } = \\
  & = \nabla \left( \frac{f}{g} \right) \cdot v + E_{f/g}(a;v) 
\end{aligned} \\
\text{ Let $\| v \| \to 0$  } \Longrightarrow \frac{ g(a) \nabla f(a) - f(a) \nabla g(a) }{ g^2(a) } = \nabla \left( \frac{f}{g} \right)(a) 
\end{gathered}
\]
\end{enumerate}

\exercisehead{8} In $\mathbb{R}^3$, let $r(x,y,z) = xi + yj + zk$, and let $r(x,y,z) = \| r(x,y,z) \|$
\begin{enumerate}
\item $\nabla r = \nabla \sqrt{ x^2 + y^2 + z^2} = \frac{1}{ \sqrt{ x^2 + y^2 + z^2 }} (x,y,z) = \frac{ \vec{r}}{r}$
\item Use induction. \[
\begin{aligned}
  & \nabla (r^2) = r \frac{\vec{r}}{r} + r \frac{\vec{r}}{r} = 2 \vec{r} \\
  & \nabla (r^3) = 2\vec{r} r + r^2 \frac{ \vec{r}}{r} = 3r \vec{r} \\
  &  \nabla (r^{n+1}) = nr^{n-2} \vec{r} r + r^{n-1} \frac{\vec{r}}{r} = (n+1) r^{n-1} \vec{r}
\end{aligned}
\]
\item $n=0$.  $\nabla (1) =0$
\[
\begin{aligned}
  & \nabla (r^{-1}) = \nabla \frac{1}{ \sqrt{ x^2 + y^2 + z^2 } } = \frac{-\vec{r}}{r^2} \\
  & \nabla (r^{-2}) = \nabla \frac{1}{ x^2 + y^2 + z^2 } = (-2) \vec{r} r^{-4} 
\end{aligned}
\]
Then $\nabla (r^{n+1})  = (n+1) r^{n-1} \vec{r}$, where we reuse the induction step above, because no reference was made to whether $n$ was positive or negative.  \\
\phantom{Then} So the formula is still valid when $n$ is a negative integer (by induction).  
\item $\nabla f = \vec{r}$
\[
\begin{gathered}
  \partial_x f = x \quad \, \partial_y f = y \quad \, \partial_z f = z \\
  \boxed{ \frac{1}{2} x^2 + \frac{1}{2} y^2 + \frac{1}{2} z^2 =  f }
\end{gathered}
\]
\end{enumerate}

\exercisehead{9} Given $n$ independent vectors, $y_1, \dots, y_n$, then by Thm., $y_1, \dots, y_n$ for a basis for $\mathbb{R}^n$.  \medskip \\
$f'(x,y) = \nabla f(x) \cdot y$, so $f'(x,y)$ is linear.  Then $\forall \, y \in \mathbb{R}^n$, $y=\sum a_j y_j$ and 
\[
f'(x,y) = \nabla f(x) \cdot \sum a_j y_j = \sum a_j \nabla f(x) \cdot y_j = 0
\]
Then from Exercise 20 of Sec. 8.9, $f$ is constant on $B(a)$.  

\exercisehead{10}
\begin{enumerate}
\item Consider $x \in B(a)$, \, $x = a + x'$.  
\[
\begin{gathered}
  f'(x;y) = f'(a+x',y) = \nabla f(x) \cdot y \\
  \text{ Let } y = x' \Longrightarrow f'(a+x';x') \\
  \text{ By mean value thm.}, f'(a+ \theta x'; x') = f(a+x') - f(a) \\
  f'(a+x';x') = \nabla f(x) \cdot x' = 0 \Longrightarrow f(a+x') = f(a) 
\end{gathered}
\]
This must be true $\forall \, x'$ s.t. $|x'| < r$ for $B(a;r)$.  Then $f$ is constant on $B(a)$.
\item \[
\begin{gathered}
  \lim_{h\to 0} \frac{ f(a+hy) - f(a)}{h} = f'(a;y) \leq 0 \\
  f'(a;y) = \nabla f(a) \cdot y = |\nabla f(a)| |y| \cos{\theta} \leq 0 
\end{gathered}
\]
Consider when $\frac{-\pi/2} < \theta < \pi/2$, $|y| \neq 0$.  Then $|\nabla f(a)| = 0$.  
\end{enumerate}

\exercisehead{11} Consider the following six statements about a scalar field $f:S \to \mathbb{R}$, where $S \subseteq \mathbb{R}^n$ and $a \in int{S}$.  
\begin{enumerate}
  \item \begin{enumerate}
\item $f$ continuous at $a$ 
\item $f$ is differentiable at $a$
\item $\exists \, f'(a,y)$ \, $\forall \, y \in \mathbb{R}^n$.  
\item All the first-order partial derivatives of $f$ exist in a neighborhood of $a$ and are continuous at $a$.  
\item $\nabla f(a) =0 $
\item $f(x) = \| x - a\|$ for all $x$ in $\mathbb{R}^n$.  
\end{enumerate}
\end{enumerate}

(b) imples (a),(c), because differentiability implies continuity and differentiability through the total derivative gave what the directional derivative would be $\forall \, y \in \mathbb{R}^n$.  (d) imples (a),(b),(c) because (d), by theorem, is a sufficient condition for differentiability, and thus differentiability implies (a),(c).  (e) doesn't tell us anything because we need a scalar function $E(a;v)$ as well for differentiability.  (f) is a continuous function, so (f) imples (a).  

%-----------------------------------%-----------------------------------%-----------------------------------
\section*{ 8.17 Exercises - A chain rule for derivatives of scalar fields, Applications to geometry.  Level sets.  Tangent planes. }
%-----------------------------------%-----------------------------------%-----------------------------------

\exercisehead{1} 
\begin{enumerate}
\item \[ \begin{aligned}
  & u = f(x,y) \\
  & u = F(t)
\end{aligned} \quad \quad \quad \begin{aligned} 
  x & = X(t) \\
  y & = Y(t) 
\end{aligned} \] \\
  \[
\nabla f(r) \cdot r'(t) = (\partial_x f) x' + (\partial_y f)y' = F'(t) = u'
\]
\item 
\[
\begin{aligned}
  & F(t) = u = f(x,y) = f(r(t)) \\
  & F'(t) = \nabla f(r) \cdot r'(t) = (\partial_x f) x' + (\partial_y f) y' 
\end{aligned}
\]
\[
\begin{gathered}
  \nabla f(r) = \nabla f(r(t)) \\
  \frac{d}{dt} \nabla f(r(t)) = \frac{d}{dt} (\partial_x f, \partial_y f) = ((\partial_{xx}^2 f) x' + (\partial_{yx}^2 f) y', (\partial_{xy}^2 f) x' + (\partial_{yy}^2 f) y' ) \\
  \begin{aligned}
    F''(t) & = \left( \frac{d}{dt} \nabla f(r(t)) \right) \cdot r'(t) + \nabla f(r) \cdot r''(t) = \\
    & = (\partial_{xx}^2 f) x'^2 + \left( (\partial^2_{yx} f) + \partial^2_{xy} f \right) x'y' + (\partial_{yy}^2 f) y'^2 + (\partial_x f) x'' + \partial_y f y''
  \end{aligned}
\end{gathered}
\]
\end{enumerate}

\exercisehead{2}
\begin{enumerate}
\item $f(x,y) = x^2 +y^2$, \quad $X(t) = t, Y(t) = t^2$ 
\[
\begin{aligned}
  \partial_x f & = 2x \\
  \partial_y f & = 2y 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  X' & = 1 \\
  Y' & = 2t 
\end{aligned}
\]
\[
\begin{aligned}
  & F'(t) = 2x (1) + 2y 2t = 2t + 4 t^3 \\
  & F''(t) = 2 + 12 t^2 
\end{aligned}
\]
\item $f(x,y) = e^{xy} \cos{(xy^2)}$; $X(t) = \cos{t}$, $Y(t) = \sin{t}$
\[
\begin{aligned}
  & \partial_x f = y f + -e^{xy} \sin{(xy^2)} y^2 \\
  & \partial_y f = xf + -e^{xy} \sin{(xy^2)} 2yx
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & X' = -s = -y \\
  & Y' = c= x 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  X'' & = -c = -x \\
  Y'' &= -s = - y
\end{aligned}
\]
\[
F'(t) = -y^2 f + e^{xy} \sin{(xy^2)}y^3 + x^2 f + -e^{xy} \sin{(xy^2)} 2yx^2 
\]
\emph{ This is the answer I got}.  Note that I tried it 2 ways: using the formula $(\partial_{xx}^2 f) x'^2 + (\partial_{yx}^2 f + \partial_{xy}^2 f )x'y' + (\partial^2_{yy} f) y'^2 + (\partial_x f) x'' + (\partial_y f) y''$, and second, taking our answer $F'(t) = G(t)$ and then applying $\partial g_x x' + \partial g_y y'$ on it (which seemed clever).    
\[
\begin{gathered}
  \begin{aligned}
    \partial_x g & = 4xf + (2x^2 - 1)( yf - y^2 e^{xy} \sin{(xy^2)} ) + (3y^3 - 2y )y e^{xy} \sin{(xy^2) } + (3y^3 - 2y)e^{xy} \cos{(xy^2)} y^2 = \\
    & = 4xf + 2x^2 y f - yf - 2x^2 y^2 e^{xy} \sin{(xy^2)} + y^2 e^{xy} \sin{(xy^2)} + 3y^4 e^{xy} \sin{(xy^2)} -2y^4 e^{xy} \sin{(xy^2)} + 3y^5 f - 2y^3 f \\
    & = f(4x  + 2x^2 y - y +3y^5 - 2y^3) + e^{xy} \sin{(xy^2)} ( -2x^2 y^2 + y^2 + y^4) 
  \end{aligned} \\
\begin{aligned}
  \partial_y g & = (2x^2 - 1)( xf - 2yx e^{xy} \sin{ (xy^2)} ) + (9y^2 - 2) e^{xy} \sin{(xy^2) } + (3y^3 - 2y ) e^{xy} x \sin{(xy^2 )} + (3y^3 - 2y) e^{xy} \cos{(xy^2) } 2yx = \\
  &= (2x^3 - x + 6y^4 x - 4y^2 x ) f + e^{xy} \sin{(xy^2)} (-2yx (2x^2-  1) + 9y^2 - 2 + 3y^3 x - 2yx)
\end{aligned}
\end{gathered}
\]
\begin{multline*}
  \partial_x g x' + \partial_y g y'  = (-12 y^5 + 14 y^3 - 4y + 7x - 9x^3 ) e^{xy} \sin{(xy^2)} + f (9x^6 - 11 x^4 + 3x^2 - 4xy)
\end{multline*}
\item $f(x,y) = \log{ \left( \frac{(1+e^{x^2} ) }{ 1 + e^{y^2} } \right) } = \log{ (1 + e^{x^2 }) } - \log{ (1 + e^{y^2 } )}$ 
\[
\begin{aligned}
  X(t) & = e^t \\
  Y(t) & = e^{-t} 
\end{aligned} \quad \quad 
\begin{aligned}
  X' & = X \\
  Y' & = -Y 
\end{aligned} \quad \quad 
\begin{aligned}
  X'' & = X \\
  Y'' & = Y 
\end{aligned}
\]
\[
\begin{aligned}
  & \partial_x f = \frac{1}{ 1 + e^{x^2 } } ( 2xe^{x^2 } ) \\
  & \partial_y f = \frac{ - 2y e^{y^2 }}{ 1 + e^{y^2 } } 
\end{aligned} \quad \quad \quad 
F'(t) = \boxed{ \frac{ 2x^2 e^{x^2 }}{ 1 + e^{x^2 } } + \frac{ 2 y^2 e^{y^2 }}{ 1 + e^{y^2 } } }
\]
\[
\begin{aligned}
  & \partial_{xx} f = (2) \left( \frac{ (e^{x^2 } + 2x^2 e^{x^2 } )( 1 + e^{x^2 }) - (2x e^{x^2 }) ( xe^{x^2 }) }{ (1+ e^{x^2 })^2 } \right) = (2) \left( \frac{ e^{x^2 } + 2 x^2 e^{x^2 } + e^{2x^2 } }{ ( 1 + e^{x^2 })^2 } \right) \\
  & \partial_{yy} f = (-2) \left( \frac{ e^{y^2} + 2y^2 e^{y^2} + e^{2y^2 } }{ (1+e^{y^2})^2 } \right) \\
  & \partial_{xy} f = 0 
\end{aligned}
\]
\begin{multline*}
  (\partial_{xx}^2 f) x'^2 + ((\partial_{yx}^2 f + \partial_{xy}^2 f) x' y' + (\partial_{yy}^2 f ) y'^2 + (\partial x f) x'' + \partial y f y'' = \\
  = (2) \frac{ e^{x^2} + 2x^2 e^{x^2 } + e^{2x^2 } }{ (1+e^{x^2})^2 } (x^2 ) + (-2) \frac{ e^{y^2 } + 2y^2 e^{y^2 } + e^{2y^2 } }{ (1+e^{y^2} )^2 } y^2 + \frac{ 2x e^{x^2 }(1+e^{x^2 }) }{ (1+e^{x^2 })^2 } x + \frac{ -2y e^{y^2} ( 1 + e^{y^2 }) }{ ( 1 + e^{y^2 })^2 } y = \\
  = \boxed{ \frac{ 4x^2 e^{x^2 } ( 1 + x^2 + e^{x^2 } ) }{ (1+e^{x^2})^2 } + \frac{ -4 y^2 e^{y^2} ( 1 + y^2 + e^{y^2} ) }{ (1+e^{y^2})^2 }  }
\end{multline*}
\end{enumerate}

\exercisehead{3}
\begin{enumerate}
\item 
\[
\begin{gathered}
  \nabla f = (3,-5,2) \\
  N = (2x, 2y, 2z) = 2r \\
  \nabla f \cdot \frac{ (2,2,1) }{3 } = (3,-5,2) \cdot (2,2,1)/3 = \boxed{ -2/3} 
\end{gathered}
\]
It should be noted that the normal to a sphere is the position vector.  
\item \[
\begin{gathered}
  \nabla f = (2x,-2y,0) \\
  x^2 + y^2 + z^2 = 4 \text{ is a sphere } \\
  \nabla f \cdot \frac{ (x,y,z)}{r} = \frac{2x^2  -2y^2 }{r}
\end{gathered}
\]
\item $x^2 + y^2 = 25$ and $2x^2 + 2(z^2 - x^2) - z^2 = 25$
\[
\begin{gathered}
  \nabla f = (2x,2y,-2z) \\
  T = \frac{ (1, \frac{ \mp x }{ \sqrt{ 25 - x^2 } }, 0  ) }{ \sqrt{ 1 + \frac{ x^2 }{ 25 - x^2 } } } = \frac{ \left( 1 , \frac{ \mp x }{ \sqrt{ 25 - x^2 } }, 0 \right) }{ \sqrt{ 25 /(25-x^2 ) } } = \left( \frac{ \sqrt{ 25 - x^2 }}{5} , \frac{ \mp x }{ 5}, 0 \right) \\
  \Longrightarrow \nabla f \cdot T = \left( \frac{ 2x \sqrt{ 25 - x^2 }}{5} , \frac{ -2 \sqrt{ 25 -x^2 } x }{5 }, 0 \right) = \left( \frac{ 6 }{5} 4 , \frac{ -2 (4) 3 }{ 5 }, 0 \right) = \left( \frac{ 24}{5} + \frac{-24}{5} + 0 \right) =0 
\end{gathered}
\]
\end{enumerate}

\exercisehead{4} 
\begin{enumerate}
  \item Find a vector $V(x,y,z)$ normal to the surface
\[
z = \sqrt{ x^2 +y^2} + (x^2 + y^2)^{3/2}
\]
at a general point $(x,y,z)$ of the surface, $(x,y,z) \neq (0,0,0)$ \medskip \\
\[
\begin{gathered}
  0 = \sqrt{ x^2 + y^2 } + (x^2 + y^2)^{3/2} -z = f(r) \\
  \Longrightarrow \nabla f = \left( \frac{ x}{\sqrt{ x^2 +y^2 } } + 3x(x^2 + y^2)^{1/2}, \frac{y}{\sqrt{ x^2 + y^2 }} + 3y (x^2 + y^2)^{1/2}, -1 \right)
\end{gathered}
\]
\item \[
\begin{gathered}
  \nabla f \cdot e_z = |\nabla f| \cos{\theta_z} \Longrightarrow \cos{\theta_z} = \frac{-1}{ \sqrt{ \frac{ (x+3x^3 + 3xy^2 )^2 }{ x^2 + y^2} + \frac{ (y + 3yx^2 + 3y^3 )^2 }{ x^2 + y^2 } + 1 } } \\
  \cos{ \theta_z} = \frac{ -1 }{ \sqrt{ (1 + 3(x^2 + y^2))^2 + 1 } }
\end{gathered}
\]
\[
\begin{gathered}
\lim_{y \to 0} \cos{\theta_z} = \frac{-1}{ \sqrt{ ( 1 + 3 (x^2))^2 + 1 } } \xrightarrow{ x \to 0} = \frac{-1}{\sqrt{2}} \\
\lim_{x\to 0} \lim_{y\to 0} \cos{\theta_z} = \boxed{ \sqrt{-1}{\sqrt{2}} }
\end{gathered}
\]
$\cos{\theta_z}$ is differentiable at $(x,y) = (0,0)$ (we can observe that the partial derivatives exist and are continuous at $(0,0)$), so $\cos{\theta_z}$ is continuous at $(x,y) = (0,0)$.  
\end{enumerate}

\exercisehead{5} $
\begin{aligned}
  & e^u \cos{v} = x \\
  & e^u \sin{v} = y 
\end{aligned}  $ \quad \quad \, $\begin{aligned}
  & u = u(x,y) \\
  & v = v(x,y) 
\end{aligned}$ 
\[
\begin{aligned}
  x^2 + y^2 & = e^{2u} \\
  \ln{ (x^2 + y^2) } & = 2u 
\end{aligned}  \Longrightarrow \boxed{ \frac{1}{2} \ln{(x^2 + y^2)} = u } \quad \quad \quad \begin{aligned}
  \sin{v} & = \frac{ y}{\sqrt{ x^2 + y^2 } } \\
   \cos{v} & = \frac{x}{\ sqrt{ x^2 + y^2 } } 
\end{aligned} \Longrightarrow \tan{v} = \frac{y}{x} 
\]
\[
\begin{aligned}
  & \nabla U = \left( \frac{x}{ x^2 + y^2 } , \frac{y}{ x^2 + y^2 } \right) \\
  & \nabla V = \left( \frac{ -y/x^2 }{ 1 + (y/x)^2 }, \frac{1/x}{ 1 + (y/x)^2 } \right)
\end{aligned} \Longrightarrow \nabla U \cdot \nabla V = 0 
\]

\exercisehead{6} $f(x,y) = \sqrt{ |xy|}$ 
\begin{enumerate}
\item \[
\begin{aligned}
  & \text{ if } x \gtrless 0, \, y \gtrless 0, \quad & f=(xy)^{1/2} \quad & \partial_x f = \frac{1}{2} \sqrt{ \frac{y}{x}}  \quad \quad & \partial_y f = \frac{1}{2} \sqrt{ \frac{x}{y} } \\
  & \text{ if } x > 0, \, y < 0 , \quad & f= (x(-y))^{1/2} \quad & \partial_x f = \frac{1}{2} \left( \frac{|y|}{x} \right)^{1/2} \quad & \partial_y f = \frac{-1}{2} \left( \frac{x}{|y|} \right)^{1/2} \\
  & \text{ if } x <0, \, y > 0, \quad & f = (-xy)^{1/2} \quad & \partial_x f = \frac{-1}{2} \left( \frac{y}{|x|} \right)^{1/2} \quad & \partial_y f = \frac{1}{2} \left( \frac{|x|}{y} \right)^{1/2}
\end{aligned}
\]
\item Does the surface $z= f(x,y)$ have a tangent plane at the origin?
\[
\begin{gathered}
  z = f(x,y) \\
  g = f(x,y) -z \Longrightarrow \nabla g = (\partial_x f, \partial_y f,-1)
\end{gathered}
\]
For $x=y$,
\[
\nabla g(0,0,0) = \left( \frac{1}{2}, \frac{1}{2}, -1 \right)
\]
But when approaching from the $x$ or $y$ axis, $\nabla g = (0,0,-1)$.  A tangent plane cannot be defined at the origin.  
\end{enumerate}

\exercisehead{7} Given surface $z = xy$, $z = y_0 x,\, y = y_0$ and $z = x_0 y, \, x = x_0$ intersect at $(x_0,y_0, z_0)$ and lie on the surface.  We want to show that the tangent plane to this surface at $(x_0,y_0,z_0)$ contains these 2 lines.  

Note that the 2 lines could be reexpressed in vector form:
\[
\begin{gathered}
  x (1,0,y_0) + (0,y_0,0) \\
  y(0,1,x_0) + (x_0,0,0) 
\end{gathered}
\]
Rewrite the surface equation so to get the gradient
\[
\begin{gathered}
  0 = xy - z \\
  \nabla f = (y,x,-1) 
\end{gathered}
\]
\[
\begin{gathered}
\begin{aligned}
  & \nabla f(r_0) = (y_0,x_0,-1) \\
  & \nabla f(r_0) \cdot (x,y,z) = y_0 x + x_0 y - z = x_0 y_0 
\end{aligned} \\
\nabla f(r_0) \cdot (1,0,y_0) = \nabla f(r_0) \cdot (0,1,x_0) = 0  \text{ and note that } \begin{aligned}
  & (0,y_0,0) \in S \\
  & (x_0,0,0) \in S
\end{aligned}
\end{gathered}
\]
So indeed, the tangent plane contains these lines.  

\exercisehead{8} $xyz = a^3$  $(x_0,y_0, z_0)$, $\nabla f = (yz, xz, xy)$
\[
y_0 z_0 x + x_0 z_0 y + x_0 y_0 z = 3a^3
\]
Volume of the tetrahedron: 
\[
V = \frac{1}{3} B h = \frac{1}{3} \left( \frac{1}{2} x y \right) h = \frac{1}{6} xyz = \frac{1}{6} (3x_0)(3y_0)(3z_0) = \boxed{ \frac{9a^3}{2} }
\]

\exercisehead{9} We want a pair of linear Cartesian equations for the line tangent to $x^2 +y^2 +2z^2 = 4$, $z = e^{x-y}$ at pt. $(1,1,1) = P_1$

We calculate the gradients for the 2 surfaces, so to get the normal to these surfaces.  
\[
\begin{gathered}
  \nabla f= (2x,2y,4z) \quad \quad \quad \nabla g = (e^{x-y}, -e^{x-y}, -1 ) \\
  \xrightarrow{ (1,1,1) } \nabla f(1,1,1) = 2(1,1,2) \quad \quad \quad \nabla g(1,1,1) = (1,-1,-1)
\end{gathered}
\]
We know the general form of the equation for the line with these normals, $N$, will be $X\cdot N = X\cdot P_1$.  Then
\[
\boxed{ \begin{gathered}
    x - y -z = -1 \\
    x + y+ 2z =4 
\end{gathered} }
\]

\exercisehead{10} Find a constant $c$ s.t. at any pt. of intersection, the corresponding tangent planes will be $\perp$ to each other. 
\[
\begin{gathered}
\begin{aligned}
  & (x-c)^2 + y^2 + z^2 = 3 \\
  & x^2 + (y-1)^2 + z = 1 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \nabla f = 2 (x-c, y,z) \\
  & \nabla g = 2 (x,y-1,z)
\end{aligned} \\
\text{ tangent planes are $\perp$ to each other } \Longrightarrow \nabla f \cdot \nabla g  = x(x-c) + y(y-1) + z^2 = x^2 - xc + y^2 -y + z^2 = 0 \\
\Longrightarrow y = xc
\end{gathered}
\]
We have the intersection condition, and so solving for the system of 2 linear equations, with $y=xc$, 
\[
\boxed{ c = \pm \sqrt{3}}
\]

\exercisehead{11} Without loss of generality, choose the origin to make the ellipse symmetrical and the major axis to lie on the $x$ axis. 
\[
\begin{gathered}
  R = (x,y) \\
  \begin{aligned}
    F_1 & = (ae,0) \\
    F_2 & = (-ae,0) 
  \end{aligned} \quad \quad \, \begin{aligned}
    & |R- F_1| = r_1 = \sqrt{ (x-ae)^2 + y^2 } \\
    & |R-F_2| = r_2 = \sqrt{ (x+ae)^2 + y^2 }
\end{aligned} \quad \quad \begin{aligned}
    & R - F_1 = (x-ae,y) \\ 
    & R - F_2 = (x+ae,y) 
\end{aligned} \\
\begin{aligned}
  & \nabla |R-F_1| = \frac{ (x-ae, y) }{ \sqrt{ (x-ae)^2 + y^2 } } = \frac{ R-F_1}{r_1} \\
  & \nabla |R- F_2| =  \frac{ (x+ae,y) }{ \sqrt{ (x+ae)^2 + y^2 } } =  \frac{ R-F_2}{r_2} 
\end{aligned}
\end{gathered}
\]
\[
\begin{gathered}
  r_1 + r_2 = K \\
  \frac{ x^2}{a^2} + \frac{y^2}{b^2} = 1 \quad \quad \, \begin{aligned}
    & y^2 = b^2 \left( 1 - \frac{x^2}{a^2} \right) \\
    & y = \pm b \sqrt{ 1 - \frac{x^2}{a^2} }
  \end{aligned} \quad \quad \, \frac{dy}{dx} = \frac{ \mp bx/a^2}{ \sqrt{ 1 - (x/a)^2 }} = \frac{-b^2}{a^2} \frac{x}{y} \\
R' = (1, \frac{-b^2}{a^2 } \frac{x}{y} )
\end{gathered}
\]
\[
R' \cdot \nabla (|R-F_1| + |R-F_2|) = R' \cdot \left( \frac{R - F_1}{r_1} + \frac{R-F_2}{r_2} \right) = \frac{ R' \cdot kR + R' \cdot( -F_1 r_2 - F_2 r_1 ) }{ r_1 r_2 } 
\]
Consider $R' \cdot k R + r_2 (-F_1 \cdot R') - r_1 (R'\cdot F_2) = K (x -\frac{b^2}{a^2} x ) + r_2 (-ae) - r_1 (-ae)$
\[
\begin{gathered}
  r_{1,2} = \sqrt{ (x \mp ae)^2 + b^2 - \frac{b^2 x^2}{a^2} } = \sqrt{ x^2 \mp 2xae + a^2 e^2 + b^2 - \frac{b^2 x^2}{a^2} } = \sqrt{ e^2 x^2 \mp 2xae + a^2 } = a \mp xe \\
  \begin{aligned}
    & r_2 - r_1 = 2xe \\
    & r_2 + r_1 = 2a 
  \end{aligned} \\
  \Longrightarrow R'\cdot kR + r_2 (-F_1 \cdot R') - r_1 (R' \cdot F_2) = 2ax e^2 + (-ae)(2xe) = 0 
\end{gathered}
\]
Thus $T\cdot (\nabla r_1 + r_2 ) = 0$.  This means that $T\cdot \nabla r_1 = -T\cdot \nabla r_2$.  As we had shown above, $\nabla r_{1,2}$ is in the direction from the respective foci to the arbitrary point $(x,y)$ and both $\nabla r_1$ and $\nabla r_2$ are of length $1$.  Thus $T\cdot \nabla r_1 = -T \cdot \nabla r_2$ geometrically says that the angle between $\nabla r_1$ and the tangent line is equal to the angle between $\nabla r_2$ and the tangent line.  

\exercisehead{12} $f=f(x,y,z)$
\[
\begin{gathered}
  \partial_z f = k_0 z \Longrightarrow f = k_1 z^2 g(x,y) + h(x,y) \\
  f(0,0,a) = k_1 a^2 g(0,0) + h(0,0) = f(0,0,-a)
\end{gathered}
\]

\section*{ 8.22 Exercises - Derivatives of vector fields, Differentiability implies continuity, The chain rule for derivatives of vector fields, Matrix form of the chain rule }

\exercisehead{1} Recall 
\[
(Dh(a))_{jk} = \sum_{l=1}^n (Df(b))_{jl} (Dg(a))_{lk} = (\partial_k h_j(a)) = \sum_{l=1}^n (\partial_l f_j(b)) (\partial_k g_l(a))
\]
\begin{enumerate}
\item \[
\begin{gathered}
  \partial_x f = \partial_t F \partial_x g \Longrightarrow \frac{ \partial f}{\partial x } = F'(g(x,y)) \frac{ \partial g}{\partial x } \\
  \frac{\partial f}{\partial y} = F'(g(x,y)) \frac{ \partial g}{\partial y}
\end{gathered}
\]
\item \[
  \begin{aligned}
    F(t) & = e^{\sin{t}} \\
    g(x,y) & = \cos{ (x^2 + y^2) }
  \end{aligned} 
\quad \quad \quad \begin{aligned}
  & \frac{ \partial f}{\partial x} = -\cos{t} e^{\sin{t} } \sin{(x^2 + y^2 )} 2x \\
  & \frac{ \partial f}{ \partial y } = -\cos{t} e^{\sin{t}} \sin{(x^2 + y^2) } 2y 
\end{aligned}
\]
\end{enumerate}

\exercisehead{2} Given
\[
\begin{aligned}
  u & = \frac{x-y}{2} \\
  v & = \frac{x+y}{2}
\end{aligned} \quad \quad \quad 
f(u,v) \to F(x,y), \quad F(x,y) = f(u(x,y), v(x,y) )
\]
\[
\begin{aligned}
  & \partial_x F = \partial_u f \partial_x u + \partial_v f \partial_x v & = \frac{1}{2} \partial_u f + \frac{1}{2} \partial_v f \\
  & \partial_y F = \partial_u f \partial_y u + \partial_v f \partial_y v & = -\frac{1}{2} \partial_u f + \frac{1}{2} \partial_v f 
\end{aligned}
\]

\exercisehead{3} Given 
\[
u = f(x,y) \quad \quad 
\begin{aligned}
  & x = X(s,t) \\
  & y = Y(s,t)
\end{aligned} \quad \quad \quad u = F(s,t) = f(x(s,t),y(s,t))
\]
\begin{enumerate}
\item \[
\begin{aligned}
  & \partial_s F = \partial_x f \partial_s x + \partial_y f \partial_s y \\
  & \partial_t F = \partial_x f \partial_t x + \partial_y f \partial_t y
\end{aligned}
\]
\item To get to the second order partial derivatives, it seems that a direct application of the partial derivatives is needed: there's not a way to reformulate a matrix chain rule for second order partial derivatives, until maybe the Hessian matrix.  
\[
\begin{gathered}
  \partial_{ss}^2 f  = \partial^2_{xs} F \partial_s x + \partial_x f \partial_{ss}^2 x + \partial_{ys}^2 F \partial_s y + \partial_y f \partial_{ss}^2 y  \medskip \\
  \begin{gathered}
    \partial_s f  = \partial_x f \partial_s x + \partial_y f \partial_s y  \\
    \begin{aligned}
      \Longrightarrow \partial_{xs} f & = \partial_{xx} f \partial_s x + \partial_x f \partial_s \partial_x x + \partial_{xy} f \partial_s y + \partial_y f \partial_s \partial_x y = \\
      & = \partial_{xx} f \partial_s x + \partial_{xy} f \partial_s y 
    \end{aligned} 
  \end{gathered} \\
\begin{aligned}
  \Longrightarrow \partial_{ss}^2 f & = (\partial_{xx}^2 f \partial_s x + \partial_{xy}^2 f \partial_s y) \partial_s x + \partial_x f \partial_{ss}^2 x + (\partial_{yx}^2 f \partial_s x + \partial_{yy}^2 f \partial_s y)\partial_s y + (\partial_y f)(\partial_{ss}^2 y) = \\ 
  & = (\partial_{xx}^2 f)(\partial_s x)^2 + 2\partial_{xy}^2 f \partial_s y \partial_s x + \partial_{yy}^2 f (\partial_s y)^2 + (\partial_x f) \partial_{ss}^2 x + (\partial_y f)(\partial_{ss}^2 y )
\end{aligned}
\end{gathered}
\]
\item By label symmetry:
\[
\partial_{tt}^2 f = (\partial_{xx}^2 f)(\partial_t x)^2 + 2\partial_{xy}^2 f \partial_t y \partial_t x + \partial_{yy}^2 f (\partial_t y)^2 + (\partial_x f) \partial_{tt}^2 x + (\partial_y f)(\partial_{tt}^2 y )
\]
Let's calculate $\partial_{st}^2 F$
\[
\begin{aligned}
  \partial_{st}^2 F & = \partial_{xs}^2 f \partial_t x + \partial_x f \partial_{st}^2 x + \partial_{ys}^2 f \partial_t y + \partial_y f \partial_{st}^2 y = \\
  & = (\partial_{xx}^2 f \partial_s x + \partial_{xy}^2 f \partial_s y) \partial_t x + \partial_x f \partial_{st}^2 x + ( \partial_{yx}^2 f \partial_s x + \partial_{yy}^2 f \partial_s y ) \partial_t y + \partial_y f \partial_{st}^2 y = \\
  & = \partial_{xx}^2 f \partial_s x \partial_t x + \partial_{xy}^2 f ( \partial_s y \partial_t x + \partial_s x \partial_t y) + \partial_{yy}^2 f \partial_s y \partial_t y + \partial_x f \partial_{st}^2 x + \partial_y f \partial_{st}^2 y 
\end{aligned}
\]
\end{enumerate}

\exercisehead{4} \begin{enumerate}
  \item \[
\begin{gathered}
  \begin{aligned}
    & X(s,t) = s +t \\
    & Y(s,t) = st 
  \end{aligned} \quad \quad 
\begin{aligned}
  & \partial_s X = \partial_t X = 1 \\
  & \partial_s Y = t \quad \partial_t Y = s 
\end{aligned} \quad \quad 
  \begin{aligned}
    & \partial_s F = \partial_x f + t \partial_y f \\
    & \partial_t F = \partial_x f + s \partial_y f 
\end{aligned} \\
  \begin{aligned}
    & \partial_{ss}^2 f = (\partial_{xx}^2 f) + 2 \partial_{xy}^2 f t + \partial_{yy}^2 f t^2 \\ 
    & \partial_{tt}^2 f = (\partial_{xx}^2 f) + 2 \partial_{xy}^2 f s + \partial_{yy}^2 f s^2 \\
    & \partial_{st}^2 f = \partial_{xx}^2 f + \partial_{xy}^2 f(t+s) + \partial_{yy}^2 f ts 
  \end{aligned}
\end{gathered}
\]
  \item \[
\begin{gathered}
  \begin{aligned}
    X(s,t) & = st \\
    Y(x,t) & = s/t 
  \end{aligned} \quad \quad 
\begin{aligned}
  & X_s = t \\
  & X_t = s 
\end{aligned} \quad \quad 
\begin{aligned}
  & Y_s = 1/t \\ 
  & Y_t = -s/t
\end{aligned} \quad \quad 
\begin{aligned}
  & \partial_s F = \partial_x f t + \partial_y f (1/t) \\
  & \partial_t F = \partial_x f s + \partial_y f (-s/t^2) 
\end{aligned} \\
\begin{aligned}
  \partial_{ss}^2 F & = (\partial_{xx}^2 f)(t^2) + 2 \partial_{xy}^2 f \left( \frac{1}{t} \right) t + \partial_{yy}^2 f (1/t)^2 \\
  \partial_{tt}^2 F & = (\partial_{xx}^2 f)s^2 + 2 \partial_{xy}^2 f \left( \frac{-s}{t} \right) s + \partial_{yy}^2 f \left( \frac{-s}{t^2} \right)^2 \\
  \partial_{st}^2 F & = \partial_{xx}^2 f ts + \partial_{xy}^2 f \left( \frac{1}{t} s + t \left( \frac{-s}{t^2} \right) \right) + \partial_{yy}^2 f \frac{1}{t} \left( \frac{-s}{t^2 } \right) + \partial_x f + \partial_y f \left( \frac{-1}{t^2} \right) 
\end{aligned}
\end{gathered}
\]
  \item \[
\begin{gathered}
  \begin{aligned}
    X(s,t) & = \frac{s-t}{2} \\
    Y(s,t) & = \frac{s+t}{2} 
\end{aligned} \quad \quad \begin{aligned} x_s & = 1/2 \\ x_t & = -1/2 \end{aligned} \quad \quad \begin{aligned} Y_s & = 1/2 \\ Y_t & = 1/2 \end{aligned} \quad \quad \begin{aligned} \partial_s F & = \partial_x f 1/2 + \partial_y f 1/2 \\ \partial_t F & = \partial_x f (-1/2) + \partial_y f 1/2 \end{aligned} \\ 
  \begin{aligned}
    \partial_{ss}^2 F & = \left(\frac{1}{2} \right) ((\partial_{xx}^2 f + \partial_{xy} f )1/2 + (\partial_{yx}^2 f + \partial_{yy}^2 ) 1/2) = \frac{1}{4} (\partial_{xx}^2 f + \partial_{xy}^2 f + \partial_{yx}^2 f + \partial_{yy}^2 f ) \\
    \partial_{tt}^2 F & = \frac{1}{4} (\partial_{xx}^2 f - \partial_{xy}^2 f - \partial_{yx}^2 f + \partial_{yy}^2 f ) \\
    \partial_{st}^2 F  & = \frac{1}{4} ( -\partial_{xx}^2 f + \partial_{xy}^2 - \partial_{yx}^2 f + \partial_{yy}^2 f )
  \end{aligned}
\end{gathered}
\]
\end{enumerate}

\exercisehead{5} {\large You cannot interchange $\partial_x$ and $\partial_r$, $\partial_x$ and $\partial_{\theta}$, etc.}
\[
\begin{aligned}
  \partial_r \phi & = \partial_x f \partial_r x + \partial_y f \partial_{\theta} y = f_x c + f_y s \\
  \partial_{\theta} \phi & = \partial_x f \partial_{\theta} x + \partial_y f \partial_{\theta} y = -f_x rs + f_y rc
\end{aligned}
\]
Notice that the above formulas give a prescription or algorithm for computing the $\partial_r$ or $\partial_{\theta}$ of functions of $x,y$.  Notice also that $f_x, f_y$ are each composite functions.  

\[
\begin{aligned}
  \partial_{r\theta}^2 \phi & = \partial_r (-f_x rs + f_y rc) = -\partial_r f_x rs - f_x s + \partial_r f_y fc + f_y c = \\
  & = -(f_{xx} c + f_{yx} s) rs - f_x s + (f_{xy} c + f_{yy} s)rc + f_y c = \\
  & = -f_{xx} rcs - f_{yx} r s^2 + f_{xy} rc^2 + f_{yy} rsc - f_x s + f_y c 
\end{aligned}
\]
\[
\begin{aligned}
  \partial_{\theta r}^2 \phi & = \partial_{\theta} (f_x c + f_y s) = \partial_{\theta} f_x c - f_x s + \partial_{\theta} f_y s + f_y c = \\
  & = (-f_{xx} rs + f_{yx} rc )c  -f_x s + (-f_{xy} rs + f_{yy} rc )s + f_y c = \\
  & = -f_{xx} rsc + f_{yx} rc^2 - f_x s - f_{xy} rs^2 + f_{yy} rcs + f_y c 
\end{aligned}
\]
\[
\begin{aligned}
  \partial_{rr}^2 \phi & = \partial_r (f_x c + f_y s) = \\
  & = \partial_r f_x c + \partial_r f_y s = (f_{xx} c + f_{yx} s) c + (f_{xy}c + f_{yy} s) s = f_{xx} c^2 + f_{yx} sc + f_{xy} cs + f_{yy} s^2 
\end{aligned}
\]

\exercisehead{6} Given $u = f(x,y,z)$, $\begin{aligned} x & = X(r,s,t) \\
  y & = Y(r,s,t) \\
  z & = Z(r,s,t) 
\end{aligned}$ \quad \quad $u = F(r,s,t)$ 
\[
\begin{aligned}
  \partial_r F & = \partial_x F \partial_r x + \partial_y F \partial_r y + \partial_z F \partial_r z \\
  \partial_s F & = \partial_x F \partial_s x + \partial_y F \partial_s y + \partial_z F \partial_s z \\
  \partial_t F & = \partial_x F \partial_t x + \partial_y F \partial_t y + \partial_z F \partial_t z 
\end{aligned}
\]

\exercisehead{7}
\begin{enumerate}
\item Given $\begin{aligned}
  & X(r,s,t) = r + s+ t \\
  & Y(r,s,t) = r + -2s+ 3t \\
  & Z(r,s,t) = 2r + s+ -t 
\end{aligned}$ 
\[
\begin{aligned}
  & \partial_r F = \partial_x F + \partial_y F + 2 \partial_z F \\ 
  & \partial_s F = \partial_x F + -2\partial_y F +  \partial_z F \\ 
  & \partial_t F = \partial_x F + 3 \partial_y F - \partial_z F  
\end{aligned}
\]
\item Given $\begin{aligned}
  & X(r,s,t)  = r^2  + s^2+ t^2 \\
  & Y(r,s,t)  = r^2  - s^2- t^2 \\
  & Z(r,s,t)  = r^2  - s^2+ t^2 
\end{aligned}$
\[
\begin{aligned}
  & \partial_r F = 2r(\partial_x F + \partial_y F +  \partial_z F) \\ 
  & \partial_s F = 2s (\partial_x F + -\partial_y F -  \partial_z F) \\ 
  & \partial_t F = 2t (\partial_x F - \partial_y F + \partial_z F )
\end{aligned}
\]
\end{enumerate}

\exercisehead{8} $u = f(x,y,z)$ \quad $\begin{aligned}
  x  & = X(s,t) \\
  y & = Y(s,t) \\
  z & = Z(s,t)
\end{aligned}$ \quad $u = F(s,t)$ 
\[
\begin{aligned}
  & \partial_s F = \partial_x F \partial_s X + \partial_y F \partial_s Y + \partial_z F \partial_s Z \\
  & \partial_t F = \partial_x F \partial_t X + \partial_y F \partial_t y + \partial_z F \partial_t Z
\end{aligned}
\]

\exercisehead{9}
\begin{enumerate}
  \item $\begin{aligned}
    & X(s,t) = s^2 + t^2 \\
    & Y(s,t) = s^2 - t^2 \\
    & Z(s,t) = 2st 
\end{aligned}$ \quad \quad \quad $
\begin{aligned}
  & \partial_s F = 2s(\partial_x F + \partial_y F) + 2t \partial_z F \\
  & \partial_t F = 2t (\partial_x F - \partial_y F) + 2s \partial_z F 
\end{aligned}
$
  \item $\begin{aligned}
    & X(s,t) = s + t \\
    & Y(s,t) = s - t \\
    & Z(s,t) = st    
\end{aligned}$ \quad \quad \quad $
\begin{aligned}
  & \partial_s F = (\partial_x F + \partial_y F ) + t \partial_z F \\
  & \partial_t F = (\partial_x F - \partial_y F) + s \partial_z F
\end{aligned}$
\end{enumerate}

\exercisehead{10} Given $u = f(x,y)$; \quad $\begin{aligned}
  & x = X(r,s,t) \\
  & y = Y(r,s,t)
\end{aligned}$ \quad $u = F(r,s,t)$ \quad $\Longrightarrow \begin{aligned}
  & \partial_r F = \partial_x F \partial_r x + \partial_y F \partial_r y \\
  & \partial_s F = \partial_x F \partial_s x + \partial_y F \partial_s y \\ 
  &  \partial_t F = \partial_x F \partial_t x + \partial_y F \partial_t y \\ 
\end{aligned}$ 

\exercisehead{11}  \begin{enumerate}
\item Given $X(r,s,t) = r+s$, $Y(r,s,t) = t$ \quad \quad $\Longrightarrow \begin{aligned}
  & \partial_r F = \partial_x F  \\
  & \partial_s F = \partial_x F \\
  & \partial_t F = \partial_y F
\end{aligned}$
\item Given $X(r,s,t) = r+s+t$, $Y(r,s,t) = r^2 + s^2 + t^2$ \quad \quad $\Longrightarrow \begin{aligned}
  & \partial_r F = \partial_x F + \partial_y F(2r) \\
  & \partial_s F = \partial_x F + 2s \partial_y F \\
  & \partial_t F = \partial_x F + 2t \partial_y F 
\end{aligned}$
\item Given $X(r,s,t) = r/s$, $Y(r,s,t) = s/t$ \quad \quad $\Longrightarrow \begin{aligned}
  & \partial_r F = \frac{1}{s} \partial_x F \\
  & \partial_s F = \partial_x F (-r/s^2) + \partial_y F /t \\
  & \partial_t F = \partial_y F (-s/t^2)
\end{aligned}$
\end{enumerate}

\exercisehead{12} $h(x) = f(g(x))$ \quad \, $g= (g_1,\dots, g_n)$
\[
\nabla h(a) \Longrightarrow \partial_k h(a) = \sum_{l=1}^n \partial_l f \partial_k g_l \text{ or } \nabla h(a) = \sum_{l=1}^n \partial_l f \nabla g_l
\]

\exercisehead{13}
\begin{enumerate}
\item $f(x,y,z) = xi + yj +zk$
\[
Df(x) = \left[ \begin{matrix} \nabla f_x(x) \\ \nabla f_y(x) \\ \nabla f_z(x) \end{matrix} \right] = \left[ \begin{matrix} 
    \partial_x f_x & \partial_y f_x & \partial_z f_x \\
    \partial_x f_y & \partial_y f_y & \partial_z f_y \\
    \partial_x f_z & \partial_y f_z & \partial_z f_z 
\end{matrix} \right] = \left[ \begin{matrix} 1 & & \\ & 1 & \\ & & 1 \end{matrix} \right]
\]
\item $f = (x+c_x, y+c_y, z+c_z)$ where $c_z, c_y, c_z$ are constants.  
\item \[
\begin{gathered}
Df(x) = \left[ \begin{matrix} \nabla f_x(x) \\ \nabla f_y(x) \\ \nabla f_z(x) \end{matrix} \right] = \left[ \begin{matrix} 
    \partial_x f_x & \partial_y f_x & \partial_z f_x \\
    \partial_x f_y & \partial_y f_y & \partial_z f_y \\
    \partial_x f_z & \partial_y f_z & \partial_z f_z 
\end{matrix} \right] = \left[ \begin{matrix} p(x) & & \\ & q(y) & \\ & & r(z) \end{matrix} \right] \\
\Longrightarrow f(x) = ((\int p(x) dx + x_0), (\int q(y) dy + y_0), (\int r(z) dz + z_0 ) ) \\
\text{ where $x_0, y_0, z_0$ are constants. }
\end{gathered}
\]
\end{enumerate}

\exercisehead{14} Given $f: \mathbb{R}^2 \to \mathbb{R}^2$, $g: \mathbb{R}^3 \to \mathbb{R}^2$ \quad $\begin{aligned}
  f(x,y) & = (e^{x+2y}, \sin{(y+2x)}) \\
  g(u,v,m) & = ((u+2v^2 + 3w^3), (2v- u^2) )
\end{aligned}$ 
\begin{enumerate}
\item $Df(x,y), Dg(u,v,w)$ \quad $\Longrightarrow Df = \left[ \begin{matrix} e^{x+2y} & 2 e^{x + 2y} \\
    2 \cos{(y+2x)} & \cos{(y+2x)} \end{matrix} \right]$ \quad \quad $Dg = \left[ \begin{matrix} 1 & 4v & 9w^2 \\ -2u & 2 & 0 \end{matrix} \right]$ 
\item $h(u,v,w) = f(g(u,v,w))$
\[
\begin{aligned}
f(g(u,v,w)) & = (e^{u + 2v^2 + 3w^3 + 2(2v - u^2) }, \sin{( 2v - u^2 + 2(u + 2v^2 + 3w^3) ) } ) = \\
& = (e^{u + 2v^2 + 3w^3 + 4v - 2u^2 }, \sin{(2v - u^2 + 2u + 4v^2 + 6w^3 ) } ) 
\end{aligned}
\]
\item 
\[
\begin{gathered}
  \begin{aligned}
  Dh & = Df Dg = \left[ \begin{matrix} e^{x+ 2y} & 2e^{x+2y} \\
      2\cos{ (y+2x)} & \cos{(y+ 2x) } 
\end{matrix} \right]\left[ \begin{matrix} 1 & 4v & 9w^2 \\
      -2u & 2 & 0 \end{matrix} \right] = \\
  & = \left[ \begin{matrix} e^{x+2y} (1-4u) & e^{x+2y} (4v +4) & 9 w^2 e^{x+2y} \\
      \cos{(y+2x)} (2-2u) & \cos{(y+2x) }(8v + 2) & 18 w^2 \cos{(y+ 2x) } \end{matrix} \right] 
\end{aligned} \\
  Dh(1,-1,1) = \left[ \begin{matrix} -3 & 0 & 9 \\
      0 & -6 \cos{9} & 18 \cos{9} \end{matrix} \right]
\end{gathered}
\]
\end{enumerate}

\exercisehead{15} Given \\
$\begin{aligned}
  f & = ((x^2 + y + z),(2x + y+z^2)) \\
  g & = (uv^2 w^2 , w^2 \sin{v}, u^2 e^v )
\end{aligned}$
\begin{enumerate}
\item $Df = \left[ \begin{matrix} 2x & 1 & 1 \\ 2 & 1 & 2z \end{matrix} \right]$ \quad \quad $Dg = \left[ \begin{matrix} v^2 w^2 & 2uvw^2 & 2uv^2 w \\ 
    0 & w^2 \cos{v} & 2w \sin{v} \\ 2u e^v & u^2 e^v & 0 \end{matrix} \right]$ 
\item \[
\begin{aligned}
  h(u,v,w) & = f[g(u,v,w)] = ((uv^2 w^2)^2 + w^2 \sin{v} + u^2 e^v, 2uv^2 w^2 + w^2 \sin{v} + u^4 e^{2v} ) = \\
  & = (u^2 v^4 w^4 + w^2 \sin{v} + u^2 e^v, 2uv^2 w^2 + w^2 \sin{v} + u^4 e^{2v} )
\end{aligned}
\]
\item \begin{multline*}
  Dh(u,0,w) = \left[ \begin{matrix} 2x & 1 & 1 \\ 2 & 1 & 2z \end{matrix} \right]\left[ \begin{matrix} v^2 w^2 & 2uvw^2 & 2uv^2 w \\ 0 & w^2 \cos{v} & 2w \sin{v} \\ 2u e^v & u^2 e^v & 0 \end{matrix} \right] = \\
  = \left[ \begin{matrix} 2xv^2 w^2 + 2u e^v & 4x uvw^2 + w^2 \cos{v} + u^2 e^v & 4xu v^2 w + 2w \sin{v} \\ 2v^2 w^2 + 4z ue^v & 4uvw^2 + w^2 \cos{v} + 2z u^2 e^v & 4uv^2 w + 2w \sin{v} \end{matrix} \right] = \left[ \begin{matrix} 2u & w^2 + u^2 & 0 \\ 4(u^3) & w^2 + 2u^4 & 0 \end{matrix} \right]
\end{multline*}
\end{enumerate}

\section*{ 8.24 Miscellaneous exercises - Sufficient conditions for the equality of mixed partial derivatives }

\exercisehead{2} $f = \frac{ y (x^2 - y^2)}{ x^2 +y^2 }$.  
\[
f_1 = (y) \frac{ 2x (x^2 + y^2) - (2x)(x^2 - y^2) }{ (x^2 + y^2)^2} = \frac{ 4 x^3 y}{ (x^2 +y^2)^2 }
\]
\[
f_2 = \frac{ ( (x^2 -y^2 ) - 2y^2 )(x^2 + y^2) - 2y^2 (x^2 - y^2 ) }{ (x^2 + y^2 )^2} = \frac{ x^4 - 4 x^2 y^2 - y^4 }{ (x^2 +y^2 )^2 }
\]
\[
D_{2,1} f= 4x^3 \frac{ (x^2 +y^2)^2 - 2(x^2 + y^2 )( 2y) y }{ (x^2 +y^2)^4} = \frac{ x^4 - 4x^2 y^2 - y^4}{ (x^2 +y^2)^2 }
\]
\[
\begin{aligned}
  D_{1,2} f & = \frac{ (4x^3 - 8xy^2) (x^2 + y^2)^2 - 2(x^2 + y^2) (2x) ( x^4 - 4x^2 y^2 - y^4) }{ (x^2 +y^2)^4 }  = \\
  & = \frac{ 4x(x^2 - 2y^2)(x^2 + y^2) - 4x (x^4 - 4x^2 y^2 - y^4) }{ (x^2  +y^2)^3}  = \frac{ 4xy^2 ( 3x^2  -y^2) }{ (x^2  +y^2)^3 }
\end{aligned}
\]
From the above results, clearly,
\[
\lim_{x \to 0} f_1 =  0, \quad \, \lim_{y\to 0} f_1 = 0 
\]
So that $\boxed{ f_1(0,0) = 0 }$, while
\[
\lim_{x \to 0 } f_2 = -1 \quad \, \lim_{y\to 0} f_2 =  1 
\]
so $f_2(0,0)$ undefined.  

\[
\lim_{x \to 0} f_{12} =0 \quad \, \lim_{ y\to 0} f_{12} = 0 
\]
so that $\boxed{ f_{12}(0,0)= 0}$, but
\[
\lim_{x\to 0} f_{21} =0 \quad \, \lim_{y \to 0} f_{21} = \frac{4x^3}{x^4} = \frac{4}{x} \xrightarrow{ x\to 0} \infty
\]

\exercisehead{3} Given $f(x,y) = \frac{ xy^3 }{ x^3 + y^6 }$ if $(x,y) \neq (0,0)$, $f(0,0) = 0$
\begin{itemize}
\item[a.]
\[
\begin{aligned}
  f'(0;a) & = \lim_{h\to 0} \frac{ f(x+ha) - f(x)}{h} = \lim_{h\to 0 } \frac{f(ha) - f(0) }{ h } = \lim_{h\to 0} \left( \frac{ h a_x h^3 a_y^3 }{ h^3 a_x^3 + h^6 a_y^6 } \right)/h = \lim_{h\to 0} \frac{ h^3 a_x a_y^3 }{ h^3 a_x^3 + h^6 a_y^6 } = \\
    & = \lim_{h\to 0} \frac{ a_x a_y^3 }{ a_x^3 + h^3 a_y^6} = \frac{ a_y^3}{a_x^2 }
\end{aligned}
\]
So $f'(0;a) = \frac{ a_y^3}{a_x^2 }$ if $a_x \neq 0$, $f'(0;a) = 0$ if $a_x = 0$
\item[b.] If $x=y^2$, then 
\[
f(x,y) = \frac{ xy^3}{x^3 + y^6} = \frac{ y^5 }{ 2y^6} = \frac{1}{ 2y} \xrightarrow{ y\to 0 } \infty \text{ not } 0
\]
So $f(x,y)$ is not continuous at $(0,0)$.  
\end{itemize}

\exercisehead{4} $f(x,y) = \int_0^{\sqrt{xy}} e^{-t^2} dt$ for $x>0$; $y>0$.  \\
Let $u = u(x,y) = \sqrt{ xy}$ and then we can use chain rule.  
\[
\partial_x f = \partial_u f \partial_x u = \boxed{ e^{-xy} \frac{1}{2} \sqrt{ y/x} } \quad \quad \partial_y f = e^{-xy} \frac{1}{2} \sqrt{ x/y} \text{ by label symmetry }
\]

\exercisehead{5} Given $u = f(x,y)$; $\begin{aligned}
  x & = x(t) \\
  y & = y(t) 
\end{aligned}$ and $u=F(t)$.  
\[
\begin{aligned}
  F'(t) & = (\partial_x u) x' + (\partial_y u )y' =  x' u_x + y' u_y \\
  F''(t) & = x''u_x + x'(x'u_{xx} + y'u_{yx}) + y'' u_y + y'(x' u_{xy} + y' u_{yy}) = x'' u_x + y'' u_y + x'^2 u_{xx} + y'^2 u_{yy} + (x'y')(u_{yx} + u_{xy})
\end{aligned}
\]
\[
\begin{aligned}
  F'''(t) & = \begin{aligned} & \quad \\
    & x'' u_x + x''(x' u_{xx} + y'u_{yx}) + y''' u_y + y'' (x' u_{xy} + y' u_{yy}) + \\
  & \, + 2 x' x'' u_{xx} + 2y' y'' u_{yy} + x'^2 ( x'u_{xxx} + y' u_{yxx}) + y'^2 ( x' u_{xyy} + y' u_{yyy}) + \\
  & \, + (x'' y' + x' y'') (u_{yx} + u_{xy} ) + (x'y') (x' u_{xyx} + y' u_{yyx} + x' u_{xxy} + y' u_{yxy}) = \end{aligned} \\
  & = \begin{aligned} & \quad \\
    &  x'' u_x + y''' u_y + x'^3 u_{xxx} + y'^3 u_{yyy} + 3x'' x' u_{xx} + 3y'' y' u_{yy} + \\
  & \, + 2x'' y' u_{yx} + 2y'' x' u_{xy} + x' y'' u_{yx} + x'' y' u_{xy} + \\
  & \, + x'^2 y' u_{yxx} + y'^2 x' u_{xyy} + x'^2 y' u_{xyx} + x'y'^2 u_{yxy} + x' y'^2 u_{yyx} + x'^2 y' u_{xxy} \end{aligned}
\end{aligned}
\]

\exercisehead{6} Given $\begin{aligned}
  & x = u + v \\
  & y = uv^2 
\end{aligned}$ \quad $f(x,y)$ into $g(u,v)$, and 
\[
\frac{ \partial f}{ \partial y } = \frac{ \partial^2 f }{ \partial^2 x } = \frac{ \partial^2 f }{ \partial y^2 } = \frac{ \partial^2 f }{ \partial x \partial y } = \frac{ \partial^2 f }{ \partial y \partial x } = 1 
\]  
So 
\[
\begin{aligned}
  & \partial_u y = v^2 \\
  & \partial_u x = 1 
\end{aligned} \quad \quad \quad 
\begin{aligned}
  & \partial_u g = \partial_x f \partial_u x + \partial_y f \partial_u y = \partial_x f + v^2 \partial_y f \\
  & \partial_v g = \partial_x f \partial_v x + \partial_y f \partial_v y = \partial_x f(1) + 2vu \partial_y f = \partial_x f + 2vu \partial_y f 
\end{aligned}
\]
\[
\begin{aligned}
  \frac{ \partial^2 g}{ \partial v \partial u } & = \partial_v (\partial_x f ) + 2v \partial_y f + v^2 \partial_v (\partial_y f) = \\
  & = (\partial_{xx}^2 f + 2vu \partial_{yx}^2 f ) + 2v (\partial_y f) + v^2 (\partial_{xy}^2 f + 2vu \partial_{yy}^2 f ) = \\
  & = (\partial_{xx}^2 f + 2vu \partial_{yx}^2 f + v^2 \partial_{xy}^2 f + 2vu \partial_{yy}^2 f + 2v (\partial_y f) 
\end{aligned}
\]
So for $u=1$, $v=1$
\[
\frac{ \partial^2 g}{ \partial v \partial u } = 1 + 2 + 1(1) + 2(1)(1)(1) + 2 (1)(1) = \boxed{ 8 }
\]

\exercisehead{7} Given $\begin{aligned}
  & x = uv \\
  & y = \frac{1}{2} (u^2 - v^2)
\end{aligned}$
\begin{enumerate}
\item Assume equality of mixed partials.  
\[
\begin{aligned}
  & \partial_u x = v \\
  & \partial_v x = u 
\end{aligned} \quad \quad 
\begin{aligned}
  & \partial_u y = u \\
  & \partial_v y = -v  
\end{aligned} \quad \quad 
\begin{aligned}
  & \frac{ \partial g }{ \partial u } = v \partial_x f + u \partial_y f \\
  & \frac{ \partial g}{ \partial v} = u \partial_x f - v \partial_y f 
\end{aligned}
\]
\[
\begin{aligned}
  \partial_u \partial_v g & = \partial_x f + u \partial_u (\partial_x f ) + - v \partial_u (\partial_y f ) = \\
  & = \partial_x f + u (v \partial_{xx}^2 f + u \partial_{yx}^2 f ) + -v (v \partial_{xy}^2 f + u \partial_{yy}^2 f ) = \\
  & = \boxed{ \partial_x f + uv \partial_{xx}^2 f + 2y \partial_{xy}^2 f - x \partial_{yy}^2 f  }
\end{aligned}
\]
\item Given $\| \nabla f(x,y) \|^2 = (\partial_x f)^2 + (\partial_y f)^2 = 2$
\[
\begin{gathered}
  a \left( \frac{ \partial g}{ \partial u } \right)^2 + - b \left( \frac{ \partial g}{ \partial v} \right)^2 = u^2 + v^2 = a (v^2 (\partial_x f)^2 + u^2 (\partial_y f)^2 + 2 vu \partial_x f \partial_y f ) + -b (u^2 (\partial_x f)^2 + v^2 (\partial_y f)^2 - 2uv \partial_x f \partial_y f) \\
  \Longrightarrow a = -b \text{ since $u,v$ are independent } \\
\quad \\
(\partial_x f)^2 ( av^2 + au^2) + (\partial_y f)^2 (au^2 + av^2) = a ((\partial_x f)^2 + (\partial_y f)^2 ) (u^2 + v^2) = u^2 + v^2  \\
\Longrightarrow \boxed{ a = 1/2 }
\end{gathered}
\]
\end{enumerate}

\exercisehead{8} Given that 
\[
(F(x) + G(y))^2 e^{ z(x,y) } = 2F'(x) G'(y); \quad F(x) + G(y) \neq 0 \text{ or } e^{z(x,y)} = \frac{ 2F'(x) G'(y) }{ (F+G)^2 }
\]
so
\[
\begin{gathered}
  z(x,y) = \ln{ (2F'G' /(F+G)^2 ) } = \ln{ F' } + \ln{G'} - 2\ln{ (F+G) } \\
  \partial_x z = \frac{1}{F'}F'' - \frac{2}{F+G} F' \\ 
  \Longrightarrow \partial_{yx}^2 z = \frac{ -2F'G' }{ F+G} = -e^{z(x,y) } \neq 0 
\end{gathered}
\]

\exercisehead{9}

\exercisehead{11} 
\[
\begin{aligned}
  (\nabla f)_i & = \partial_i ((r \times A)_j (r \times B)_j) = \partial_i (\epsilon_{jkl} x_k A_l)(\epsilon_{jmn} x_m B_n) = \\
  & = \epsilon_{jik}A_k \epsilon_{jmn} x_m B_n  + \epsilon_{jkl} x_k A_l \epsilon_{jim} B_m = \\
  &= \epsilon_{ijk} A_j \epsilon_{kmn}x_m B_n + \epsilon_{ijk} B_j \epsilon_{klm} x_l A_m 
\end{aligned}
\]
So for $f(x,y,z) = (r\times A)\cdot (r\times B)$,
\[
\boxed{ \nabla f(x,yz) = B \times(r\times A) + A \times (r\times B) }
\]

\exercisehead{12}
\begin{enumerate}
  \item \[
\partial_i \left( \frac{1}{r} \right) = \frac{-1}{r^2} \frac{1}{2} \left( \frac{ 2x_i }{r} \right) = \frac{-x_i}{r^3} 
\]
\[
\boxed{ A \cdot \nabla \left( \frac{1}{r} \right) = \frac{-A\cdot r}{r^3}  }
\]
  \item \[
\partial_i \left( \frac{-a_j x_j}{r^3} \right) = \frac{-a_i}{r^3} + -a_j x_j \left( \frac{-3}{r^4} \right) \left( \frac{x_i}{r} \right) = \frac{-a_i}{r^3} + \frac{3a_j x_j x_i }{r^5} 
\]
\[
\boxed{ B\cdot \nabla \left( A \cdot \nabla \left( \frac{1}{r} \right) \right) = \frac{-A\cdot B}{r^3} + \frac{ 3(A\cdot x)(x\cdot B) }{r^5} }
\]
\end{enumerate}

\exercisehead{13} 
\[
\begin{gathered}
  (x-a)^2 + (y-b)^2 + (z-c)^2 = 1 \text{ or } x^2 + y^2 + z^2 -2xa - 2by - 2zc + a^2 + b^2 +c^2 = 1 \\
\text{ consider pts. of intersection, with $x^2 + y^2 + z^2 = 1$ } \Longrightarrow 2xa + 2by + 2zc = a^2 + b^2 + c^2 
\end{gathered}
\]
\[
\begin{gathered}
  \begin{aligned}
    & \text{ Let } f(x,y,z) = x^2 + y^2 + z^2 -1 \quad \Longrightarrow \nabla f = 2 (x,y,z) \\
    &  \text{ Let } g(x,y,z) = (x-a)^2 + (y-b)^2 + (z-c)^2 - 1 \quad \Longrightarrow \nabla g = 2(x-a,y-b,z-c)
\end{aligned} \\
\begin{aligned}
  \text{ orthogonality condition: } \nabla g \cdot \nabla f & = 0 = x(x-a) + y(y-b)+(z-c)z = 1 - ax - by - cz = \\
  & = 1 - \left( \frac{ a^2 + b^2 + c^2 }{2} \right) = 0 
\end{aligned} \\
\Longrightarrow \boxed{ 2 = a^2 + b^2 + c^2 } 
\end{gathered}
\]
$2 = a^2 + b^2 + c^2$ describes a sphere of radius $\sqrt{2}$ and center at the origin.  

\exercisehead{14} 
\[
z^2 + 2xz + y = 0 \quad \Longrightarrow \begin{aligned} z & = \frac{-2x \pm \sqrt{ 4x^2 - 4(1)(y) } }{2(1) } = \\
  & = -x \pm \sqrt{ x^2 - y } \end{aligned}
\]
Consider parametrizing the position vector for the surface by the $x$ coordinate:
\[
\begin{aligned}
  r & = (x,f(x), -x \pm \sqrt{ x^2 - y } ) \\
  r' & = (1,f', -1 \pm \frac{1}{ 2 \sqrt{ x^2 - y }} (2x- y') )
\end{aligned}
\]
Now consider the position vector for points contained in the ``cylinder.''  Note that the $z$ coordinate does not depend upon $x$ for this cylinder because it looks the same in each $x-y$ plane for each $z$ coordinate.  
\[
\begin{aligned}
  r & = (x,y,z) \\
  r' & = (1,f',0)
\end{aligned}
\]
These two tangent vectors must coincide (since the $x$ coordinate and $y$ coordinate are the same, $1$ and $f'$, respectively).  
\[
\begin{gathered}
  0 = -1 \pm \frac{1}{ 2 \sqrt{ x^2 - y }} (2x- y') \text{ or } 4 = \frac{ 4x^2 - 4xy' + y'^2 }{ x^2 - y} \\
  \Longrightarrow 4x^2 - 4y = 4x^2 - 4xy' + y'^2 \text{ or } y'^2 - 4xy' + 4y = 0 \\
  \Longrightarrow y' = \frac{ 4x \pm \sqrt{ 16x^2 - 4(1)(4y)} }{2} = 2x \pm 2 \sqrt{ x^2 - y } 
\end{gathered}
\]
A solution to this ordinary differential equation is $\boxed{ y = x^2 }$

\section*{ 9.3 Exercises - Partial differential equations, A first-order partial differential equation with constant coefficients }

\exercisehead{1} $4 \partial_x f + 3 \partial_y f =0$ 
\[
\begin{gathered}
  g(3x- 4y ) = f(x,y) \\
  f(x,0) = \sin{x} = g(3x) \Longrightarrow \boxed{ g(3x - 4 y) = \sin{(x - \frac{4}{3} y ) } }
\end{gathered}
\]

\exercisehead{2} $5\partial_x f - 2 \partial_y f = 0$ 
\[
\begin{gathered}
g(2x + 5y) = f(x,y) \\
\partial_x f(x,0) = 2\left. g'(2x + 5y) \right|_{y=0} = 2g'(2x) = e^x \text{ or } g(u) =  e^{u/2} +C \\
\boxed{ g(2x+5y) = e^{(x + \frac{5}{2} y ) } + -1} 
\end{gathered}
\]

\exercisehead{3} \begin{enumerate}
\item If $u(x,y) = f(xy)$, then consider that $xy=$ const. represent level curves for $f$ (because if $f(xy) = f(const.)$, then, ``obviously,'' $f(const.) = $ another constant.  

Parametrize $r$ by $x$
\[
r = (x,y) = (x, \frac{+k}{m} ); \quad \, r' = (1, \frac{-k}{x^2} ) = (1,\frac{-y}{x} ) \text{ where } y = \frac{k}{x}
\] 
\[
(\nabla u ) \cdot r' = \partial_x u + \frac{-y}{x} \partial_y u = 0 \text{ or } x \partial_x u - y \partial_y u = 0 
\]
\[
\begin{gathered}
  u(x,x) = x^4 e^{x^2} \quad \, \partial \, x \\
  u(x,x) = f(xx) = f(x^2 ) = (x^2)^2 e^{x^2} \Longrightarrow \boxed{ f(xy) = (xy)^2 e^{xy} }
\end{gathered}
\]
\item  $v(x,y) = f\left( \frac{x}{y} \right)$ for $y\neq 0$ \\
$\frac{x}{y} = $ const., then $f$ const.  $\nabla f \cdot r' = 0 $ on these level curves with $\frac{x}{y} = $ const.; $r = (x,y) = (x,\frac{x}{k} )$; $r' = (1,1/k)$ or $(1,\frac{y}{x})$
\[
\Longrightarrow \partial_x v + \frac{y}{x} \partial_y v = 0 \text{ or } x \partial_x v + y \partial_y v = 0 
\]
\[
\begin{gathered}
  \partial_x v(x,1/x) = 1/x; \quad \, \partial_x v = \frac{1}{y} f'\left( \frac{x}{y} \right) \xrightarrow{ y = 1/x} x f'(x^2) = \frac{1}{x} \text{ or } f'(x^2) = \frac{1}{x^2} \text{ or } f(x) = \ln{x} + C \\
  f\left( \frac{x}{y} \right) = \ln{\frac{x}{y}} + C = v(x,y) \quad \, \\ 
\text{ Since } v(1,1) = 2 \Longrightarrow \boxed{ v(x,y) = \ln{ \frac{x}{y} } + 2  }
\end{gathered}
\]
\end{enumerate}

\exercisehead{4}$\frac{ \partial^2 g(x,y) }{ \partial x \partial y } = 0$ \\
$\partial_y g(x,y) = \psi_2(y)$ for $\partial_{xy}^2 g = 0$; \quad $g(x,y) = \phi_2(y) + \phi_1(x)$ for $\phi_2'(y) = \psi_2(y)$

\exercisehead{5} $ a=1$, \, $b=-2$, \, $c = -3$ \\
Consider the general problem: $a \partial_{xx}^2 f + b \partial_{xy}^2 f + c \partial_{yy}^2 f = 0$ \quad \, $\begin{aligned} x & = Au + Bv \\ y & = Cu + D v \end{aligned}$, \quad \, $g(u,v) = f(Au + Bv, Cu + Dv)$ \medskip \\
$\frac{\partial^2 g }{ \partial u \partial v } = 0$ (assume equality of mixed partials)
\[
\begin{gathered}
\begin{aligned}
  \partial_v g & = B \partial_x f + D \partial_y f \\
  \partial_u g & = A \partial_x f + C \partial_y f 
\end{aligned} \quad \quad \, 
\begin{aligned}
  \partial_{uv}^2 g & = B(A \partial_{xx} f + C \partial_{yx} f ) + D(A \partial_{xy} f + C \partial_{yy} f) = 0 = \\
  & = AB \partial_{xx}^2 f + (BC +DA) \partial_{xy}^2 f + DC \partial_{yy}^2 f = 0 
\end{aligned} \\
\Longrightarrow \begin{gathered} AB = a \\ BC + DA = b \\ DC = c \end{gathered}
\end{gathered}
\]
\[
\begin{gathered}
  \partial_{uv}^2 g = 0 \Longrightarrow \partial_v g = h(v) \text{ or } g = H(v) + l(u) \\
  \begin{aligned}
  g(u,v) & = H_1(v) + l_1(u) = H_1\left( \frac{Cx-Ay }{BC - AD } \right) + l_1 \left( \frac{Dx - By }{ AD - BC } \right) \\
  & = H(Cx- Ay ) + l(Dx - By)
\end{aligned}
\end{gathered}
\]

\exercisehead{6} $u(x,y) = xy f\left( \frac{x+y}{xy} \right)$
\[
\begin{gathered}
  x^2 \partial_x u + - y^2 \partial_y u = G(x,y) u \, \Longrightarrow \begin{aligned}
    \partial_x u(x,y) & = y f\left( \frac{x+y}{xy} \right) + xy f'\left( \frac{1}{y} + \frac{1}{x} \right)\left( \frac{-1}{x^2} \right) = y f\left( \frac{x+y}{xy} \right) + \frac{-1}{x} y f'\left( \frac{1}{y} + \frac{1}{x} \right) \\
    \partial_y u(x,y) & = x f\left( \frac{x+y}{xy} \right) + xy f'\left( \frac{x+y}{xy} \right) \left( \frac{-1}{y^2} \right)
\end{aligned} \\
  \Longrightarrow x^2 \partial_x - y^2 \partial_y u = x^2 y f - xyf' - y^2x f + xyf' = (x-y)u \quad \, \boxed{ G = x-y } 
\end{gathered}
\]

\exercisehead{7} $\begin{aligned}
  x & = e^s \\
  y & = e^t
\end{aligned}$ \quad \, $f(x,y) \Longrightarrow g(s,t)$ \quad \, $g(x,t) = f(e^s, e^t)$
\[
\begin{gathered}
  x^2 \partial_{xx}^2 f + y^2 \partial_{yy}^2 f + x\partial_x f + y \partial_y f = 0 \\
  \begin{aligned}
    \partial_s g & = x\partial_x f \\
    \partial_{ss}^2 g & = x\partial_x f + x(x\partial_{xx}^2 f ) 
\end{aligned} \quad \quad \, \begin{aligned} \partial_t g & = y \partial_y f \\ \partial_{tt}^2 g & = y \partial_y f + y^2 \partial_{yy}^2 f \end{aligned} \medskip \\
  \boxed{ \partial_{ss}^2 g + \partial_{tt}^2 g = x\partial_x f + x^2 \partial_{xx}^2 f + y \partial_y f + y^2 \partial_{yy}^2 f = 0 }
\end{gathered}
\]

\exercisehead{8} $f(tx) = t^p f(x)$ \quad $\forall \, t > 0 , \, \forall \, x \in S$ s.t. $tx \in S$  
For fixed $x$, define $g(t) = f(tx)$; 
\[
\begin{gathered}
  \begin{aligned}
    g(t) & = f(tx) = t^p f(x) \\
    g'(t) & = pt^{p-1} f(x) 
\end{aligned} \quad \quad \, \Longrightarrow g'(1) = p f(x) = f'(x) = (\nabla f )\cdot x \quad \, \text{ (by definition of total derivative ) }
\end{gathered}
\]

\exercisehead{9} Given $g(t) = f(tx) - t^p f(x)$, note that we want $g(t) = 0$.  
\[
g'(t) = \frac{d}{dt} f(tx) - p t^{p-1} f(x) 
\]
It is very \textbf{ useful } to recall the \emph{total derivative} definition.
\[
\frac{d}{dt} f(tx) = \lim_{\Delta t \to 0 } \frac{ f((t+\Delta t) x ) - f(tx) }{ \Delta t} = \lim_{\Delta t \to 0} \frac{f(tx + \Delta t x) - f(tx) }{ \Delta t} = \left( (\nabla f)(tx) \right) \cdot x 
\]
Use the fact that we're given: $x\cdot (\nabla f)(x) = pf(x)$, so that $tx\cdot \nabla f(tx) = pf(tx)$
\[
\begin{aligned}
  g'(t) & = x \cdot (\nabla f)(tx) - p t^{p-1} f(x) = \frac{p}{t} (f(tx) - t^p f(x)) = \\
  & = \frac{p}{t} g(t)
\end{aligned} \quad \quad \, \Longrightarrow \begin{gathered} 
  \frac{g'}{g} = \frac{p}{t} \\
  \ln{g} = p \ln{t} +C \\
  g = K t^p 
\end{gathered}
\]
Now $g(1) = 0$ (by plugging into the given $g(t) = f(tx) - t^p f(x)$).  But $g(1) = 0$ if $K=0$ \smallskip \\
$\Longrightarrow g = 0 \quad \forall \, t$

\exercisehead{10} 
\[
\begin{gathered}
  \begin{aligned}
    g'(1) & = pf = x\partial_x f + y \partial_y f \\
    g''(1) & = p (x\partial_x f + y \partial_y f) = x \partial_x (x \partial_x f + y \partial_y f) + y \partial_y (x \partial_x f + y \partial_y f ) = \\
    & = x (\partial_x f + x \partial_{xx}^2 f + y \partial_{xy}^2 f ) + y (x \partial_{yx}^2 f + \partial_y f + y\partial_{yy}^2 f ) = x \partial_x f + x^2 \partial_{xx}^2 f + 2xy \partial_{xy}^2 f + y \partial_y f + y^2 \partial_{yy}^2 f
\end{aligned} \\
  \Longrightarrow x^2 \partial_{xx}^2 f + 2xy \partial_{xy}^2 f + y^2 \partial_{yy}^2 f + (pf ) = p^2 f \text{ or } 
\boxed{ x^2 \partial_{xx}^2 f + 2xy \partial_{xy}^2 f + y^2 \partial_{yy}^2 f = p(p-1) f }
\end{gathered}
\]



\section*{ 9.5 Exercises - The one-dimensional wave-equation }

\exercisehead{4} 
\[
\begin{gathered}
\begin{aligned}
  \partial_{xx}^2 f & = \frac{1}{r} \partial_r g + \frac{-x}{r^2} \left( \frac{x}{r} \right) \partial_r g + \frac{x}{r} \left( \frac{x}{r} \partial_{rr}^2 g + \frac{-y}{r^2 } \partial_{\theta r}^2 g \right) + \frac{2y}{r^3} \left( \frac{x}{r}\right) \partial_{\theta} g + \frac{-y}{r^2} \left( \frac{x}{r} \partial_{r\theta}^2 g + \frac{-y}{r^2} \partial_{\theta \theta}^2 g \right) \\
  \partial_{yy}^2 f & = \frac{1}{r} \partial_r g + \frac{-y}{r^2} \left( \frac{y}{r} \right) \partial_r g + \frac{y}{r} \left( \frac{y}{r} \partial_{rr}^2 g + \frac{x}{r^2} \partial_{ \theta r}^2 g \right) + \frac{-2x}{r^3 }\left( \frac{y}{r} \right) \partial_{\theta} g + \frac{x}{r^2} \left( \frac{y}{r} \partial_{r\theta}^2 g + \frac{x}{r^2} \partial_{\theta \theta}^2 g \right)
\end{aligned} \\
\begin{aligned}
\partial_{xx}^2 f + \partial_{yy}^2 f  & = \frac{2}{r} \partial_r g - \frac{ \partial_r g }{ r} + \partial_{rr}^2 g + \frac{1}{r^2} \partial_{\theta \theta}^2 g = \frac{1}{r} \partial_r g + \partial_{rr}^2 g + \frac{1}{r^2} \partial_{\theta \theta}^2 g = \\
& = \frac{1}{r} \partial_r (r \partial_r g ) + \frac{1}{r^2} \partial_{\theta \theta}^2 g 
\end{aligned}
\end{gathered}
\]

\exercisehead{5} We want for \\
$\begin{aligned}
  x & = \rho \cos{\theta} \sin{\phi } \\
  y & = \rho \sin{\theta} \sin{\phi } \\
  z & = \rho \cos{\phi }
\end{aligned}$ \quad \quad \, $f(x,y,z) \to F(\rho, \theta, \phi)$ \\

But first, consider $\begin{aligned} x & = r \cos{\theta} \\ y & = r\sin{\theta} \end{aligned}$ so that $f(x,y,z) \to g(r,\theta, z)$ 
\begin{enumerate}
\item \[
\nabla^2 f = \frac{1}{r} \partial_r (r\partial_r g) + \frac{1}{r^2} \partial_{\theta \theta}^2 g + \partial_{zz}^2 g = \frac{ \partial_r g }{r} + \partial_{rr}^2 g + \frac{1}{r^2} \partial_{\theta \theta}^2 g + \partial_{zz}^2 g 
\]
\item $\begin{aligned} z & = \rho \cos{\phi} \\ r & = \rho \sin{\phi} \end{aligned}$, so 
\[
\frac{1}{r^2} \partial_{\theta \theta}^2 g = \frac{1}{ \rho^2 \sin^2{\phi} } \partial_{\theta \theta}^2 g 
\]
Note that, except for a change in notation, this transformation is the same as that used in (a).  
\[
\begin{gathered}
  \partial_{zz}^2 g + \partial_{rr}^2 g = \frac{1}{\rho } \partial_{\rho} (\partial \partial_{\rho} g ) + \frac{1}{\rho^2} \partial_{\phi \phi}^2 g \\
  \frac{1}{r} \partial_r g = \frac{1}{\rho \sin{\phi}} \left( \rho \sin{\phi} \partial_{\rho} g + \frac{\rho \cos{\phi}}{\rho^2} \partial_{\phi} g \right) = \frac{1}{\rho} \partial_{\rho} g + \frac{ \cos{\phi} }{ \rho^2 \sin{\phi} } \partial_{\phi} g \\
  \nabla^2 f = \partial_{\rho \rho}^2 F + \frac{2}{\rho} \partial_{\rho} F + \frac{1}{\rho^2} \partial_{\phi \phi}^2 F + \frac{\cos{\phi} }{ \rho^2 \sin{\phi}} \partial_{\rho} F + \frac{1}{\rho^2 \sin{\phi}} \partial_{\theta \theta}^2 g 
\end{gathered}
\]
\end{enumerate}

\section*{ 9.8 Exercises - Derivatives of functions defined implicitly, Worked examples }

\exercisehead{1} 
\[
\begin{aligned}
  & x + y = uv \\
  & xy = u -v 
\end{aligned} \quad \,
\begin{aligned}
  x & = X(u,v) \\
  y & = Y(u,v)
\end{aligned}
\quad \quad \, 
\partial_u : \, \begin{aligned}
  x_u + y_u & = v \\
  x_u y + x y_u & = 1 
\end{aligned}
\quad \, \partial_v : \,  
\begin{aligned}
  x_v + y_v & = u \\
  x_v y + x y+v & = -1 
\end{aligned}
\]
\[
\begin{aligned}
  \left[ \begin{matrix} 1 & 1 \\ y & x \end{matrix} \right]\left[ \begin{matrix} x_u \\ y_u \end{matrix} \right] & = \left[ \begin{matrix} v \\ 1 \end{matrix} \right] \\
  \left[ \begin{matrix} 1 & 1 \\ y & x \end{matrix} \right]\left[ \begin{matrix} x_v \\ y_v \end{matrix} \right] & = \left[ \begin{matrix} u \\ -1 \end{matrix} \right]
\end{aligned} \quad \quad \, 
\begin{aligned}
  \frac{1}{ x- y} \left[ \begin{matrix} x &  -1 \\ -y & 1 \end{matrix} \right]\left[ \begin{matrix} v \\ 1 \end{matrix} \right] & = \left( \begin{matrix} xv - 1 \\ -vy + 1 \end{matrix} \right) \left( \frac{1}{x-y} \right) \\
  \frac{1}{x-y} \left[ \begin{matrix} x & -1 \\ - y & 1 \end{matrix} \right] \left[ \begin{matrix} u \\ -1 \end{matrix} \right] & = \left[ \begin{matrix} ux + 1 \\ -uy -1 \end{matrix} \right]\frac{1}{x-y}
\end{aligned}
\]
\[
\boxed{ \begin{aligned} x_u & = \frac{1}{x-y} (xv-1) \\ y_u & = \frac{-vy + 1 }{ x-y} \end{aligned} \quad \quad \, \begin{aligned} x_v & = \frac{1}{x-y} (ux +1) \\ y_v & = \frac{1}{x-y}(-uy - 1) \end{aligned} }
\]

\exercisehead{5}  Given 
\[
\begin{aligned}
  & F(u,v) = 0 \\
  & u = u(x,y,z) = xy \\ 
  & v = v(x,y,z) = \sqrt{ x^2 + z^2 }
\end{aligned} \quad \quad \,
\begin{aligned}
  \partial_x u & = y \\
 \partial_y u & = x \\
 \partial_z u & = 0 \\
\end{aligned}
\quad \quad \, 
\begin{aligned}
  \partial_x v & = \frac{ 1}{ 2 \sqrt{ x^2 + z^2 } } (2x) = \frac{x}{ \sqrt{ x^2 + z^2 }} \\
  \partial_y v & = 0 \\
  \partial_z v & = \frac{z}{ \sqrt{ x^2 + z^2 } }
\end{aligned}
\]
\[
\begin{aligned}
  & \partial_x f = \partial_x u \partial_u F + \partial_x v \partial_v F = y \partial_u F + \frac{x}{v} \partial_v F \\
  & \partial_y f = \partial_y u \partial_u F + \partial_y v \partial_v F = x \partial_u F  \\
  & \partial_z f = \partial_z u \partial_u F + \partial_z v \partial_v F = \frac{z}{v} \partial_v F 
\end{aligned}
\]
Since $F = f = 0$, $\nabla f \cdot R' = 0$, so $\nabla f$ is a normal vector to this surface.  

We're given
\[
x = 1 , \, y = 1 , \, z = \sqrt{3} \quad \quad \, 
\begin{aligned}
  & D_1 F(1,2) = 1 \\
  & D_2 F(1,2) = 2 
\end{aligned}
\]
so then
\[
\begin{aligned}
  \nabla f & = (y \partial_u F + \frac{x}{v} \partial_v F , x \partial_u F, \frac{z}{v} \partial_v F ) = \\
  & = (1 + \frac{1}{2} 2 , 1(1) , \frac{\sqrt{3}}{2} 2 ) =\boxed{ (2,1,\sqrt{3}) }  \\
  & \Longrightarrow \frac{ (2,1,\sqrt{3} ) }{ 2 \sqrt{2} } = \boxed{ \left( \frac{1}{\sqrt{2}} , \frac{1}{ 2 \sqrt{2}}, \frac{1}{2} \sqrt{ \frac{3}{2} } \right) }
\end{aligned}
\]

\exercisehead{6} 
\[
\begin{aligned}
  & x^2 - y \cos{(uv)} + z^2 = 0 \\
  & x^2 + y^2 - \sin{ (uv)} + 2z^2  = 2 \\
  & xy - \sin{u} \cos{v} + z = 0 
\end{aligned} \quad \quad \, 
\begin{aligned}
  & x = x(u,v) \\ 
  & y = y(u,v) \\
  & z = z(u,v) 
\end{aligned} \quad \quad \, \text{ we want } \begin{aligned} & \partial_u x \\ & \partial_v x \end{aligned} \text{ at } \begin{aligned}
x = y & = 1 \\ u & = \pi/2 \\ v & = 0 \\ z & = 0 \end{aligned} 
\]
\[
\begin{gathered}
\partial_u \, : \, \begin{aligned} & 2xx_u - y_u \cos{(uv)} + y \sin{(uv)} v + 2zz_u = 0 \\
 & 2x x_u + 2y y_u - \cos{(uv)} (v) + 4 z z_u = 0 \\ & x_u y + xy_u - \cos{u}\cos{v} + z_u = 0 \end{aligned} \text{ or } \\
(2x,2x, y) x_u + (-\cos{(uv)},2y,x) y_u + (2z,4z,1) z_u = (-y\sin{(uv)}v, v\cos{(uv)}, \cos{u} \cos{v} )
\end{gathered}
\]
\[
\begin{gathered}
  x_u = \frac{ \left| \begin{matrix} -y \sin{(uv)}v & v \cos{(uv)} & \cos{u} \cos{v} \\ -\cos{(uv)} & 2y & x \\ 2z & 4z & 1 \end{matrix} \right| }{ \left| \begin{matrix} 2x & 2x & y \\ -\cos{(uv)} & 2y & x \\ 2z & 4z & 1 \end{matrix} \right| }  \\
  \text{ Note that } -y\sin{(uv)} v = v\cos{(uv)} = \cos{u}\cos{v} = 0 \\
  \Longrightarrow x_u = 0 
\end{gathered}
\]
\[
\begin{gathered}
  \partial_v \, : \, \begin{aligned} & 2xx_v - y_v \cos{(uv)} + y \sin{(uv)} u + 2zz_v = 0 \\ & 2xx_v  + 2 y y_v - \cos{(uv)} u + 4zz_v = 0 \\ & x_v y + xy_v + \sin{u} \sin{v} + z_v = 0 \end{aligned} \text{ or } \\
  (2x,2x,y)x_v + (-\cos{(uv)} , 2y, x ) y_v + (2z,4z,1) z_v = (-y\sin{(uv)} u, \cos{(uv)} u , -\sin{u} \sin{v} ) 
\end{gathered}
\]
\[
\begin{aligned}
  x_v & = \frac{ \left| \begin{matrix} -yu \sin{(uv)} & u \cos{(uv)} & - \sin{u} \sin{v} \\ -\cos{(uv)} & 2y & x \\ 2z & 4z & 1 \end{matrix} \right| }{ \left| \begin{matrix} 2x & 2x & y \\ - \cos{(uv) } & 2y & x \\ 2z & 4z & 1 \end{matrix} \right| }  = \frac{ \left| \begin{matrix} 0 & \pi/2 & 0 \\ -1 & 2 & 1 \\ 0 & 0 & 1 \end{matrix} \right| }{ \left| \begin{matrix} 2 & 2 & 1 \\ -1 & 2 & 1 \\ 0 & 0 & 1 \end{matrix} \right| } \\ & = \boxed{ \pi/12}
\end{aligned}
\]

\section*{ 9.13 Exercises - Maxima, minima, and saddle points.  Second-order Taylor formula for scalar fields.  The nature of a stationary point determined by the eigenvalues of the Hessian matrix.  Second-derivative test for extrema of functions of two variables.  }

\exercisehead{1} $z= x^2 + (y-1)^2$
\[
\begin{gathered}
  \begin{aligned}
    & f(x,y) = x^2 + (y-1)^2 \\ 
    & \nabla f = (2x,2(y-1)) =0 \text{ where } (x,y) = (0,1) 
  \end{aligned} \quad \, 
f \geq 0 \text{ and } f= 0 \text{ when } (x,y) = (0,1)
\end{gathered}
\]
$(0,1)$ is an abs. min.  

\exercisehead{2} $z=x^2 - (y-1)^2$
\[
\nabla f = (2x, -2(y-1)) = 0 \text{ when } (x,y) = (0,1) \quad \, 
\begin{aligned}
  & \text{ For $(x,y)$ } = (t,1), \, f(t,1) = t^2 \geq 0 \\ 
  & \text{ For $(x,y)$ } = (0,1 +\delta), \, f(0,1+\delta) = -\delta^2 < 0 
\end{aligned}
\]
So $(0,1)$ is a saddle pt.  

\exercisehead{3} $z = 1 + x^2 - y^2$ 
\[
\nabla f = (2x,-2y) =0 \text{ when } (x,y) = (0,0) \quad \, \begin{aligned} & \text{ For } (x,y) = (0,u), \, z = 1 + -u^2 \leq 1 \\ & \text{ For } (x,y) = (t,0), \, z = 1 + t^2 \geq 1 \end{aligned}
\]
So $(0,0)$ is a saddel pt.  

\exercisehead{4} $z = (x-y+1)^2$
\[
\begin{gathered}
  \nabla f = (2(x-y+1), 2(x-y+1)(-1)) = 0 \text{ when } y = x + 1 \\ 
  f \geq 0 \, \forall \, (x,y), \text{ so } (x,x+1) \text{ is an abs. min. since $f(x,x+1) =0$ }
\end{gathered}
\]

\exercisehead{5} $ z= 2x^2 - xy - 3y^2 - 3x +7y$  
\[
\nabla f = (4x - y -2, -x + 2y +1) =0 \text{ where } \begin{aligned} y & = 4x - 2 \\ y & = \frac{x-1}{2} \end{aligned} \text{ so } \begin{aligned} x & = 3/7 \\ y & = - 2/7 \end{aligned}
\]
\[
H = \left[ \begin{matrix} 4 & -1 \\ -1 & 2 \end{matrix} \right] \Longrightarrow (\lambda -4)(\lambda -2) - 1 = (\lambda -7)(\lambda+1)
\]
So we have a saddle point at $(3/7,-2/7)$.

\exercisehead{6} For $z = x^2 - xy + y^2 - 2x+y$, 
\[
\nabla f = (2x - y-2, -x+2y + 1 ) =0 
\]
so the critical point is at $(x,y) = (1,0)$.  

The Hessian matrix is 
\[
H = \left[ \begin{matrix} 2 &  -1 \\ -1 & 2 \end{matrix} \right]
\]
So $\lambda =  1, +3$ are the eigenvalues.  $(1,0)$ is a relative minimum.  

\exercisehead{7} For $z = x^3- 3xy^2 + y^3$, 
\[
\nabla f  =(3x^2 - 3y^2, -6xy + 3y^2) = 3(x^2- y^2, -2xy + y^2) = 0
\]
Then because $y^2 - 2xy=0$, $(x,y) = (0,0)$.  

The Hessian matrix is 
\[
H = \left[ \begin{matrix} 6x & - 6 y \\ -6y & - 6x + 6y \end{matrix} \right]
\]

For $(x,y) = (0,0)$, by theorem, the Hessian matrix doesn't give a definite conclusion.  Then resort to the definitions of saddle points, relative minima, relative maxima.  

Now $z = x^3-  3xy^2 + y^3 = y^2(y-3x) + x^3$.  $z(0,0) = 0$.  

Consider $(x,y) = (\delta, \epsilon)$.  Then \\

$z = \epsilon^2(\epsilon -3 \delta) + \delta^3$

So for $y=3x$,  \\

$\forall \, E > 0 , \, \exists \delta >0$ s.t. \\
\quad \quad \, if $ 0 < x < \delta $, then $0<z < 2 \delta = E(\delta)$, \\
\quad \quad \, if $- \delta < x < 0$, then $-E(\delta) = -2\delta^3 < z < 0$

So in the neighborhood of $(0,0)$, there exist pts. above and below $z=0$.  By definition, $(0,0)$ is a saddle point.  

\exercisehead{8} For $z = x^2 y^3 (6-x-y)$,
\[
\nabla f = (12 xy^3 - 3x^2 y^3 - 2xy^4, 18 x^2 y^2 - 3x^3 y^2 - 4x^2 y^3) = 0 
\]
With
\[
\begin{aligned}
  & 12 xy^3 - 3x^2 y ^3 - 2xy^4 = xy^3(12-3x - 2y) = 0 \\
  & x^2 y ^2 ( 18 - 3x - 4y ) = 0 
\end{aligned}
\]
So $(x,y) = (2,3)$ or $(x,0)$, $(0,y)$ are the critical points.  

The Hessian matrix is 
\[
H = \left[ \begin{matrix} 12 y^3 - 6xy^3 - 2y^4 & 36 xy^2 - 9x^2 y^2 - 8xy^3 \\ 36 xy^2 - 9x^2 y^2 - 8xy^3 & 36 x^2  y - 6 x^3 y - 12 x^2 y^2 \end{matrix} \right]
\]

Now
\[
\begin{aligned}
  & A = D_{1,1}f = 2y^3 (6-3x - y) \\ 
  & B = D_{1,2}f = xy^2 (36 - 9x - 8y) \\ 
  & C = D_{2,2}f = 6x^2 y(6-x-2y)
\end{aligned}
\]
For $(2,3)$, $\Delta < 0$.  $(2,3)$ is a saddle point.  

Looking at the Hessian matrix, the definitions must be used to determine if the critical points are saddle points, relative maxima, or relative minima.  

Consider $(x,0)$, $z(x,0) = 0$.  

Consider $|y| < \delta_2$.  

$z = y^3 x^2(6-x-y)$

Choose $\delta_2$, s.t. $\delta_2 < |6-x|$ (since $\delta_2$ is arbitrarily small, we can make this choice).  

Then for fixed $x$, either $6-x < 0$, or $6-x >0$.  

But for $|y| < \delta_2$, $y >0$, or $y<0$, either $z<0$, $z>0$, since $y$ or $-y$ allowed, for $|y| < \delta_2$.  
\[
|z| = |y^3| |x^2| |6-x-y| < \delta_2^3 2 |6-x| x^2 = E(x,\delta_2)
\]

$\forall \, E > 0, \, \exists \delta_2 >0$ s.t. for $|y| < \delta_2$, $|z| < E(x,\delta_2)$ and in this neighborhood, $\exists \, (x,y)$ s.t. $z<0$ and $(x,y)$ s.t. $z>0$.  

$(x,0)$ are saddle points.  

$(0,y)$, $z(0,y) =0$.  

For $|x| < \delta_1$, 

$z = x^2  y^3 (6-y-x)$.  

Consider $\delta_1 < |6-y|$.  

For $y< 0$, $y>6$, $z<0$ for infinitesimal neighborhood about $z$ (with $\delta_1 < |6-y|$).  

For $(0,y)$, $y<0$, $y>6$, $z(0,y)$ a relative minimum.  

Likewise, for $0<y<6$, $z>0$ for infinitesimal neighborhood about $z$, (with $\delta_1 < |6-y|$), so $z(0,y)$ a relative maximum.  

For $(0,6)$, $z(x,6) = 216 x^2 ( -x) = -216 x^3$.  $\forall \, E > 0$, $\exists \, \delta_1 >0$ s.t. $|z| < E$ when $|x| < \delta_1$, \\

For $|x| < \delta_1$, both $x,-x$ fulfill the condition, so that \\
\quad \, $\exists$ pts. $(x,6)$, $(-x,6)$ in this neighborhood such that $z<0$, $z>0$, respectively.

$(0,6)$ a saddle point.  

\exercisehead{9} $z = x^3 + y^3 - 3xy$
\[
\begin{gathered}
  \nabla f = (3x^2 - 3y, 3y^2 - 3x) = 0 \Longrightarrow \begin{aligned} x^2 = y \\ y^2 = x \end{aligned} \Longrightarrow (0,0), (1,1) \\ 
|Df| = \left| \begin{matrix} 6x & -3 \\ -3 7 6y \end{matrix} \right| = 36xy - 9 
\end{gathered}
\]
\[
\begin{gathered}
  (1,1) \text{ minimum since } Df(1,1) = 27 \text{ and } D_{1,1}f(1,1) = 6 > 0 \\
  (0,0) \text{ saddle pt. since } Df(0,0) = -9 < 0 
\end{gathered}
\]

\exercisehead{10} $z= \sin{x} \cosh{y} $
\[
\begin{gathered}
  \nabla f = (\cos{x} \cosh{y}, \sin{x} \sinh{y} ) \quad \quad \, |Df| = \left| \begin{matrix} -\sin{x} \cosh{y} & \cos{x}\sinh{y} \\ \cos{x} \sinh{y} & \sin{x} \cosh{y} \end{matrix} \right| = -\sin^2{x} \cosh^2{y} + -\cos^2{x} \sinh^2{y}  \\
  \nabla f =0 \Longrightarrow (x,y) = \left( \left( \frac{2j-1}{2} \right) \pi , 0 \right) \\ 
  Df\left( \left( \frac{2j-1}{2} \right) \pi , 0 \right) = -1  \quad \Longrightarrow  \left( \left( \frac{2j-1}{2} \right) \pi , 0 \right) \text{ is a saddle pt. }
\end{gathered}
\]
\exercisehead{11} $z= e^{(2x + 3y)}(8x^2 - 6xy + 3y^2) = fe^g$.  It helps alot to make these notation substitutions.  
\[
\begin{gathered}
  \begin{aligned}
    f_x = 16x - 6y \\
    f_y = -6x + 6y 
  \end{aligned} \quad \quad \nabla z = (f_x e^g + 2f e^g, f_y e^g + 3fe^g ) \\
  \xrightarrow{ \nabla z}  \begin{aligned} (f_x + 2f) e^g = 0 \\ (f_y + 3f)e^g = 0 \end{aligned} \Longrightarrow (0,0), \, (\frac{-1}{4}, \frac{-1}{2} )  
\end{gathered}
\]
\[
\begin{gathered}
  D_{ij}z = \left| \begin{matrix} 16e^g + 4f_x e^g + 4 fe^g & -6e^g + 2f_y e^g + 3f_x e^g + 6f e^g \\ -6e^g + 3f_x e^g + 2f_y e^g + 6fe^g & 6e^g + 6f_y e^g + 9f e^g \end{matrix} \right| \\
  D_{ij}z(0,0) = \left| \begin{matrix} 16 & -6 \\ -6 & 6 \end{matrix} \right| = 96 - 36 = 60  \quad \quad \, \text{ $(0,0)$ is a minimum } \\
  D_{ij}z(\frac{-1}{4}, \frac{-1}{2}) = e^{-4} \left| \begin{matrix} 16 & -9 \\ -6 & \frac{-3}{2} \end{matrix} \right| = e^{-4}(-24-54) < 0 \quad \quad \, \text{ $(\frac{-1}{4}, \frac{-1}{2})$ is a saddle pt. }
\end{gathered}
\]

\exercisehead{12} $z= (5x + 7y -25) e^{-(x^2 + xy+ y^2) } = f e^{-g}$.  Using these shorthand, substitution notation helps with the calculation.  
\[
\begin{gathered}
  \nabla z = ( 5e^{-g} + fe^{-g}(-2x-y), 7e^{-g} + fe^{-g}(-x-y) ) \\ 
  \nabla z = 0 \Longrightarrow \begin{aligned} 5 + (-2x-y)f = 0 \\ 7 + (-x-2y)f = 0 \end{aligned} \Longrightarrow \boxed{ (x,y) = (1,3), \left( \frac{-1}{26}, \frac{-3}{26} \right) }
\end{gathered}
\]
\[
\begin{gathered}
  D_{ij} z = \\ 
e^{-g} \left[ \begin{matrix} 5(-2-y) 2 + f (-2x-y)^2 + f (-2) & 7 (-2x-y) + 5 (-x-2y) + f (-x-2y)(-2x -y) - f \\ 7 (-2x-y) + 5 (-x-2y) + f (-x-2y)(-2x -y) - f & 7 (-x-2y) 2 + (-x-2y)^2 f + -2f \end{matrix} \right] \\
  D_{ij} z(1,3) = e^{-2g} \left| \begin{matrix} -27 & -36 \\ -36 & -51 \end{matrix} \right| > 0 \Longrightarrow \text{ $(1,3)$ is a maximum } \\ 
  D_{ij} z(\frac{-1}{26}, \frac{-3}{26} ) = \left| \begin{matrix} \frac{25}{26} + 52 & \frac{35}{26} + 26 \\ \frac{35}{26} + 26 & \frac{49}{26} +52 \end{matrix} \right| > 0 \Longrightarrow \text{ $(\frac{-1}{26}, \frac{-3}{26} )$ is a minimum.} 
\end{gathered}
\]

\exercisehead{13} $z= \sin{x} \sin{y} \sin{ (x+y) }$, \quad $0 \leq x \leq \pi$, \, $0\leq y \leq \pi$  


\exercisehead{21} \emph{Method of least squares.}  Given $n$ distinct numbers $x_1, \dots, x_n$ and $n$ further numbers $y_1, \dots, y_n$, and $f(x) = ax +b$ fitting form,
\[
\begin{gathered}
  E(a,b) = \sum_{i=1}^n (f(x_i) -y_i)^2 = \sum_{i=1}^n (ax_i +b - y_i)^2 \\ 
  \nabla E = 0 \Longrightarrow  \begin{aligned}
    \partial_a E & = \sum_{i=1}^n 2 (ax_i + b - y_i) x_i = 2 \left( a \sum x_i^2 + b \sum x_i - \sum y_i x_i \right) = 0 \\
    \partial_b E & = \sum_{i=1}^n 2 (ax_i + b- y_i) = 2 \left( a \sum x_i + nb + - \sum y_i \right) = 0 
  \end{aligned}
\end{gathered}
\]
 
\[
\begin{aligned}
  X^2 & = \sum x_i^2 \\ 
  \overline{X} & = \frac{1}{n} \sum x_i \\ 
  \overline{Y} & = \frac{1}{n} \sum y_i
\end{aligned} \quad \quad \, \Longrightarrow \left[ \begin{matrix} X^2 & n \overline{X} \\ n \overline{X} & n \end{matrix} \right] \left[ \begin{matrix} a \\ b \end{matrix} \right] = \left[ \begin{matrix} \sum y_i x_i \\ n \overline{Y} \end{matrix} \right]
\]
\[
\Longrightarrow \left[ \begin{matrix} a \\ b \end{matrix} \right] = \left( \frac{1}{ nX^2 - n^2 \overline{X}^2 } \right) \left[ \begin{matrix} n & - n\overline{X} \\ -n \overline{X} & X^2 \end{matrix} \right] \left[ \begin{matrix} \sum y_i x_i \\ n \overline{Y} \end{matrix} \right] = \left[ \begin{matrix} n \sum y_i x _i - n^2 \overline{X} \overline{Y} \\ -n \overline{X} \sum y_i x_i + n X^2 \overline{Y} \end{matrix} \right] \left( \frac{1}{ nX^2 - n^2 \overline{X}^2 } \right)
\]
Suppose $ \begin{aligned} 
  u_i & = x_i - \overline{X} \\ 
  u_i^2 & = x_i^2 - 2x_i \overline{X} + \overline{X}^2 \quad \quad \, \Longrightarrow \sum u_i^2 = X^2 - 2n\overline{X}^2 + n\overline{X}^2 = X^2 - n\overline{X}^2 \\ 
  \sum y_i u_i & = \sum y_i (x_i - \overline{X} ) = \sum y_i x_i - \overline{X} \overline{Y} n 
\end{aligned}$
\[
\Longrightarrow a = \sum y_i u_i / \sum u_i^2 
\]
Then use $an\overline{X} + nb - n\overline{Y} = 0$ or $b = \overline{Y} -a\overline{X}$ to get $b$.  

\exercisehead{22} $f(x,y) = ax + by +c$.  $E(a,b,c) = \sum_{i=1}^n (f(x_i,y_i) - z_i)^2 = \sum_{i=1}^n (ax_i + by_i + c - z_i)^2$.  $(x_i,y_i)$ are $n$ given distinct pts.  $z_1, \dots, z_n$ are $n$ given real numbers.  
\[
\begin{aligned}
  & \partial_a E = 0 = 2 \sum (ax_i + by_i +c - z_i ) x_i \Longrightarrow & a \sum x_i^2 + b \sum x_i y_i + c \sum x_i - \sum z_i x_i = 0 \\
  & \partial_b E = 0 = 2 \sum (ax_i + b y_i + c - z_i ) y_i \Longrightarrow & a \sum x_i y_i + b \sum y_i^2 + c \sum y_i - \sum z_i y_i = 0 \\
  & \partial_c E = 0 = 2 \sum (ax_i + b y_i + c - z_i ) \Longrightarrow & a \sum x_i + b \sum y_i + nc - \sum z_i = 0  \text{ or } c = \overline{Z} - a\overline{X} - b \overline{Y}
\end{aligned}
\]
Then rewrite the above equations substituting the expression for $c$.  
\[
\begin{gathered}
  aX^2 + b \sum x_i y_i + cn \overline{X} = \sum z_i x_i = aX^2 + b \sum x_i y_i + n \overline{X} (\overline{Z} - a\overline{X} - b\overline{Y}) = \\
  = a(X^2 - n\overline{X}^2 ) + b ( \sum x_i y_i - n \overline{X} \overline{Y}) + n\overline{X}\overline{Z} \\ 
  a\sum x_i y_i  + bY^2 + cn \overline{Y} = \sum z_i y_i = a ( \sum x_i y_i - n\overline{X} \overline{Y}) + b (Y^2 - n \overline{Y}^2 ) + n\overline{Y} \overline{Z} 
\end{gathered}
\]
Then \[
\left[ \begin{matrix} X^2 - n \overline{X}^2 & \sum x_i y_i - n\overline{X} \overline{Y} \\ \sum x_i y_i - n \overline{X} \overline{Y} & Y^2 - n\overline{Y}^2 \end{matrix} \right]\left[ \begin{matrix} a \\ b \end{matrix} \right] = \left[ \begin{matrix} \sum z_i x_i - n \overline{X} \overline{Z} \\ \sum z_i y_i - n \overline{Y} \overline{Z} \end{matrix} \right] = \left[ \begin{matrix} \sum u_i z_i \\ \sum v_i z_i \end{matrix} \right]
\]

Note that for $u_i = x_i - \overline{X}$, $v_i = y_i - \overline{Y}$, we already showed in the previous exercise, Exercise 21, that $ \begin{aligned} X^2 - n\overline{X}^2  & = \sum u_i^2 \\ Y^2 - n\overline{Y}^2 & = \sum v_i^2 \end{aligned} $
\[
\sum u_i v_i = \sum (x_i-\overline{X})(y_i - \overline{Y}) = \sum x_i y_i - n \overline{X} \overline{Y} - n \overline{X} \overline{Y} + \overline{X} \overline{Y} n = \sum x_i y_i - n \overline{X} \overline{Y}
\]

So let $\Delta = \left| \begin{matrix} \sum u_i^2 & \sum u_i v_i \\ \sum u_i v_i & \sum v_i^2 \end{matrix} \right|$ and use Cramer's rule to obtain
\[
\begin{aligned}
  & \boxed{ a = \frac{1}{ \Delta } \left| \begin{matrix} \sum u_i z_i & \sum u_i v_i \\ \sum v_i z_i & \sum v_i^2 \end{matrix} \right| } \\ 
  &  \boxed{ b = \frac{1}{\Delta } \left|  \begin{matrix} \sum v_i z_i & \sum u_i v_i \\ \sum u_i z_i & \sum u_i^2 \end{matrix} \right| } \\
  & \boxed{ c = \overline{Z} - a \overline{X} - b \overline{Y} }
\end{aligned}
\]

\exercisehead{23} $z_1, \dots, z_n$ are $n$ distinct pts. in $m$-space.  \\
Let $x\in \mathbb{R}^m$, let $f(x) = \sum_{k=1}^n \| x - z_k \|^2 = \sum_{k=1}^n \sum_{j=1}^m (x_j - (z_k)_j)^2$ 
\[
\begin{gathered}
  \text{ Now } \partial_i f = \sum_{k=1}^n 2 (x_i - (z_k)_i) \\ 
  \text{ Conditions we want: } \nabla f = 0 \Longrightarrow \sum_{k=1}^n (x_i - (z_k)_i) = 0 \Longrightarrow nx_i - \sum_{k=1}^n (z_k)_i =0 \\ 
  \Longrightarrow x_i = \frac{1}{n} \sum_{k=1}^n (z_k)_i \text{ or } x = \frac{1}{n} \sum_{k=1}^n z_k \\
  \partial_{ij} f = \partial_i \sum_{k=1}^n 2 (x_j - (z_k)_j) = \sum_{k=1}^n 2(1) \delta_{ij} = 2n \delta_{ij}
\end{gathered}
\]
$H$ is diagonalized and $\lambda_j > 0$, $\forall \, j = 1, \dot, m$.  By Thm., $a = \frac{1}{n} \sum_{k=1}^n z_k$, (the centroid) is a minimum.  

\exercisehead{25} $f(x,y,z) = x^4 + y^4 + z^4 - 4xyz$.  
\[
\nabla f = (4x^3 - 4 yz, 4 y^3 + -4xz ,4 z^3 - 4xy) = 0 = (x^3 - yz, y^3 -xz, z^3- xy) \quad \quad \, \Longrightarrow \begin{aligned} x^3 & = yz \\ y^3 & = xz \\ z^3 & = xy \end{aligned} \quad \, \text{ thus } \nabla f (1,1,1) = 0 
\]
\[
\begin{gathered}
  H = \left[ \begin{matrix} 12 x^2 & -4 z & -4 y \\ -4 z & 12 y^2 & -4x \\ -4 y & -4x & 12 z^2 \end{matrix} \right] = 4 \left[ \begin{matrix} 3x^2 & -z & -y \\ -z & 3y^2 & -x \\ -y & -x & 3z^2 \end{matrix} \right]  \quad \quad \, H(a) = 4 \left[ \begin{matrix} 3 & -1 & -1 \\ -1 & 3 & -1 \\ -1 & -1 & 3 \end{matrix} \right]  \\  
  | \lambda I - H | = \left| \begin{matrix} \lambda -12 & 4 & 4 \\ 4 & \lambda -12 & 4 \\ 4 & 4 & \lambda -12 \end{matrix} \right| = (\lambda - 16)^2 (\lambda -4) = 0 \\
  \Longrightarrow \lambda = 16, 4
\end{gathered}
\]

$a=(1,1,1)$ is a minimum, by theorem.  

\section*{ 9.15 Exercises - Extrema with constraints.  Lagrange's multipliers}

\exercisehead{1} Given $f(x,y)= z= xy$ and $g(x,y) = 0 = x+y - 1 $  
\[
\begin{gathered}
  \begin{aligned}
    \nabla f & = (y,x) \\ 
    \nabla g & = (1,1)
  \end{aligned} \quad \, \Longrightarrow \nabla f = \lambda \nabla g = (y,x) = \lambda (1,1) = (1-x,x) \\
  \Longrightarrow 1 - x = x \text{ so that } \begin{aligned} x & = \frac{1}{2} \\ y & = \frac{1}{2} \end{aligned}  \quad \quad \, 
\boxed{ z= \frac{1}{4} }
\end{gathered}
\]

\exercisehead{2} 
\[
\begin{aligned}
  f(x,y) & = r = \sqrt{ x^2 +y^2 } \\ 
  g(x,y) & = 5x^2 + 6xy + 5y^2 - 8 
\end{aligned} \quad \quad \, \begin{aligned} \nabla f & = \frac{ (x,y) }{r} = \lambda (10x + 6y, 10 y + 6x) \\ \nabla g & = (10x + 6y , 10y + 6x) \end{aligned}
\]
\[
\begin{gathered}
  \nabla f = \frac{ (x,y)}{r} = \lambda (10x + 6y, 10y + 6x) \quad \quad \, \Longrightarrow \frac{x}{r} \left( \frac{1}{10x+6y } \right) = \frac{y}{r} \left( \frac{1}{ 10y + 6x} \right) \text{ or } x^2 = y^2  \\
  g(x, \pm x) = 5x^2 \pm 6 x^2 + 5x^2 -8 = 0 \Longrightarrow 10x^2 \pm 6x^2 =8 \text{ or } x = \pm \frac{1}{\sqrt{2}}, \, \pm \sqrt{2} 
\end{gathered}
\]
\[
\begin{aligned}
  & r \text{ maximum }, 2, \text{ when } (\sqrt{2}, \pm \sqrt{2}), (-\sqrt{2}, \pm \sqrt{2}) \\ 
  & r \text{ minimum }, 1, \text{ when } ( \frac{1}{\sqrt{2}}, \pm \frac{1}{\sqrt{2}} ), ( \frac{1}{\sqrt{2}}, \pm \frac{1}{\sqrt{2}} )
\end{aligned}
\]
\exercisehead{3} $a,b>0$
\begin{enumerate}
\item \[
\begin{aligned}
  f & = z = \frac{x}{a} + \frac{y}{b} \\ 
  \nabla f & = \left( \frac{1}{a}, \frac{1}{b} \right) 
\end{aligned}  \quad \quad \, \begin{aligned} g(x,y) & = x^2 + y^2 = 1 \\ \nabla g & = (2x, 2y) \end{aligned}
\]
\[
\begin{gathered}
  \nabla f = \lambda \nabla g \Longrightarrow \begin{aligned} \frac{1}{a} & = \lambda 2x \\ \frac{1}{b} & = \lambda 2y \end{aligned} \text{ or } \frac{y}{x} = \frac{a}{b} \quad \quad \,  
 \text{ so then } x^2 \left( 1 + \frac{a^2}{b^2} \right) = 1 \text{ or } \begin{aligned} x & = \frac{ \pm b }{ \sqrt{ a^2 + b^2 }} \\ y & = \frac{ \pm a }{ \sqrt{ a^2 +b^2 } } \end{aligned} 
\end{gathered}
\]
\[
\boxed{ z = \frac{ \sqrt{ b^2 + a^2 }}{ ab} , \, - \frac{ \sqrt{ b^2 + a^2 }}{ab}  }
\]
Geometrically, consider lines of $bz - \frac{b}{a} x = y$ inside a circular region of $x^2 + y^2 =1$.  
\item \[
 \begin{aligned}
   f & = z = x^2 + y^2 \\ 
   \nabla f & = 2 (x,y) 
 \end{aligned} \quad \quad \, \begin{aligned} g(x,y) & = \frac{x}{a} + \frac{y}{b} -1 \\ \nabla g & = \left( \frac{1}{a}, \frac{1}{b} \right) \end{aligned} \quad \quad \,
  \nabla f = \lambda \nabla g \Longrightarrow 2(x,y) = \lambda \left( \frac{1}{a}, \frac{1}{b} \right)  \text{ or } \frac{a}{b} = \frac{y}{x} 
\]
\[
\begin{gathered}
  \text{ Plug back into $g(x,y)$:} \Longrightarrow \begin{aligned} x & = \frac{ ab^2 }{ a^2 + b^2 } \\ y & = \frac{ ba^2}{a^2 + b^2 } \end{aligned} 
\quad \quad \,   \text{ minimum at } \left( \frac{ ab^2}{b^2 + a^2}, \frac{ ba^2 }{ a^2 + b^2 } \right) \quad \, z = \frac{ a^2 b^2 }{ a^2 + b^2 }
\end{gathered}
\]
Geometrically, consider points on a line defined by $g(x,y)$, $y = b - \frac{bx}{a}$.  Then $f$ defines circles of increasing radius.  Obviously, we can make the radius for $f$, $z$, as large as we want.  
\end{enumerate} 

\exercisehead{4}

\exercisehead{5} 
\[
\begin{gathered}
  \begin{aligned}
    f(x,y,z) & = x - 2y + 2z \\ 
    \nabla f & = (1,-2,2) 
  \end{aligned} \quad \quad \begin{aligned} g & = x^2 + y^2 + z^2 -1 = 0 \\ \nabla g & = (2x,2y,2z) \end{aligned} \xrightarrow{ \nabla f = \lambda \nabla g } \frac{1}{2x} = \frac{-1}{y} = \frac{1}{z} \\ 
  \begin{aligned} 2x & = z \\ z & = -y \end{aligned} \quad \Longrightarrow z = \frac{ \pm 2}{3}  
\end{gathered}
\]
\[
\begin{aligned}
  f\left( \frac{1}{3}, \frac{-2}{3}, \frac{2}{3} \right) & = 3 \\ 
  f\left( \frac{-1}{3}, \frac{2}{3}, \frac{-2}{3} \right) & = -3 
\end{aligned}
\]

\exercisehead{6}  
\[
\begin{aligned}
  f & = \sqrt{ x^2 +y^2 + z^2 } \\ 
  \nabla f & = \frac{ (x,y,z) }{4} \end{aligned} \quad \quad \, \begin{aligned} g & = z^2 - xy - 1 \\ \nabla g & = (-y, -x, 2z) \end{aligned}
\]
\[
\begin{gathered}
  \xrightarrow{ \nabla f = \lambda \nabla g } \frac{x}{-y} = \frac{y}{ -x} = \frac{1}{2} \Longrightarrow \begin{aligned} x^2 & = y^2 \\ y & = \frac{-x}{2} \end{aligned} \text{ so } x= y = 0 \\ 
  \Longrightarrow z = 1,-1 \text{ or } (0,0,\pm 1) \text{ are the points where the distance is minimized. } 
\end{gathered}
\]

\exercisehead{7} \[
\begin{aligned}
f(x,y) & = \sqrt{ (x-1)^2 + y^2 } \\ 
\nabla f & = \frac{ (x-1, y) }{ \sqrt{ (x-1)^2 + y^2 } } \end{aligned} \quad \, \begin{aligned} g(x,y) & = 4x- y^2 \\ \nabla g  & = (4,-y) \end{aligned}  \quad \, \xrightarrow{ \nabla f = \lambda \nabla g } \begin{aligned}
  \frac{ (x-1)}{\sqrt{ (x-1)^2 + y^2 } } & = 4 \lambda  \\ \frac{y }{ \sqrt{ (x-1)^2 +y^2  } } & = -2y \lambda \end{aligned}
\]
$x > 0$, but if $ y \neq 0$, the equations imply $x=-1$.  
\[
\Longrightarrow (x,y) = (1,0) \text{ is the point of shortest distance on the parabola to $(1,0)$ }
\]

\exercisehead{8} Given the constraining surfaces
\[
\begin{aligned}
  x^2 - xy + y^2 - z^2 = 1 \\ 
  x^2 + y^2 = 1 
\end{aligned} \text{ or } xy + z^2 = g = 0 
\]
Then we want to minimize $f = \sqrt{ x^2 + y^2 + z^2 }$.  $\nabla f = \frac{(x,y,z)}{f} $ 
\[
\begin{gathered}
  \nabla g_1 = (y,x,2z) \xrightarrow{ \nabla f = \lambda \nabla g } \begin{aligned} \frac{x}{f} = \lambda y \\ \frac{y}{f} = \lambda x \\ \frac{z}{f} = \lambda 2z \end{aligned} \\ 
  \text{ Suppose } z \neq 0, \, \text{ then } \frac{1}{2f} = \lambda \Longrightarrow \begin{aligned} \frac{y}{f} = \frac{x}{2f} \\ \frac{x}{f} = \frac{1}{2f} y \end{aligned} \text{ or } \begin{aligned} y = \frac{x}{2} \\ x = \frac{y}{2} \end{aligned} \text{ Contradiction. }
\end{gathered}
\]
Then $z=0$.  
\[
\begin{gathered}
  \text{ Suppose $x,y \neq 0$} \Longrightarrow \frac{x}{y} = \frac{y}{x} \text{ or } x^2 = y^2 \\ 
  \Longrightarrow 2x^2 = 1 \text{ or } x = \frac{ \pm 1}{\sqrt{2}} \text{ but } z^2 = - xy = 0 \quad \text{ Contradiction.}
\end{gathered}
\]
Then $x=0$ or $y=0$, so that $\lambda = 0$
\[
\boxed{ (0,\pm 1,0), (\pm 1, 0 , 0) }
\]

\exercisehead{9} 
\[
\begin{aligned}
  f(x,y,z) & = x^a y^b z^c \\ 
  \nabla f & = f \left( \frac{a}{x}, \frac{b}{y}, \frac{c}{z} \right)
\end{aligned} \quad \, \begin{aligned}  g & = x + y + z - 1 \\ \nabla g & = (1,1,1) \end{aligned} \xrightarrow{ \nabla f = \lambda \nabla g } \frac{af}{x} = \frac{bf}{y} = \frac{cf}{z} 
\]
If $x,y,z \neq 0$ then 
\[
\begin{aligned} 
  y & = \frac{bx}{a} \\ 
  z & = \frac{cx}{a} \end{aligned} \Longrightarrow x + \frac{bx}{a}  + \frac{cx}{a} = 1 \\ 
\text{ so that the maximum occurs at } (x,y,z) = \frac{ 1}{ a+b+c} (a,b,c) \text{ and } f = \frac{ a^a b^b c^c }{ (a+b+c)^{a+b+c} }
\]

\exercisehead{10} Consider the ellipsoid $\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} - 1 = g_1$.  Then ellipsoid will have the same normal at a point on the ellipsoid as the tangent plane through the same point.  Thus, we want
\[
\nabla g_1 = 2 \left( \frac{x}{a^2}, \frac{y}{b^2}, \frac{z}{c^2} \right)
\]
to be a normal that defines a plane through $(x,y,z)$, that's on the ellipsoid, in the $uvw$ plane.
\[
\Longrightarrow \frac{xu}{a^2} + \frac{yv}{b^2} + \frac{zw}{c^2} = 1 
\]
The volume of the tetrahedron is
\[
\begin{aligned}
  V  = \int_0^{a^2/x} du \int_0^{ \frac{b^2}{y} \left( 1 - \frac{xu}{a^2} \right) } dv \int_0^{ \frac{c^2}{z} \left( 1 - \frac{xu}{a^2} - \frac{yv}{b^2} \right) } dv = \frac{(abc)^2}{6 xyz} \quad \quad \quad \,    \nabla V = \frac{(abc)^2}{6} \left( \frac{-1}{ x^2 y z}, \frac{-1}{ xy^2 z}, \frac{-1}{xyz^2} \right) 
\end{aligned}
\]
\[
\begin{gathered}
  \xrightarrow{  \nabla V = \lambda \nabla g_1 } \begin{aligned} \frac{ (abc)^2 }{6} \left( \frac{-1}{ x^2 y z} \right) = \lambda 2 \frac{x}{a^2} \\  \frac{ (abc)^2 }{6} \left( \frac{-1}{ x y^2 z} \right) = \lambda 2 \frac{y}{b^2} \\   \frac{ (abc)^2 }{6} \left( \frac{-1}{ x y z^2} \right) = \lambda 2 \frac{z}{c^2} \end{aligned} \text{ so } \begin{aligned} y^2 = \left( \frac{bx}{a} \right)^2 \\ z^2 = \left( \frac{c}{a} x \right)^2 \end{aligned} \quad \quad \, 
  \xrightarrow{ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 } \begin{aligned} x = \frac{a}{\sqrt{3}} \\ y = \frac{b}{\sqrt{3}} \\ z = \frac{c}{ \sqrt{3}} \end{aligned} 
\end{gathered}
\]
\[
\boxed{ V = abc \frac{\sqrt{3}}{2} }
\]

\exercisehead{12} Consider the conic section as a quadratic form.  
\[
Ax^2 + 2Bxy + Cy^2 = 1 \text{ where } A > 0 \text{ and } B^2 < AC \quad \Longrightarrow T = \left[ \begin{matrix} A & B \\ B & C \end{matrix} \right]
\]
Note that $det{T} = AC - B^2$, so normalize $T$ by $det{T}$ so to obtain only pure rotation, no ``amplification.''  
\[
\begin{gathered}
  T \to T = \frac{1}{ AC - B^2} \left[ \begin{matrix}  \lambda -A & - B \\ -B & \lambda -C \end{matrix} \right] =0 \Longrightarrow \lambda_{\pm} = \frac{ (A+C) \pm \sqrt{ (A-C)^2 + 4B^2 } }{2 (AC-B^2) } 
\end{gathered}
\]
We don't need to find the eigenvectors.  By theorem, we can find a $C$ s.t. $Y=XC$ and $Y$ are the coordinates in which $T$ is diagonalized.  
\[
\begin{gathered}
\lambda_+ u^2 + \lambda_- v^2 = 1 \Longrightarrow \frac{ u^2}{ 1/\lambda_+ } + \frac{v^2}{ 1/\lambda_- } =1
\end{gathered}
\]
Immediately we recognize this to be the equation of an ellipse.  The $T$ rotation does not amplify distances since $det{T} =1$, and so distances from the origin to the conic section are preserved.  Then we can immediately name the minimum and maximum distances:
\[
M^2, m^2 = 1/ \frac{ (A+C) + \sqrt{ (A-C)^2 + 4B^2 } }{2 (AC-B^2) }, 1/\frac{ (A+C) - \sqrt{ (A-C)^2 + 4B^2 } }{2 (AC-B^2) }  
\]

\exercisehead{13} Let $X = (x,y)$ be a point on the ellipse.  \\
The line is given by the set $\{ (0,4) + s(1,-1) | s\in \mathbb{R} \}$.  \\
The normal to the line is $(1,1)/\sqrt{2}$, so connect a point on the ellipse to the line by a perpendicular distance $t$ by the following:
\[
X = t \frac{ (1,1)}{\sqrt{2} } = (0,4) + s(1,-1) 
\]
so that 
\[
\begin{gathered}
  \frac{ t (1,1) }{ \sqrt{2} } = (0,4) + (s,-s)  - (x,y) = (s-x, 4-s -y) \\ 
  \begin{aligned}
\frac{t}{\sqrt{2}} & = s -x \\ 
\frac{t}{\sqrt{2}} & = 4 - s - y \end{aligned} \Longrightarrow \sqrt{2} t = 4 - x -y \text{ so let } f(x,y) = t = \frac{4- x -y }{ \sqrt{2}} 
\end{gathered}
\]
\[
\begin{gathered}
  \nabla f = \left( \frac{-1}{\sqrt{2}}, \frac{-1}{\sqrt{2}} \right) \quad \quad \, \begin{aligned} g(x,y) & = \frac{x^2}{4} + y^2 - 1 = 0 \\ \nabla g & = \left( \frac{x}{2} , 2y \right) \end{aligned} \quad  \quad \, \Longrightarrow \frac{x}{2} = 2y \quad \quad \, 
  \Longrightarrow 16y^2/4 + y^2 = 5y^2 = 1 
\end{gathered}
\]
Thus, the points that extremize $f$ are $(x,y) = \left( \frac{4}{\sqrt{5}}, \frac{1}{\sqrt{5}} \right), \left( \frac{-4}{\sqrt{5}}, \frac{-1}{\sqrt{5}} \right)$.  
\[
\boxed{ t_{min} = \frac{ 4 - \sqrt{5}}{\sqrt{2}}, \quad \, t_{max} = \frac{ 4 + \sqrt{5}}{\sqrt{2}} }
\]

\section*{ 10.5 Exercises - Introduction, Paths and line integrals, Other notations for line integrals, Basic properties of line integrals }

\exercisehead{1} $f= ((x^2-2xy),(y^2 - 2xy))$ from $(-1,1)$ to $(1,1)$; \quad $y = x^2$ \smallskip \\
$\alpha(x) = (x,x^2)$; \quad $\alpha' = (1,2x)$
\[
\begin{gathered}
  \int ((x^2 - 2xy),(y^2 - 2xy))\cdot (1,2x) dx = \int (x^2 - 2xy + 2xy^2 - 4x^2 y ) dx = \\
_{-1}^1 (x^2  - 2x^3 + 2x^5 - 4x^4) dx = \left. \left( \frac{1}{3} x^3 - \frac{2}{4} x^4 + \frac{2}{6} x^6 - \frac{4}{5} x^5 \right) \right|_{-1}^1 = \frac{1}{3} (1-(-1)) - \frac{4}{5} (1-(-1)) = \frac{2}{3} - \frac{8}{5} = \boxed{ \frac{-14}{15} }
\end{gathered}
\]

\exercisehead{2} $f=(2a-y,x)$ along the path described by $\alpha = (a(t-\sin{t}), a(1-\cos{t}))$ \quad $0 \leq t \leq 2 \pi$ \\
$f(t) = (2a - a(1-\cos{t}), a(t- \sin{t})) = (a+a\cos{t}, a(t-\sin{t}))$ \smallskip \\
$\alpha'(t) =(a(1-\cos{t}), a\sin{t})$
\[
\begin{gathered}
  \int f(t) \cdot \alpha'(t) dt = \int_0^{2\pi} (a^2 ( 1- \cos^2{t}) + a^2 ( t\sin{t} - \sin^2{t}) ) dt = a^2 \int_0^{2\pi} (1+ t\sin{t} - 1) dt = \\
  = a^2 \int_0^{2\pi} t \sin{t} dt = a^2 \left( \left. \left( -t \cos{t} \right) \right|_0^{2\pi} - \int_0^{2\pi} -\cos{t} dt \right) = a^2 ( -2\pi) + 0 = \boxed{ -2\pi a^2 } 
\end{gathered}
\]

\exercisehead{3} $f(x,y,z) =((y^2- z^2), 2yz, -x^2)$; \quad $\alpha(t) = (t,t^2, t^3)$, \quad $0\leq t \leq 1$ \smallskip \\
$f[\alpha(t)] = ((t^4 - t^6), 2t^5, -t^2)$ \quad \, $\alpha'(t) = (1,2t, 3t^2)$
\[
\int_0^1 f(\alpha(t))\cdot \alpha'(t) dt = \int_0^1 (t^4 - t^6 + 4t^6 - 3t^4) dt = \left. \left( (-2)\frac{1}{5} t^5 + \frac{1}{7} 3t^7 \right) \right|_0^1 = \frac{-2}{5} + \frac{3}{7} = \boxed{ \frac{1}{35} }
\]

\exercisehead{4} $f = (x^2 + y^2, x^2 - y^2)$ from $(0,0)$ to $(2,0)$ along the curve $y= 1 - |1-x|$.  
\[
|1-x| = \begin{cases} 1-x & \text{ if } 1 - x > 0 \text{ or } 1 > x \\ -(1-x) & \text{ if } 1 - x < 0 \text{ or } 1 < x \quad \end{cases} \quad \, y = \begin{cases} x & 1 > x \\ 2-x & 1 < x \end{cases}
\]
\[
\begin{aligned}
  \text{For} x<1, & \\
  & \alpha(x) = (x,x) \\ 
  & \alpha'(x) = (1,1)
\end{aligned} \quad \quad \, \begin{aligned}
  \text{ For } x > 1, & \\ 
 & \alpha(x) = (x,(2-x)) \\ 
  & \alpha'(x) = (1, -1)
\end{aligned}
\]
\[
\begin{aligned}
  \int f\cdot \alpha'(x) dx & = \int_0^1 ((x^2 + y^2) + (x^2 - y^2)) dx + \int_1^2 ((x^2 + y^2) - (x^2 - y^2)) dx = \int_0^1 2x^2 dx + \int_1^2 2(2-x)^2 dx = \\
  & = \left. \frac{2}{3} x^3 \right|_0^1 + 2 \left. \left( \frac{1}{3} (2-x)^3 (-1) \right) \right|_1^2 = \frac{2}{3} + \left( \frac{-2}{3} \right) (0 - 1^3 ) = \frac{2}{3} + \frac{2}{3} = \boxed{ \frac{4}{3} }
\end{aligned}
\]

\exercisehead{5} $f = (x+y, x-y)$ \quad  $b^2 x^2 + a^2 y^2 = a^2 b^2$ \quad \, $\Longrightarrow \left( \frac{x}{a} \right)^2 + \left( \frac{y}{b} \right)^2 = 1$.  From the ellipse equation, parametrize by $\theta$.  \quad $\Longrightarrow \begin{aligned} x & = a \cos{\theta} \\ y & = b \sin{\theta} \end{aligned}$ 
\[
\begin{aligned}
  \alpha(\theta) & = (a \cos{\theta}, b \sin{\theta} ) \\
  \alpha'(\theta) & = (-a\sin{\theta}, b \cos{\theta})d\theta
\end{aligned}
\]
\[
\begin{gathered}
  \int_0^{2\pi} f(\theta)\cdot \alpha'(\theta) d\theta = \int_0^{2\pi} \left( (a\cos{\theta} + b \sin{\theta})(-a\sin{\theta})d\theta + (a\cos{\theta} - b \sin{\theta})b\cos{\theta} d\theta \right) = \\
%   = \int_0^{2\pi} \left( -a^2 \cos{\theta} \sin{\theta} - ab \sin^2{\theta} + ab \cos^2{\theta}-b^2 \sin{\theta} \cos{\theta} \right) d\theta = \\\int_{-\pi/2}^{\pi/2} \cos{t} a \cos{t} dt = a \int_{-\pi/2}^{\pi/2} \frac{ 1 + \cos{2t}}{2}  = \frac{a \pi}{2} = \\ %
  = (-a^2-b^2) \int_0^{2\pi} \cos{\theta}\sin{\theta} d\theta + ab \int_0^{2\pi} (\cos^2{\theta} - \sin^2{\theta}) d\theta = \\
  = \left. (-a^2 - b^2)\left( \frac{ \sin^2{\theta}}{2} \right) \right|_0^{2\pi} + ab \left. \left( \frac{ \sin{2\theta} }{2} \right) \right|_0^{2\pi } = \boxed{ 0 } 
\end{gathered}
\]

\exercisehead{6} Given $f = (2xy, x^2 + z, y)$ from $x_1 = (1,0,2)$ to $x_2 = (3,4,1)$, use vector calculus and analytic geometry to form a line with direction vector $P = x_2 - x_1 = (2,4,-1)$.  Thus, the line is described by $x= tP + x_1$, where $t$ is the parameter.  
\[
x = tP + x_1 \quad \Longrightarrow \begin{aligned} x & = 2t + 1 \\ y & = 4t \\ z & = -t + 2 \end{aligned}
\]
\[
\begin{aligned}
  f(t) & = (2 ( 2t+ 1)(4t), ((2t+1)^2 + (-t+2)), 4t) = (16t^2 + 8t, 4t^2 + 3t + 3, 4t ) \\ 
  \alpha'(t) & = (2,4,-1)
\end{aligned}
\]
\[
\begin{gathered}
  \int_0^1 f(t) \cdot \alpha'(t) dt = \int_0^1 ( 32t^2 + 16t + 16t^2 + 12t + 12 - 4t) dt = \int_0^1 dt ( 48t^2 + 24 t + 12) = \\
  = \left. \left( \frac{48}{3} t^3 + \frac{24}{2} t^2 + 12t \right) \right|_0^1 = 16 + 12 + 12 = \boxed{ 40 } 
\end{gathered}
\]

\exercisehead{7} $f(x,y,z) = (x,y,(xz-y))$ from $(0,0,0)$ to $(1,2,4)$ along a line segment.  \smallskip \\
$\begin{aligned} x_1 & = (0,0,0) \\ x_2 & = (1,2,4) \end{aligned}$  \quad \, $P = x_2 - x_1 = x_2$.  The line is described by $Pt+x_1 = x = Pt$, so $\left[ \begin{matrix} x \\ y \\ z \end{matrix} \right] = \left[ \begin{matrix} t \\ 2t \\ 4t \end{matrix} \right]$
\[
\int_0^1 f(t) \cdot \alpha'(t)dt = \int (t + 4t + (4t^2 - 2t) 4 ) dt = \int (t + 4t + 16 t^2 - 8t) dt = \int_0^1 (-3t + 16 t^2 ) dt = \left. \left( \frac{-3t^2}{2} + \frac{ 16 t^3}{2} \right) \right|_0^1 = \boxed{ \frac{23}{6} }
\]

\exercisehead{8} Given $f(x,y,z) = (x,y,(xz-y))$ along the path described by $\alpha(t) = (t^2 + 2t, 4t^3)$; \quad $0 \leq t \leq 1$ 
\[
\begin{aligned}
  \alpha'(t) & = (2t, 2, 12t^2) \\
  f(t) & = (t^2, 2t, (4t^2 t^3 - 2t)) = (t^2, 2t, (4t^5 - 2t)) \\
  \int f(t) \cdot \alpha'(t) dt & = \int_0^1 ( 2t^3 + 4t + 12t^2 ( 4t^5 - 2t) ) dt = \left. \left( \frac{2}{4} t^4 + \frac{4}{2} t^2 + \frac{48}{8} t^8 - \frac{24 t^4}{4} \right) \right|_0^1 = \boxed{ \frac{5}{2} }
\end{aligned}
\]

\exercisehead{9} Given $\int_C (x^2 - 2xy) dx + (y^2-  2xy) dy$; where $C$ is a path from $(-2,4)$ to $(1,1)$ along the parabola $y=x^2$ parametrize to $x$.  
\[
\begin{gathered}
  \int_C ((x^2 - 2x (x^2))dx + (x^4-2x(x^2 ))2x dx) = \int_{-2}^1 (x^2 - 2x^3 + 2x^5 - 4x^4) dx = \left. \left( \frac{1}{3} x^3 - \frac{2}{4} x^4 + \frac{2}{6} x^6 - \frac{4x^5}{5} \right) \right|_{-2}^1 = \\ 
  = \frac{1}{3} (1 - (-8)) - \frac{1}{2} ( 1 - 16) + \frac{1}{3} (1- 64) - \frac{4}{5} (1- (-32)) = 3 + \frac{15}{2} - \frac{63}{3} - \frac{4}{5}(33) = \boxed{ \frac{-369}{10} }
\end{gathered}
\]

\exercisehead{10} $\int_C \frac{ (x+y) dx - (x-y)dy}{x^2 + y^2 }$ where $C$ is the circle $x^2 + y^2 = a^2$ or $\left( \frac{x}{a} \right)^2 + \left( \frac{y}{a} \right)^2 =1$.  Let $\begin{aligned} \frac{x}{a} & = \cos{\theta} \\ \frac{y}{a} & = \sin{\theta} \end{aligned}$ \quad \, $\begin{aligned} \frac{dx}{d\theta} & = -a \sin{\theta} \\ \frac{dy}{d\theta} & = a \cos{\theta} \end{aligned}$ 
\[
\Longrightarrow \int_0^{2\pi} \left(  (a \cos{\theta} + a\sin{\theta} )(-a \sin{\theta})d\theta- (a\cos{\theta} - a\sin{\theta})a \cos{\theta} d\theta\right)/a^2 = (-1)(2\pi) = \boxed{ - 2\pi }
\]

\exercisehead{11} $\int_F \frac{dx + dy}{ |x| + |y| }$, where $F = A+B+C+D$, where 
\[
\begin{aligned}
  & A: \, y = -x + 1 \\ 
  & B: \, y = x + 1 \\  
  & C: \, y = -x - 1 \\ 
  & D: \, y = x - 1 
\end{aligned}
\]
So
\[
\begin{aligned}
  & \int_A \left( \frac{dx}{ x + (-x+1) } + \frac{-dx}{ x + (-x +1) } \right) = 0 \\ 
  & \int_B  \frac{ 2 dx }{ -x + x+ 1 } = 2 \int_0^{-1} \frac{dx}{1} = 2(-1) = -2 \\
  & \int_C \frac{dx - dx}{ -x + x+ 1} = 0 \\
  & \int_D \frac{  2 dx }{ x + (-x+1)} = 2 \int_0^1 \frac{dx}{1} = 2 (1) =2 
\end{aligned} \quad \quad \, \Longrightarrow \boxed{ \int_F \frac{ dx + dy }{ |x| + |y|} = 0 }
\]

\exercisehead{12} 
\begin{enumerate}
\item Given that we want to compute $\int_C y dx + z dy + x dz$, on the intersection of $x+ y = 2$ or $y = 2-x$ and $x^2 + y^2 + z^2 = 2 (x+y) = 2(2) = 4$, then
\[
\begin{aligned}
  dx & = dx \\ 
  dy & = -dx \\ 
  \frac{ dz}{dx} 2z & = -4x + 4 \text{ or } dz  = \frac{-4x + 4}{ 2 \sqrt{ 4x - 2x^2} } dx
\end{aligned} 
\]
and
\[
z^2 = 4 - x^2 - y^2 = 4 - x^2 - (2-x)^2 = -2x^2 + 4x
\]
\[
\begin{gathered}
  \int_0^2 (2-x)dx+ \sqrt{ 4x - 2x^2} (-dx) + x \frac{ 2 ( 1- x)}{\sqrt{ 4x - 2x^2} } dx + \int_2^0 \left( (2-x) dx + - \sqrt{ 4x - 2x^2} (-dx) + \frac{x 2(1-x) }{ - \sqrt{ 4x - 2x^2} } dx \right) = \\
  = 2 \int_0^2 \frac{ - (4x - 2x^2) + 2x - 2x^2}{ \sqrt{ 4x - 2x^2} } dx = (-4) \int_0^2 (x/\sqrt{4x - 2x^2} ) dx 
\end{gathered}
\]
Let $u = \frac{x}{2}$.  Then $2du = dx$.  
\[
\begin{gathered}
  \Longrightarrow (-4) \int_0^1 (2u)(2 du) / \sqrt{2} \sqrt{ 4u -(2u)^2}  = -4 \sqrt{2} \int_0^1 \frac{ \sqrt{u}}{ \sqrt{ 1 - u } } du = -4 \sqrt{2} \int_0^{\pi/2} \frac{\sin{\theta} }{\cos{\theta} } 2 \sin{\theta} \cos{\theta} d\theta = \\
  = \left. -8\sqrt{2} \left( \frac{1}{2} \left( \frac{\pi}{2} - 9 \right) \frac{-\sin{2\theta}}{4} \right) \right|_0^{\pi/2} = \boxed{ -2 \sqrt{2} \pi } \\
\quad \\ 
\text{ since } \begin{aligned} u & = \sin^2{\theta} \\
du & = 2 \sin{\theta} \cos{\theta} d\theta \end{aligned} \text{ and } \\
\sqrt{ 1 - u }  = \sqrt{ 1 - \sin^2{\theta}} = \cos{\theta} 
\end{gathered}
\]
\item With $x^2 + y^2 = 1$, $z=xy$, let $x = \cos{\theta}$, $y = \sin{\theta}$, $z= \cos{\theta}\sin{\theta}$, so that 
\[
\begin{gathered}
  \int_C y dx + z dy + x dz = \int_0^{2\pi} ( \sin{\theta} (-\sin{\theta})d\theta + \cos{\theta} \sin{\theta} \cos{\theta} d\theta + \cos{\theta}(-\sin^2{\theta} + \cos^2{\theta}) d\theta = \\
  = \int_0^{2\pi} (-\sin^2{\theta} + \cos^2{\theta} \sin{\theta} - \sin^2{\theta} \cos{\theta} + \cos^3{\theta} ) d\theta = \\ 
  = \left. \left( (-1)\left( \frac{1 -\cos{2\theta} }{2} \right) + \frac{-\cos^3{\theta}}{3} - \frac{1}{3} \sin^3{\theta} + \sin{\theta} - \frac{1}{3} \sin^3{\theta} \right) \right|_0^{2\pi} = \boxed{ - \pi}
\end{gathered}
\]
\end{enumerate}

\section*{ 10.9 Exercises - The concept of work as a line integral, Line integrals with respect to arc length, Further applications of line integrals }

\exercisehead{1} $f(x,y,z) = (x,y,(xz-y))$ 
\[
\begin{gathered}
  \begin{aligned}
    x_1 & = (0,0,0) \\
    x_2 & = (1,2,4)
  \end{aligned} \quad \quad \, \begin{aligned}
    P & = x_2 - x_1 = x_2 \\ 
    x & = tx_2 + x_1; \quad \, 0 \leq t \leq 1 
  \end{aligned} \\
\int f\cdot ds = \int f\cdot \frac{ds}{dt} dt = \int_0^1 (t,2t, t(4t) - 2t)\cdot (1,2,4) dt = \int_0^1 (t + 4t + 16t^2 -8t) dt = \frac{-3}{2} + \frac{16}{3} = \boxed{ \frac{23}{6} }
\end{gathered}
\]

\exercisehead{2} $f(x,y) = ((x^2 - y^2),2xy)$ 
\[
\begin{gathered}
  \begin{aligned}
    & A: \, r= (a,ta) \quad &  \\  
    & B: \, r= (a(1-t),a) \quad &  \\
    & C: \, r= (0,a(1-t)) \quad &  \\
    & D: \, r = (at,0) \quad &
  \end{aligned} \\
\begin{aligned}
  & A: \, \int_0^1 (a^2 - a^2 t^2, 2ta^2)\cdot (0,a) dt = \int_0^1 2t a^3 dt = a^3 \\ 
  & B: \, \int_0^1 ((a^2 ( 1-2t +t^2)-a^2),2a(1-t)a) \cdot (-a,0) dt = -a\int_0^1 a^2 ( -2t + t^2) dt = -a^3 \left. \left( -t^2 + \frac{1}{3} t^3 \right) \right|_0^1 = \frac{2}{3} a^3 \\
  & C: \, \int_0^1 (-a^2 ( 1-2t + t^2), 0)\cdot (0,-a) = 0 \\
  & D: \,  \int_0^1 (a^2 t^2 ,0)\cdot (a,0) dt = a^3 \frac{1}{3}
\end{aligned} \\
 \Longrightarrow \int_C f\cdot ds = \boxed{ 2a^3 }
\end{gathered}
\]

\exercisehead{3} $f(x,y) = (cxy,x^6 y^2)$  \quad $c>0$.  $(0,0)$ to line $x=1$ via $y=ax^b$; \, $a>0, \, b>0$.  
\[
\begin{gathered}
\begin{aligned}
  W & = \int f\cdot ds = \int (cx(ax^b),x^6 a^2 x^{2b} )\cdot (1,bax^{b-1}) = \int (acx^{b+1} + a^3 b x^{3b+5}) dx = \\ 
  &  = \frac{ac}{b+2} + \frac{a^3b}{3b+ 6} = \frac{3ac}{ 3(b+2)} + \frac{a^3b}{3(b+2)} = \frac{3ac + a^3 b }{3(b+2)} 
\end{aligned} \\
\Longrightarrow \frac{3c}{a^2} = 2 \Longrightarrow \boxed{ a = \sqrt{ \frac{3c}{2} } }
\end{gathered}
\]

\exercisehead{4} $ f= (yz, xz, x(y+1))$.  \quad $\begin{aligned} a & = (0,0,0) \\ b & = (1,1,1) \\ c & = (-1,1,-1) \end{aligned}$ \\
\[
\begin{gathered}
\begin{aligned}
  & A: \, (b-a) = b; \quad & r = tb \quad &  \\
  & B: \, (c-b) = (-2,0,-2); \quad & r = t(-2,0,-2) + b \quad &  \\ 
  & C: \, (a-c) = -c; \quad & r = t(-c) + c = c(1-t) \quad & 
\end{aligned} \\
\begin{aligned}
  & A: \, \int (t^2 ,t^2, t(t+1))\cdot (1,1,1) dt = \int_0^1 t^2 + t^2 + t^2 + t = \left. \left( t^3 + \frac{1}{2} t^2 \right) \right|_0^1 = \frac{3}{2} \\
  & B: \, \begin{aligned} \int (1 (-2t + 1), (-2t +1), (-2t+1)(2)) \cdot (-2,0,-2) dt & = \int (-2t +1)(-2) + (-2)(-2t+1) = \\ & = \int (-2)(-2t +1)(3) = -6 \left. ( -t^2 + t) \right|_0^1 = 0 \end{aligned} \\
  & C: \, \begin{gathered} \int ((1-t)(-1)(1-t), -1(1-t)(-1)(1-t), (-1)(1-t)((1-t) +1))\cdot (1,-1,1)  = \\ 
    = \int - (1-t)^2 + (1-t)^2 (-1) + (-1)(1-t)^2 - (1-t) = \int -3 (1-2t + t^2 ) -1 +t = \int -3t^2 + 7t -4 = \\
    = \left. \left( - t^3 + \frac{7t^2}{2} - 4t \right) \right|_0^1 = \frac{-3}{2} \end{gathered}
\end{aligned} \\
\int f \cdot ds = \boxed{ 0 } 
\end{gathered}
\]

\exercisehead{5} $f = (y-z,z-x,x-y)$ 
\[
\begin{gathered}
  x^2 + y^2 + z^2 = 4 \\
  x^2 + y^2 \sec^2{\theta} = 4 
\end{gathered} \quad \, z = y \tan{\theta} \quad \quad \, \begin{aligned} x & = 2 \cos{\phi} \\ y \sec{\theta} & = 2 \sin{\phi} \\ z & = 2 \sin{\phi} \sin{\theta} \end{aligned}
\]
\[
\begin{gathered}
  f = \left( \frac{ 2 \sin{\phi} }{ \sec{\theta}} - 2 \sin{\phi} \sin{\theta}, 2 \sin{\phi} \sin{\theta} - 2 \cos{\phi}, 2 \cos{\phi} - \frac{ 2\sin{\phi}}{\sec{\theta}} \right)  \\
  \frac{ds}{d\phi} = ( - 2 \sin{\phi}, \frac{ 2 \cos{\phi}}{\sec{\theta} } , 2\cos{\phi} \sin{\theta} )
\end{gathered}
\]
\[
\begin{aligned}
  \int f\cdot ds & = \int 4 ( \sin{\phi} (\cos{\theta} - \sin{\theta})(-\sin{\phi}) + (\sin{\phi}\sin{\theta} - \cos{\phi})(\cos{\phi} \cos{\theta}) + (\cos{\phi} - \sin{\phi}\cos{\theta}) \cos{\phi} \sin{\theta} ) d\phi = \\
  & = 4 \int (-\sin^2{\phi} ( \cos{\theta} - \sin{\theta} ) + -\cos^2{\phi}( \cos{\theta} - \sin{\theta}) = 4 \int (-\cos{\theta} + \sin{\theta} ) d\phi = \boxed{ 8 \pi (\sin{\theta} - \cos{\theta} ) }
\end{aligned}
\]

\exercisehead{6} $f = (y^2,z^2,x^2)$.  $\begin{aligned} & x^2 + y^2 + z^2 = a^2 \\ & x^2 + y^2 = ax \end{aligned}$ \quad \, $\Longrightarrow \left( x - \frac{a}{2} \right)^2 + y^2 = \left( \frac{a}{2} \right)^2$.  \quad \, $\begin{aligned} & x - \frac{a}{2} = \frac{a}{2} \cos{\phi} \\ & y = \frac{a}{2} \sin{\phi} \\ & z^2 = a^2 - a \left( \frac{a}{2} \left( \cos{\phi} + 1 \right) \right) \end{aligned}$ 
\[
\begin{aligned}
  f & = \left( \left( \frac{a}{2} \right)^2 \sin^2{\phi}, \frac{a^2}{2} (1-\cos{\phi}), \left( \frac{a}{2} \right)^2 (\cos{\phi} + 1 )^2 \right) \\
  r' & = \left( \frac{-a}{2} \sin{\phi}, \frac{a}{2} \cos{\phi}, \frac{a^2}{4} \sin{\phi}/z \right) \\
  f\cdot r' & = \left( \frac{a}{2} \right)^3 \sin^3{\phi} + \frac{a^3}{4} (\cos{\phi} - \cos^2{\phi}) + \left( \frac{a}{2} \right)^4 \frac{ (\cos{\phi} +1)^2 \sin{\phi} }{z} 
\end{aligned}
\]
\[
\begin{gathered}
  \sin^3{\phi} = \sin{\phi} (1-\cos^2{\phi}) \xrightarrow{ \int } - \cos{\phi} + \frac{1}{3} \cos^3{\phi} \xrightarrow{ \int_0^{2\pi}} 0 \\
  \int_0^{2 \pi} \cos{\phi} = 0 \\
  \int_0^{2\pi} \cos^2{\phi} = \boxed{ \pi } \\
  z \geq 0, \quad \Longrightarrow z = \frac{a}{2} \sqrt{ 1 + \cos{\phi}} = \frac{a}{2} \sqrt{ 2 \cos^2{ \phi/2}} = \frac{a}{\sqrt{2}} |\cos{\phi/2} | \text{ and  so } 
\end{gathered}
\]
\[
\begin{gathered}
  \left( \frac{a}{2} \right)^4 (1+ \cos{\phi})^2 = \left( \frac{a^2}{4} + \frac{a^2}{4} \cos{\phi} \right)^2 = \left( \frac{a^2 }{4} + \frac{a^2}{4} - \frac{z^2}{2} \right)^2 = \frac{ (a^2 - z^2)^2 }{2^2} \quad \text{ so that } \\
  \int \left( \frac{a}{2} \right)^4 \frac{ (1+\cos{\phi})^2 \sin{\phi}}{z} = \int \frac{ (a^2 -z^2)^2 \sin{\phi}}{z} = \int \frac{ (a^4 - 2a^2 z^2 + z^4)\sin{\phi} }{z} 
\end{gathered}
\]
\[
\begin{aligned}
  \int \sin{\phi/2}\cos{\phi/2}/|\cos{\phi/2}| & = \int_0^{\pi} \sin{\phi/2} - \int_{\pi}^{2\pi} \sin{\phi/2} = \left. -2 \cos{\phi/2} \right|_0^{\pi} + \left. 2 \cos{\phi/2} \right|_{\pi}^{2\pi} = (-2)(-1) + 2(-1) = 0 \\
  \int z \sin{\phi} & = \int_0^{2\pi} \frac{a}{\sqrt{2}} \sqrt{ 1 - \cos{\phi} }\sin{\phi} = \frac{a}{\sqrt{2}} \left. (1- \cos{\phi} )^{3/2} \frac{2}{3} \right|_0^{2\pi} = 0 \\
  \int z^3 \sin{\phi} & = \int_0^{2\pi} \left( \frac{a}{\sqrt{2}} \sqrt{ 1 - \cos{\phi}} \right)^3 \sin{\phi} = \left. \frac{a^3}{2^{3/2}} (1-\cos{\phi})^{5/2} \frac{2}{5} \right|_0^{2\pi} = 0 
\end{aligned}
\]
So we finally get 
\[
\int f \cdot r' d\phi = -a^3 (\pi)/4
\]
Since we had gone counterclockwise, the exercise asked for the clockwise direction, so reverse the sign to get $\boxed{ \frac{ a^3 \pi}{4} }$

\exercisehead{7} $\int_C (x+y)ds$.  
\[
\begin{aligned}
  a & = (0,0) \\ 
  b & = (1,0) \\
  c & = (0,1)
\end{aligned} \quad \, \begin{aligned} & A: \, b - a = b \\ & B: \, c-b = (-1,1) \\ & C: \, a-c = -c \end{aligned} \quad \, \begin{aligned} r & = bt + a = bt \\ r & = (-1,1)t + (1,0) \\ r & = -ct + c = c(1-t) \end{aligned} \quad \, \begin{aligned} |r'| & = |b| = 1 \\ |r'| & = \sqrt{2} \\ |r'| & = 1 \end{aligned} \quad \, \begin{aligned} (x+y) & = t \\ (x+y) & = -t + 1 + t = 1 \\ (x+y) & = 1 - t \end{aligned}
\]
\[
\int_C (x+y)ds = \frac{1}{2} t^2 + t\sqrt{2} + t - \frac{1}{2}t^2 = \sqrt{2}  + 1 
\]

\exercisehead{8} $\int_C y^2 dx$ \quad $\alpha(t) = (a(t-\sin{t}), a(1-\cos{t}))$, \quad $0\leq t \leq 2\pi$
\[
\begin{gathered}
\begin{aligned}
  \alpha' & = (a(1-c(t)), a(s(t))) \\
  \alpha'^2 & = a^2 (1 - 2c + c^2 + s^2) = a^2  2 (1-c)
\end{aligned} \\
\begin{aligned}
  \int a^2 ( 1 - 2c + c^2) (a\sqrt{2} \sqrt{ 1 - c } ) dt & = a^3 \sqrt{2} \int (1-c)^{5/2} dt  = \\
  & = a^3 \sqrt{2} \int_0^{2\pi} \left( 2 \sin^2{ \left( \frac{t}{2} \right) } \right)^{5/2} dt = a^3 2^{1/2} 2^{5/2} \int_0^{2\pi } \sin^5{\left( \frac{t}{2} \right)} dt 
\end{aligned} \quad \quad \, \\
\text{ since } \begin{aligned} \cos{(2t)} & = \cos^2{t} - \sin^2{t} \\ &  =1 - 2 \sin^2{t} \end{aligned} \quad \, \text{ or } 2 \sin^2{t} = 1-\cos{(2t)} 
\end{gathered}
\]
Now
\[
\sin^5{\left( \frac{t}{2} \right)} = (1-\cos^2{\left( \frac{t}{2} \right)})^2 \sin{\left( \frac{t}{2} \right) } = \left( 1 - 2 \cos^2{\left(\frac{t}{2} \right)} + \cos^4{\left( \frac{t}{2} \right)} \right)\sin{\left( \frac{t}{2} \right)}
\]
So
\[
\begin{gathered}
  \int_0^{2\pi} \sin^5{\left( \frac{t}{2} \right)} dt = \left. (-2\cos{(t/2)} ) \right|_0^{2\pi} + \left. \left( (4)(1/3) \cos^3{(t/2)} + \frac{-2}{5} \cos^5{(t/2)} \right) \right|_0^{2\pi} = (-2) \left( (-2) + \frac{4}{3} + \frac{-2}{5} \right) = \frac{32}{15} \\
  \int_C y^2 ds = 8 a^3 \frac{32}{15} = \boxed{ \frac{256}{15} a^3  }
\end{gathered}
\]

\exercisehead{9} $\int_C (x^2 + y^2) ds$ where $C$ has the vector equation $\alpha(t) = (a(\cos{t} + t\sin{t}), a(\sin{t} - t\cos{t}) )$, \, $0 \leq t \leq 2\pi$ \\
\[
\alpha'(t) = (a((-s +s + tc), c- c + ts) ) = a(tc,ts) = at(c,s)  \quad \quad \, \| a' \| at 
\]
\[
\begin{gathered}
  x^2 + y^2 = a^2 ( c^2 + 2tcs + t^2 s^2 + s^2 - 2tsc + t^2c^2 ) = a^2(1+t^2) \\
  \int_C a^2 (1+t^2) at dt = a^3 \int (t+t^3)dt = a^3 \left( \frac{1}{2} (2\pi)^2 + \frac{1}{4} (2\pi)^4 \right) = \boxed{ a^3 \frac{(2\pi)^2}{2} \left( 1 + \frac{ (2\pi)^3}{2} \right) }
\end{gathered}
\]

\exercisehead{10} $\int_C z dx$ \quad \, $\alpha(t) = (t\cos{t}, t\sin{t},t)$
\[
\begin{gathered}
  \alpha' = (\cos{t} + -t\sin{t}, \sin{t} + t\cos{t},1) \quad \quad \, |\alpha'|^2 = c^2 - 2tsc + t^2 s^2 + s^2 + 2sct + t^2 c^2 + 1 = 2 +t^2 \\ 
  \int t \sqrt{ 2+ t^2} dt = \left. \left( \frac{1}{3} (2+t^2)^{3/2} \right) \right|_0^{t_0} = \boxed{ \frac{ (2+t_0^2)^{3/2} - 2^{3/2}}{3} }
\end{gathered}
\]

\exercisehead{11} 
\begin{enumerate}
\item
\[
\begin{gathered}
  \begin{aligned}
    r & = a(\cos{t},\sin{t}) \\ 
    r' & = a(-\sin{t}, \cos{t}) \\ 
    \| \alpha'(t) \| & = \| r'(t) \| = a \end{aligned}  \quad \, t \in [ 0,\pi ] \quad \, \begin{aligned} \overline{z} & = 0  \\ 
    \overline{y} & = \frac{1}{ \pi a} \int_0^{\pi} a\sin{t} a dt = \left. \frac{-a}{\pi} \cos{t} \right|_0^{\pi} = \frac{2a}{\pi} \\
    \overline{x} & = \frac{1}{ \pi a} \int_0^{\pi} a \cos{t} a dt = 0 
\end{aligned}
\end{gathered}
\]
\item \[  \left( \frac{M}{\pi a} \right) \int_0^{\pi} a^2 \sin^2{t} (a) dt = \frac{a^2 M}{\pi} \int_0^{\pi} \frac{1 - \cos{2t}}{2} dt = \boxed{ \frac{1}{2} M a^2 } \]
\end{enumerate} 

\exercisehead{12} $\rho = |x|+|y|$  \quad \quad $\begin{aligned} r & = a (\cos{t}, \sin{t}) \\ r' & = a(-s(t),c(t)) \\ \| \alpha'(t) \| & = \| r'(t) \| = a \end{aligned}$  \quad \, $t \in [0, 2\pi]$
\[
\begin{aligned}
  &  \int_0^{\pi/2} (a\cos{t} + a \sin{t} )a dt = \left. a^2 (\sin{t} - \cos{t} ) \right|_0^{\pi/2} = a^2 ( 1 - (-1)) = 2a^2 \\ 
  &  \int_{\pi/2}^{\pi} (-a\cos{t} + a \sin{t} )a dt = \left. a^2 (-\sin{t} - \cos{t} ) \right|_{\pi/2}^{\pi} = -a^2 ( -1 + (-1)) = 2a^2 \\ 
  &  \int_{\pi}^{3\pi/2} (-a\cos{t} - a \sin{t} )a dt = \left. -a^2 (\sin{t} - \cos{t} ) \right|_{\pi}^{3\pi/2} = -a^2 ( -1 - (-(-1))) = 2a^2 \\ 
   &  \int_{3\pi/2}^{2\pi} (a\cos{t} - a \sin{t} )a dt = \left. a^2 (\sin{t} + \cos{t} ) \right|_{3\pi/2}^{2\pi} = a^2 ( 1 + 1) = 2a^2 \\ 
\end{aligned} \Longrightarrow \boxed{ M = 8a^2}
\]

\[
\begin{aligned}
  & \int_0^{\pi/2} (a^2 \sin^2{t})( a\cos{t} + a \sin{t}) adt = a^4 \int_0^{\pi/2} \sin^2{t} \cos{t} + \sin{t}(1- \cos^2{t}) dt = a^4 \left. \left( \frac{\sin^3{t}}{3} + - \cos{t} + \frac{1}{3} \cos^3{t} \right) \right|_0^{\pi/2} = a^4 \\
  &  \int_{\pi/2}^{\pi} (a^2 \sin^2{t})( -a\cos{t} + a \sin{t}) adt = a^4 \int_{\pi/2}^{\pi} (-\sin^2{t} \cos{t} + \sin{t}(1- \cos^2{t})) dt = \\
  & = a^4 \left. \left( \frac{-\sin^3{t}}{3} + - \cos{t} + \frac{1}{3} \cos^3{t} \right) \right|_{\pi/2}^{\pi}  = a^4  \\
  &  \int_{\pi}^{3\pi/2} (-a^2 \sin^2{t})( a\cos{t} + a \sin{t}) adt  = -a^4 \left. \left( \frac{-\sin^3{t}}{3} + - \cos{t} + \frac{1}{3} \cos^3{t} \right) \right|_{\pi}^{3\pi/2} = -a^4 \left( \frac{-1}{3} + -1 + \frac{1}{3} \right) = a^4 \\ 
  &   \int_{3\pi/2}^{2\pi} (a^2 \sin^2{t})( a\cos{t} - a \sin{t}) adt  = a^4 \left. \left( \frac{\sin^3{t}}{3} +  \cos{t} - \frac{1}{3} \cos^3{t} \right) \right|_{3\pi/2}^{2\pi} = a^4 \\ 
  & \Longrightarrow \boxed{ I = 4a^4}
\end{aligned}
\]

\exercisehead{13} Notice that we have the plane cut through the center of the sphere: like a conic section, we obtain a circle with perpendicular $\frac{1}{\sqrt{3}}(1,1,1)$.  
\[
\begin{aligned}
  x^2 + y^2 + z^2 & = 1 \\ 
  x+ y+z & = 0 
\end{aligned} \quad \quad \Longrightarrow x^2 + y^2 + xy = \frac{1}{2} \Longrightarrow \begin{aligned} 2x + 2y y_x + y + xy_x & =0  \\ y_x & = \frac{ - y -2x }{ x + 2y } \end{aligned}
\]
\[
\begin{aligned}
  r & = (x,y,z) \\ 
  r_x & = \left( 1 , \frac{ -y -2x }{ x + 2y}, -1 - \left( \frac{ - y - 2x}{ x+2y} \right) \right) = \left( 1, - \frac{ (y+2x)}{ x+2y} , \frac{ x-y}{ x+2y} \right) \\
  r_x^2 & = 1 + \frac{ (y+2x)^2}{ (x+2y)^2} + \frac{ (x-y)^2}{(x+2y)^2} = \left( \frac{ 3 }{ 2-3x^2} \right) \\
  |r_x| & = \frac{ \sqrt{3}}{ \sqrt{ 2-3x^2}}
\end{aligned}
\]

I guess that $x$ ranges between $\pm \sqrt{ \frac{2}{3} }$.  \\
We're given that the mass density is $x^2$.  If we go around the circle on one branch, one semicircle, from $-\sqrt{2/3}$ to $\sqrt{2/3}$ in $x$, and then around in the same direction on the other branch, other semicircle, from $\sqrt{2/3}$ to $-\sqrt{2/3}$ in $x$, then we calculate for this branch the same number.  So do the calculation for one semicircle.

\[
\begin{aligned}
  \int \frac{x^2}{ \sqrt{ 2- 3x^2}} dx & = \int \frac{ \sqrt{ \frac{3}{2} } x^2 }{ \sqrt{ 1 - \left( \sqrt{ \frac{3}{2} } x \right)^2 } } = \int_{-\pi/2}^{\pi/2} \frac{ \sqrt{ \frac{3}{2} } \frac{2}{3} \sin^2{\theta} \sqrt{ \frac{2}{3} } \cos{\theta} d\theta}{ \sqrt{ 1 - \sin^2{\theta} } } = \\ 
  & = \int_{-\pi/2}^{\pi/2} \frac{2}{3} \sin^2{\theta} d\theta = \frac{2}{3} \left. \left( \frac{ \theta - \sin{2\theta}/2}{ 2} \right) \right|_{-\pi/2}^{\pi/2} = \boxed{ \pi/3} 
\end{aligned} \quad \quad \text{ where } \begin{aligned}
    \sqrt{ \frac{3}{2} } x & = \sin{\theta} \\ 
    \sqrt{ \frac{3}{2} } dx & = \cos{\theta} d\theta
  \end{aligned} \\
\]
$ \Longrightarrow M = \boxed{ \frac{2 \pi}{3} }$

\exercisehead{14} \textbf{??? (work on it)} Given $x^2  +y^2 = z^2$, $y^2 = x$, $(0,0,0)$ to $(1,1,\sqrt{2})$, curve is parametrized s.t.
\[
\alpha = \alpha(y) = (y^2, y, y\sqrt{ 1 +y^2})
\]
We want $z$-coordinate of the centroid for a uniform wire.  

Consider mass on infinitesimal segment $\lambda ds$.  

Weight each $\lambda ds$ with corresponding $z$-coordinate: $z\lambda dx$

Now $\alpha'(y) = (2y, 1, \sqrt{1 +y^2} + \frac{ y^2}{\sqrt{ 1 + y^2} } )$.  
\[
\begin{gathered}
  \| \alpha'(y) \|^2 = 7y^2 + 2 + \frac{y^4}{ 1 + y^2} \\
  ds = \| \alpha'(y) \| dy \\
z = y \sqrt{ 1 + y^2 }
\end{gathered}
\]
Then 
\[
\begin{gathered}
  \int z ds = \int y \sqrt{ 8y^4 + 9y^2 + 2 } dy = \int y 2 \sqrt{2} \sqrt{ (y^2 + \frac{9}{16} )^2 - \frac{17}{16^2} } dy \\ 
  \begin{aligned} u & = y^2 + 9/16 \\ du & = 2 y dy \end{aligned} \quad \, \begin{aligned} y & = 0 \Longrightarrow u = 9/16 \\ y & = 1 \Longrightarrow u = 25/16 \end{aligned}
\end{gathered}
\]

Now
\[
\int \sqrt{ u^2 + \beta} = \frac{1}{2} ( u \sqrt{ u^2 + \beta} + \beta \ln{ ( u + \sqrt{ u^2 + \beta} ) } )
\]

So then 
\[
\int z ds = \sqrt{2} \int_{9/16}^{25/16} \sqrt{ u^2 - \frac{17 }{16^2} } du  = \sqrt{ 2}/2 \left( \frac{25}{16^2} 4 \sqrt{38} - \frac{9}{16} \frac{8}{16} + \frac{-17}{16} \ln{ \left( \frac{ 25+ 4 \sqrt{38} }{ 17}  \right) } \right)
\]
since $\begin{aligned} 25^2 -17 = 608 = 38 * 16 \\ 81 - 17 =64 \end{aligned}$

However, $M = \lambda \int ds = \lambda \int \frac{ \sqrt{ 8y^4 + 9y^2 + 2 } }{ \sqrt{ y^2 + 1 } } dy $  and we need to divide by $M$.  

\exercisehead{15} Given $r=(a\cos{t},a\sin{t},bt)$, recall that 
\[
M = \sqrt{ a^2 + b^2 } \int_0^{2\pi} (a^2 + b^2 t^2) dt = \sqrt{ a^2 + b^2 }(2\pi a^2 + \frac{8}{3} \pi^3 b^2)
\]
\[
\begin{gathered}
  \begin{aligned}
  \overline{x}M & = \int_C x (x^2 + y^2 + z^2) ds = \sqrt{ a^2 + b^2 } \int_0^{2\pi} a \cos{t} (a^2 + b^2 t^2) dt = \sqrt{ a^2 + b^2} \int_0^{2\pi} ab^2 t^2 \cos{t} dt = \\
  & = \left( \sqrt{ a^2 +b^2 } ab^2 \right) \left. (t^2 \sin{t} + 2t \cos{t} - 2\sin{t} ) \right|_0^{2\pi} = \sqrt{ a^2 + b^2} ab^2 (2 (2\pi)) = \boxed{ 4 \pi \sqrt{a^2 + b^2 } ab^2 }
  \end{aligned} \\
  \begin{aligned}
    \overline{y}M & = \int_C y (x^2 + y^2 + z^2)ds = \sqrt{ a^2 +b^2 } \int_0^{2\pi} a\sin{t} (a^2 + b^2 t^2)dt = \\
    & = \sqrt{ a^2 + b^2} ab^2 \left. \left( -t^2 \cos{t} + 2t \sin{t} + 2\cos{t} \right) \right|_0^{2\pi} = \boxed{ \sqrt{ a^2 + b^2 }ab^2 (-(2\pi)^2) }
\end{aligned}
\end{gathered}
\]

\exercisehead{16} 
\[
\begin{gathered}
  \begin{gathered}
    I_x  = \int_C (y^2 + z^2)(x^2 + y^2 +z^2) ds = \sqrt{a^2 + b^2} \int_C (a^2 \sin^2{t} + b^2 t^2) (a^2 +b^2 t^2) dt = \\
    \begin{aligned}
    & = \rho_0^2 \int_C (a^4 \sin^2{t} + a^2 b^2 t^2 + a^2 b^2 t^2 \sin^2{t} + b^4 t^4 ) dt  = \rho_0^2 \int_C a^4 \left( \frac{1 - \cos{2t}}{2} \right) + a^2 b^2 t^2 + a^2 b^2 t^2 \left( \frac{ 1 - \cos{(2t)}}{2} \right) + b^4 t^4 dt = \\
    & = \rho_0^2 \left( \frac{a^4(2\pi)}{2} + \frac{ a^2 b^2 (2\pi)^3}{3}  + \frac{ a^2 b^2 (2\pi)^3}{2(3)}  + \frac{b^4 (2\pi)^5}{5}  - \frac{ \pi a^2 b^2}{2}  \right)  = \boxed{ \sqrt{ a^2 + b^2 } \left( \pi a^4 +  \frac{(2\pi)^3a^2 b^2}{2} + \frac{ (2\pi)^5 b^4}{5} - \frac{\pi (a^2 b^2)}{2} \right)}
  \end{aligned} \end{gathered}\\
  \begin{gathered}
    I_y  = \int_C (x^2 + z^2)(x^2 +y^2+z^2) ds = \rho_0^2 \int_C (a^2 \cos^2{t} + b^2 t^2 ) (a^2 + b^2 t^2) dt = \\
    \begin{aligned}
    & = \rho_0^2 \int_C ( a^4 \cos^2{t} + a^2 b^2 t^2 + a^2 b^2 t^2 \cos^2{t} + b^4 t^4 ) dt = \rho_0^2 \int_C a^4 \left( \frac{ 1 + \cos{2t} }{2} \right) + a^2 b^2 t^2 + a^2 b^2 t^2 \left( \frac{1 + \cos{(2t)} }{2} \right) + b^4 t^4 dt = \\
    & = \rho_0^2 \left( \frac{ a^4 (2\pi)}{2} + \frac{ a^2 b^2 (2\pi)^3}{3}  + \frac{a^2 b^2 (2\pi)^3}{2 (3)}  + \frac{a^2 b^2 \pi}{2}  + \frac{ b^4 (2\pi)^5}{5} \right) = \boxed{ \sqrt{ a^2 + b^2 } \left( \pi a^4 + \frac{ (2\pi)^3 a^2 b^2}{2} + \frac{ (2\pi)^5 b^4}{5} + \frac{ \pi a^2 b^2 }{2} \right) }
  \end{aligned} \end{gathered}
\end{gathered}
\]

\section*{ 10.13 Exercises - Open connected sets.  Independence of the path.  The second fundamental theorem of calculus for line integrals.  Applications to mechanics.  }

\exercisehead{1} Recall the lesson of the preceding sections.  

Let $S$ be an open set in $\mathbb{R}^n$.  The set $S$ is called connected if every pair of points in $S$ can be joined by a piecewise smooth path whose graph lies in $S$.  That is, for every pair of points $a$ and $b$ in $S$ there is a piecewise smooth path $\alpha$ defined on an interval $[a,b]$ such that $\alpha(t) \in S$ for each $t \in [a,b]$ with $\alpha(a) = a$, $\alpha(b) = b$.  

\begin{enumerate}
\item $S = \{ (x,y) | x^2 + y^2 \geq 0 \}$ connected.  \\
Consider $(x_1,y_1) = (r_1,\theta_1)$  $(x_2,y_2) = (r_2,\theta_2)$  

Suppose $r_2>r_1$.  Let $\alpha_1 = (r\cos{\theta_2}, r \sin{\theta_2})$ s.t. $r_1 \leq r \leq r_2$  \\
Then consider $\alpha_2 = (r_1 \cos{\theta}, r_1 \sin{\theta})$ s.t. $\theta: \theta_2 \to \theta_1$  
\item $S = \{ (x,y) | x^2 + y^2 > 0 \}$ connected.  \\
See part(a), with $\alpha_1$, $\alpha_2$  
\item $S = \{ (x,y) | x^2 + y^2 < 1 \}$ connected.  \\
See part(a), with $\alpha_1, \alpha_2$ but with $r_1,r_2 <1$  
\item $S = \{ (x,y) | 1 < x^2 + y^2 < 2 \}$ connected.  \\
See part (a), with $\alpha_1$, $\alpha_2$, but with $1 < r_1,r_2 <2$  
\end{enumerate}

\exercisehead{2} $f = (P,Q) = \left( \frac{ \partial \varphi}{\partial x }, \frac{ \partial \varphi}{ \partial y } \right)$  

Since $\frac{ \partial P}{\partial y}$, $\frac{ \partial Q}{ \partial x}$ continuous, then by Apostol Vol. 2, Thm. 8.12, $\frac{ \partial P}{\partial y} = \frac{ \partial }{ \partial y} \left( \frac{ \partial \varphi }{ \partial x} \right)  = \frac{ \partial^2 \varphi }{ \partial x \partial y} = \frac{ \partial Q}{ \partial x} $  

\exercisehead{3}
\begin{enumerate}
\item  $\frac{ \partial P }{\partial y} = 1$  \\
$\frac{ \partial Q}{\partial x} = -1$  $f(x,y) = y\mathbf{i} - x \mathbf{j}$ \\
 Consider a square contour lying on $x$ and $y$ axes.  
\[
\begin{aligned}
  \int_{(0,0)}^{(1,0)} f dx & = 0 \\ \int_{(1,1)}^{(0,1)} 1 dy & = -1  \end{aligned}\quad \, \begin{aligned}
  \int_{(1,0)}^{(1,1)} (-1) dy & = -1 \\ \int_{(0,1)}^{(0,0)} 0 = 0 
\end{aligned}
\]
So then $\int_C f \cdot ds = -2$
\item $f(x,y) = y \mathbf{i} + (xy-x)\mathbf{j}$  $\frac{ \partial P}{\partial y} = 1$  $\frac{ \partial Q}{ \partial x} = y-1$  
\[
\begin{aligned}
  \int_{(0,0)}^{(1,0)} f dx & = 0 \\ \int_{(1,1)}^{(0,1)} 1 dx & = -1=-1  \end{aligned}\quad \, \begin{aligned}
  \int_{(1,0)}^{(1,1)} (y-1) dy & = 1/2-1=-1/2 \\ \int_{(0,1)}^{(0,0)} 0 = 0 
\end{aligned}
\]
$\int_C f\cdot ds = -3/2$ \end{enumerate}

\exercisehead{4} $f(x,y,z) = P(x,y,z) \mathbf{i} + Q(x,y,z) \mathbf{j} + R(x,y,z)\mathbf{k}$  \\
 We're given that 
\[
\partial_y P, \partial_z P, \partial_x Q, \partial_z Q, \partial_x P, \partial_y R
\]
are cont.  

Now
\[
f= \nabla \varphi = (P,Q,R) = (\partial_x \varphi, \partial_y \varphi, \partial_z \varphi)
\]
\[
\begin{aligned}
  & \partial_y P = \partial_y \partial_x \varphi = \partial_x \partial_y \varphi = \partial_x Q \\  
  & \partial_z P = \partial_z \partial_x \varphi = \partial_x \partial_z \varphi = \partial_x R \\
  & \partial_z Q = \partial_z \partial_y \varphi = \partial_y \partial_z \varphi = \partial_x R 
\end{aligned}
\]

\exercisehead{6} \begin{enumerate}
\item $P = y$, \quad $Q=z$.  \\
$\partial_y P = 1$ \quad $\partial_x Q = 0$  Not conservative.  
\item Since $f\cdot d\alpha = f\cdot \alpha'(t) dt$  
\[
\alpha(t) = (\cos{t}, \sin{t} ,e^t) \Longrightarrow \alpha'(t) = (-\sin{t}, \cos{t}, e^t ) 
\]
$f=(y,z,yz)$.  
\[
\begin{gathered}
  f \cdot \alpha'(t) = (-\sin^2{t} + e^t \cos{t} + \sin{t} e^{2t} ) \\ 
\begin{aligned}  \int_0^{\pi} (-\sin^2{t} + e^t \cos{t} + \sin{t} e^{2t} ) dt & = - \pi + \left. \left( \frac{ e^t \sin{t} + e^t \cos{t}  }{2} + \left( e^{2t} \sin{t} + \frac{ -e^{2t} \cos{t} }{2} \right)/ (5/2) \right) \right|_0^{\pi} = \\
  & = \boxed{ - \pi + \left( \frac{ e^{ \pi }(-1) - 1}{2} \right) + \frac{2}{5} \left( \frac{ -e^{2\pi } + 1}{2} \right) } \end{aligned}
\end{gathered}
\]
\end{enumerate}

\section*{ 11.9 Exercises - Introduction.  Partitions of rectangles.  Step functions.  The double integral of a step function.  The definition of the double integral of a function defined and bounded on a rectangle.  Upper and lower double integrals.  Evaluation of a double integral by repeated one-dimensional integration.  Geometric interpretation of the double integral as a volume.  Worked examples.  }

\exercisehead{1} 
\[
\begin{gathered}
  A(y) = \int_0^1 yx(x+y) dx = \frac{y}{3} + \frac{y^2}{2} \\
  \int_0^1 A(y) dy = \frac{1}{6} + \frac{1}{6} = \frac{1}{3}
\end{gathered}
\]

\exercisehead{2} 
\[
\begin{gathered}
  A(y) = \int_0^1 dx (x^3 + 3x^2 y + y^3) = \frac{1}{4} + y + y^3 \\
  \int_0^1 A(y) = \frac{1}{4} + \frac{1}{2} + \frac{1}{4} = \boxed{1}
\end{gathered}
\]

\exercisehead{3} 
\[
\begin{gathered}
  A(y) = \int_0^1 (\sqrt{y} + x - 3xy^2) dx = \sqrt{y} + \frac{1}{2} - \frac{3}{2} y^2 \\
  \int_1^3 \sqrt{ y} + \frac{1}{2} - \frac{3}{2} y^2 = \left. \left( \frac{2}{3} y^{3/2} + \frac{y}{2} - \frac{y^3}{2} \right) \right|_1^3 = 2 \sqrt{3} + \frac{-2}{3} + \frac{3}{2} - \frac{1}{2} - \frac{27}{2} + \frac{1}{2} = \boxed{ 2\sqrt{3} -\frac{38}{3} }
\end{gathered}
\]

\exercisehead{4} \[
\begin{gathered}
  A(y) = \int_0^{\pi} \sin^2{x} \sin^2{y} dx = \sin^2{y} \frac{\pi}{2} \\ 
  \int A(y)dy = \frac{\pi}{2} \left( \frac{\pi}{2} \right) = \frac{\pi^2}{4}
\end{gathered}
\]

\exercisehead{5} 
\[
\begin{gathered}
  A(y) = \int_0^{\pi/2} \sin{(x+y)} dx = \left. -\cos{(x+y)} \right|_0^{\pi/2} = \cos{y} - \cos{\left( \frac{\pi}{2} + y \right) } = \cos{y} + \sin{y} \\
  \int_0^{\pi/2} A(y) dy = \left. + \sin{y}\right|_0^{\pi/2} - \left. \cos{y} \right|_0^{\pi/2} = \boxed{ 2} 
\end{gathered}
\]

\exercisehead{6} Split the integral up into 4 parts.  Given $\iint_Q |\cos{(x+y)}| dx dy$ where $Q = [0,\pi]\times [0,\pi]$
\[
\begin{gathered}
  \begin{aligned}
    & A(x) = \int_0^{-x + \pi/2} \cos{(x+y)} dy = 1 - \sin{x} \\ 
    & A(x) = \int_{-x+\pi/2}^{\pi} -\cos{(x+y)} dy = \left. \sin{(x+y)} \right|_{\pi}^{\pi/2 - x} = 1 - \sin{(x+\pi)} = 1 + \sin{x} 
\end{aligned} \quad \quad \, \Longrightarrow 2 \\ 
  \begin{aligned}
    & A(x) = \int_0^{-x + 3\pi/2} -\cos{(x+y)} dy = \left. \sin{(x+y)} \right|_{3\pi/2 - x}^0 = \sin{x} - (-1) =  1 + \sin{x} \\ 
    & A(x) = \int_{-x+3\pi/2}^{\pi} \cos{(x+y)} dy = \left. \sin{(x+y)} \right|_{-x+3\pi/2}^{\pi} = \sin{(x+\pi)} - (-1) = 1 - \sin{x}
  \end{aligned}  \quad \quad \, \Longrightarrow 2 \\ 
  \int_0^{\pi} A(x) = \boxed{ 2 \pi }
\end{gathered}
\]

\exercisehead{7} $\iint_Q f(x+y) dx dy$ and $Q = [0,2]\times [0,2]$, $f(t)$ greatest integer $\leq t$
\[
\begin{aligned}
  y <1 & \\ 
  & A(y) = \int_{1-y}^{2-y} 1 dx + \int_{2-y}^2 2 dx  = 2-y - (1-y) + 2 (2-(2-y)) = 2y +1 \\
  y > 1 & \\ 
  & \begin{gathered}
    A(y) = \int_0^{2-y} dx + \int_{2-y}^{3-y}2dx = \int_{3-y}^2 3 dy = 2-y + 2 (3-y-(2-y)) + 3(2-(3-y)) = 2y + 1 \\ 
  \end{gathered} 
\end{aligned}
\]
\[
\int_0^2 (2y+1) = \boxed{ 6 }
\]

\exercisehead{8} $\iint_Q y^{-3} e^{tx/y} dx dy$, and $Q = [0,t]\times [1,t]$, $t>0$
\[
\begin{gathered}
  \int_0^t y^{-3} e^{tx/y} dx = \left. \left( \frac{ y^{-3} e^{tx/y} }{ t/y} \right) \right|_0^t = \frac{ y^{-3} e^{t^2/y}}{ t/y} - \frac{y^{-2}}{t} \\ 
  \int_1^t y^{-2} e^{t^2/y} dy = \left. \frac{ -e^{t^2/y}}{t^2} \right|_1^t = \frac{-e^t }{t^2} + \frac{e^{t^2}}{t^2} \\ 
  \int_1^t y^{-2}/t dy = \left. \frac{-1}{yt} \right|_1^t = \frac{-1}{t^2} + \frac{1}{t} \\ 
  \Longrightarrow \boxed{ -\frac{e^t}{t^3} + \frac{e^{t^2}}{t^3} + \frac{-1}{t} + \frac{1}{t^2} }
\end{gathered}
\]

\exercisehead{9} $Q$ rectangle, $Q = [a,b] \times [c,d]$.  
\[
\iint_Q f(x)g(y) dxdy = \int \left( \int_a^b f(x) dx \right) g(y) dy = \left( \int_a^b f(x) dx \right) \int_c^d g(y) dy
\]
Assume $\int_a^b f(x) dx = A$ exists.  

\exercisehead{10} $f(x,y) = \begin{cases} 1 - x - y & \text{ if } x + y \leq 1 \\ 0 & \text{ otherwise } \end{cases}$
\[
\begin{gathered}
  A(y) = \int_0^{1-y} (1-x-y) dx = 1- y - \frac{1}{2} ( 1- 2y + y^2) - y (1-y) = \frac{1}{2} - y + \frac{1}{2} y^2 \\ 
  \int_0^1 A(y) dy = \frac{1}{2} -\frac{1}{2} + \frac{1}{6} = \boxed{ 1/6}
\end{gathered}
\]
Indeed, vol. of tetrahedron $= \frac{1}{3} Bh = \frac{1}{3} \left( \frac{1}{2} (1)(1) \right) = 1/6$

\exercisehead{11} If $x < \frac{1}{\sqrt{2}}$ 
\[
\begin{gathered}
  A(x) = \int_{x^2}^{2x^2} (x+y) dy = x x^2 + \frac{1}{2} (4x^4 - x^4) = x^3 \left( 1 + \frac{3}{2} x \right) \\ 
\Longrightarrow \int_0^{1/\sqrt{2}} A(x) dx \left. \left( \frac{1}{4} x^4 + \frac{3}{10} x^5 \right) \right|_0^{1/\sqrt{2}} = \frac{1}{4} \left( \frac{1}{4} \right) + \frac{3}{10} \left( \frac{1}{4} \right) \left( \frac{\sqrt{2}}{2} \right) = \frac{1}{16} + \frac{3\sqrt{2}}{80}
\end{gathered}
\]
When $x > 1/\sqrt{2}$, \\
\[
\begin{gathered}
  A(x) = \int_{x^2}^1 (x+y) dy = (x)(1-x^2) + \frac{1}{2} (1-x^4) = x - x^3 + \frac{1}{2} - \frac{x^4}{2} \\ 
  \int_{1/\sqrt{2}}^1 ( x - x^3 + \frac{1}{2} - \frac{x^4}{2} ) dx = \frac{1}{2} (1- \frac{1}{2} ) - \frac{1}{4} ( 1- \frac{1}{4} ) + \frac{1}{2} ( 1 - \frac{1}{\sqrt{2}} ) - \frac{1}{10} ( 1 - \frac{1}{4\sqrt{2}} ) = \frac{ 84}{160} + \frac{-16\sqrt{2}}{80} 
\end{gathered}
\]
So we get $\boxed{ \frac{21}{40} - \frac{\sqrt{2}}{5} }$

\exercisehead{12} $f(x,y) = \begin{cases} x^2 + y^2 & \text{ if } x^2 + y^2 \leq 1 \\ 0 & \text{ otherwise } \end{cases}$
\[
\begin{gathered}
  A(x) = \int_{-\sqrt{ 1 = x^2}}^{\sqrt{ 1- x^2} } (x^2 + y^2) dy = 2x^2 \sqrt{ 1 - x^2} + \frac{1}{3} \left( (\sqrt{ 1 - x^2} )^3 - (-\sqrt{ 1 - x^2} )^3  \right) = \frac{4}{3} x^2 \sqrt{ 1 - x^2} + \frac{2}{3} \sqrt{ 1 - x^2} \\ 
  \text{ Now } \\ 
  \begin{aligned}
    & \int_{-1}^1 x^2 \sqrt{ 1 - x^2} = \int_{-\pi/2}^{\pi/2} \sin^2{\theta} \cos^2{\theta} d\theta = \int_{-\pi/2}^{\pi/2} \left( \frac{\sin{2\theta}}{2} \right)^2 d\theta = \frac{1}{4} \int_{-\pi/2}^{\pi/2} \left( \frac{1 - \cos{4\theta} }{2} \right) = \pi/8 \\ 
    & \int \sqrt{ 1 - x^2} dx = \int_{-\pi/2}^{\pi/2} \cos^2{\theta} d\theta = \pi/2
  \end{aligned} \\ 
  \Longrightarrow \frac{4}{3} \left( \frac{\pi}{8} \right) + \frac{2}{3} \left( \frac{ \pi }{2} \right) = \boxed{ \pi/2}
\end{gathered}
\]

\exercisehead{13} Split the integral up into 2 parts.
\[
\begin{gathered}
  \begin{aligned} 
    & \int_1^y (x+y)^{-2} dx = - \left. (x+y)^{-1} \right|_1^y = - (2y)^{-1} + (y+1)^{-1} \\ 
    & \int_1^2 \int_1^y (x+y)^{-2} dx dy = \frac{-1}{2} \ln{2} + \ln{\left( \frac{3}{2} \right) } 
\end{aligned} \\ 
  \begin{aligned}
    & \int_{y/2}^2 (x+y)^{-2} dx = \left. -(x+y)^{-1} \right|_{y/2}^2 = -(2+y)^{-1} + \left( \frac{3y}{2} \right)^{-1} \\ 
    & \int_2^4 \int_{y/2}^2 (x+y)^{-2} dx dy = \left. -\ln{(2+y)} \right|_2^4 + \frac{2}{3} \ln{2} = - \ln{6} + 2\ln{2} + \frac{2}{3} \ln{2}
  \end{aligned}
\end{gathered}
\]
Add the two up to get $\boxed{ \frac{\ln{2}}{6} }$ (it may help to remember that $\ln{3} + -\ln{6} = \ln{3} + \ln{1/6} = \ln{1/2} = -\ln{2}$)

\exercisehead{14}  $Q = [0,1] \times [0,1]$ and $f(x,y) = \begin{cases} 1 & \text{ if } x = y \\ 0 & \text{ if } x \neq y \end{cases}$ \\

Let $D = \{ (x,y) | x = y \}$, $D = $ ``diagonal'' of $Q$.  \\
$D$ has content zero as it's the graph of a continuous function $y=x$, \, $0\leq x \leq 1$.  \smallskip \\
$f$ discontinuous only on $D$.   \\ so $f$ continuous on $D$, with $D$ of content zero, so $f$ integrable on $R$.  
\[
\iint_{Q-D} f = 0 \text{ since } f = 0 \quad \forall \, (x,y) \in Q - D
\]

\section*{ 11.15 Exercises - Integrability of continuous functions.  Integrability of bounded functions with discontinuities.  Double integrals extended over more general regions.  Applications to area and volume.  Worked examples.  }

\exercisehead{1} 
\[
\begin{gathered}
  \int_0^x x\cos{(x+y)} dy = \left. x \sin{(x+y)} \right|_0^x = x (\sin{2x} - \sin{x} ) \\
  \int_0^{\pi} dx x (\sin{2x} - \sin{x}) = \left. \left( \frac{x \cos{2x}}{-2} + \frac{ \sin{2x}}{4 } + x \cos{x} - \sin{x} \right) \right|_0^{\pi} = \frac{ \pi }{-2} - \pi = \boxed{ \frac{ -3 \pi }{2} }
\end{gathered}
\]

\exercisehead{2} 
\[
\begin{gathered}
  \int_0^{x+1} (1+x) \sin{y} dy = (1+x) ( 1 - \cos{(x+1)} ) \\
  \int_0^1 (1+x) - (1+x) \cos{(x+1)} = 1 + \frac{1}{2} - \left. (1+x)\sin{(x+1)} - \cos{(x+1)} \right|_0^1 = \frac{3}{2} - 2\sin{2} - \cos{2} + \sin{1} + \cos{1}
\end{gathered}
\]

\exercisehead{3} $\iint_S e^{x+y} dx dy$ where $S = \{ (x,y) | |x|+|y| \leq 1 \}$
\[
\begin{gathered}
  \begin{gathered}
    \int_{-1+x}^{1-x} e^{x+y} dy = e^x (e^{1-x} - e^{-1+x} ) = e^1 - e^{-1 + 2x} \\
    \int_0^1 (e^{+1} - e^{-1 + 2x} ) dx = e - \frac{ e^{-1}}{2} (e^2 - 1) = \frac{e}{2} + \frac{e^{-1}}{2} 
  \end{gathered} \quad \quad \, 
  \begin{gathered}
    \int_{-x-1}^{1+x} e^{x+y} dy = e^x (e^{1+x} - e^{-x-1} ) = e^{1+ 2x} - e^{-1} \\
    \int_{-1}^0 (e^{1+2x} - e^{-1} ) dx = \frac{e^1}{2} (1- e^{-2}) - e^{-1}(1) = \frac{-3e^{-1}}{2} + \frac{e^1}{2}
  \end{gathered} \\
  \Longrightarrow \boxed{ e - e^{-1} }
\end{gathered}
\]

\exercisehead{4} $\iint_S x^2 y^2 dx dy$  and $\begin{aligned} xy & = 1 \\ xy & = 2 \\ y & = x \\ y & = 4x \end{aligned} \quad \quad \, \begin{aligned} y & = \frac{1}{x} \ y & = \frac{2}{x} \end{aligned}$ 
\[
\begin{aligned}
  & I: \,  (1/2,2) \to (1/\sqrt{2}, 2\sqrt{2}) & \\
   & &  \begin{gathered} \int_{1/x}^{4x} x^2 y^2 dy = x^2 \frac{1}{3} \left( 64 x^3 - \frac{1}{x^3} \right) \\ 
    \frac{1}{3} \int_{1/2}^{1/\sqrt{2}} \left( 64 x^5 - \frac{1}{x} \right) dx = \left. \frac{1}{3} \left( \frac{64 x^6}{6} - \ln{x} \right) \right|_{1/2}^{1/\sqrt{2}} = \frac{1}{3} \left( \frac{4}{3} - \frac{1}{6} \right) - \frac{1}{3} \left( \ln{\frac{1}{\sqrt{2}} } - \ln{ \frac{1}{2} } \right) = \\
    = \frac{7}{18} - \frac{1}{3} \left( \frac{1}{2} \ln{2} \right) \end{gathered}  
\end{aligned}
\]

\[
\begin{aligned}
  & II: \, & (1/\sqrt{2},2\sqrt{2}) \to (1,1) & \quad \begin{gathered} \int_{1/x}^{2/x} x^2 y^2 dy = x^2 \frac{1}{3} \left( \frac{8}{x^3} - \frac{1}{x^3} \right) = \frac{7}{3} \frac{1}{x} \\ \int_{1/\sqrt{2}}^1 \frac{7}{3} \frac{1}{x} = \frac{7}{3} - \ln{ \frac{1}{\sqrt{2}}} = \frac{7}{6} \ln{2} \end{gathered} \\ 
  & \quad \\
  & III: \, & (1,1) \to (\sqrt{2},\sqrt{2}) & \quad \begin{gathered} \int_x^{2/x} x^2 y^2 dy = x^2 \frac{1}{3} \left( \frac{8}{x^3} - x^3 \right) = \frac{8}{3} \frac{1}{x} - \frac{1}{3} x^5 \\ 
    \int_1^{\sqrt{2}} \frac{8}{3} \frac{1}{x} - \frac{1}{3} x^5 = \frac{8}{3} \ln{\sqrt{2}} - \left. \frac{1}{18} x^6 \right|_1^{\sqrt{2}} = \frac{4}{3} \ln{2} - \frac{7}{18} \end{gathered}
\end{aligned}
\]
\[
\Longrightarrow \frac{4}{3} \ln{2} - \frac{7}{18} + \frac{7}{6} \ln{2} +  \frac{7}{18} - \frac{1}{6} \ln{2} = \boxed{ \frac{7}{3} \ln{2} }
\]

\exercisehead{5} $ \iint_S (x^2 - y^2) dx dy$.  
\[
\begin{gathered}
  \int_0^{\sin{x}} (x^2 - y^2) dy = x^2 \sin{x} - \frac{1}{3} \sin^3{x} = x^2 \sin{x} - \frac{1}{3} (1- \cos^2{x}) \sin{x}\\
  \int x^2 \sin{x} = - x^2 \cos{x} + 2x \sin{x} + 2\cos{x} \\ 
  \iint_S (x^2 - y^2) dx dy = -\pi^2 (-1) + 2 ((-1)-1) + \frac{1}{3} (-1-1) + \left. \left( \frac{ \cos^3{x}}{-9} \right) \right|_0^{\pi} = \pi^2 + -4 - \frac{2}{3} + \frac{2}{9} = \boxed{ \frac{-40}{9} + \pi^2 }
\end{gathered}
\]
\exercisehead{6} $x+2y + 3z = 6$ $\Longrightarrow z = \frac{ 6 - x - 2y}{3}$
\[
\begin{gathered}  
  \int_0^{3- \frac{x}{2} } \left( \frac{ 6- x - 2y}{3} \right) dy = \frac{1}{3} \left( 6 \left( 3 - \frac{x}{2} \right) - x \left( 3 - \frac{x}{2} \right) - \left( 3 - \frac{x}{2} \right)^2 \right) = \frac{1}{3} \left( 18 - 3x -3x + \frac{x^2}{2} - \left( 9 - 3x + \frac{x^2}{4} \right) \right) = \\
  = \frac{1}{3} \left( 9 - 3x + \frac{x^2}{4} \right) \\ 
  \int_0^6 \frac{1}{3} \left( 9 - 3x + \frac{x^2}{4} \right) = \frac{1}{3} \left( 9 (6) - \frac{3 (6)^2}{2} + \frac{1}{12}6^3 \right) = \frac{1}{3}(6) (9-9 + 3 ) = \boxed{ 6}
\end{gathered}
\]
Indeed, $\frac{1}{3} BH = \frac{1}{3} ( 9)(2) = 6$

\exercisehead{7} \[
\begin{gathered}
  \int_{-x}^x (x^2 - y^2) dy = x^2 ( x - (-x)) - \frac{1}{3} (x^3 - (-x)^3 ) = 2x^3 - \frac{1}{3} (x^3 + x^3) = \frac{4}{3} x^3 \\ 
  \int_1^3 \frac{4}{3} x^3 dx = \left. \frac{1}{3} x^4 \right|_1^3 = \frac{1}{3} (81 - 1) = \boxed{ \frac{80}{3} }
\end{gathered}
\]

\exercisehead{8}\begin{enumerate}
\item \[
\begin{gathered}
  \int_{-1}^1 (x^2 + y^2) dy = x^2 (2) + \frac{1}{3} (1^3 - (-1)^3) = 2x^2 + \frac{2}{3} \\ 
  \int_{-1}^1 2x^2 + \frac{2}{3} = \frac{2}{3} (2) + \frac{2}{3} (2) = \boxed{ 8/3} 
\end{gathered}
\]
\item $f(x,y) = 3x + y$.  $S = \{ (x,y) | 4x^2 + 9y^2 \leq 36, \, x > 0, \, y > 0 \}$.  Thus, $y^2 \leq 4 - \frac{4}{9} x^2$
\[
\begin{gathered}
  \int_0^{2\sqrt{ 1 - (x/3)^2}} (3x+ y)dy = 3x 2\sqrt{ 1 - \left( \frac{x}{3} \right)^2} + \frac{1}{2} 4 (1- \left( \frac{x}{3} \right)^2 ) = 6x \sqrt{ 1 - \left( \frac{x}{3} \right)^2 } + 2 ( 1 - \left( \frac{x}{3} \right)^2 ) \\
\int_0^3 6x \sqrt{ 1- \left( \frac{x}{3} \right)^2 } + 2 (1 - \frac{x^2}{9} ) = \left. -18 (1- \frac{x^2}{9} )^{3/2} \right|_0^3 + 2 (3) - \frac{2}{27} (27) = \boxed{ 22 } \\
\text{ since } ((1- \frac{x^2}{9} )^{3/2} )' = \frac{3}{2} ( 1 - \frac{x^2}{9} )^{1/2} (\frac{-2x}{9} ) = \frac{-x}{3}(1-\frac{x^2}{9} )^{1/2}
\end{gathered}
\] 
\item \[
\begin{gathered}
  \int_{-\sqrt{ 16 - x^2}}^{\sqrt{ 16 - x^2}} (y+2 x + 20) dy = (2x+ 20) (2\sqrt{ 16 - x^2}) = 4x \sqrt{ 16 - x^2} + 40 \sqrt{ 16 - x^2} \\
  \int_{-4}^4 4 x \sqrt{ 16 - x^2} + 40 \sqrt{ 16 - x^2} = \int_0^{\pi} (16 \cos{\theta} 4 \sin{\theta} + 40 (4) \sin{\theta}) 4 \sin{\theta} d\theta = \frac{640}{2} \pi = \boxed{ 320 \pi } \\
  \text{ since } \quad 
\begin{aligned}
  x & = 4 \cos{\theta} \\
  dx & = -4 \sin{\theta} d\theta
\end{aligned}
\end{gathered}
\]
\end{enumerate}

\exercisehead{9} $\int_0^1 \left( \int_0^y f(x,y) dx \right) dy = \int_0^1 \left( \int_x^1 f(x,y) dy \right) dx$ \exercisehead{10} $\int_0^2 \left( \int_{y^2}^{2y} f(x,y)dx \right) dy = \int_0^4 \left( \int_{x/2}^{\sqrt{x}} f(x,y) dy \right) dx $ \exercisehead{11} $ \int_1^4 \left( \int_{\sqrt{x}}^2 f(x,y) dy \right) dx = \int_0^2 \left( \int_0^{y^2} f(x,y) dx \right) dy$  \\
\exercisehead{12} $\int_1^2 \left( \int_{2-x}^{\sqrt{ 2x - x^2}} f(x,y) dy \right) dx = \int_0^1 \left( \int_{2-y}^{\sqrt{ 1 - y^2} + 1 } f(x,y)dx \right) dy $   \exercisehead{13} $ \int_{-6}^2 \left( \int_{(x^2-4)/4 }^{2-x} f(x,y) dy \right) dx = \int_{-1}^0 \left( \int_{ - \sqrt{ 4y + 4 } }^{\sqrt{4y+4}} f(x,y) dx \right) dy + \int_0^8 \left( \int_{-\sqrt{ 4y + 4}}^{2-y} f(x,y) dx \right) dy$  \exercisehead{14} $\int_1^e \left( \int_0^{\log{x}} f(x,y) dy \right) dx = \int_0^1 \left( \int_{e^y}^e f(x,y) dx \right) dy$  \exercisehead{15} $\int_{-1}^1 \left( \int_{-\sqrt{ 1 -x^2} }^{1-x^2} f(x,y)dy \right) dx = \int_0^1 \left( \int_{-\sqrt{ 1 - y}}^{\sqrt{ 1- y}} f(x,y)dx \right) dy + \int_{-1}^0 \left( \int_{-\sqrt{ 1 - y^2}}^{\sqrt{ 1 - y^2}} f(x,y) dx \right) dy$  \exercisehead{16} $\int_0^1 \left( \int_{x^3}^{x^2} f(x,y)dy \right) dx = \int_0^1 \left( \int_{\sqrt{y}}^{y^{1/3}} f(x,y)dx \right) dy $ 

\exercisehead{17} Consider that $\sin{(\pi- x)} = -1 \sin{(-x)} = \sin{x} = y$.  This way, we get the ``branch'' of values for $\pi/2 < x < \pi$ and $0 < y < 1$.  
\[
\int_0^{\pi} \left( \int_{-\sin{(x/2)}}^{\sin{x}} f(x,y)dy \right) dx = \int_0^1 \left( \int_{\arcsin{y}}^{\pi - \arcsin{y}} f(x,y)dx \right) dy + \int_{-1}^0 \int_{2 \arcsin{(-y)}}^{\pi} f(x,y) dx dy
\]

\exercisehead{18} $\int_0^4 \left( \int_{-\sqrt{ 4 - y}}^{(y-4)/2} f(x,y) dx \right) dy = \int_{-2}^0 \left( \int_{2x + 4}^{4-x^2} f(x,y)dy \right) dx$

\exercisehead{19} 
\[
\begin{gathered}
  V = \int_0^1 \left( \int_0^y (x^2 + y^2) dx \right) dy + \int_1^2 \left( \int_0^{2-y} (x^2 + y^2) dx \right) dy = \int_0^1 \left( \int_x^{-2x} (x^2 + y^2) dy \right) dx \\
\quad \, \\ 
\begin{gathered}
  \int_x^{2-x} (x^2 + y^2) dy  = x^2 ( 2-x-x) + \frac{1}{3} ( (2-x)^3 - x^3) = x^2 ( 2-  2x ) + \frac{1}{3} ( 8 - 4x (3) + 3(2) x^2 - x^3 - x^3) = \\
  = 2x^2 - 2x^3 + \frac{8}{3} - 4x + 2x^2 - \frac{2x^3}{3} = \frac{-8}{3} x^3 + 4x^2 - 4x + \frac{8}{3} \\
  \xrightarrow{ \int_0^1 } \frac{-2}{3} + \frac{4}{3} - 2 + \frac{8}{3} = \boxed{ \frac{4}{3} }
\end{gathered}
\end{gathered}
\]

\exercisehead{21} 
\begin{enumerate}
\item $V = \int_1^2 \left( \int_x^{x^3} f(x,y) dy \right) dx + \int_2^8 \left( \int_x^8 f(x,y) dy \right) dx = \int_1^8 \left( \int_{y^{1/3}}^y f(x,y) dx \right) dy $
\item
\end{enumerate}

\exercisehead{22} $I= \int_{-1/2}^1 \left( \int_0^x e^{-y^2} dy \right) dx$ 
\[
\begin{gathered}
  \int_{-1/2}^1 \left( \int_0^x e^{-y^2} dy \right) dx = \int_0^1 \left( \int_0^x e^{-y^2} dy \right) dx + \int_{-1/2}^0 \left( \int_0^x e^{-y^2} dy \right) dx \\ 
  \begin{aligned}
    \int_0^1 \left( \int_0^x e^{-y^2} dy \right) dx & = \int_0^1 \left( \int_y^1 e^{-y^2} dx \right) dy = \int_0^1 e^{-y^2} (1-y) dy = A + \int_0^1 -ye^{-y^2} dy = \\
    & = A + \left. \left( \frac{e^{-y^2}}{2} \right) \right|_0^1 = A + \frac{e^{-1}}{2} - \frac{1}{2}
  \end{aligned}
\end{gathered}
\]
\[
\begin{gathered}
  \text{ since } \begin{aligned} z & = -x \\ dz & = -dx \end{aligned} \\ 
  \begin{aligned} 
    \int_{-1/2}^0 \left( \int_0^x e^{-y^2} dy \right) dx  & = -\int_{1/2}^0 \left( \int_0^{-x} e^{-y^2} dy \right) dx = \int_0^{1/2} \left( \int_0^{-x} e^{-y^2} dy \right) dx = -\int_0^{1/2} \left( \int_{-x}^0 e^{-y^2} dy \right) dx = \\
    & = - \int_{-1/2}^0 \left( \int_{-y}^{1/2} e^{-y^2} dx \right) dy =  -\int_{-1/2}^0 e^{-y^2} \left( \frac{1}{2} - (-y) \right) dy = \\
    & = \frac{-1}{2} \int_{-1/2}^0 e^{-y^2} dy + - \int_{-1/2}^0 y e^{-y^2} dy = \frac{1}{2} \int_{1/2}^0 e^{-y^2} (+dy) + - \left. \left( \frac{-e^{-y^2}}{2} \right) \right|_{-1/2}^0 = \\ 
    & = \frac{-1}{2} \int_0^{1/2} e^{-y^2} dy + \frac{1}{2} + \frac{-e^{-1/4}}{2}
    \end{aligned}
\end{gathered}
\]
\[
\Longrightarrow I = 2A + e^{-1} - 1 + - B + 1 - e^{-1/4} = \boxed{ 2A - B + e^{-1} - e^{-1/4} }
\]


\exercisehead{23} \begin{enumerate}
\item Suppose $S$ is a type $I$ region, without loss of generality.  \\
Use the geometry of similar triangles.  Thus, observe that the cross-sectional area is a projection of plane region $S$ (from the geometry of similar triangles).  Now express this mathematically.  
\[
A = \int_a^b dx \int_{\phi_1(x)}^{\phi_2(x)} dy = \int_a^b \int_{\phi_1(x)}^{\phi_2{x}} dy dx
\]
\[
\int_{ at /h}^{bt/h} dx \int_{\phi_1(x) \left( \frac{t}{h} \right)}^{ \phi_2(x) \left( \frac{t}{h} \right)} dy = \int_{ at /h}^{bt/h} dx \int_{\phi_1}^{\phi_2} dY \frac{t}{h} = \left( \frac{t}{h} \right)^2 \int_a^b dX \int_{\phi_1}^{\phi_2} dY = \left( \frac{t}{h} \right)^2 A
\]
\item $\int_0^h \frac{t^2}{h^2} A = \boxed{ \frac{1}{3} hA }$
\end{enumerate}

\exercisehead{24} 
\[
\int_0^1 \left( \int_x^a e^{m(a-x)} f(x) dy \right) dx = \int_0^1 e^{m(a-x)} f(x)(a-x) dx
\]


\section*{ 11.18 Exercises - Further applications of double integrals, Two theorems of Pappus }

\exercisehead{1} \[
\begin{gathered}
  \int_{-2}^1 \int_{x^2}^{2-x} x dy dx = \int_{-2}^1 x((2-x) -x^2) = \left. \left( x^2  - \frac{1}{3} x^3 - \frac{1}{4} x^4 \right) \right|_{-2}^1 = 1 - 4 - \frac{1}{3}(1+8) -\frac{1}{4} (1-16) = -9/4 \\
  \begin{aligned}
    \int_{-2}^1 \int_{x^2}^{2-x} y dy dx  &= \int_{-2}^1 \frac{1}{2} ((2-x)^2 - x^4) dx = \int_{-2}^1 \frac{1}{2} (4-4x + x^2 - x^4) dx = 2 (1+2) - \left. x^2 \right|_{-2}^1 + \left. \frac{1}{8} x^3 \right|_{-2}^1 - \left. \frac{1}{10} x^5 \right|_{-2}^1 = \\
    & = 6 + \frac{1}{6} ( 1 + 8 ) -\frac{1}{10} (1+32) = \frac{72}{10} 
\end{aligned} \\ 
\int_2^1 \int_{x^2}^{2-x} dy dx = \int_{-2}^1 (2-x-x^2) = 2(1+2) - \frac{1}{2} (1-4) - \frac{1}{3} ( 1 - (-8)) = 9/2 
\end{gathered}
\]
\[
\overline{x} = -1/2, \, \overline{y} = 8/5
\]

\exercisehead{2} $\begin{aligned} y^2 & = x  +3 \quad \, & (-3,0), \, (1, \pm 2) \\ y^2 & = 5-x \quad \, & (1,\pm2), \, (5,0) \end{aligned}$
\[
\begin{aligned}
  \int_{-2}^2 \left( \int_{y^2 - 3}^{5-y^2} dx \right) dy & = \int_{-2}^2 5- y^2 - (y^2 - 3) dy = \int_{-2}^2 8 - 2y^2 dy = 8(4) - \left. \frac{2}{3} y^3 \right|_{-2}^2 = 32 - \frac{2}{3} ( 8 - (-8)) = \\
  &  = \frac{ 96 - 32}{3} = \boxed{ \frac{64}{3} } 
\end{aligned}
\]
\[
\begin{aligned}
  \int_{-2}^2 \left( \int_{y^2 -3}^{5-y^2} x dx \right) dy & = \int_{-2}^2 \frac{1}{2} ( 25 - 10y^2 + y^4 - (y^4 - 6y^2 +9)) dy = \frac{1}{2} \int_{-2}^2 (16 - 4y^2 ) dy = \frac{1}{2} \left( 16(4) - \left. \frac{4}{3} y^3 \right|_{-2}^2 \right) = \\ 
  & = \frac{1}{2} (64 - 4/3(16)) = \frac{1}{2} \left( \frac{ 192 - 64 }{3} \right) = \frac{1}{6} (128) = \frac{64}{3}
\end{aligned}
\]
\[
\int_{-2}^2 \int_{y^2-3}^{5-y^2} ydx dy = \int_{-2}^2 8y -2y^3 = 0 
\]
\[
\overline{x} = 1, \, \quad \overline{y} =0 
\]

\exercisehead{3} $\begin{aligned} x - 2y + 8 & = 0 \quad \, & x & =-2 \\ x+ 3y + 5 & = 0 \quad \, & x & =4 \end{aligned}$
\[
\int_{-2}^4 \int{\frac{5+x}{-3}}^{\frac{x+8}{2}} dy dx = \int_{-2}^4 \left( \frac{3x + 24 + 10 + 2x }{6} \right) dx = \int_{-2}^4 \left( \frac{5x + 34}{6} \right) dx = \left. \frac{5 x^2}{12} \right|_{-2}^4 + \frac{17}{3} (6) = \frac{5}{12}(12) + 34 = -39 
\]
\[
\overline{x}A = \int_{-2}^4 dx \left( \frac{5x^2 + 34 x}{6} \right) = \left. \frac{1}{6} \left( \frac{5}{3} x^3 + 17 x^2 \right) \right|_{-2}^4 = \frac{1}{6} \left( \frac{5}{3} ( 64 + 8 ) + 17 (16-4) \right) = \frac{1}{6} ( 120 + 17 (12) ) = 54
\]
\[
\begin{aligned}
  \overline{y}A & = \int_{-2}^4 dx \frac{1}{2} \left( \frac{(x^2 + 16x + 64)}{4} -\frac{25 + 10x + x^2}{9} \right) = \int_{-2}^4 \frac{dx}{2} \left( \frac{ 9x^2 + 9(16x) + 9(64) - 100 - 40 x - 4x^2 }{36} \right)= \\ 
  & = \frac{1}{2(36)} \int_{-2}^4 dx ( 5x^2 + 18(8x) - 8(5x) + 9(4)(16) - 4(25) ) = \left. \frac{1}{36} \left( \frac{5}{3} x^3 + 52 x^2 + 119 (4x) \right) \right|_{-2}^4 = \\
  & = \frac{1}{ 2(36) } \left( \frac{5}{3} (64 + 8) + 52 (16 -4) + 119(4)(6) \right) = \boxed{ 50} 
\end{aligned}
\]
\[
\boxed{ \overline{y} = \frac{50}{39} \quad \, \overline{x} = \frac{18}{13} }
\]

\exercisehead{4} $y = \sin^2{x}$; \quad $ y = 0$; \, $ 0 \leq x \leq \pi$
\[
\begin{aligned}
  & \int_0^{\pi} \int_0^{\sin^2{x}} dy dx = \int_0^{\pi} \sin^2{x} dx = \int_0^{\pi} \left( \frac{1 - \cos{2x}}{2} \right) dx = \frac{\pi}{2} \\ 
  & \int_0^{\pi} \int_0^{\sin^2{x}} x dy dx = \int_0^{\pi} x \sin^2{x} dx = \int_0^{\pi} x \left( \frac{ 1-  \cos{2x}}{2} \right) dx = \frac{\pi^2}{4 } - \left. \frac{1}{2} \left( \frac{ x\sin{2x}}{2} + \frac{\cos{2x}}{4} \right) \right|_0^{\pi} = \frac{ \pi^2}{4} \quad \, \\ 
  & \int_0^{\pi} \int_0^{\sin^2{x}} y dy dx = \int_0^{\pi} \frac{1}{2} \sin^4{x} dx = \frac{1}{2} \int_0^{\pi} \left( \frac{ 1 - \cos{2x} }{2} \right)^2 dx = \frac{1}{8} \int_0^{\pi} 1 - 2 \cos{2x} + \cos^2{2x} = \frac{1}{8} (\pi + \frac{\pi}{2} ) = \frac{3\pi}{16} \quad \,
\end{aligned}
\]
\[
\overline{x} =  \pi^2/4 / \pi/2 = \boxed{ \pi/2 } \quad \,  \overline{y} =   \frac{ \frac{3\pi}{16} }{ \frac{ \pi}{2} } = \boxed{ \frac{3}{8 } }
\]

\exercisehead{5} \[
\begin{gathered}
  \int_0^{\pi/4} \int_{\sin{x}}^{\cos{x}} dy dx = \int_0^{\pi/4} \cos{x} - \sin{x} = \left. (\sin{x} + \cos{x} ) \right|_0^{\pi/4} = \sqrt{2} - 1 \\ 
  \int_0^{\pi/4} \int_{\sin{x}}^{\cos{x}} x dy dx = \int_0^{\pi/4} x (\cos{x} - \sin{x}) dx = \left. (x\sin{x} + \cos{x} + x\cos{x} - \sin{x} ) \right|_0^{\pi/4} = \frac{\pi}{2} \frac{\sqrt{2}}{2} - 1 \quad \quad \, \boxed{ \overline{x} = \frac{ \frac{ \pi \sqrt{2}}{4} - 1 }{ \sqrt{ 2}- 1} } \\ 
  \int_0^{\pi/4} \frac{1}{2} (\cos^2{x} - \sin^2{x}) dx = \frac{1}{2} \int_0^{\pi/4} \cos{2x} dx = \left. \frac{1}{4} \sin{2x} \right|_0^{\pi/4} = \frac{1}{4} \quad \quad \, \boxed{ \overline{y} = \frac{1/4}{ \sqrt{2}- 1} }
\end{gathered}
\]

\exercisehead{6} $\begin{aligned} y & = \log{x} \\ y & = 0 \end{aligned}$, \quad $1 \leq x \leq a$.  
\[
\begin{gathered}
  \int_1^a \int_0^{\log{x}} dy dx = \int_1^a \log{x} dx = \left. ( x\log{x} - x ) \right|_1^a = a \log{a} - a + 1 \\ 
  \int_1^a \int_0^{\log{x}} x dy dx = \int_1^a x dx \log{x}=  \left. \left( \frac{x^2 \log{x}}{2} - \frac{x^2}{4} \right) \right|_1^a = \frac{a^2 \log{a} }{2} - \frac{ (a^2 -1)}{4} \quad \, \Longrightarrow \boxed{ \overline{x} = \frac{ \left( \frac{ 2a^2 \log{a} - (a^2-1)}{4} \right) }{ a\log{a} - a + 1 } } \\ 
  \begin{aligned}
\int_1^a \int_0^{\log{x}} y dy dx & = \int_1^a \frac{1}{2} (\log{x})^2 dx = \left. \frac{1}{2} \left( (\log{x})^2 x - 2x \log{x} + 2x \right) \right|_1^a = \frac{1}{2} (a(\log{a})^2 - 2a \log{a} + 2a - 2 ) = \\
 &  = \frac{1}{2} a (\log{a})^2 - a \log{a} + a - 1 
\end{aligned}\\ 
  \begin{aligned} ((\log{x})^2 x )' & = (\log{x})^2 + 2(\log{x}) \\ 
    (x\log{x} - x)' & = \log{x}
\end{aligned} \quad \quad \, \Longrightarrow \boxed{ \overline{y} = \frac{ \frac{1}{2} a (\log{a})62 - a\log{a} + a - 1 }{ a \log{a} - a + 1 } }
\end{gathered}
\]

\exercisehead{7} $ \sqrt{x} + \sqrt{y} =1$ or $\sqrt{y} = 1 - \sqrt{x}$.  $x=0, y=0$.  So $y = 1 - 2\sqrt{x} + x$.  
\[
\begin{gathered}
  \int_0^1 \int_0^{1-2\sqrt{x} + x } dy dx = \int_0^1 (1-2\sqrt{x} + x) = \left. (x- \frac{4}{3} x^{3/2} + \frac{1}{2} x^2 ) \right|_0^1 = 1 - \frac{4}{3} + \frac{1}{2} = \boxed{ \frac{1}{6} } \\ 
  \begin{aligned}
    \int_0^1 \int_0^{1-2\sqrt{x} + x} y dy dx & = \int_0^1 dx \frac{1}{2} ( 1 -4 \sqrt{x} + 2x + 4x - 4x^{3/2} + x^2) = \int_0^1 dx \frac{1}{2} ( 1 - 4 x^{1/2} + 6x - 4x^{3/2} + x^2) = \\
    & = \frac{1}{2} \left. (x- \frac{8}{3} x^{3/2} + 3x^2 - \frac{8x^{5/2}}{5} + \frac{1}{3} x^3 ) \right|_0^1 =  \frac{1}{30} 
\end{aligned} \\ 
  \Longrightarrow \boxed{ \overline{y} = 1/5 } \\ 
  \int_0^1 \int_0^{1-2\sqrt{x} + x} x dy dx = \int_0^1 x (1-2\sqrt{x} + x) dx = \left. \left( \frac{1}{2} x^2 - 2\frac{2}{5} x^{5/2} + \frac{1}{3} x^3 \right) \right|_0^1 = \frac{1}{3} \\ 
  \Longrightarrow \boxed{ \overline{ x} = 1/5 }
\end{gathered}
\]

\exercisehead{8} $x^{2/3} + y^{2/3} = 1$ or $\begin{aligned} y^{2/3} & = 1 - x^{2/3} \\ y & = (1-x^{2/3})^{3/2} \end{aligned}$ and $x =0$, \, $ y=0$.  
\[
\begin{gathered}
  \text{ Since } \begin{aligned} u & = 1 - x^{2/3} \quad \quad \, \text{ or } x^{2/3} = 1 - u \\ du & = \frac{-2}{3} x^{-1/3} dx \\ & \frac{-3}{2} du ( \sqrt{ 1 - u } ) = dx \end{aligned} \\ 
  \int_0^1 \int_0^{(1-x^{2/3})^{3/2} } dy dx = \int_0^1 (1-x^{2/3})^{3/2} dx = \int_1^0 u^{3/2} \left( \frac{-3}{2} \right) du (1-u)^{1/2} 
\end{gathered}
\]
\[
\begin{gathered}
\begin{aligned}
  \int u^{3/2} (1-u)^{1/2} & = \int u^{3/2} \left( \frac{-2}{3} (1-u)^{3/2} \right)' = u^{3/2} \frac{-2}{3} (1-u)^{3/2} - \int \frac{3}{2} u^{1/2} \frac{-2}{3} (1-u)(1-u)^{1/2} = \\
  & = \frac{-2}{3} u^{3/2} (1-u)^{3/2} + \int (u^{1/2} (1-u)^{1/2} - u^{3/2} (1-u)^{1/2} ) 
\end{aligned} \\
\Longrightarrow 2 \int u^{3/2}(1-u)^{1/2} = \frac{-2}{3} u^{3/2} (1-u)^{3/2} + \int u^{1/2} (1-u)^{1/2} 
\end{gathered}
\]
\[
\int u^{1/2} (1-u)^{1/2} = \int (u-u^2)^{1/2} = \int \left( \frac{1}{4} - \left( \frac{1}{2} - u\right)^2 \right)^{1/2} = \frac{1}{2} \int \sqrt{ 1 - (1-2u)^2 }
\]
\[
\begin{gathered}
\text{ Since } \begin{aligned} x & = (1-2u) \\ dx & = -2 du \end{aligned} \quad \text{ and } \quad \begin{aligned} x &= \sin{\theta} \\ dx & = \cos{\theta} d\theta \end{aligned} \text{ then } \\ 
\int \sqrt{ 1 - (1-2u)^2 } = \int \frac{dx}{-2} \sqrt{ 1 - x^2} = \int \frac{ \cos{\theta} d\theta}{-2} \cos{\theta} = \int \frac{ 1 + \cos{2\theta} }{-4}  = \frac{-1}{4} ( \theta + \frac{ \sin{2\theta}}{2} )
\end{gathered}
\]
\[
\begin{gathered}
  \begin{aligned}
    \int_0^1 u^{3/2} (1-u)^{1/2} du & = \frac{1}{2} \int_0^1 u^{1/2} (1-u)^{1/2} = \frac{1}{4} \int_0^1 \sqrt{ 1 - (1-2u)^2 } = \frac{-1}{8} \int_1^{-1} dx \sqrt{ 1 - x^2} = \\
    & = \frac{-1}{8} \int_{\pi/2}^{-\pi/2} \left( \frac{1+ \cos{2\theta}}{2} \right) d\theta = \\ 
    & = \frac{-1}{16} \left. \left( \theta + \frac{ \sin{2\theta}}{2} \right) \right|_{\pi/2}^{-\pi/2} = \frac{-1}{16} \left( \frac{-\pi}{2} - \frac{\pi}{2} \right) = \boxed{ \pi/16} 
  \end{aligned} \\
  \Longrightarrow A = \frac{3}{2} \frac{\pi}{16} = \boxed{ \frac{3\pi}{32} }
\end{gathered}
\]
\[
\begin{gathered}
  \begin{aligned}
  \int_0^1 \int_0^{(1-x^{2/3})^{3/2}} x dy dx & = \int_0^1 x(1-x^{2/3})^{3/2} dx = \int_1^0 \frac{-3}{2} du \sqrt{ 1-  u} u^{3/2} (1-u)^{3/2} = \frac{3}{2} \int_0^1 du(1 -2u + u^2) u^{3/2} = \\ 
  & = \frac{3}{2} \int_0^1 du (u^{3/2} - 2u^{5/2} + u^{7/2} ) = \\
  & = \frac{3}{2} \left( \frac{2}{5} - 2 \left( \frac{2}{7} \right) + \frac{2}{9} \right) = \frac{3}{2} \left( \frac{2}{5} - \frac{4}{7} + \frac{2}{9} \right) = \frac{8}{105}
  \end{aligned} \\
  \Longrightarrow \boxed{ \overline{x} = 256\pi/315 }
\end{gathered}
\]
\[
\begin{gathered}
  \begin{aligned}
    \int_0^1 \int_0^{(1-x^{2/3})^{3/2}} y dy dx & = \int_0^1 \frac{1}{2} ( 1 - x^{2/3})^3 dx = \frac{1}{2} \int_0^1 ( 1 + 3 (-x^{2/3} ) + 3 x^{4/3} - x^2 ) dx = \\ 
    & = \frac{1}{2} \left( 1 + -3 \left( \frac{ 3 (1)^{5/3}}{5} \right) + 3 \frac{3}{7} - \frac{1}{3} \right) = \frac{1}{2} \left( 1 + \frac{ -9}{5} + \frac{9}{7} + \frac{-1}{3} \right) = \frac{1}{2} \left( \frac{-4}{5} + \frac{9}{7} - \frac{1}{3}  \right) = \frac{8}{105}
  \end{aligned} \\
  \Longrightarrow \boxed{ \overline{y} = 256\pi/315 }
\end{gathered}
\]

\exercisehead{9} $\int_0^2 \int_0^{ x(2-x)} \left( \frac{ 1 - y}{ 1+ x} \right) dy dx = \int_0^{2} \frac{1}{1+x} \int_0^{x(2-x)} (1-y)dy dx$
\[
\begin{gathered}
  \frac{1}{2} ( x(2-x))^2 = \frac{1}{2} x^2 (4- 4x + x^2) = 2x^2 - 2x^3 + \frac{1}{2} x^4 \\ 
\int_0^{x(2-x)} (1-y)dy =   2x - x^2 - 2x^2 + 2x^3 - \frac{1}{2} x^4 = 2x - 3x^2 + 2x^3 - \frac{1}{2} x^4 = \\ 
= \frac{-1}{2} x^4 - \frac{1}{2} x^3 + \frac{5}{2} x^3 + \frac{5}{2} x^2 - \frac{11}{2} x^2 - \frac{11}{2} x + \frac{15}{2} x = \left( \frac{-1}{2} x^3 + \frac{5}{2} x^2 - \frac{11}{2} x \right) (x+1) + \frac{15}{2} x 
\end{gathered}
\]
\[
\begin{gathered}
  \int_0^2 \frac{1}{1+x} \int_0^{x(2-x)} (1-y)dy dx = \int_0^2 \frac{1}{1+x} \left( \left( \frac{-1}{2} x^3 + \frac{5}{2} x^2 - \frac{11x}{2} \right)(x+1) + \frac{15x}{2} \right) = \\
  = \int_0^2 dx \left( \left( \frac{-1}{2} x^3 + \frac{5}{2} x^2 - \frac{11x}{2} \right) + \frac{15x}{12(1+x)} \right) = \\
  = \frac{-1}{8}(16) + \frac{5}{6} (8) -\frac{11}{4} (4) + \frac{15}{2} \left( 2 + \left. \ln{(1+x)} \right|_0^2 \right) = -2 + \frac{20}{3} - 11 + \frac{15}{2} (2 - \ln{(3)}) = \boxed{ \frac{26}{3} + \frac{-15}{2} \ln{3} }
\end{gathered}
\]

\exercisehead{10} \[
\begin{aligned}
  & \int_0^a \int_0^b (xy) dy dx = \int_0^a x \frac{1}{2} b^2 dx = \frac{1}{4} a^2 b^2 \\ 
  & \int_0^a \int_0^b (xy^2) dy dx = \int_0^a x \frac{1}{3} b^3 dx = \frac{1}{6} a^2 b^3 \\ 
  & \int_0^a \int_0^b x^2 y dy dx = \int_0^a x^2 \frac{1}{2} b^2 = \frac{1}{6} b^2 a^3 
\end{aligned}
\]
\[
\boxed{ \overline{x} = \frac{ \frac{1}{6} b^2 a^3 }{ \frac{1}{4} a^2 b^2 } = \frac{2}{3} a \quad \, \overline{y} = \frac{ \frac{1}{6} a^2 b^3 }{ \frac{1}{4} a^2 b^2 } = \frac{2}{3} b }
\]

\exercisehead{11} \quad \\ 
$\begin{aligned} 
y & = \sin^2{x} \\ 
y & = -\sin^2{x} \end{aligned}$ \quad \, $-\pi \leq x \leq \pi$; \, $f(x,y) = 1$  
\[
\begin{aligned}
  I_x & = \int_{-\pi}^{\pi} \left( \int_{-\sin^2{x}}^{\sin^2{x} } y^2 dy \right) dx = \int_{-\pi}^{\pi} \frac{1}{3} 2 \sin^6{x} dx = \frac{2}{3} \int_{-\pi}^{\pi} \left( \frac{1- \cos{2x}}{2} \right)^3 = \\
  & = \frac{1}{12} \int_{-\pi}^{\pi} 1 + -3\cos{2x} + 3 \cos^2{2x} + \cos^3{2x}  = \boxed{ \frac{5 \pi}{12} } 
\end{aligned}
\]
\[
\begin{aligned}
  I_y & = \int_{-\pi}^{\pi} \int_{-\sin^2{x}}^{\sin^2{x}} x^2 dy dx = \int_{-\pi}^{\pi} x^2 2\sin^2{x} dx = 2 \int_{-\pi}^{\pi} 2x^2 \left( \frac{1- \cos{2x}}{2} \right) dx = \\
  &  = \int_{-\pi}^{\pi} x^2 - x^2 \cos{2x}= \boxed{ \frac{2\pi^3}{3} - \pi }
\end{aligned}
\]

\exercisehead{12} $\frac{x}{a} + \frac{y}{b} = 1$, \, $\frac{x}{c} + \frac{y}{b} = 1$, \, $y =0, \, 0 < c < a, \, b > 0 ;  \, f(x,y) = 1$

\[
I_y = \int_0^b \left( \int_{ c(1 - y/b )}^{a(1 - y/b)} x^2 dx \right) dy  = \int_0^b \left( \frac{ a^3 (1-y/b)^3 - c^3(1-y/b)^3 }{3} \right) dy = \left. \left( \frac{a^3 - c^3}{3} \right)(-b)\left( 1 - \frac{y}{b} \right)^4/b \right|_a^b = \boxed{ (a^3 - c^3) \frac{b}{12} }
\]
\[
I_x = \int_0^b y^2 (a-c) (1- y/b) dy = (a-c) \left( \frac{1}{3} b^3 - \frac{1}{4} \frac{b^4}{b} \right) = \boxed{ (a-c)(b^3)/12 }
\]

\exercisehead{13} $(x-r)^2 + (y-r)^2 = r^2$, $y=0, \, x=0$.  $0 \leq x \leq r$, $0 \leq y \leq r$.  So we want the piece of the graph that is the ``lower left-hand corner'' of the ``complement'' of the circle centered at $(r,r)$, with radius $r$.  Be careful about this point.  
\[
\begin{aligned}
  & \text{ since } \begin{aligned} x -r & = r \sin{\theta} \\ dx & = r \cos{\theta} d\theta \end{aligned} \\
  I_x & = \int_0^r \int_0^{r - \sqrt{ r^2 - (x-r)^2} } y^2 dy dx = \int_0^r \frac{1}{3} r^3 \left( 1 - \sqrt{ 1 - \left( \frac{x-r}{r} \right)^2 } \right)^3 dx = \frac{r^4}{3} \int_{-\pi/2}^0 (1-\cos{\theta})^3 \cos{\theta} d\theta = \\
  & = \frac{r^4}{3} \int_{-\pi/2}^0 c - 3c^2 + 3c^3 - c^4 = \boxed{ r^4 \left( 1 - \frac{5\pi}{16} \right) }
\end{aligned} 
\]
Since 
\[
\begin{aligned}
  & \int_{-\pi/2}^0 c = \left. s \right|_{-\pi/2}^0 = -(-1) = 1 \\ 
  & \int_{-\pi/2}^0 c^2 = \int_{-\pi/2}^0 \frac{1 + \cos{2\theta}}{2} d\theta = \frac{\pi}{4} \\ 
  & \int_{-\pi/2}^0 c^3 = \int_{-\pi/2}^0 c(1-s^2) = 1 - \frac{1}{3} ( 0 - (-1)) = 2/3 \\
  & \int_{-\pi/2}^0 c^4 = \int_{-\pi/2}^0 \left( \frac{1 + \cos{2\theta}}{2} \right)^2 d\theta = \int_{-\pi/2}^0 \frac{1}{4} (1 + 2\cos{2\theta} + \cos^2{2\theta} ) d\theta = \frac{1}{4} \left( \frac{\pi}{2} + \frac{\pi}{4} \right) = \frac{3\pi}{16} 
\end{aligned}
\]
\[
\begin{aligned}
  I_y & = \int_0^r \int_0^{r - \sqrt{ r^2 - (x-r)^2} } x^2 dy dx = \int_0^r x^2 r \left( 1 - \sqrt{ 1 - \left( \frac{x-r}{r} \right)^2} \right) dx = \int_{-\pi/2}^0 (r^2)(\sin{\theta} +1)^2 r(1-\cos{\theta}) r\cos{\theta} d\theta = \\
  & = r^4 \int_{-\pi/2}^0 (s^2 + 2s +1)(1-c) c d\theta = r^4 \int_{-\pi/2}^0 (s^2 c + 2sc + c - c^2 s^2 - 2sc^2 - c^2 ) d\theta = \boxed{ r^4 \left( 1 - \frac{5\pi}{16} \right) }
\end{aligned}
\]
Since
\[
\begin{aligned}
  & \int_{-\pi/2}^0 s^2 c = \left. \frac{1}{3} s^3 \right|_{-\pi/2}^0 = \frac{1}{3} \\ 
  & \int c = \left. \frac{1}{2} s^2 \right|_{-\pi/2}^0 = \frac{-1}{2} \\ 
  & \int c = 1 
\end{aligned} \quad \quad \, 
\begin{aligned} 
  & \int c^2 s^2 = \int \left( \frac{ \sin{2\theta}}{2} \right)^2 = \frac{1}{4} \int_{-\pi/2}^0 \frac{1 - \cos{4\theta} }{2} = \frac{\pi}{16} \\ 
  & \int sc^2 = \left. \left( \frac{-1}{3} c^3 \right) \right|_{-\pi/2}^0 = -1/3 \\ 
  & \int c^2 = \pi/4 
\end{aligned}
\]

\exercisehead{16} $y = \sqrt{ 2x}$, \, $y=0$, \, $ 0 \leq x \leq 2$, \, $f(x-y) = |x-y|$
\[
\begin{aligned}
  I_y & = \int_0^2 \int_0^x x^2 dy dx ( x-y) + \int_0^2 \int_x^{\sqrt{ 2x}} x^2 dy dx ( y -x ) = \\
  & = \int_0^2 \left( x^3 (x) - x^2 \frac{1}{2} x^2 \right) + \int_0^2 x^2 \left( \frac{1}{2} ((2x) - x^2) \right) - x^3 (\sqrt{ 2x} - x )  = \\ 
  & = \frac{1}{10} \left. x^5 \right|_0^2 + \frac{1}{4} \left. x^4 \right|_0^2 - \frac{1}{10} \left. x^5 \right|_0^2 - \sqrt{2} \left. \frac{2x^{9/2}}{9} \right|_0^2 + \frac{1}{5} 2^5 = 4- \frac{2^6}{9} + \frac{2^5}{5} = \boxed{ \frac{148}{45} } \\
\end{aligned} 
\]
\[
\begin{aligned} 
 I_x & = \int_0^2 \int_0^x y^2 dy dx (x-y) + \int_0^2 \int_x^{\sqrt{2x}} y^2 dy dx (y-x) = \\
 & = \int_0^2 \left( \left. \frac{1}{3} y^3 \right|_0^x x - \frac{1}{4} \left. y^4 \right|_0^4 \right) dx + \int_0^2 \left( \left. \frac{1}{4} y^4 \right|_x^{\sqrt{2x}} - x \left. \frac{1}{3} y^3 \right|_x^{\sqrt{2x}} \right) dx = \\
  & = \int_0^2 \left( \frac{1}{3} x^4 - \frac{1}{4} x^4 \right) dx + \int_0^2 \frac{1}{4} (4x^2 - x^4) - \frac{x}{3} (2^{3/2} x^{3/2} - x^3 ) = \\
  & = \int_0^2 \left( \frac{1}{12} x^4 + x^2 - \frac{x^4}{4} - \frac{2^{3/2}}{3} x^{5/2} + \frac{x^4}{3} \right) = \int_0^2 \frac{1}{6} x^4 + x^2 - \frac{2^{3/2}}{3} x^{5/2} = \\
  & = \frac{1}{30} (2^5) + \frac{1}{3} 2^3 - \frac{2^{3/2}}{3} \frac{2}{7} 2^{7/2} = \boxed{ \frac{24}{35} }
\end{aligned}
\]


\exercisehead{17} Let $S$ be thin plate of mass $m$.  \\
Let the center of mass of thin plate $S$ be located at the coordinate axis origin.  \\
Let $L_0, L$ be parallel to the $x$ axis.  \\
Let $h$ be the perpendicular distance of $L$ from $L_0$, with the sign of $h$ included.  \\
Since $m$ is the mass, $\int_a^b \int_{\phi_1(x)}^{\phi_2(x)} dy dx = m $ \\ 
Since CM is at $(0,0)$, $\overline{y} = 0 = \int_a^b \int_{\phi_1(x)}^{\phi_2(x)} y dy dx = 0$
\[
\text{ moment of inertia about $L$ } = \int_a^b \int_{\phi_1(x)}^{\phi_2(x)} (y-h)^2 dy dx = \int_a^b \int_{\phi_1(x)}^{\phi_2(x)} y^2 - 2yh + h^2 dy = \boxed{ I_{L_0} + mh^2 } 
\]

\exercisehead{18} The perpendicular direction is given by the following:
\[
(\cos{(\alpha + \pi/2)}, \sin{(\alpha + \pi/2)} ) = (-\sin{\alpha}, \cos{\alpha})
\]
Then
\[
(x,y) \cdot (-\sin{\alpha}, \cos{\alpha}) = - x \sin{\alpha} + y \cos{\alpha} = \delta
\]
We want to find the square of the above quantity, $\delta^2$.
\[
\begin{gathered}
  \int_{-b\sqrt{ 1 - \left( \frac{x}{a} \right)^2 }}^{ b \sqrt{ 1 - \left( \frac{x}{a} \right)^2}} (x^2 \sin^2{\alpha} + -2xy \sin{\alpha} \cos{\alpha} + y^2 \cos^2{\alpha} ) dy = 2x^2 \sin^2{\alpha} b \sqrt{ 1 - (x/a)^2} + \frac{ \cos^2{\alpha}}{3} \left( 2  b^3 \left( 1 - \left( \frac{x}{a} \right)^2 \right)^{3/2} \right) \\ 
  \text{ Let } \left( \frac{x}{a} \right) = \sin{t} \\ 
  \int a^2 \sin^2{t} \cos^2{t} a dt = a^2 \int \left( \frac{\sin{2t}}{2} \right)^2 dt = \frac{a^2}{4} \int \frac{ 1 - \cos{4t}}{2} dt = \frac{a^2 \pi }{8 } \\
  \int_{-\pi/2}^{\pi/2} \cos^3{t} a \cos{t} dt = a \int_{-\pi/2}^{\pi/2} \frac{1 + 2 \cos{2t} + \cos^2{2t}}{4 } = a \left( \frac{\pi}{4} + \frac{\pi}{8} \right) = \frac{ a 3 \pi }{ 8 }  \\
\Longrightarrow 2 b \sin^2{\alpha} \frac{ a^3 \pi }{8} + \frac{2}{3} \cos^2{\alpha} b^3 a \frac{3\pi}{8} = \frac{1}{4} \pi ab ( a^2 \sin^2{\alpha} + b^2 \cos^2{\alpha} )
\end{gathered}
\]
With $m = \pi ab$, the area of the ellipse, we get the desired answer.  


\exercisehead{19}  We want $\int_0^h \int_0^h \sqrt{ x^2 + y^2} dx dy$.  
\[
\int_0^h \sqrt{ x^2 + y^2} dx = \left. \left( \frac{x}{2} \sqrt{ x^2  +y^2} + \frac{y^2}{2} \ln{ (x+ \sqrt{ x^2 +y^2 } )}\right) \right|_0^h = \frac{1}{2} \left( h \sqrt{ h^2 +y^2} + y^2 \ln{( \frac{h}{y} + \sqrt{ 1 + \left( \frac{ h}{y} \right)^2 } )} \right)
\]
since, recall
\[
(\ln{ (x + \sqrt{ x^2 + y^2} )})' = \frac{ 1 + \frac{ x }{\sqrt{ x^2 + y^2}} }{ x + \sqrt{ x^2  +y^2} } = \frac{1}{\sqrt{ x^2 + y^2} } \quad \, \text{ and } \quad \, (x\sqrt{ x^2  +y^2} )' = \sqrt{ x^2 + y^2} + \frac{ x^2}{ \sqrt{ x^2 + y^2}}
\]
\[
\begin{gathered}
  \int_0^h y^2 \ln{ \left( \frac{h}{y} + \sqrt{ 1 + \left( \frac{h}{y} \right)^2 } \right) } dy \xrightarrow{ u = \frac{h}{y} } \int_{\infty}^1 \left( \frac{h}{u} \right)^2 \ln{ (u + \sqrt{ 1 + u^2} )} \frac{-h}{u^2} du = h^3 \int_1^{\infty} \frac{ \ln{ ( u + \sqrt{ 1 + u^2} )}}{u^4} du 
\end{gathered}
\]
\[
\begin{gathered}
  \int \frac{ \ln{ (u + \sqrt{ 1 + u^2})}}{ u^4} = \int \left( \frac{u^{-3}}{-3} \right)' \ln{(u+ \sqrt{ 1 + u^2})} = \frac{u^{-3}}{-3} \ln{ ( u + \sqrt{ 1 + u^2})} - \int \frac{u^{-3}}{-3} \frac{1}{ \sqrt{ 1 + u^2} }
\end{gathered}
\]
\[
\begin{gathered}
  \text{ If we make the following substitution, } \begin{aligned} y & = \frac{1}{u} \\ du & = \frac{-1}{y^2} dy \end{aligned} \\
\begin{aligned}
  \int \frac{u^{-3}}{ \sqrt{ 1 + u^2 } } & = \int \frac{u^{-4}}{ \sqrt{ 1 + \left( \frac{1}{u} \right)^2} } = \int \frac{y^4 \left( \frac{-1}{y^2} \right) dy }{ \sqrt{ 1 + y^2 } } = \int \frac{-y^2}{ \sqrt{ 1 + y^2}} dy = - \left( y \sqrt{ 1 + y^2}  - \int \sqrt{ 1 + y^2 } \right) = \\
  & = -y \sqrt{ 1 + y^2} + \frac{1}{2} ( y \sqrt{ 1 + y^2} + \ln{ ( y + \sqrt{ 1 + y^2} ) } )  = \frac{-1}{2} y \sqrt{ 1 + y^2} + \frac{1}{2} \ln{ (y + \sqrt{ 1 + y^2} ) }
\end{aligned} \\
\left. h^3 \left( \frac{u^{-3}}{-3} \ln{ ( u + \sqrt{ 1 + u^2} ) } \right|_1^{\infty} + \left. \frac{1}{3} \left( \frac{ - \sqrt{ 1 + \left( \frac{1}{u} \right)^2} }{ 2u} + \frac{1}{2} \ln{ \left( \frac{1}{u} + \sqrt{ 1 + \left( \frac{1}{u} \right)^2} \right) } \right) \right) \right|_1^{\infty} = \frac{h^3}{6} ( \sqrt{ 2} + \ln{ (1+ \sqrt{2})} )
\end{gathered}
\]
\[
\Longrightarrow \frac{1}{4} ( h^3 \sqrt{2} + h^3 \ln{ (1+\sqrt{2})}) + \frac{h^3}{12} (\sqrt{2} + \ln{(1+\sqrt{2})} ) = \boxed{ \frac{h^3}{3} (\sqrt{2} + \ln{(1+\sqrt{2})} ) }
\]

\exercisehead{20} Let $P_0 = (0,h)$.  We want
\[
\int_{-R}^R \int_{-\sqrt{ R^2 - x^2}}^{\sqrt{R^2 - x^2 }} (x^2 + (y-h)^2) dy dx
\]
\[
\begin{gathered}
  \int_{-\sqrt{R^2 - x^2} }^{\sqrt{ R^2 - x^2}} (x^2 + (y-h)^2) dy = 2x^2 \sqrt{ R^2 - x^2} + \frac{1}{3} (( \sqrt{ R^2-x^2} - h )^3 - (-\sqrt{ R^2 - x^2 } - h )^3 ) = \\
  =  2 x^2 \sqrt{ R^2-x^2 }+\frac{2}{3} ((R^2-x^2)^{3/2} + 3 \sqrt{ R^2-x^2} h^2 )  = \frac{4}{3} x^2 \sqrt{ R^2-x^2} + \left( \frac{2}{3} R^2 + 2h^2 \right) \sqrt{ R^2-x^2}
\end{gathered}
\]
\[
\begin{gathered}
  \text{ Since } \begin{aligned} x & = R \sin{\theta} \\ dx & = R \cos{\theta} d\theta \end{aligned} \\ 
  \begin{gathered}
  \int_{-R}^{R} x^2 \sqrt{ R^2- x^2} = \int_{-\pi/2}^{\pi/2} R^2 \sin^2{\theta} R^2 \cos^2{\theta} d\theta = R^4 \int_{-\pi/2}^{\pi/2} \left( \frac{\sin{2\theta}}{2} \right)^2 d\theta = \frac{R^4}{4} \int_{-\pi/2}^{\pi/2} \left( \frac{ 1 - \cos{4\theta}}{2} \right) d\theta = \frac{R^4}{8} \pi  
  \end{gathered} \\
  \begin{gathered}
    \int_{-\pi/2}^{\pi/2} \sqrt{ R^2 - x^2} = \int_{-\pi/2}^{\pi/2} \cos{\theta} R \cos{\theta} d\theta (R) = R^2 \int_{-\pi/2}^{\pi/2} \frac{1 + \cos{2\theta} }{2} d\theta = R^2 \frac{\pi}{2} 
  \end{gathered} \\
  \Longrightarrow \frac{4}{3} \frac{ R^4 \pi}{8} + \left( \frac{2}{3} R^2 + 2h^2 \right) R^2 \frac{\pi}{2} = \frac{ R^4 \pi}{6} + \frac{ \pi R^4}{3} + h^2 R^2 \pi = \frac{ \pi R^4}{2} + \pi R^2 h^2 
\end{gathered}
\]
Now 
\[
\iint dy dx = \pi r^2
\]
So then the average of $\delta^2$ is $\boxed{ \frac{R^2}{2} + h^2 }$

\exercisehead{21} 
\[
\begin{aligned}
  A & = [0,4] \times [0,1] \\ 
  B & = [2,3] \times [1,3] \\ 
  C & = [2,4] \times [3,4]
\end{aligned} 
\]
\begin{enumerate}
  \item $A \cup B$ \[
\frac{ 4(2,\frac{1}{2} ) + (2)(\frac{5}{2}, \frac{4}{2} ) }{ 4+2} = \frac{ \frac{1}{2} ( 16 + 10, 10) }{6} = \left( \frac{13}{6} , 1 \right)
\]
  \item $A \cup C$ \[
\frac{ 4 \left( \frac{4}{2}, \frac{1}{2} \right) + 2 \left( \frac{6}{2}, \frac{7}{2} \right) }{ 4 + 2 } = \frac{ (8,2) + (6,7) }{6}  = \left( \frac{7}{3}, \frac{3}{2} \right)
\]
  \item $B \cup C$, \[
\frac{ 2 \left( \frac{5}{2}, \frac{4}{2} \right) + 2 \left( \frac{6}{2}, \frac{7}{2} \right) }{2 + 2 } = \left( \frac{11}{4} , \frac{11}{4} \right)
\]
  \item $A \cup B \cup C$\[
\frac{ 4 ( 2,\frac{1}{2} ) + 4 ( \frac{11}{4}, \frac{11}{4} ) }{ 8 } = \boxed{ \left( \frac{19}{8}, \frac{13}{8} \right) }
\]
\end{enumerate}

\exercisehead{22} \quad \\ $\begin{aligned}
   \text{ rectangle } R: & \, \text{ area } A_R & = 1(2) \quad \, (\overline{x},\overline{y})_R = (0,-1) \\ 
   \text{ triangle } T: & \, \text{ area} A_T & = \frac{1}{2}(1)h = \frac{h}{2} \quad \, \overline{x}_T = 0 
\end{aligned}$
\[
\overline{y}_T A_T = \int_0^h \int_0{ \left( \frac{y}{h} -1 \right)/2 }^{ \left( \frac{y}{h} - 1 \right)/(-2) } y dx dy = \int_0^h \frac{y}{-2} \left( \frac{y}{h} - 1 + \left( \frac{y}{h} - 1 \right) \right) = \int_0^h y - \frac{y^2}{h} = \frac{1}{6} h^2 
\]
\[
\overline{y}_T = \frac{ \frac{1}{6}h^2 }{h/2} = \frac{1}{3} h 
\]
Condition for centroid to lie on the common edge, with the common edge located at the origin:
\[
0 = \frac{ \left( \frac{h}{2} \right)\left( \frac{h}{3} \right) + 2 (-1) }{ h /2 + 2} \Longrightarrow \boxed{ h = 2\sqrt{3}}
\]

\exercisehead{23} 
\[
\begin{aligned}
  \text{ isosceles triangle $T$ }: & A_T = \frac{1}{2} 2r h = rh \quad \, \begin{gathered}  
    \overline{y}_T A_T = \int_0^h \int_{ \left( \frac{y}{h} - 1 \right)(r) }^{ \left( \frac{y}{h} - 1 \right) (-r) } y dx dy = \int_0^h y r \left( \left( \frac{y}{h} -1 \right)(-1) - \left( \frac{y}{h} - 1 \right) \right) dy = \\ 
    = 2 (-r) \int_0^h \frac{y^2}{h} - y dy = (-r) \left( \frac{1}{h} \frac{1}{3}h^3 - \frac{1}{2}h^2 \right) = \frac{1}{3} h^2 r \\ 
    \Longrightarrow \overline{y}_T  = h^2 r /3rh = h /3 
\end{gathered} \\ 
  \text{ semicircular disk $D$ }: & A_D = \frac{1}{2} \pi r^2; \quad \, (2\pi \overline{y})A = 2 \pi \overline{y} \frac{\pi}{2} r^2 = \frac{4}{3} \pi r^3
\end{aligned}
\]
Condition for centroid to lie in triangle:
\[
\frac{ (rh) \left( \frac{h}{3} \right) + \left( \frac{1}{2} \pi r^2 \right) \left( \frac{-4r}{3 \pi } \right) }{ (rh) + \frac{1}{2} \pi r^2 } \geq 0 \quad \text{ or } \frac{r}{3} \left( h^2 + -2r^2 \right) \geq 0  \, \Longrightarrow \boxed{ h > \sqrt{2} r }
\]

\section*{ 11.22  Green's theorem in the plane.  Some applications of Green's theorem.  A necessary and sufficient condition for a two-dimensional vector field to be a gradient. }

\exercisehead{1} Green's theorem: $\int_C P dx + Q dy = \iint_R \left( \frac{\partial Q}{\partial x} - \frac{ \partial P}{\partial y } \right) dx dy $.  Thus
\[
\oint_C y^2 dx + x dy = \iint_R (1-2y)dx dy
\]
\begin{enumerate}
\item $\int_0^2 \int_0^2 (1-2y)dy dx = 4-4(2) = -4$
\item $\int_{-1}^1 \int_{-1}^1 (1-2y)dy dx = 4 $
\item $ \int_{-2}^0 \int_{-2-x}^{2+x} (1-2y) dy dx + \int_0^2 \int_{-2+x}^{2-x} (1-2y) dy dx = \int_{-2}^0 (2(2+x)) dx + \int_0^2 (4-2x) dx = \int_{-2}^0 (4+2x)dx + 4(2)-4 = \boxed{ 8 } $
\item $\int_{-2}^2 \int_{-\sqrt{ 4 -x^2}}^{\sqrt{ 4- x^2}} (1-2y)dy dx = \int_{-2}^2 2 \sqrt{ 4- x^2} dx = \int_{-\pi/2}^{\pi/2} 8 \cos^2{\theta} d\theta = \boxed{ 4 \pi} $ where we used \\
  $\begin{aligned} x & = 2\sin{\theta} \\ dx & = 2 \cos{\theta} d\theta \end{aligned}$
\item $\alpha(t) = (2\cos^3{t},2\sin^3{t}) = 2(\cos^3{t}, \sin^3{t})$, \, $ 0 \leq t \leq 2\pi$
\end{enumerate}

\exercisehead{2} \quad \\
$\begin{aligned}
  P(x,y) & = x e^{-y^2} \\ 
  Q(x,y) & = -x^2 y e^{-y^2} + \frac{1}{x^2+y^2}
\end{aligned}$ \quad \quad \, $\oint P dx + Q dy = \iint \left( \frac{ \partial Q}{\partial x } - \frac{ \partial P }{ \partial y} \right) dx dy$ \\
\[
\begin{gathered}
  \begin{aligned} Q_x & = -2xy e^{-y^2} + \frac{-2x}{ (x^2 +y^2)^2 } \\ 
    P_y & = x e^{-y^2} (-2y) \end{aligned} \\ 
  \int_{-a}^a \int_{-a}^a \frac{-2x}{ (x^2 + y^2)^2 } dx dy = \int_{-a}^a \left. \left( \frac{1}{x^2 + y^2} \right) \right|_{-a}^a dy = \int_{-a}^a \frac{1}{ a^2 + y^2} - \frac{1}{a^2 + y^2} = 0 
\end{gathered}
\]

\exercisehead{3} $n I_z = \oint_C x^3 dy - y^3 dx = \iint_R (3x^2 + 3y^2) dy dx = 3 I_z$  \, $n=3$

\exercisehead{4} $f = (v,u)$, \, $g= ((u_x - u_y), v_x - v_y)$
\[
\begin{gathered}
  (f\cdot g) = vu_x - vu_y + uv_x - uv_y = (uv)_x - (uv)_y = Q_x - P_y \\ 
  \iint_R (f\cdot g) dx dy = \int (uv,uv)\cdot ds = \int (uv,uv) \cdot (-\sin{t},\cos{t}) dt = \int_0^{2\pi} (-\sin^2{t} + \sin{t} \cos{t} dt = \boxed{ - \pi }
\end{gathered}
\]

\exercisehead{5} $f,g \in \mathcal{C}^1$, $f,g$ on open connected set $S$ in the plane.  
\[
\begin{gathered}
  \oint_C f\nabla g \cdot d\alpha = \oint_C fg_x dx + fg_y dy = \iint_R (f_x g_y + fg_{xy}) - (f_y g_x + fg_{yx}) = \\
  = \iint_R -(g_x f_y + gf_{xy}) + (g_y f_x + gf_{yx}) = \iint_R (-gf_y)_x - (-gf_x)_y = \oint -gf_x dx - gf_y dy = -\oint g(\nabla f) \cdot d\alpha
\end{gathered}
\]
Since $f_{xy} = f_{yx}$; \, $g_{xy} = g_{yx}$.  

\exercisehead{6} \begin{enumerate}
\item $\oint_C uv dx + uv dy = \iint (\partial_x (uv) - \partial_y (uv) ) dx dy = \iint v(\partial_x u - \partial_y u) + u (\partial_x v - \partial_y v) dx dy$
\item \[
\begin{gathered}
  \frac{1}{2} \oint_C (v \partial_x u - u \partial_x v ) dx + (u \partial_y v - v \partial_y u ) dy = \frac{1}{2} \iint (u_x v_y + uv_{xy} - v_x u_y - vu_{xy} ) - (v_y u_x + vu_{yx} - u_y v_x - uv_{yx} ) = \\
  = \frac{1}{2} \iint u (v_{xy} + v_{yx}) - v(u_{xy} + u_{yx} ) = \iint u\partial_{yx} v - v \partial_{yx} u 
\end{gathered}
\]
\end{enumerate}

Note the formulation of normal derivatives.  Note that $ds$ refers to the arc length.  
\[
\begin{gathered}
  \int_C (P dx + Q dy ) = \int_C f\cdot T ds \\ 
  T \equiv \text{ unit tangent vector to $C$ } 
\end{gathered} \quad \quad \, \begin{aligned} \alpha(t) & = (X(t),Y(t) ) \\ n(t) & = \frac{1}{ \| \alpha'(t) \| } (Y'(t), X'(t)) \text{ whenever } \| \alpha'(t) \| \neq 0  \end{aligned}
\]
So the normal derivative is defined as 
\[
\frac{ \partial \psi }{ \partial n} = \nabla \psi \cdot n 
\]
\exercisehead{7} \[
\begin{gathered}
  \int_C P dx + Q dy = \int_C (P,Q) \cdot \left( \frac{ds}{dt} \right) dt = \int_C \left( P \frac{dx}{dt} + Q \frac{dy}{dt} \right) dt = \int_C (Q Y' + (-P)(-X'))dt = \\
  = \int_C (Q,-P)\cdot \frac{ (Y',-X')}{ \| \alpha'(t) \|} \| \alpha'(t) \| dt = \int_C f\cdot n ds
\end{gathered}
\]

\exercisehead{8} \begin{enumerate}
\item \[
  \begin{gathered}
    \oint_C \frac{\partial g}{\partial n} ds = \oint_C \nabla \cdot n ds = \oint_C \nabla g \cdot \frac{ (Y', -X')}{\| \alpha'(t) \| } \| \alpha'(t) \| dt = \\
    = \oint_C (g_x Y' + -g_y X')dt = \oint_C g_x dy + - g_y dx = \iint (g_{xx} - (-g_{yy})) dx dy = \iint \nabla^2 g dx dy 
\end{gathered}
  \]
\item \[
\begin{gathered}
  \oint_C f \nabla g \cdot n ds = \oint_C f \nabla g \cdot \frac{ (Y',-X') }{ \| \alpha'(t) \| } \| \alpha'(t) \| dt = \oint_C f(g_x dy - g_y dx) = \\
  = \iint (fg_x)_x - (-fg_y)_y = \iint f_x g_x + fg_{xx} + f_y g_y + f g_{yy} = \iint (\nabla f \cdot \nabla g + f(\nabla^2 g) ) dx dy \\
  \Longrightarrow \oint_C f \frac{\partial g}{\partial n} ds = \iint_R (f\nabla^2 g + \nabla f \cdot \nabla g ) dx dy 
\end{gathered}
\]
\item Use previous part, (b), of this exercise, Exercise 8.  
\[
\begin{aligned}
  \oint_C \left( f \frac{ \partial g }{\partial n} \right) ds & = \iint_R (f\nabla^2 g + \nabla f\cdot \nabla g ) dx dy \\ 
  \oint_C \left( g \frac{ \partial f }{\partial n} \right) ds & = \iint_R (g\nabla^2 f + \nabla g\cdot \nabla f ) dx dy \\ 
\end{aligned} \quad \quad \, \Longrightarrow \oint_C \left( f \frac{ \partial g}{\partial n} - g \frac{ \partial f}{ \partial n } \right) ds = \iint_R ( f \nabla^2 g - g \nabla^2 f) dx dy 
\]
\end{enumerate}

\exercisehead{9}  $P(x,y) dx + Q(x,y) dy = 0$.   \\
$\mu(x,y)$ is an integration factor, so $\mu P dx + \mu Q dy = 0$ leads to $\phi{(xy)} =C$ s.t. $\begin{aligned} \phi_x & = \mu P \\ \phi_y & = \mu Q \end{aligned}$ \smallskip \\
Slope of $\phi(x,y) = c$ at $(x,y)$ is $\tan{\theta}$, so $\tan{\theta} = \frac{ dY /dt}{ dX /dt}$ \smallskip \\
$ n =(\sin{\theta}, -\cos{\theta})$

\[
\begin{gathered}
  \frac{ \partial \phi}{ \partial n} = \nabla \phi \cdot n = (\nabla \phi) \cdot (\sin{\theta}, -\cos{\theta}) = \phi_x \sin{\theta} - \phi_y \cos{\theta} = \mu P \sin{\theta} - \mu Q \cos{\theta} = \\
  = \mu (P \sin{\theta} - Q \cos{\theta}) = \mu(x,y) g(x,y) \\ 
\Longrightarrow g = P \sin{\theta} - Q \cos{\theta} \\
\begin{aligned}
  \sin{\theta} & = \frac{- P}{ \sqrt{ P^2 + Q^2 }} \text{ or }  \frac{ P}{\sqrt{ P^2 + Q^2 } } \\ 
  \cos{\theta} & = \frac{ Q}{ \sqrt{ P^2 + Q^2} } \text{ or } \frac{ Q}{ \sqrt{ P^2 + Q^2 } }
\end{aligned} \Longrightarrow g = -\sqrt{ P^2 + Q^2 } \text{ or } \sqrt{ P^2 + Q^2 }
\end{gathered}
\]

\section*{ 11.25 Exercises - Green's theorem for multiply connected regions.  The winding number.  }

\exercisehead{1}
\begin{enumerate}
\item  Note that 
\[
\begin{aligned}
  & \partial_x Q = \frac{ -x }{ x^2 + y^2 } \left( \frac{1}{x} + \frac{ (-1)(2x) }{ x^2 + y^2 } \right) = \frac{-x}{ x^2 + y^2 } \left( \frac{ x^2  +y^2 - 2x^2 }{ x(x^2 + y^2 )} \right) = \frac{ x^2 - y^2 }{ (x^2 + y^2)^2 } \\
  &  \partial_y P = \partial_y \left( \frac{y}{ x^2 + y^2 } \right) = - \left( \frac{ y^2 - x^2 }{ (x^2 + y^2)^2 } \right)
\end{aligned}
\]
Note that $\partial_x Q, \, \partial_y P$ is not continuous at $(0,0)$.  
\[
\begin{gathered}
  \text{ So then for } \begin{aligned} x &= \cos{t} \\ y & = \sin{t} \end{aligned} \quad \quad \, \begin{aligned} P(x,y) & = \frac{y}{ x^2 + y^2 } \\ Q(x,y) & = \frac{-x}{x^2 + y^2 } \end{aligned}  \\
  \begin{aligned}
    \int_C P dx & = \int_0^{2\pi} \sin{t} (-\sin{t}) dt = -\pi \\
    \int_C Q dx & = \int_0^{2\pi} -\cos{t} (\cos{t}) dt = - \pi 
\end{aligned} \\
  \int_C P dx + Q dy = - 2\pi 
\end{gathered}
\]
$+$ sign occurs when $C$ is in the clockwise direction, since if $x= \cos{t}$, $y= -\sin{t}$, then $\int_C P dx + Q dy = 2\pi$ and all clockwise direction, piecewise smooth Jordan curves whose interior contains $(0,0)$ can be deformed into a circle (by Thm.).
\item By Thm., we can pick any piecewise smooth Jordan curve whose interior doesn't contain $(0,0)$.  

Recall Green's theorem.  
\[
\int_C P dx + Q dy = \iint_R \left( \frac{ \partial Q }{ \partial y} - \frac{ \partial P }{ \partial x } \right) = 0 
\]
Since $\frac{ \partial Q}{ \partial y}, \, \frac{ \partial P}{ \partial x }$, is continuous everywhere in $C \cup int{C}$, where $(0,0) \notin C$
\end{enumerate}

\exercisehead{2} \[
\begin{gathered}
  f = \left( \frac{ \partial (\ln{r} )}{ \partial y}\, , - \frac{ \partial (\ln{r})}{ \partial x } \right)  \quad \quad \, \begin{aligned} x & = a \cos{t} \\ y &  = a \sin{t} \end{aligned} \quad \, \alpha = (x,y)  \quad \quad \, \sqrt{ x'^2  +y'^2 } = \| \alpha' \| =a \\
  \begin{aligned}
  \ln{r} = \ln{ \sqrt{ x^2 + y^2 }} = \frac{1}{2} \ln{ (x^2 + y^2 )} \\
  (\ln{r})_x = \frac{1}{2} \frac{ 1 }{ x^2 + y^2 } (2x) = \frac{x}{ x^2 + y^2 } 
\end{aligned} \quad \, 
\end{gathered}
\]
\[
\begin{aligned}
  \int f \cdot ds & = \int f \cdot \frac{dr}{dt} dt = \int \left( \frac{ \partial (\ln{r})}{\partial y} a (-\sin{t}) + \frac{ - \partial (\ln{r})}{ \partial x} a \cos{t} \right) dt = \int \frac{ \partial (\ln{r})}{ \partial y } \frac{dx}{dt} + \frac{ - \partial (\ln{r} )}{ \partial x } \frac{dy}{dt} dt = \\
  & = \int \frac{ y}{ x^2 + y^2 } dx + \frac{-x}{ x^2 + y^2 } dy = \boxed{ - 2\pi } \text{ as shown in the previous exercise, Exercise 1. }
\end{aligned}
\]

\exercisehead{5}
\begin{enumerate}
\item $I_1 - I_3 = 12 - 15 = -3$  
\item One possible solution is this: Draw a large curve around all 3 points, for $I_1 + I_2 + I_3 = 37$.  Then circle around, inside, point 1, three times, in a clockwise fashion, to obtain $-3I_1 = -36$.  
\end{enumerate}

\exercisehead{6} $\alpha(t) = (X(t),Y(t))$ if $a \leq t \leq b$  \quad \quad \, $ n = \frac{ (Y'(t),X'(t))}{ \sqrt{ X'^2 + Y'^2}}$
\[
\begin{gathered}
\begin{aligned}
  W(\alpha_0; P_0) & = \frac{1}{2\pi} \int_a^b \frac{ (X(t) - x_0) Y'(t) - (Y(t) - y_0)X'(t) }{ (X(t) - x_0)^2 + (Y(t) - y_0)^2 } dt = \\ 
  & = \frac{1}{2\pi} \int_a^b \frac{ (r(t) - P_0) \cdot n}{ \| r(t) - P_0 \|^2 } \| \alpha'(t) \| dt = \frac{1}{2\pi} \int_a^b \left( \frac{ r(t) - P_0 }{ \| r(t) - P_0 \| } \right) \frac{ n }{ \| r(t) - P_0 \| } ds 
\end{aligned} \\
  I_k = \oint_{C_k} P dx + Q dy \\ 
  \begin{aligned}
  P(x,y) & = -y \left( \frac{1}{ (x-1)^2 + y^2 } + \frac{1}{ x^2 + y^2} + \frac{1}{ (x+1)^2 + y^2 } \right) = \\ 
  &  = - y \left( \frac{1}{ \| (x,y) - (1,0) \|^2 } + \frac{1}{ \| (x,y) - (0,0) \|^2 } + \frac{1}{ \| (x,y) - (-1,0) \|^2 } \right) 
\end{aligned} \\
  Q(x,y) = \frac{ (x-1) }{ \| (x,y) - (1,0) \|^2 } + \frac{ x}{ \| (x,y) - (0,0) \|^2 } + \frac{ x+1}{ \| (x,y) - (-1,0) \|^2 }
\end{gathered}
\]
\[
\begin{aligned}
  & C_1 \text{ is the smallest circle,} x^2 + y^2 = \left( \frac{1}{ 2\sqrt{2}} \right)^2 \\
  & C_2: \, x^2 + y^2 = 2^2 \\
  & \quad \, \\
  & C_3: \, \begin{aligned} (x-1)^2  + y^2 & = \left( \frac{1}{2} \right)^2 \\ x^2 + y^2 & = \left( \frac{1}{2} \right)^2 \\ (x+1)^2 + y^2 & = \left( \frac{1}{2} \right)^2 \end{aligned}
\end{aligned} \quad \quad \, 
\begin{aligned}
  I_2 & = 6 \pi \\ 
  I_3 & = 2 \pi 
\end{aligned}
\]

$I_k = \oint_{C_k} P dx + Q dy = \int \left( \frac{ (x,y) - (1,0)}{ \| (x,y) - (1,0) \|^2 } + \frac{ (x,y) - (0,0) }{ \| (x,y) - (0,0) \|^2 } + \frac{ (x,y) - (-1,0)}{ \| (x,y) - (-1,0) \|^2 } \right) \cdot n ds $ \\
$I_2$ wraps around 3 holes, $(1,0), (0,0), (-1,0)$.   \\
$I_3$ wraps around $(0,0)$ clockwise and around $(1,0), (-1,0)$ counterclockwise.  The wrap around $(0,0)$ and $(1,0)$ cancel each other and so the result is we wrap around $(-1,0)$.  
\[
\Longrightarrow \boxed{ I_1 = 2\pi }
\]

\section*{ 11.28 Exercises - Change of variables in a double integral, Special cases of the transformation formula }

\exercisehead{1} $S = \{ (x,y) | x^2 + y^2 \leq a^2 \}$ where $a >0$.  \\
Recall,
\[
\idotsint_{\mathcal{D}} f(\phi(u)) |det{D \phi(u)} | du_1, \dots, du_n = \idotsint_{\mathcal{D}} f(x) dx_1, \dots, dx_n \quad \quad \, \phi(\mathcal{D}) = \mathcal{D}^*
\]
\[
\begin{aligned}
  x & = r\cos{\theta} \\ 
  y & = r\sin{\theta}
\end{aligned} \quad \quad \, \left| \begin{matrix} \cos{\theta} & - r\sin{\theta} \\ \sin{\theta} & r\cos{\theta} \end{matrix} \right| = r > 0 \quad \quad \, \iint_S f(x,y) dx dy = \int_0^{2\pi} \int_0^a f(r\cos{\theta},r\sin{\theta})r dr d\theta
\]
\exercisehead{2} $S = \{ (x,y) | x^2  +y^2 \leq 2 x \}$
\[
\begin{gathered}
  (x-1)^2  + y^2 = 1 \\ 
  (1,0)
\end{gathered} \quad \, \begin{aligned}
  x-1 & = r \cos{\theta} \\ 
  x & = r\cos{\theta} + 1 \\ 
  y & = r\sin{\theta} 
\end{aligned} \quad \, \iint_S f(x,y) dx dy = \int_0^{2\pi} \int_0^1 f(r\cos{\theta}  +1, r\sin{\theta}) r dr d\theta
\]

\exercisehead{3} $S = \{ (x,y) | a^2 \leq x^2 + y^2 \leq b^2 \}$ where $0 < a < b$
\[
\iint_S f(x,y) dx dy = \int_0^{2\pi} \int_a^b f(r\cos{\theta}, r\sin{\theta})r dr d\theta
\]

\exercisehead{4} $S = \{ (x,y) | 0 \leq y \leq 1 - x, \, 0 \leq x \leq 1 \}$
\[
\begin{gathered}
  r\sin{\theta} \leq 1 - r\cos{\theta} \Longrightarrow r \leq \frac{1}{ \sin{\theta} + \cos{\theta} }, \, \text{ since } \sin{\theta}, \cos{\theta} \geq 0 \\
  \int_0^{\pi/4} \int_0^{\frac{1}{\sin{\theta} + \cos{\theta}}} f(r\cos{\theta}, r\sin{\theta}) rdr d\theta
\end{gathered}
\]

\exercisehead{5} $S = \{ (x,y) | x^2 \leq y \leq 1, \, - 1 \leq x \leq 1 \}$
Consider imaginary angular wedges dividing up the parabolic region.  Then we identify 3 regions since each region have different boundaries.  
\[
\begin{gathered}
  y = 1 = r\sin{\theta} \text{ or } r =\csc{\theta} \\ 
  x^2 = r^2 \cos^2{\theta} = r\sin{\theta} \text{ or } r = \tan{\theta} \csc{\theta}
\end{gathered}
\]
Observe that $y=x$ or $\theta = \frac{\pi}{4}$, and $y=-x$ or $\theta = \frac{-\pi}{4}$, divide up the regions.  
\[
\int_0^{\pi/4} \int_0^{\tan{\theta} \csc{\theta}} f(r\cos{\theta}, r\sin{\theta}) rdr d\theta + \int_{\frac{\pi}{4}}^{ \frac{3\pi}{4} } \int_0^{\csc{\theta}} f(r\cos{\theta}, r\sin{\theta}) rdr d\theta + \int_{\frac{3\pi}{4} }^{\pi} \int_0^{\tan{\theta} \csc{\theta}} f(r\cos{\theta},r\sin{\theta}) r dr d\theta
\]

\exercisehead{6} Note that $\sqrt{ 2ax - x^2} = \sqrt{ a^2 - (a-x)^2}$.  Then
\[
\begin{gathered}
  y^2 = a^2 - (a-x)^2 \\ 
  (x-a)^2 + y^2 = a^2 
\end{gathered} \quad \quad \, 
\begin{gathered}
  x - a =r \cos{\theta} \\ 
  y = r \sin{\theta} \\
  x^2 = (a + r\cos{\theta})^2 = a^2 + 2ar \cos{\theta} + r^2 \cos^2{\theta} 
\end{gathered}
\]
\[
\int_0^{2a} \left( \int_0^{\sqrt{ 2ax - x^2}} (x^2 + y^2 ) dy \right) dx = \int_0^{\pi} d\theta \int_0^a r dr (a^2 + 2ar\cos{\theta} + r^2 ) = a^2 \frac{ a^2 \pi}{2} + \int_0^{\pi} \frac{2a\cos{\theta} a^3}{3} d\theta + \frac{ a^4 \pi}{4} = \boxed{ \frac{3a^4 \pi}{4} } 
\]


\exercisehead{7} $x=a \Longrightarrow r\cos{\theta} =a \text{ or } r = a \sec{\theta}$
\[
\begin{gathered}
  \int_0^a \left( \int_0^x \sqrt{ x^2 + y^2} dy \right) dx = \int_0^{\pi/4} d\theta \int_0^{a \sec{\theta}} r^2 dr = \int_0^{\pi/4} \frac{ a^3 \sec^3{\theta}}{3}  \\
  \text{ Now } \int \sec^3{\theta} = \int \sec{\theta}(1 + \tan^2{\theta}) \text{ and } \\ 
  \begin{gathered}
    \int \sec{\theta} = \ln{ | \sec{\theta} + \tan{\theta} |} \\
    \int (\sec{\theta} \tan^2{\theta}) = \int (\sec{\theta})' \tan{\theta} = \sec{\theta} \tan{\theta} - \int \sec{\theta} \sec^2{\theta} 
  \end{gathered} \Longrightarrow \int \sec^3{\theta} = \frac{ \sec{\theta} \tan{\theta} + \ln{ |\sec{\theta} +\tan{\theta} } }{2} \\ 
  \Longrightarrow \frac{a^3}{3} \int_0^{\pi/4} \sec^3{\theta} d\theta = \frac{ a^3 (\sqrt{2} + \ln{ |\sqrt{2} + 1 | } ) }{6} 
\end{gathered}
\]

\exercisehead{8} 
\[
\begin{gathered}
\text{ Since } 
  y = r \sin{\theta} = x^2 = r^2 \cos^2{\theta} \text{ or } r = \tan{\theta} \sec{\theta}  \\ 
  \int_0^{\pi/4} d\theta \int_0^{\tan{\theta} \sec{\theta} } \frac{1}{r} r dr = \int_0^{\pi/4} d\theta \tan{\theta} \sec{\theta} = \boxed{ \sqrt{2} - 1 } 
\end{gathered}
\]

\exercisehead{9}
\[
\int_0^a \left( \int_0^{\sqrt{ a^2 - y^2}} (x^2 +y^2) dx \right) dy = \int_0^{\pi/2} \int_0^a r^2 r dr d\theta = \frac{ a^4 \pi}{8 }
\]

\exercisehead{10} After sketching a box with vertices at $(0,0), (1,0), (0,1), (1,1)$, it's very clear that in polar coordinates, we must divide the region into 2 parts by the $y=x$ line since each region have different boundaries for $r$.  
\[
\begin{gathered}
  \int_0^1 \left( \int_0^x f(x,y) dy \right) dx = \int_0^{\pi/4} d\theta \int_0^{\sec{\theta}} f(r\cos{\theta}, r\sin{\theta}) r dr + \int_0^{\pi/4} d\theta \int_0^{\csc{\theta}} f(r\cos{\theta}, r\sin{\theta}) r dr \text{ since } \\ 
  \begin{aligned}
    x & = 1 = r \cos{\theta} \\ 
    y & = 1 = r \sin{\theta} 
  \end{aligned}
\end{gathered}
\]

\exercisehead{11} $\int_0^2 \left( \int_x^{x\sqrt{3}} f(\sqrt{ x^2 + y^2} ) dy \right) dx = \int_{\pi/4}^{\pi/3} \int_0^{2 \sec{\theta} } f(r) r dr d\theta$ 
\[
\begin{gathered}
  x = 2 = r\cos{\theta} \\ 
  r = 2\sec{\theta}
\end{gathered}
\]

\exercisehead{12} $\int_0^1 \left( \int_{1-x}^{\sqrt{ 1 - x^2}} f(x,y) dy \right) = \int_0^{\pi/2} d\theta \int_{\frac{1}{ \sin{\theta} + \cos{\theta}}}^1 f(r\cos{\theta}, r\sin{\theta}) rdr$ since
\[
\begin{gathered}
  y = 1 - x = r\sin{\theta} = 1 - r \cos{\theta} \\
  r = \frac{1}{ \sin{\theta} + \cos{\theta} }
\end{gathered}
\]

\exercisehead{13} $\int_0^1 \left( \int_0^{x^2} f(x,y) dy \right) dx = \int_0^{\pi/4} \int_{\sec{\theta}}^{\tan{\theta} \sec{\theta}} f(r\cos{\theta}, r\sin{\theta}) r dr d\theta$ since
\[
\begin{gathered}
  y = x^2 = r\sin{\theta} = r^2 \cos^2{\theta} \\ 
  \Longrightarrow r = \tan{\theta} \sec{\theta} 
\end{gathered} \quad \quad \, 
\begin{gathered}
  1 = x = r \cos{\theta} \\ 
   r = \sec{\theta}
\end{gathered}
\]

\exercisehead{14} Let $\begin{aligned} x + y & =  u \\ x - y & =v \end{aligned}$ 
\[
\begin{gathered}
  \left[ \begin{matrix} 1 & 1 \\ 1 & -1 \end{matrix} \right] \left[ \begin{matrix} x \\ y \end{matrix} \right] = \left[ \begin{matrix} u \\ v \end{matrix} \right]  \quad \, \Longrightarrow \left[ \begin{matrix} x \\ y \end{matrix} \right] = \frac{1}{-2} \left[ \begin{matrix} 1 & -1 \\ -1 & 1 \end{matrix} \right] \left[ \begin{matrix} u \\ v \end{matrix} \right] \\
  J = \left| \begin{matrix} \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & \frac{-1}{2} \end{matrix} \right| = \frac{-1}{2}
\end{gathered}
\]
Sketch the transformation of $S$ to obtain a rectangle with vertices $(\pi,\pi), (3\pi,\pi), (\pi,-\pi), (3\pi,-\pi)$.  
\[
\int_{\pi}^{3\pi} du \int_{-\pi}^{\pi} dv v^2 \sin^2{u} \left( \frac{-1}{2} \right) = \frac{-1}{2} \int_{\pi}^{3\pi} \left( \frac{ 1 - \cos{2u}}{2} \right) \frac{2}{3} \pi^3 = \boxed{ - \frac{ \pi^4}{3}}
\]


\exercisehead{15} \[
\begin{gathered}
  (0,0), (2,10), (3,17), (1,7) \Longrightarrow (0,0), (4,2)  \\
  \begin{aligned} u & = ax + by \\ v & = cx + dy \end{aligned} \quad \quad \begin{aligned} \left( \begin{matrix} 4 \\ 0 \end{matrix} \right) & = \left( \begin{matrix} a 2 + b 10 \\ c 2 + d 10 \end{matrix} \right) \\ \left( \begin{matrix} 0 \\ 2 \end{matrix} \right) & = \left( \begin{matrix} a + 7b \\ c + 7 d \end{matrix} \right) \end{aligned} \quad \, \Longrightarrow \begin{aligned} b & = -1 \quad \, a & = 7 \\ d & = 1 \quad \, c & = -5 \end{aligned} \\
  \left[ \begin{matrix} 7 & - 1 \\ -5 & 1 \end{matrix} \right] \left[ \begin{matrix} x \\ y \end{matrix} \right] = \left[ \begin{matrix} u \\ v \end{matrix} \right] \quad \quad \, \frac{1}{2} \left[ \begin{matrix} 1 & 1 \\ 5 & 7 \end{matrix} \right] \left[ \begin{matrix} u \\ v \end{matrix} \right] = \left( \begin{matrix} \frac{ u + v }{2} \\ \frac{ 5u + 7v }{2} \end{matrix} \right) = \left( \begin{matrix} x \\ y \end{matrix} \right) 
\end{gathered}
\]
\[
\int_0^2 \int_0^4 \frac{ 5 u^2 + 12 uv + 7 v^2 }{ 8} du dv = \int_0^2 \frac{5}{24} \left.  u^3 \right|_0^4 + \frac{3}{4} \left. u^2 v \right|_0^4 + \frac{7}{8}  v^2 (4) dv = \frac{ 5}{3} 16 + 24 + \frac{ 28}{3} = \boxed{ 60 } 
\]
\exercisehead{16} If $r > 0$, let $I(r) = \int_{-r}^r e^{-u^2} du$.  
\begin{enumerate}
\item \[
I^2(r) = \left( \int_{-r}^r e^{-u^2} du \right)^2 = \left( \int_{-r}^r e^{-x^2} dx \right) \left( \int_{-r}^r e^{-y^2} dy \right) = \int_{-r}^r dy \int_{-r}^r dy \int_{-r}^r e^{-x^2 - y^2} dx = \int_{-r}^r \int_{-r}^r e^{-x^2 - y^2} dx dy 
\]
\item Let $C_1$ have radius $a$, $C_2$ have radius $b$, $C_1 \subset R \subset C_2$, and since $e^{-(x^2 + y^2)} > 0$, \, $\forall \, x ,y \in \mathbb{R}$, then
\[
\iint_{C_1} e^{-(x^2 + y^2)} dx dy < I^2(r) < \iint_{C_2} e^{ - (x^2 + y^2)} dx dy
\]
\item \[
\begin{gathered}
  \int_0^{2\pi} \int_0^a e^{-r^2} dr r d\theta = \left. \int_0^{2\pi} \left( \frac{ e^{-r^2}}{ -2} \right) \right|_0^a d\theta = \left. \left( \frac{ e^{-a^2 } - 1 }{ -2} \right) \right|_0^{2\pi} = 2\pi \left( \frac{ 1 - e^{-a^2}}{2} \right) \xrightarrow{ a \to \infty} \pi \\
  I(r) \to \sqrt{ \pi} \text{ as } r \to \infty \\
  I(r) = \int_{-r}^r e^{-u^2} du = 2 \int_0^r e^{-u^2} du = \sqrt{ \pi } \quad \quad \, \int_0^r e^{-u^2} du = \frac{ \sqrt{ \pi} }{2} 
\end{gathered}
\]
\item \[
  \begin{gathered}
    \Gamma(s) = \int_{0^+}^{\infty} t^{s-1} e^{-t} dt \\
    \Gamma{\left( \frac{1}{2} \right)} = \int_0^{\infty} t^{-1/2} e^{-t} dt = \int_0^{\infty} u^{-1} e^{-u^2} 2u du = 2 \int_0^{\infty} e^{-u^2} du = 2 \frac{ \sqrt{ \pi} }{2} = \sqrt{ \pi } \\
    \text{ since } \begin{aligned} t & = u^2 \\ dt & = 2u du \end{aligned}
  \end{gathered}
  \]
\end{enumerate}

\exercisehead{17} $\begin{aligned} x & = u + v \\ y & = v - u^2 \end{aligned}$ 
\begin{enumerate}
  \item $det{ D \phi} = \left| \begin{matrix} 1 & 1 \\ -2u & 1 \end{matrix} \right| = 1 + 2u$
  \item \[ 
    \begin{aligned}
      & (u,0) \Longrightarrow (u , -u^2) \quad  u & \in [0,2] \\ 
      & (0,v) \Longrightarrow (v,v) \quad v & \in [0,2] \\ 
      & (u,2-u) \Longrightarrow (u + 2 -u, 2 - u -u^2) = (2, -(u+\frac{1}{2})^2 + \frac{9}{4}) \quad u & \in [0,2] 
\end{aligned} \]
  \item \[
\begin{gathered}
  \iint_T du dv (1+ 2u) = \int_0^2 \int_0^{2-u} (1+2u) dv du = \left. (2u - \frac{1}{2} u^2 ) \right|_0^2 + \int_0^2 2u (2-u) du = \frac{14}{3} \\ 
  \int_0^2 dx \int_{-x^2}^x dy = \int_0^2 dx ( x+x^2) = \left. \left( \frac{1}{2} x^2 + \frac{1}{3} x^3  \right) \right|_0^2 = \frac{14}{3}
\end{gathered}
\]
  \item \[
\begin{gathered}
  \iint_S (x-y+1)^{-2} dx dy = \int_0^2 \int_0^{2-u} (u+v -v + u^2 + 1 )^{-2} (1+2u) du dv = \int_0^2 dv \int_0^{2-v} \frac{1+ 2u}{ (u^2 + u +1)^2} du = \\
  = \int_0^2 dv \left. \left( \frac{-1}{ u^2 + u + 1 } \right) \right|_0^{2-v}   = \int_0^2 dv \left( 1 - \frac{1}{ 4 - 4v + v^2 + 2 -v + 1 } \right) \\ 
  \text{ Now } \\
  \int_0^2 \frac{ 1}{ 7 - 5v + v^2}  = \int_0^2 \frac{1}{ (v- \frac{5}{2} )^2 + \frac{3}{4} } = \int \frac{4/3}{ \left( \frac{2}{\sqrt{3}} (v-\frac{5}{2}) \right)^2 + 1  } = \left. \frac{ 4}{3} \left( \frac{ \arctan{ \frac{2}{\sqrt{3}} (v-\frac{5}{2} ) } }{ 2 /\sqrt{3}} \right) \right|_0^2 = \\
  = \frac{2\sqrt{3}}{3} \left( \arctan{ \left( \frac{-1}{\sqrt{3}} \right) } - \arctan{ \left( \frac{5}{\sqrt{3}} \right) } \right) \\
  \Longrightarrow \iint_S (x-y+1)^{-2} dx dy = 2 - \frac{2 \sqrt{3}}{3} \left( \arctan{ \left( \frac{-1}{\sqrt{3}} \right) } - \arctan{ \left( \frac{5}{\sqrt{3} } \right) } \right)
\end{gathered}
\]
\end{enumerate}

\exercisehead{18} $\begin{aligned} x & = u^2 - v^2 \\ y & = 2uv \end{aligned}$ 
\begin{enumerate}
\item $J(u,v) = det{D\phi} = \left| \begin{matrix} 2u & -2v \\ 2v & 2u \end{matrix} \right| = 4 u^2 + 4 v^2 = 4(u^2 + v^2)$
\item Note the transformation of the boundaries.  \[
\begin{aligned}
  & (u,1), \, u & \in [1,2] \quad & \begin{aligned} x & = u^2 - 1 \\ y & = 2u \end{aligned} \quad & x & = \frac{y^2 }{4} - 1 \quad & \begin{aligned} y & \in [2,4] \\ x & \in [0,3] \end{aligned} \\ 
  & (2,v), \, v & \in [1,3] \quad & \begin{aligned} x & = 4 - v^2 \\ y & = 4 v \end{aligned} \quad & x & = 4 - \frac{y^2}{16} \quad & \begin{aligned} y & \in [4,12] \\ x & \in [-5,3] \end{aligned} \\
  & (u,3), \, u & \in [1,2] \quad & \begin{aligned} x & = u^2 - 9 \\ y & = 6u \end{aligned} \quad & x & = \frac{y^2}{36} - 9 \quad & \begin{aligned} y & \in [6,12] \\ x & \in [-8,-5] \end{aligned} \\ 
  & (1,v), \, v & \in [1,3] \quad & \begin{aligned} x & = 1 - v^2 \\ y & = 2v \end{aligned} \quad & x & = 1 - \frac{y^2}{4} \quad & \begin{aligned} y & \in [2,6] \\ x & \in [-8,0] \end{aligned}
\end{aligned}
\]
\item \[
x^2 + y^2 = u^4 - 2u^2 v^2 + v^4 + 4u^2 v^2 = (u^2 + v^2)^2 = 1 \Longrightarrow u^2 + v^2 = 1 
\]
Circle is invariant under ``hyperbolic'' transformation.  
\[
\begin{aligned}
  \int_{-1}^1 \int_{-\sqrt{ 1 - u^2}}^{\sqrt{ 1 - u^2}} (u^2 - v^2)(2uv) 4 (u^2 + v^2) du dv & = 8 \int_{-1}^1 du \int_{-\sqrt{ 1 - u^2}}^{\sqrt{ 1 - u^2 }} (u^2 - v^2)(uv) dv = \\
  & = 8 \int_{-1}^1 du \left( \frac{u^3}{2} ((1-u^2) - (1-u^2) ) - u \frac{1}{4} (0) \right) = \boxed{ 0 } 
\end{aligned}
\]
\end{enumerate}

\exercisehead{19} \[
\begin{gathered}
  I(p,r) = \iint_R \frac{ dx dy }{ (\rho^2 + x^2 + y^2 )^p } = \int_0^{2\pi} d\theta \int_0^R \frac{ rdr }{ (p^2 + r^2)^p } = \begin{cases} \int_0^{2\pi} d\theta \left. \frac{ (p^2  +r^2)^{-p+1}}{ 2(1-p)} \right|_0^R = \frac{ \pi}{ 1 - p } ((p^2 + R^2)^{-p + 1} - (p^2)^{-p+1} ) \\
    \int_0^{2\pi} d\theta \frac{ \ln{ 1^2 + R^2}}{2 }  = \pi \ln{ ( 1 + R^2) } 
\end{cases} \\ 
  R \to \infty, \, \text{ if } p > 1, \, \lim_{R \to \infty} I(p,r) = \frac{- \pi}{1-p} p^{2 - 2p }
\end{gathered}
\]

\exercisehead{20} Let $u = x+y$.  Note that the region in $xy$ is a rectangle starting from $P = (0,-1)$ and spanned by $a = (1,1), \, b = (-1,1)$.  
\[
\begin{gathered}
  \left( \begin{matrix} x \\ y \end{matrix} \right) = \left( \begin{matrix} 0 \\ -1 \end{matrix} \right) + s \left( \begin{matrix} 1 \\ 1 \end{matrix} \right) + t \left( \begin{matrix} -1 \\ 1 \end{matrix} \right) \quad \quad \, det{D \phi} = \left| \begin{matrix} 1 & -1 \\ 1 & 1 \end{matrix} \right| = 1 + 1 = 2 \\ 
  \begin{aligned}
    x & = s + -t \\ 
    y & = -1 + s +t 
  \end{aligned} \quad \quad \, x+ y = 2s - 1 \\
  \Longrightarrow \iint_S f(x+y) dy dx = \int_0^1 \int_0^1 f(2s- 1) 2ds dt = 2 \int_0^1 f(2s-1) ds = \int_{-1}^1 f(u) du 
\end{gathered}
\]

\exercisehead{21} Look at what we want.  We eventually want $ax+by = u \sqrt{ a^2 + b^2}$.  Then try that substitution.  

Also note that we want $J(x,y) = det{D\phi} \neq 0$ for all points considered.  We are given that $a^2 +b^2  \neq 0$.  Then try to get that as a nonzero factor for $J$, the Jacobian.  

\[
\begin{gathered}
  \begin{aligned} ax + by & = Au  \\ cx + dy & = Av \end{aligned} \quad \, \Longrightarrow \begin{gathered} A = \sqrt{ a^2 + b^2 } \\ \left[  \begin{matrix} a & b \\ c & d \end{matrix} \right] \left[ \begin{matrix} x \\ y \end{matrix} \right] = \left[ \begin{matrix} A u \\ A v \end{matrix} \right] \end{gathered} \\
  \Longrightarrow \left[ \begin{matrix} x \\ y \end{matrix} \right] = \frac{1}{ ad - bc} \left[ \begin{matrix} d & -b \\ -c & a \end{matrix} \right] \left[ \begin{matrix} A u \\ Av \end{matrix} \right]  \\
\text{ We want $ad-bc \neq 0 $ so simply use our hypothesis: $a^2 + b^2 \neq 0 $.  Then $d = a, \, c = -b$ } \\
\Longrightarrow \left( \begin{matrix} x \\ y \end{matrix} \right) = \frac{1}{A} \left( \begin{matrix} ua - bv \\ ub+av \end{matrix} \right) \quad \quad det{ D \phi} = \left| \begin{matrix} \frac{a}{A} & \frac{-b}{A} \\ \frac{b}{A} & \frac{a}{A}\end{matrix} \right| = 1 
\end{gathered}
\]
Let's observe how the circular region in $xy$ changes with $uv$.  
\[
x^2 + y^2 = 1 = \frac{ a^2 u ^2 - 2ab uv + b^2 v^2 }{ A^2} + \frac{ b^2 u ^2 + 2abuv + a^2 v^2 }{A^2} = u^2 + v^2 = 1
\]
Amazing!  The circle is invariant under a normalized linear transformation of nonzero determinant.  
\[
\Longrightarrow \int_{-1}^1 \int_{-\sqrt{ 1 - u^2}}^{ \sqrt{ 1 - u^2}} f(u+c) dv du = 2 \int_{-1}^1 \sqrt{ 1 - u^2 } f(u \sqrt{ a^2 + b^2 } )du 
\]

\exercisehead{22} From the given problem, we obviously want to make the substitution $u = yx$.    Consider the transformed boundaries and the Jacobian for this transformation.    
\[
\begin{aligned}
  xy & = 1 \quad \, & u  = 1 \\ 
  xy & = 2 \quad \, & u = 2 \\ 
  y & =x \quad \, u & = x^2 \\ 
  y & = 4x \quad \, u & = 4x^2 
\end{aligned} \quad \quad \, \begin{gathered}
  \left( \begin{matrix} x \\ y \end{matrix} \right) = \left( \begin{matrix} x \\ u/x \end{matrix} \right) \end{gathered}  \\
det{ D \phi} = \left| \begin{matrix} 1 & 0 \\ -u /x^2 & 1/x \end{matrix} \right| = \frac{1}{x} 
\]
Sketch the transformed region in the $xu$ plane, with boundaries as described above.  Then clearly,
\[
\int_1^2 du \int_{ \frac{ \sqrt{u}}{2} }^{ \sqrt{u }} f(u) \frac{1}{x} dx = \int_1^2 du \left(\ln{ (\sqrt{ u} )} - \ln{ \left( \frac{ \sqrt{u}}{2} \right) } \right) f(u) = \int_1^2 du \left( \frac{1}{2} \ln{u} - \frac{1}{2} \ln{u} + \ln{2} \right) f(u) = \ln{2} \int_1^2 f(u) du
\]

\section*{ 11.34 Exercises - Proof of the transformation formula in a special case, Proof of the transformation formula in the general case, Extensions to higher dimensions, Change of variables in an $n$-fold integral, Worked examples }

\exercisehead{1} $z = xy$.  Note that $z=0$ implied $x=0$ or $y=0$.  
\[
\iiint_S xy^2 z^3 dx dy dz = \int_0^1 \int_0^x \int_0^{xy} xy^2 z^3 dz dy dx = \int_0^1 \int_0^x \frac{xy^2}{4} (xy)^4 dy dx = \int_0^1 \frac{ x^5}{4} \frac{x^7}{7} dx = \frac{1}{28} \frac{1}{13} = \frac{1}{364}
\]

\exercisehead{2} $z = 1- x-y$.  $z=0$ defines a boundary, so $y= 1-x$.  
\[
\begin{gathered}
  \iiint_S (1+x+y + z)^{-3} dx dy dz = \int_0^1 dx \int_0^{1-x} dy \int_0^{1-x-y} (1+ x+y+z)^{-3} dz = \\
  = \int_0^1 dx \int_0^{1-x} dy \left( \frac{ 1/-2}{ (1+x+y+ (1-x-y))^2 } - \frac{ 1/-2 }{ (1+x+y)^{-2}} \right) = \\
  = \frac{-1}{2} \int_0^1 dx \left( \frac{1}{4} (1-x) + \left. (1+x+y)^{-1} \right|_0^{1-x} \right) = \frac{-1}{2} \left( \frac{1}{4} (1- 1/2) + 1/2(1) - \ln{2} \right) = \boxed{ \frac{-1}{2} \left( \frac{5}{8}  -\ln{2} \right) }
\end{gathered}
\]

\exercisehead{3} $J = r^2 \sin{\theta}$  (polar coordinates).  Note $x\leq 0, \, y \leq 0, \, z \leq 0$
\[
\begin{gathered}
  \int_0^{\pi/2} d\theta \int_0^{\pi/2} d\phi \int_0^1 r \cos{\phi} \sin{\theta} r \sin{\phi} \sin{\theta} r \cos{\theta} r^2 \sin{\theta} dr = \int_0^{\pi/2} \int_0^{\pi/2} d\phi \frac{1}{6} \sin^3{\theta} \cos{\theta} \cos{\phi} \sin{\phi} = \\
   = \frac{1}{6} \int_0^{\pi/2} d\theta \sin^3{\theta} \cos{\theta} \frac{1}{2} = \boxed{ \frac{1}{48 } }
\end{gathered}
\]

\exercisehead{4} $\begin{aligned} x & = au \\ y & = bv \\ z & = cw \end{aligned}$ \quad \, $J = abc$
\[
\Longrightarrow \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^1 (u^2 + v^2 + w^2 ) abc r^2 \sin{\theta} dr  = \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \sin{\theta} \frac{ abc}{5} = \frac{2\pi}{5} abc (2) = \boxed{  \frac{ 4 \pi abc}{5 } }
\]

\exercisehead{5} $z^2 = x^2 + y^2 = r^2$.  $z=r$
\[
\iiint_S \sqrt{ x^2  +y^2} dx dy dz = \int_0^1 dz \int_0^{2\pi} d\phi \int_0^z r^2 dr = \frac{1}{3} \frac{1}{4} 2\pi = \boxed{ \frac{ \pi}{6}}
\]

For exercises 6,7,8, I think you have to sketch the region and surmise the new boundaries intuitively from the sketch.  I don't see a formula you could simply plug in to determine the new regions and boundaries.  

\exercisehead{6} 
\[
\iiint_S (x^2 +y^2) dx dy dz = \int_0^2 \int_0^{2\pi} \int_0^{\sqrt{ 2z }} r^2 ( rdr) d\phi dz = \int_0^2 2\pi \frac{1}{4} (2z)^2 = \frac{ 16 \pi }{3} 
\]

\exercisehead{7}

\exercisehead{10} 
\[
\iiint_S (x^2 + y^2) dx dy dz =\int_0^2 \int_0^{2\pi} \int_0^{\sqrt{2z}} r^2 ( r dr) d\phi dz = \int_0^2 2\pi \frac{1}{4} (2z)^2 = \boxed{ \frac{16 \pi }{3 }}
\]

\exercisehead{13} 
\[
\iiint_S dx dy dz = \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^a r^2 \sin{\theta} = \frac{ a^3}{3} (2\pi)(2) = \frac{ 4 \pi a^3 }{3 }
\]
\exercisehead{14} \[
\iiint_S dx dy dz = \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_a^b r^2 \sin{\theta} = \frac{4\pi}{3} (b^3 - a^3 )
\]

\exercisehead{15} Let $\sqrt{ a^2 + b^2 + c^2 } = \delta$ s.t. $\delta > R$.

Since the sphere $S$ of integration is rotationally symmetric, \textbf{do a rotation so that} so that $(a,b,c) = (0,0,\delta)$ \large{ it's a lot easier! }

\large{ \textbf{ Tip: } Take advantage of symmetries, particularly spherical symmetries, and make problems easier by choosing a convenient rotation of the coordinate axes. }
\normalsize
\[
\begin{gathered}
  \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^R r^2 \sin{\theta} dr ( x^2 +y^2 + (z-\delta)^2 )^{-1/2} = \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^R r^2 \sin{\theta} dr (r^2 + \delta^2 - 2r\delta \cos{\theta})^{-1/2} = \\
 = \int_0^{2\pi} d\phi \int_0^R r \left. \frac{ (r^2 + \delta^2 - 2r \delta \cos{\theta})^{1/2}}{ \delta} \right|_0^{\pi} = \int_0^{2\pi} d\phi \int_0^R \frac{r}{\delta} \left( (r^2 + \delta^2 + 2r\delta )^{1/2} - (r^2 + \delta^2 - 2r\delta)^{1/2} \right) \\
 \text{ since  $\delta > R$, then $((r - \delta)^2)^{1/2} = |r- \delta| = \delta - r$, so then } \\ 
 = 2\pi \int_0^R \frac{r}{\delta} ((r+\delta) - (\delta - r) ) = \boxed{ \frac{ 4\pi }{3} \frac{R^2}{\delta} }
\end{gathered}
\]

\exercisehead{16} $\begin{aligned} x & = a \rho \cos^m{ \theta} \sin^n{\phi} \\ y & = b\rho \sin^m{\theta} \sin^n{\phi} \\ z & = c\rho \cos^n{\phi} \end{aligned}$  
\[
\begin{gathered}
  det{J} = \left| \begin{matrix} a c^m{\theta} s^n{\phi} & na\rho c^m{\theta} s^{n-1}{\phi} c{\phi} & -m a\rho c^{m-1}{\theta} s{\theta} s^n{\phi}  \\ bs^m{\theta} s^n{\phi} & nb \rho s^m{\theta} s^{n-1}{\phi}c{\phi} & mb\rho s^{m-1}{\theta} s^n{\phi} c{\theta} \\ cc^n{\phi} & - nc\rho c^{n-1}{\phi} s{\phi} & 0 \end{matrix} \right| = \\ 
  = ac^m{\theta} s^n{\phi} (mnbc \rho^2 c^{n-1}{\phi} s{\phi} s^{m-1}{\theta} s^n{\phi} c{\theta} + - na \rho (c^m{\theta} s^{n-1}{\phi} c{\phi})( - mbc \rho s^{m-1}{\theta} s^n{\phi} c^n{\phi} c{\theta}) + \\
  + -ma\rho c^{m-1}{\theta}s{\theta}s^m{\phi}((-bnc\rho s^m{\theta} c^{n-1}{\phi} s^n{\phi} s^{\phi} ) - nb \rho c c^n{\phi} s^m{\theta} s^{n-1}{\phi} c{\phi}) = \\
  = abcmn\rho^2 ( c^{m+1}(\theta) s^{m-1}{\theta} s^{2n+1}{\phi} c^{n-1}{\phi} + c^{m+1}{\theta} s^{m-1}{\theta} s^{2n-1}{\phi} c^{n+1}{\phi} + \\
  + c^{m-1}{\theta} s{\theta} s^n{\phi}( s^m{\theta} s^{n+1}{\phi} c^{n-1}{\phi} + s^m{\theta} s^{n-1}{\phi} c^{n+1}{\phi} ) ) = \\
  = abcmn \rho^2 (c^{m+1}{\theta} s^{m-1}{\theta} s^{2n-1}{\phi} c^{n-1}{\phi} + c^{m-1}{\theta} s^{m+1}{\theta} s^{2n-1}{\phi} c^{n-1}{\phi} ) =  \\
  = \boxed{ abcmn \rho^2 (c^{m-1}{\theta} s^{m-1}{ \theta} s^{2n-1}{\phi} c^{n-1}{\phi} ) }
\end{gathered}
\]

\exercisehead{17} 
\[
\begin{gathered}
  I_x = \iiint_S (y^2 + z^2) f(x,y,z) dx dy dz =  \iiint_S y^2 f(x,y,z) dx dy dz + \iiint_S z^2 f(x,y,z) dx dy dz = I_{xy} + I_{xz} \\ 
  I_y = \iiint_S (x^2 + z^2) f(x,y,z) dx dy dz = \iiint_S x^2 f(x,y,z) dx dy dz + \iiint_S z^2 f(x,y,z) dx dy dz = I_{yz} + I_{yx} \\ 
  I_z = \iiint_S (x^2 + y^2) f(x,y,z) dx dy dz = \iiint_S x^2 f(x,y,z) dx dy dz + \iiint_S y^2 f(x,y,z) dx dy dz = I_{zy} + I_{zx}
\end{gathered}
\]

\exercisehead{18} The condition for the paraboloid and sphere to meet is the following:
\[
x^2 + y^2 = 4z = 5 - z^2 \Longrightarrow z^2 + 4z - 5 = 0 \text{ or } (z+5)(z-1) = 0
\]
\[
\begin{aligned}
V & = \int_0^2 \int_0^{2\pi} \int_{\frac{r^2}{4}}^{ \sqrt{ 5- r^2}} r dz d\phi dr = \int_0^2 2\pi r \left( \sqrt{ 5- r^2} - \frac{r^2}{4} \right) = \\
& = 2\pi \left. \left( \frac{-1}{3} (5-r^2)^{3/2} - r^4/16 \right) \right|_0^2 = 2\pi (\frac{-1}{3} (1-5^{3/2} ) - 16/16) = \boxed{ \frac{ 2\pi }{3} (5^{3/2} - 4)  }
\end{aligned}
\]

\exercisehead{20} 
\[
\int_0^{2\pi} \int_0^{\pi} \int_a^b r^2 ( r^2 \sin{\theta}) dr d\theta d\phi = \frac{1}{5} (b^5- a^5) (2)(2\pi) = \boxed{ \frac{ 4 \pi (b^5 - a^5) }{5}  }
\]

\exercisehead{21} 
\[
\begin{gathered}
  \int_0^h \int_0^{2\pi} \int_0^z  r dr d\phi dz = \int_0^h \frac{ 2\pi}{2} z^2 dz = \frac{ \pi }{3} h^3 = M \\ 
  \overline{z} M = \int_0^h \int_0^{2\pi} \int_0^z r z dr d\phi dz = \int_0^h dz 2\pi \frac{1}{2} z^3 = \frac{ \pi }{4} h^4
\end{gathered}
\]
$\overline{z} = \frac{3h}{4}$ so centroid is $\frac{h}{4}$ away from base.  


\exercisehead{22} Note the symmetry in $\phi$ and $r$.
\[
\begin{gathered}
  M = \int_0^h \int_0^{2\pi} \int_0^z (h-z) r dr d\phi dz = \int_0^h dz (2\pi) (h-z)\frac{1}{2} z^2 = (2\pi) \left( \frac{h}{6} h^3 - \frac{h^4}{8} \right) = (2\pi h^4)\left( \frac{1}{24} \right) = \boxed{ \frac{ \pi h^4 }{ 12} } \\ 
  \begin{aligned}
  \overline{z} M & = \int_0^h \int_0^{2\pi} \int_0^z (h-z) z r dr d\phi dz = 2\pi \int_0^h dz (h-z) z \frac{1}{2} z^2 = \pi \left. \left( \frac{ z^4}{4} h - \frac{1}{5} z^5 \right) \right|_0^h = \\ 
  & = \pi (h^5) (1/4 - 1/5) 
\end{aligned} \\
  \Longrightarrow \overline{z} = \frac{3}{5} h 
\end{gathered}
\]
Center of mass is $\frac{2}{5} h$ from the base.  

\exercisehead{23} Note symmetry in $\phi$ and $r$.  
\[
\begin{gathered}
  M = \int_0^h \int_0^{2\pi} \int_0^z r r dr d\phi dz = \int_0^h 2 \pi \left. \frac{r^3}{3} \right|_0^z dz = \frac{2\pi}{3} \frac{ h^4 }{4} = \frac{ \pi h^4 }{6} \\ 
  \overline{z} M = \int_0^h \int_0^{2\pi} \int_0^z r z r dr d\phi dz = 2\pi \int_0^h z \frac{1}{3} z^3 = \left. \frac{2 \pi }{3} \frac{1}{5} z^5 \right|_0^h = \frac{2\pi }{15} h^5 \\ 
\end{gathered} \quad \Longrightarrow   \overline{z} = \frac{4 h }{5} 
\]
$\frac{h}{5}$ from base.  

\exercisehead{24} Consider concentric hemispheres of radii $a$ and $b$, where $0<a<b$.  
\[
\begin{gathered}
  M  = \int_0^{\pi/2} d\theta \int_0^{2\pi} d\phi \int_a^b r^2 \sin{\theta} = \frac{ b^3 - a^3}{3} (2\pi) \\ 
  \overline{z} M = \int_0^{\pi/2} d\theta \int_0^{2\pi} d\phi \int_a^b r^2 \sin{\theta} (r \cos{\theta}) = \int_0^{\pi/2} d\theta 2\pi \frac{b^4 - a^4}{4} \sin{\theta} \cos{\theta} = \frac{\pi}{4} (b^4- a^4) 
\end{gathered} \quad \Longrightarrow \overline{z} = \frac{ 3}{8} \frac{ b^4 - a^4}{b^3 - a^3 }
\]

\exercisehead{25} I tried cylindrical coordinates first.  Didn't help.   \\
\textbf{ Tip: } quickly switch and try another way, another set of coordinates, if one way doesn't work.  \[
\begin{gathered}
  M = \int_0^1 dz \int_0^1 dy \int_0^1 dx (x^2 + y^2 +z^2) = 1 \\ 
  \overline{x} M = \int_0^1 dz \int_0^1 dy \int_0^1 dx x (x^2 + y^2 + z^2) = \frac{1}{4} + \frac{1}{2} \left( \frac{1}{3} \right) + \frac{1}{2} \left( \frac{1}{3} \right) = \frac{7}{12} 
\end{gathered}
\]
By label symmetry of $x,y,z$, $\overline{x} = \overline{y} = \overline{z} = \frac{7}{12} $  

\exercisehead{26}  Note that $\frac{r}{z} = \frac{a}{h}$  
\[
\begin{gathered}
\begin{aligned}
  I_{cone, z} & = \int_0^h \int_0^{2\pi} \int_0^{ \frac{a}{h} z} r^2 ( rdr ) dz \frac{M}{V} = 2\pi \int_0^h \frac{1}{4} \left( \frac{a}{h} \right)^4 z^4 dz \frac{M}{V}  = \frac{ \pi}{10} \left( \frac{a}{h} \right)^4 h^5 \frac{M}{V}  = \frac{ 3a^2 }{10} M 
\end{aligned} \\
V  = \int_0^h \int_0^{2\pi} d\phi \int_0^{az/h} rdr dz = 2\pi \frac{ a^2 }{ 2h^2 } \frac{1}{3} h^3 = \frac{ \pi a^2 h }{3} 
\end{gathered}
\]
\[
\begin{aligned}
  I_x + I_y & = \iiint \frac{M}{V} (y^2 + z^2 + x^2 + z^2 ) dx dy dz = \frac{M}{V} \iiint (x^2 + y^2 + 2z^2) dx dy dz = \\ 
  & = \frac{M}{V} \left( \frac{ \pi a^4 h }{10} + 2 \int_0^h \int_0^{2\pi} d\phi \int_0^{\frac{az}{h} } z^2 r dr dz \right) = \frac{M}{V} \left( \frac{ \pi a^4 h }{10 } + 2 \int_0^h 2\pi \frac{1}{2} \frac{a^2 }{h^2} z^4 dz \right) = \frac{M}{V} \left( \frac{ \pi a^4 h }{10} + \frac{ 2 \pi a^2 }{5h^2} h^5 \right) = \\
  & = 2I_x 
\end{aligned}
\]
\[
\Longrightarrow I_x = \frac{ M}{ 2 \left( \frac{ \pi a^2 h}{3} \right)} (\pi a^2 h ) \left( \frac{a^2 }{10} + \frac{ 2h^2 }{5} \right) = \boxed{ \frac{3M}{2} \left( \frac{a^2}{10} + \frac{ 2h^2}{5} \right) }
\]


\exercisehead{27} $f = M / \frac{4}{3} \pi R^3 = M/V$
\[
\begin{aligned}
  I & = \iiint (x^2 + y^2 ) \frac{M}{V} dx dy dz = \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^R r^2 ( \sin{\theta}) \frac{M}{V} r^2 \sin^2{\theta} = \frac{2\pi M}{V} \int_0^{ \pi} \sin{\theta} (1- \cos^2{\theta}) \frac{R^5}{5} = \\
  & = \frac{ 2 \pi M }{ 5 V } R^5 \left( 2 + \frac{1}{3} (-2) \right) = \frac{ 2 \pi M R^5 }{ 5 \frac{4 \pi }{3} R^3 } \left( \frac{4}{3} \right) = \boxed{ \frac{2}{5}  M R^2 } 
\end{aligned}
\]

Another way, which is quite clever, is the following.  Consider that 
\[
2(x^2 + y^2 + z^2) = x^2 + y^2 + z^2 + x^2 + x^2 + y^2 
\]
Then
\[
2 \iiint (x^2 + y^2 + z^2 ) \frac{M}{V} dx dy dz = 2 \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \int_0^R r^2 \frac{M}{V} r^2 \sin{\theta} = \frac{ 8 \pi M }{5V} R^5 = I_z + I_y + I_x 
\]
By spherical symmetry, $I_z = I_y$.  So then $I = \frac{ 8 \pi M R^5 }{ 15 \left( \frac{ 4 \pi R^3 }{3} \right) } = \frac{ 2 M R^2 } {5 } $ 

\exercisehead{28} 
\[
\begin{gathered}
  M = \int_{-h}^h dz \int_0^{2\pi} d\phi \int_0^a r r dr = 2h (2\pi) \frac{a^3}{3} \\ 
  I_z = \int_{-h}^h dz \int_0^{2\pi} d\phi \int_0^a r^2 r dr r   = (2h)(2\pi) \frac{1}{5} a^5 = \boxed{ \frac{3 M a^2}{5} }
\end{gathered}
\]

\exercisehead{29} 
\[
\begin{gathered}
  V_{cap} = \left( \frac{4\pi R^3}{3} \right) \frac{1}{2} = \frac{ 2\pi R^3 }{3} \quad \quad \, c = \frac{M}{V} = \text{ mass density } \\ 
  V_{cylinder} = \pi \left( \frac{1}{2} \right)^2 2 = \frac{\pi}{2} \\ 
  \overline{z} M = \int_0^{\pi/2} d\theta \int_0^{2\pi} d\phi \int_0^R  r \cos{\theta} r^2 \sin{\theta} dr \frac{M}{V} = \frac{ 2 \pi R^4 }{4} \frac{1}{2} \frac{M}{V} = \frac{ \pi R^4 }{ 4 } \frac{M}{V} \\
  \overline{z} = \frac{ \pi R^4 }{ 4 \left( \frac{ 2 \pi R^3}{3} \right) } = \frac{ 3 R }{8}
\end{gathered}
\]
Condition wanted is for center of mass of the mushroom to be at $z=0$, for this particular choice of coordinates.  
\[
\frac{ c \frac{ \pi R^4}{4} + \left( c \frac{\pi}{2} \right) (-1) }{ c V + c\frac{\pi}{2}  } = \frac{ \frac{ \pi R^4 }{4 } + \frac{-\pi}{2} }{ \frac{ 2\pi R^3 }{3} + \frac{\pi}{2} } = 0 \Longrightarrow R^4 = 2 \text{ or } \boxed{ R = 2^{1/4} }
\]
































\section*{ 12.4 Exercises - Parametric representation of a surface, The fundamental vector product, The fundamental vector product as a normal to the surface }

\exercisehead{1} \emph{Plane}:
\[
\mathbf{r}(u,v) = (x_0 + a_1 u + b_1 v )\mathbf{i} + (y_0 + a_2 u + b_2 v) \mathbf{j} + (z_0  + a_3 u + b_3 v) \mathbf{k} \Longrightarrow \begin{aligned} x & = x_0 + a_1 u + b_1 v \\ y & = y_0 + a_2 u + b_2 v \\ z & z_0 + a_3 u + b_3 v \end{aligned}
\]
Then get $u,v$ in terms of $x,y$.  
\[
\begin{gathered}
  \left[ \begin{matrix} a_1 & b_1 \\ a_2 & b_2 \end{matrix} \right] \left[ \begin{matrix} u \\ v \end{matrix} \right] = \left[ \begin{matrix} x-x_0 \\ y - y_0 \end{matrix} \right] \\ 
  \Longrightarrow \left[ \begin{matrix} u \\ v \end{matrix} \right] = \frac{1}{ a_1 b_@ - b_1 a_2 } \left[ \begin{matrix} b_2 & -b_1 \\ -a_2 & a_1 \end{matrix} \right] \left[ \begin{matrix} x-x_0 \\ y- y_0 \end{matrix} \right] = \frac{1}{ a_1 b_2 - b_1 a_2 } \left[ \begin{matrix} b_2 ( x-x_0) - b_1 (y_1 - y_0 ) \\ -a_2 (x-x_0) + a_1 ( y-y_0) \end{matrix} \right]
\end{gathered}
\]
So then
\[
(a_1 b_2 - b_1 a_2) (z-z_0) = (a_3 b_2 - b_3 a_2)(x-x_0) + (b_3a_1 - a_3 b_1)(y-y_0)
\]
\[
\begin{aligned}
  \partial_u r_u & = (a_1,a_2,a_3) \\ 
  \partial_v r_v & = (b_1,b_2,b_3) 
\end{aligned}
\]
\[
\partial_u r \times \partial_v r = \left| \begin{matrix} e_1 & e_2 & e_3 \\ a_1 & a_2 & a_3 \\ b_1 & b_2 & b_3 \end{matrix} \right| = (a_2 b_3 - a_3 b_2, a_3 b_1 - a_1 b_3, a_1 b_2 - a_2 b_1 )
\]

\exercisehead{2} \emph{Elliptic paraboloid}: $\mathbf{r}(u,v) = au \cos{v} \mathbf{i} + bu \sin{v} \mathbf{j} + u^2 \mathbf{k}$.  
Then
\[
\begin{aligned}
  x & = au \cos{v} \\
  y & = bu \sin{v} \\ 
  z & = u^2
\end{aligned} \Longrightarrow \boxed{ \left( \frac{x}{a} \right)^2 + \left( \frac{y}{b} \right)^2 = z  }
\]
\[
\begin{aligned}
  \partial_u r & = (a \cos{v}, b\sin{v} , 2u) \\ 
  \partial_v r & = (-au \sin{v}, bu \cos{v}, 0 )
\end{aligned} \Longrightarrow \left| \begin{matrix} e_1 & e_2 & e_3 \\ a\cos{v} & b\sin{v} & 2 u \\ -au \sin{v} & bu \cos{v} & 0 \end{matrix} \right| = \boxed{ ( -2bu^2 \cos{v}, -2u^2 a \sin{v}, abu) }
\]

\exercisehead{3} \emph{Ellipsoid}: $\mathbf{r}(u,v) = (a\sin{u}\cos{v}, b\sin{u} \sin{v}, c\cos{u})$.  
\[
\Longrightarrow \left( \frac{x}{a} \right)^2 + \left( \frac{y}{b} \right)^2 + \left( \frac{z}{c} \right)^2 = 1 
\]
Now
\[
\begin{aligned}
  \partial_u r & = (ac(u)c(v), bc(u)s(v), -cs(u) ) \\ 
  \partial_v r & = (-as(u)s(v), bs(u)c(v),0) 
\end{aligned}
\]
\[
\Longrightarrow \left| \begin{matrix} e_1 & e_2 & e_3 \\ ac(u)c(v) & bc(u)s(v) & -cs(u) \\ -as(u)s(v) & bs(u)c(v) & 0 \end{matrix} \right| = \boxed{(bcs^2(u)c(v), acs^2(u)s(v), ab(c(u))s(u)) }
\]

\exercisehead{4}\emph{Surface of revolution:} $\mathbf{r}(u,v) = (u\cos{v}, u \sin{v}, f(u))$.  $x^2 + y^2 = u^2$ so then
\[
\boxed{ f(\sqrt{ x^2 + y^2}) = z }
\]
\[
\begin{aligned}
  \partial_u r & = ( \cos{v}, \sin{v}, f'(u) ) \\ 
  \partial_V r & = (-u\sin{v}, u \cos{v} ,0 ) 
\end{aligned}
\]
\[
\partial_u r \times \partial_v r = \left| \begin{matrix} e_1 & e_2 & e_3 \\ \cos{v} & \sin{v} & f'(u) \\ -u \sin{v} & u \cos{v} & 0 \end{matrix} \right| = \boxed{ (-f' u\cos{v}, -f'u\sin{v}, u ) }
\]

\exercisehead{5} \emph{Cylinder}: $\boxed{ y^2 + z^2 = a^2}$  
\[
\mathbf{r}(u,v) = (u, a\sin{v}, a\cos{v} )
\begin{aligned}
  \partial_u r & = ( 1,0,0) \\ 
  \partial_v r & = (0 , a\cos{v}, -a\sin{v} )
\end{aligned}
\]
\[
\Longrightarrow \left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 0 & 0 \\ 0 & a \cos{v} & -a\sin{v} \end{matrix} \right| = (0, a \sin{v}, a\cos{v})
\]

\exercisehead{6} \emph{Torus}: $\mathbf{r}(u,v) = ((a+b\cos{u})\sin{v}, (a+b\cos{u}) \cos{v}, b\sin{u})$, \, $0<b<a$.
\[
x^2  +y^2 = (a+b\cos{u})^2 = (a+\sqrt{ b^2 - z^2} )^2 
\]
\[
\begin{aligned}
  \partial_u r & = (-bs(u)s(v), -bs(u)c(v), bc(u) ) \\
  \partial_v r & ((a+bc(u))c(v), (a+bc(u))(-s(v)), 0)
\end{aligned}
\]
\[
\begin{gathered}
\left| \begin{matrix} e_1 & e_2 & e_3 \\ -bs(u)s(v) & -bs(u)c(v) & bc(u) \\ (a+bc(u))c(v) & (a+bc(u))(-s(v)) & 0 \end{matrix} \right| = \\
= (b(a+bc(u))c(u)s(v), b(a+bc(u))c(u)c(v), (a+bc(u))(bs(u)s^2(v) + bs(u)c^2(v))) 
\end{gathered}
\]
\[
\Longrightarrow \boxed{ (a + b\cos{(u)} )b (\cos{(u)}\sin{(v)}, \cos{(u)} \cos{(v)}, \sin{(u)} ) }
\]

\exercisehead{7}$\mathbf{r}(u,v) = (a\sin{u}\cosh{v}, b\cos{u}\cosh{v}, c\sinh{v})$  
\[
\begin{aligned}
  \partial_u r & = (ac(u)\cosh{(v)}, -bs(u)\cosh{v},0) \\ 
  \partial_v r & = (as(u)\sinh{(v)}, bc(u)\sinh{v},c\cosh{v} )
\end{aligned}
\]
\[
\begin{gathered}
 \partial_u r \times \partial_v r  = \left| \begin{matrix} e_1 & e_2 & e_3 \\ a c(u) \cosh{(v)} & -b s(u)\cos{(v)} & 0 \\ as(u) \sinh{(v)} & bc(u) \sinh{v} & c\cosh{v} \end{matrix} \right| = \\
 = (-bc\sin{u}\cosh^2{v}, ac\cos{u}\cosh^2{v}, ab\cos^2{u} \cosh{v}\sinh{v}+ab\sin^2{u} \cosh{v}\sinh{v}) \end{gathered}
\]
\[
\| \partial_u r \times \partial_v r \| = \boxed{ ab c \cosh{v} \left( \left( \frac{\sin^2{u}}{a^2 } + \frac{ \cos^2{u}}{b^2} \right)\cosh^2{v} + \frac{ \sinh^2{v}}{c^2} \right)^{1/2} }
\]

\exercisehead{8} $\mathbf{r}(u,v) = (u+v,u-v,4v^2)$
\[
\begin{aligned}
  \partial_u r & = (1,1,0) \\ 
  \partial_v r & = (1,-1,8v)
\end{aligned} \Longrightarrow \left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 1 & 0 \\ 1 & -1 & 8v \end{matrix} \right| = (8v,-8v,-2)
\]
\[
\| \partial_u r \times \partial_v r \| = \sqrt{ 64 v^2 + 64 v^2 + 4 } = 2 \sqrt{ 1 + 32 v^2}
\]

\exercisehead{9} $\mathbf{r}(u,v) = ((u+v), u^2  +v^2, u^3 + v^3)$ 
\[
\begin{gathered}
\begin{aligned}
  \partial_u r & = (1 , 2u, 3u^2) \\ 
  \partial_v r & ( 1,2v, 3v^2) 
\end{aligned} \Longrightarrow \left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 2u & 3u^2 \\ 1 & 2v & 3v^2 \end{matrix} \right| = (6uv^2 - 6vu^2, 3u^2- 3v^2, 2v - 2u) =  \\
 = (v-u) (6uv, -3(u+v), 2) 
\end{gathered}
\]
\[
\Longrightarrow |v-u| \sqrt{ 36u^2 v^2 + 9(u^2 + 2uv + v^2) + 4}
\]

\exercisehead{10} $\mathbf{r}(u,v) = (u\cos{v}, u\sin{v}, \frac{1}{2} u^2 \sin{2v} )$.
\[
\begin{gathered}
\begin{aligned}
  \partial_u r & = (c(v), s(v), u s(2v) ) \\ 
  \partial_v r & = (-us(v), uc(v), u^2 c(2v) )
\end{aligned} \Longrightarrow \partial_u r \times \partial_v r = \left| \begin{matrix} e_1 & e_2 & e_3 \\ c(v) & s(v) & us(2v) \\ -us(v) & u c(v) & u^2 c(2v) \end{matrix} \right| =  \\
= (u^2 s(v)c(2v) - u^2 c(v) s(2v), -u^2 c(2v) c(v)  - u^2 s(2v)s(v) , u ) = (u^2 s(-v), -u^2 c(v), u ) 
\end{gathered}
\]
\[
\| \partial_u r \times \partial_v r \|   = \sqrt{ u^4 s^2(v) + u^4 c^2(v) + u^2 } = \boxed{ u \sqrt{ u^2 + 1}}
\]

\section*{ 12.6 Exercises - Area of a parametric surface }





















\exercisehead{2} $S=r(T)$ \\
$x^2 + y^2 = a^2$ represents $T$.  \\
$x+y+z = a$ is $S$.  

Using $z = a-x-y$, $r = (x,y,a-x-y)$.  Then $\begin{aligned} \partial_x r & = (1,0,-1) \\ \partial_y r & = (0,1,-1) \end{aligned}$ $\Longrightarrow \left| \begin{matrix} e_x & e_y & e_z \\ 1 & 0 & -1 \\ 0 & 1 & -1 \end{matrix} \right| = (1,1,1)$  
\[
\| \partial_x r \times \partial_y r \| = \sqrt{ 1 + 1 + 1 } = \sqrt{3}
\]
\[
\iint_T \sqrt{3} dx dy = \boxed{ \sqrt{3} \pi a^2 }
\]































\exercisehead{4} $z^2 = 2xy$ $x=2, \, y=1$.  Then $2 z \partial_x z = 2y$ or $\partial_x z = \frac{y}{z}$.  Similarly $\partial_y z = \frac{x}{z}$.  
\[
\left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 0 & \frac{y}{z} \\ 0 & 1 & \frac{x}{z} \end{matrix} \right| = ( \frac{-y}{z}, \frac{-x}{z}, 1 ) \Longrightarrow \| \partial_x r \times \partial_y r \|^2 = \frac{y^2}{z^2} + \frac{x^2 }{z^2} + \frac{z^2}{z^2} = \frac{ (x+y)^2}{z^2}
\]
\[
\| \partial_x r \times \partial_y \| = \frac{x+y}{z} = \frac{x+y}{ \sqrt{2} \sqrt{xy}} = \frac{1}{\sqrt{2}} \left( \sqrt{ \frac{x}{y} } + \sqrt{ \frac{y}{x} } \right)
\]
$\int a(S) = \iint \frac{1}{\sqrt{2}} \left( \sqrt{ \frac{x}{y} } + \sqrt{ \frac{y}{x} } \right) dx dy $ so with
\[
\begin{aligned}
& \int \sqrt{ \frac{x}{y} } dx = \left. \frac{ \frac{2}{3} x^{3/2}}{ \sqrt{y}} \right|_0^2 = \frac{ \frac{2}{3} 2 \sqrt{2} }{\sqrt{y}} = \frac{ 4 \sqrt{2}}{ 3} y^{-1/2} \xrightarrow{ \int dy } \left. \frac{4\sqrt{2}}{3}  2 y^{1/2} \right|_0^1 = \frac{8\sqrt{2}}{3} \\
& \int \sqrt{ \frac{y}{x}} = \left. \frac{ \frac{2}{3} y^{3/2}}{\sqrt{x} } \right|_0^1 = \frac{2}{3 \sqrt{x}}\xrightarrow{ \int dx} \frac{2}{3} \left. 2 x^{1/2} \right|_0^2 = \frac{4\sqrt{2}}{3}
\end{aligned}
\]
\[
\Longrightarrow a(S) = \frac{1}{\sqrt{2} } \left( \frac{8\sqrt{2}}{3}  + \frac{4 \sqrt{2}}{3} \right) = \boxed{4}
\]

\exercisehead{5} $\mathbf{r} = (u\cos{v},u\sin{v},u^2)$
\begin{itemize}
\item[a.]
$x^2  +y^2 = z$.  $u$ is radius, $v$ is angle in $x-y$ plane.  












\item[b.] \[
\begin{aligned}
  \partial_u r & = (c,s,2u) \\ 
  \partial_v r & = (-us, uc,0)
\end{aligned} \Longrightarrow \partial_u r \times \partial_v r = \left| \begin{matrix} e_1 & e_2 & e_3 \\ c & s & 2u \\ -us & uc & 0 \end{matrix} \right| = (-2u^2 c, -2u^2s, u)
\]
\item[c.] $\| \partial_u r \times \partial_v r \|^2 = 4u^4 + u^2$
\[
a(S) = \iint u \sqrt{ ( 1 + 4u^2) } du dv = \left. 2\pi \frac{2}{3} ( 1 + 4u^2)^{3/2} \left( \frac{1}{8} \right) \right|_0^4 = \frac{\pi}{6} ((1 + 64)^{3/2} - 1 ) = \frac{\pi}{6} (65 \sqrt{65} - 1 )
\]
$\boxed{n=6}$
\end{itemize}

\exercisehead{6} $x^2  +y^2 = z^2$.  \\
$x^2  + y^2 + z^2 = 2ax$ $\Longrightarrow x^2  - 2ax + a^2 + y^2 +z^2 = a^2 = (x-a)^2 + y^2 + z^2 = a^2$ 

Determine where sphere and cone intersect: $z^2 =ax$, so then $y^2 = ax - x^2 = x(a-x)$.  Since $x > 0$, $a-x>0$, $a>x$
\[
\Longrightarrow y = \pm \sqrt{ x ( a-x)} = \pm \sqrt{ \frac{-a^2}{4} + ax - x^2 + \frac{a^2}{4} } = \sqrt{ \frac{a^2 }{4} - \left( \frac{a}{2} - x\right)^2 }
\] 
Now $ 2z \partial_x z = 2x$.  Then
\[
\left| \begin{matrix} e_1 & e_2 & e_3 \\ 1 & 0 & \frac{x}{z} \\ 0 & 1 & \frac{y}{z} \end{matrix} \right| = ( \frac{-x}{z}, \frac{-y}{z}, 1 ) \quad \, \Longrightarrow \| \partial_x r \times \partial_y r \|^2 = \frac{x^2}{z^2 } + \frac{y^2}{z^2} + \frac{z^2}{z^2} = 2 
\]
\[
\begin{aligned}
  a(S) & = \iint \sqrt{2} dx dy = \sqrt{2} \int_0^1 \int_{-\sqrt{x(a-x)}}^{\sqrt{ x(a-x)}} dy dx = 2 \sqrt{2} \int_0^a dx \sqrt{ \frac{a^2}{4} - \left( \frac{a}{2} - x \right)^2 } = 2\sqrt{2} \int_{-a/2}^{a/2} \sqrt{ \frac{a^2}{4} - x^2 } = \\
  & = a\sqrt{2} \int_{-a/2}^{a/2} \sqrt{ 1 - \left( \frac{2x}{a} \right)^2} \xrightarrow{\begin{aligned} u & = \frac{2x}{a} \\ \frac{a}{2} du & = dx \end{aligned}} \frac{a^2 \sqrt{2}}{2} \int_{-1}^1 \sqrt{ 1 - u^2 } du \\ 
 & \xrightarrow{ \begin{aligned} u & = \sin{\theta} \\ du & = \cos{\theta} d\theta \end{aligned}}  = \frac{a^2\sqrt{2}}{2} \int_{-\pi/2}^{\pi/2} \cos^2{\theta} d\theta = \frac{a^2 \sqrt{2}}{2} \int_{-\pi/2}^{\pi/2} \frac{ 1 + \cos{2\theta}}{2} = \boxed{ \frac{ \sqrt{2} \pi a^2}{4} }
\end{aligned}
\]

















%\begin{abstract}

%\end{abstract}
%	\section*{\sffamily \textsc{}}{S: }		% {\scshape	 }

	%	\section*{\sffamily \textmd{}	}	% {\mdseries }

%\begin{definition}\label{D: }
%\begin{notation}
%\begin{theorem}\label{T: }

%
%	thebibliography
%	There are fewer than 10 references in this article, so Latex will make room for single-digit numbering by providing the argument 9 to the bibliography environment; use 99 if the number of references is between 10 and 99.  
%
%\begin{thebibliography}{9}
%	\bibitem
	
%	\bibitem	

%\end{thebibliography}

\end{document} 

